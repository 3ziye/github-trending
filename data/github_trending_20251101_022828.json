[
  {
    "basic_info": {
      "name": "nanochat",
      "full_name": "karpathy/nanochat",
      "owner": "karpathy",
      "description": "The best ChatGPT that $100 can buy.",
      "url": "https://github.com/karpathy/nanochat",
      "clone_url": "https://github.com/karpathy/nanochat.git",
      "ssh_url": "git@github.com:karpathy/nanochat.git",
      "homepage": "",
      "created_at": "2025-10-13T13:46:35Z",
      "updated_at": "2025-11-01T02:25:46Z",
      "pushed_at": "2025-10-30T15:36:32Z"
    },
    "stats": {
      "stars": 34766,
      "forks": 3917,
      "watchers": 34766,
      "open_issues": 59,
      "size": 453
    },
    "tech_info": {
      "language": "Python",
      "languages": {
        "Python": 325510,
        "HTML": 20192,
        "Rust": 16627,
        "Shell": 14084
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# nanochat\n\n![nanochat logo](dev/nanochat.png)\n\n> The best ChatGPT that $100 can buy.\n\nThis repo is a full-stack implementation of an LLM like ChatGPT in a single, clean, minimal, hackable, dependency-lite codebase. nanochat is designed to run on a single 8XH100 node via scripts like [speedrun.sh](speedrun.sh), that run the entire pipeline start to end. This includes tokenization, pretraining, finetuning, evaluation, inference, and web serving over a simple UI so that you can talk to your own LLM just like ChatGPT. nanochat will become the capstone project of the course LLM101n being developed by Eureka Labs.\n\n## Talk to it\n\nTo get a sense of the endpoint of this repo, you can currently find [nanochat d32](https://github.com/karpathy/nanochat/discussions/8) hosted on [nanochat.karpathy.ai](https://nanochat.karpathy.ai/). \"d32\" means that this model has 32 layers in the Transformer neural network. This model has 1.9 billion parameters, it was trained on 38 billion tokens by simply running the single script [run1000.sh](run1000.sh), and the total cost of training was ~$800 (about 33 hours training time on 8XH100 GPU node). While today this is enough to outperform GPT-2 of 2019, it falls dramatically short of modern Large Language Models like GPT-5. When talking to these micro models, you'll see that they make a lot of mistakes, they are a little bit naive and silly and they hallucinate a ton, a bit like children. It's kind of amusing. But what makes nanochat unique is that it is fully yours - fully configurable, tweakable, hackable, and trained by you from start to end. To train and talk to your own, we turn to...\n\n## Quick start\n\nThe fastest way to feel the magic is to run the speedrun script [speedrun.sh](speedrun.sh), which trains and inferences the $100 tier of nanochat. On an 8XH100 node at $24/hr, this gives a total run time of about 4 hours. Boot up a new 8XH100 GPU box from your favorite provider (e.g. I use and like [Lambda](https://lambda.ai/service/gpu-cloud)), and kick off the training script:\n\n```bash\nbash speedrun.sh\n```\n\nAlternatively, since the script runs for 4 hours, I like to launch it like this inside a new screen session `speedrun` (and also log output to `speedrun.log`):\n\n```bash\nscreen -L -Logfile speedrun.log -S speedrun bash speedrun.sh\n```\n\nSee the [screen cheatsheet](https://gist.github.com/jctosta/af918e1618682638aa82) if you are less familiar. You can watch it go inside the screen session, or detach with `Ctrl-a d` and `tail speedrun.log` to view progress. Now wait 4 hours. Once it's done, you can talk to your LLM via the ChatGPT-like web UI. Make sure again that your local uv virtual environment is active (run `source .venv/bin/activate`), and serve it:\n\n```bash\npython -m scripts.chat_web\n```\n\nAnd then visit the URL shown. Make sure to access it correctly, e.g. on Lambda use the public IP of the node you're on, followed by the port, so for example [http://209.20.xxx.xxx:8000/](http://209.20.xxx.xxx:8000/), etc. Then talk to your LLM as you'd normally talk to ChatGPT! Get it to write stories or poems. Ask it to tell you who you are to see a hallucination. Ask it why the sky is blue. Or why it's green. The speedrun is a 4e19 FLOPs capability model so it's a bit like talking to a kindergartener :).\n\n---\n\n<img width=\"2672\" height=\"1520\" alt=\"image\" src=\"https://github.com/user-attachments/assets/ed39ddf8-2370-437a-bedc-0f39781e76b5\" />\n\n---\n\nYou can also `cat report.md` file which appeared in the project directory and contains the \"report card\" of the run, i.e. a bunch of evaluations and metrics. At the very end, you'll see a summary table, for example:\n\n---\n\n- Characters: 333,989\n- Lines: 8,304\n- Files: 44\n- Tokens (approx): 83,497\n- Dependencies (uv.lock lines): 2,004\n\n| Metric          | BASE     | MID      | SFT      | RL       |\n|-----------------|----------|----------|----------|----------|\n| CORE            | 0.2219   | -        | -        | -        |\n| ARC-Challenge   | -        | 0.2875   | 0.2807   | -        |\n| ARC-Easy        | -        | 0.3561   | 0.3876   | -        |\n| GSM8K           | -        | 0.0250   | 0.0455   | 0.0758   |\n| HumanEval       | -        | 0.0671   | 0.0854   | -        |\n| MMLU            | -        | 0.3111   | 0.3151   | -        |\n| ChatCORE        | -        | 0.0730   | 0.0884   | -        |\n\nTotal wall clock time: 3h51m\n\n---\n\n(Your table might be missing the RL number by default). For a lot more information around the speedrun script and what to look for and expect, please refer to the walkthrough that I posted in Discussions of the repo: [\"Introducing nanochat: The best ChatGPT that $100 can buy\"](https://github.com/karpathy/nanochat/discussions/1).\n\n## Bigger models\n\nUnsurprisingly, $100 is not enough to train a highly performant ChatGPT clone. In fact, LLMs are famous for their multi-million dollar capex. For our purposes, I think there are two more scales of interest. First is the ~$300 tier d26 model (i.e. depth=26) that trains in ~1",
      "default_branch": "master"
    },
    "fetched_at": "2025-11-01T02:28:29.761424"
  },
  {
    "basic_info": {
      "name": "DeepSeek-OCR",
      "full_name": "deepseek-ai/DeepSeek-OCR",
      "owner": "deepseek-ai",
      "description": "Contexts Optical Compression",
      "url": "https://github.com/deepseek-ai/DeepSeek-OCR",
      "clone_url": "https://github.com/deepseek-ai/DeepSeek-OCR.git",
      "ssh_url": "git@github.com:deepseek-ai/DeepSeek-OCR.git",
      "homepage": null,
      "created_at": "2025-10-17T06:14:27Z",
      "updated_at": "2025-11-01T02:21:10Z",
      "pushed_at": "2025-10-25T02:43:18Z"
    },
    "stats": {
      "stars": 18915,
      "forks": 1279,
      "watchers": 18915,
      "open_issues": 181,
      "size": 7948
    },
    "tech_info": {
      "language": "Python",
      "languages": {
        "Python": 113538
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "<!-- markdownlint-disable first-line-h1 -->\n<!-- markdownlint-disable html -->\n<!-- markdownlint-disable no-duplicate-header -->\n\n\n<div align=\"center\">\n  <img src=\"assets/logo.svg\" width=\"60%\" alt=\"DeepSeek AI\" />\n</div>\n\n\n<hr>\n<div align=\"center\">\n  <a href=\"https://www.deepseek.com/\" target=\"_blank\">\n    <img alt=\"Homepage\" src=\"assets/badge.svg\" />\n  </a>\n  <a href=\"https://huggingface.co/deepseek-ai/DeepSeek-OCR\" target=\"_blank\">\n    <img alt=\"Hugging Face\" src=\"https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-DeepSeek%20AI-ffc107?color=ffc107&logoColor=white\" />\n  </a>\n\n</div>\n\n<div align=\"center\">\n\n  <a href=\"https://discord.gg/Tc7c45Zzu5\" target=\"_blank\">\n    <img alt=\"Discord\" src=\"https://img.shields.io/badge/Discord-DeepSeek%20AI-7289da?logo=discord&logoColor=white&color=7289da\" />\n  </a>\n  <a href=\"https://twitter.com/deepseek_ai\" target=\"_blank\">\n    <img alt=\"Twitter Follow\" src=\"https://img.shields.io/badge/Twitter-deepseek_ai-white?logo=x&logoColor=white\" />\n  </a>\n\n</div>\n\n\n\n<p align=\"center\">\n  <a href=\"https://huggingface.co/deepseek-ai/DeepSeek-OCR\"><b>📥 Model Download</b></a> |\n  <a href=\"https://github.com/deepseek-ai/DeepSeek-OCR/blob/main/DeepSeek_OCR_paper.pdf\"><b>📄 Paper Link</b></a> |\n  <a href=\"https://arxiv.org/abs/2510.18234\"><b>📄 Arxiv Paper Link</b></a> |\n</p>\n\n<h2>\n<p align=\"center\">\n  <a href=\"\">DeepSeek-OCR: Contexts Optical Compression</a>\n</p>\n</h2>\n\n<p align=\"center\">\n<img src=\"assets/fig1.png\" style=\"width: 1000px\" align=center>\n</p>\n<p align=\"center\">\n<a href=\"\">Explore the boundaries of visual-text compression.</a>       \n</p>\n\n## Release\n- [2025/10/23]🚀🚀🚀 DeepSeek-OCR is now officially supported in upstream [vLLM](https://docs.vllm.ai/projects/recipes/en/latest/DeepSeek/DeepSeek-OCR.html#installing-vllm). Thanks to the [vLLM](https://github.com/vllm-project/vllm) team for their help.\n- [2025/10/20]🚀🚀🚀 We release DeepSeek-OCR, a model to investigate the role of vision encoders from an LLM-centric viewpoint.\n\n## Contents\n- [Install](#install)\n- [vLLM Inference](#vllm-inference)\n- [Transformers Inference](#transformers-inference)\n  \n\n\n\n\n## Install\n>Our environment is cuda11.8+torch2.6.0.\n1. Clone this repository and navigate to the DeepSeek-OCR folder\n```bash\ngit clone https://github.com/deepseek-ai/DeepSeek-OCR.git\n```\n2. Conda\n```Shell\nconda create -n deepseek-ocr python=3.12.9 -y\nconda activate deepseek-ocr\n```\n3. Packages\n\n- download the vllm-0.8.5 [whl](https://github.com/vllm-project/vllm/releases/tag/v0.8.5) \n```Shell\npip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu118\npip install vllm-0.8.5+cu118-cp38-abi3-manylinux1_x86_64.whl\npip install -r requirements.txt\npip install flash-attn==2.7.3 --no-build-isolation\n```\n**Note:** if you want vLLM and transformers codes to run in the same environment, you don't need to worry about this installation error like: vllm 0.8.5+cu118 requires transformers>=4.51.1\n\n## vLLM-Inference\n- VLLM:\n>**Note:** change the INPUT_PATH/OUTPUT_PATH and other settings in the DeepSeek-OCR-master/DeepSeek-OCR-vllm/config.py\n```Shell\ncd DeepSeek-OCR-master/DeepSeek-OCR-vllm\n```\n1. image: streaming output\n```Shell\npython run_dpsk_ocr_image.py\n```\n2. pdf: concurrency ~2500tokens/s(an A100-40G)\n```Shell\npython run_dpsk_ocr_pdf.py\n```\n3. batch eval for benchmarks\n```Shell\npython run_dpsk_ocr_eval_batch.py\n```\n\n**[2025/10/23] The version of upstream [vLLM](https://docs.vllm.ai/projects/recipes/en/latest/DeepSeek/DeepSeek-OCR.html#installing-vllm):**\n\n```shell\nuv venv\nsource .venv/bin/activate\n# Until v0.11.1 release, you need to install vLLM from nightly build\nuv pip install -U vllm --pre --extra-index-url https://wheels.vllm.ai/nightly\n```\n\n```python\nfrom vllm import LLM, SamplingParams\nfrom vllm.model_executor.models.deepseek_ocr import NGramPerReqLogitsProcessor\nfrom PIL import Image\n\n# Create model instance\nllm = LLM(\n    model=\"deepseek-ai/DeepSeek-OCR\",\n    enable_prefix_caching=False,\n    mm_processor_cache_gb=0,\n    logits_processors=[NGramPerReqLogitsProcessor]\n)\n\n# Prepare batched input with your image file\nimage_1 = Image.open(\"path/to/your/image_1.png\").convert(\"RGB\")\nimage_2 = Image.open(\"path/to/your/image_2.png\").convert(\"RGB\")\nprompt = \"<image>\\nFree OCR.\"\n\nmodel_input = [\n    {\n        \"prompt\": prompt,\n        \"multi_modal_data\": {\"image\": image_1}\n    },\n    {\n        \"prompt\": prompt,\n        \"multi_modal_data\": {\"image\": image_2}\n    }\n]\n\nsampling_param = SamplingParams(\n            temperature=0.0,\n            max_tokens=8192,\n            # ngram logit processor args\n            extra_args=dict(\n                ngram_size=30,\n                window_size=90,\n                whitelist_token_ids={128821, 128822},  # whitelist: <td>, </td>\n            ),\n            skip_special_tokens=False,\n        )\n# Generate output\nmodel_outputs = llm.generate(model_input, sampling_param)\n\n# Print output\nfor output in model_outputs:\n    print(output.outputs[0].text)\n```\n## ",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-01T02:28:30.859344"
  },
  {
    "basic_info": {
      "name": "AI-Trader",
      "full_name": "HKUDS/AI-Trader",
      "owner": "HKUDS",
      "description": "\"AI-Trader: Can AI Beat the Market?\" Live Trading: https://hkuds.github.io/AI-Trader/",
      "url": "https://github.com/HKUDS/AI-Trader",
      "clone_url": "https://github.com/HKUDS/AI-Trader.git",
      "ssh_url": "git@github.com:HKUDS/AI-Trader.git",
      "homepage": "",
      "created_at": "2025-10-23T12:45:00Z",
      "updated_at": "2025-11-01T02:22:50Z",
      "pushed_at": "2025-11-01T01:35:09Z"
    },
    "stats": {
      "stars": 8038,
      "forks": 1083,
      "watchers": 8038,
      "open_issues": 23,
      "size": 10435
    },
    "tech_info": {
      "language": "Python",
      "languages": {
        "Python": 153330,
        "Shell": 1149
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "<div align=\"center\">\n\n# 🚀 AI-Trader: Can AI Beat the Market?\n\n[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://python.org)\n[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)\n[![Feishu](https://img.shields.io/badge/💬Feishu-Group-blue?style=flat)](./Communication.md) \n[![WeChat](https://img.shields.io/badge/WeChat-Group-green?style=flat&logo=wechat)](./Communication.md)\n\n**Five AIs battle for NASDAQ 100 supremacy. Zero human input. Pure competition.**\n\n## 🏆 Current Championship Leaderboard 🏆 \n[*Click Here: AI Live Trading*](https://hkuds.github.io/AI-Trader/)\n\n<div align=\"center\">\n\n###  **Championship Period: (Last Update 2025/10/30)**\n\n| 🏆 Rank | 🤖 AI Model | 📈 Total Earnings | \n|---------|-------------|----------------|\n| **🥇 1st** | **DeepSeek** | 🚀 +13.89% |\n| 🥈 2nd | MiniMax-M2 | 📊 +10.72% |\n| 🥉 3rd | Claude-3.7 | 📊 +7.12% |\n| 4th | GPT-5 | 📊 +7.11% |\n| Baseline | QQQ | 📊 +3.78% |\n| 5th | Qwen3-max | 📊 +3.44% |\n| 6th | Gemini-2.5-flash | 📊 -0.54% |\n\n### 📊 **Live Performance Dashboard**\n![rank](assets/rank.png)\n\n*Daily Performance Tracking of AI Models in NASDAQ 100 Trading*\n\n</div>\n\n---\n\n## **How to use this dataset**\n\nIt's simple! \n\nYou just need to submit a PR that includes at least: `./agent/{your_strategy}.py` (you can inherit from Basemodel to create your strategy!), `./configs/{yourconfig}`, and instructions on how to run your strategy. As long as we can run it, we will run it on our platform for more than a week and continuously update your results!\n\n\n## 📝 Upcoming Updates (This Week)\n\nWe're excited to announce the following updates coming this week:\n\n- ⏰ **Hourly Trading Support** - Upgrade to hour-level precision trading \n- 🚀 **Service Deployment & Parallel Execution** - Deploy production service + parallel model execution\n- 🎨 **Enhanced Frontend Dashboard** - Add detailed trading log visualization (complete trading process display)\n\nStay tuned for these exciting improvements! 🎉\n\n---\n\n[🚀 Quick Start](#-quick-start) • [📈 Performance Analysis](#-performance-analysis) • [🛠️ Configuration Guide](#-configuration-guide) • [中文文档](README_CN.md)\n\n</div>\n\n---\n\n## 🌟 Project Introduction\n\n> **AI-Trader enables five distinct AI models, each employing unique investment strategies, to compete autonomously in the same market and determine which can generate the highest profits in NASDAQ 100 trading!**\n\n### 🎯 Core Features\n\n- 🤖 **Fully Autonomous Decision-Making**: AI agents perform 100% independent analysis, decision-making, and execution without human intervention\n- 🛠️ **Pure Tool-Driven Architecture**: Built on MCP toolchain, enabling AI to complete all trading operations through standardized tool calls\n- 🏆 **Multi-Model Competition Arena**: Deploy multiple AI models (GPT, Claude, Qwen, etc.) for competitive trading\n- 📊 **Real-Time Performance Analytics**: Comprehensive trading records, position monitoring, and profit/loss analysis\n- 🔍 **Intelligent Market Intelligence**: Integrated Jina search for real-time market news and financial reports\n- ⚡ **MCP Toolchain Integration**: Modular tool ecosystem based on Model Context Protocol\n- 🔌 **Extensible Strategy Framework**: Support for third-party strategies and custom AI agent integration\n- ⏰ **Historical Replay Capability**: Time-period replay functionality with automatic future information filtering\n\n---\n\n### 🎮 Trading Environment\nEach AI model starts with $10,000 to trade NASDAQ 100 stocks in a controlled environment with real market data and historical replay capabilities.\n\n- 💰 **Initial Capital**: $10,000 USD starting balance\n- 📈 **Trading Universe**: NASDAQ 100 component stocks (top 100 technology stocks)\n- ⏰ **Trading Schedule**: Weekday market hours with historical simulation support\n- 📊 **Data Integration**: Alpha Vantage API combined with Jina AI market intelligence\n- 🔄 **Time Management**: Historical period replay with automated future information filtering\n\n---\n\n### 🧠 Agentic Trading Capabilities\nAI agents operate with complete autonomy, conducting market research, making trading decisions, and continuously evolving their strategies without human intervention.\n\n- 📰 **Autonomous Market Research**: Intelligent retrieval and filtering of market news, analyst reports, and financial data\n- 💡 **Independent Decision Engine**: Multi-dimensional analysis driving fully autonomous buy/sell execution\n- 📝 **Comprehensive Trade Logging**: Automated documentation of trading rationale, execution details, and portfolio changes\n- 🔄 **Adaptive Strategy Evolution**: Self-optimizing algorithms that adjust based on market performance feedback\n\n---\n\n### 🏁 Competition Rules\nAll AI models compete under identical conditions with the same capital, data access, tools, and evaluation metrics to ensure fair comparison.\n\n- 💰 **Starting Capital**: $10,000 USD initial investment\n- 📊 **Data Access**: Uniform market data and information feeds\n- ⏰ **Operating Hours**: Synchronized trading time windows\n- 📈 **Performance Metrics**: Standardized",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-01T02:28:31.961005"
  },
  {
    "basic_info": {
      "name": "toon",
      "full_name": "johannschopplich/toon",
      "owner": "johannschopplich",
      "description": "🎒 Token-Oriented Object Notation (TOON) – JSON for LLM prompts at half the tokens. Official spec & reference implementation.",
      "url": "https://github.com/johannschopplich/toon",
      "clone_url": "https://github.com/johannschopplich/toon.git",
      "ssh_url": "git@github.com:johannschopplich/toon.git",
      "homepage": "",
      "created_at": "2025-10-22T18:17:32Z",
      "updated_at": "2025-11-01T02:25:12Z",
      "pushed_at": "2025-10-31T23:37:57Z"
    },
    "stats": {
      "stars": 6845,
      "forks": 183,
      "watchers": 6845,
      "open_issues": 3,
      "size": 647
    },
    "tech_info": {
      "language": "TypeScript",
      "languages": {
        "TypeScript": 177852,
        "JavaScript": 233
      },
      "license": "MIT License",
      "topics": [
        "data-format",
        "llm",
        "serialization",
        "tokenization"
      ]
    },
    "content": {
      "readme": "![TOON logo with step‑by‑step guide](./.github/og.png)\n\n# Token-Oriented Object Notation (TOON)\n\n[![CI](https://github.com/johannschopplich/toon/actions/workflows/ci.yml/badge.svg)](https://github.com/johannschopplich/toon/actions)\n[![npm version](https://img.shields.io/npm/v/@byjohann/toon.svg)](https://www.npmjs.com/package/@byjohann/toon)\n[![SPEC v1.3](https://img.shields.io/badge/spec-v1.3-lightgrey)](./SPEC.md)\n[![npm downloads (total)](https://img.shields.io/npm/dt/@byjohann/toon.svg)](https://www.npmjs.com/package/@byjohann/toon)\n[![License: MIT](https://img.shields.io/badge/license-MIT-blue.svg)](./LICENSE)\n\n**Token-Oriented Object Notation** is a compact, human-readable format designed for passing structured data to Large Language Models with significantly reduced token usage. It's intended for LLM input, not output.\n\nTOON's sweet spot is **uniform arrays of objects** – multiple fields per row, same structure across items. It borrows YAML's indentation-based structure for nested objects and CSV's tabular format for uniform data rows, then optimizes both for token efficiency in LLM contexts. For deeply nested or non-uniform data, JSON may be more efficient.\n\n> [!TIP]\n> Think of TOON as a translation layer: use JSON programmatically, convert to TOON for LLM input.\n\n## Table of Contents\n\n- [Why TOON?](#why-toon)\n- [Key Features](#key-features)\n- [Benchmarks](#benchmarks)\n- [📋 Full Specification](./SPEC.md)\n- [Installation & Quick Start](#installation--quick-start)\n- [CLI](#cli)\n- [Format Overview](#format-overview)\n- [API](#api)\n- [Using TOON in LLM Prompts](#using-toon-in-llm-prompts)\n- [Notes and Limitations](#notes-and-limitations)\n- [Syntax Cheatsheet](#syntax-cheatsheet)\n- [Other Implementations](#other-implementations)\n\n## Why TOON?\n\nAI is becoming cheaper and more accessible, but larger context windows allow for larger data inputs as well. **LLM tokens still cost money** – and standard JSON is verbose and token-expensive:\n\n```json\n{\n  \"users\": [\n    { \"id\": 1, \"name\": \"Alice\", \"role\": \"admin\" },\n    { \"id\": 2, \"name\": \"Bob\", \"role\": \"user\" }\n  ]\n}\n```\n\nTOON conveys the same information with **fewer tokens**:\n\n```\nusers[2]{id,name,role}:\n  1,Alice,admin\n  2,Bob,user\n```\n\n<details>\n<summary>Another reason</summary>\n\n[![xkcd: Standards](https://imgs.xkcd.com/comics/standards_2x.png)](https://xkcd.com/927/)\n\n</details>\n\n## Key Features\n\n- 💸 **Token-efficient:** typically 30–60% fewer tokens than JSON\n- 🤿 **LLM-friendly guardrails:** explicit lengths and fields enable validation\n- 🍱 **Minimal syntax:** removes redundant punctuation (braces, brackets, most quotes)\n- 📐 **Indentation-based structure:** like YAML, uses whitespace instead of braces\n- 🧺 **Tabular arrays:** declare keys once, stream data as rows\n\n## Benchmarks\n\n> [!TIP]\n> Try the interactive [Format Tokenization Playground](https://www.curiouslychase.com/playground/format-tokenization-exploration) to compare token usage across CSV, JSON, YAML, and TOON with your own data.\n\nThe benchmarks test datasets that favor TOON's strengths (uniform tabular data). Real-world performance depends heavily on your data structure.\n\n<!-- automd:file src=\"./benchmarks/results/token-efficiency.md\" -->\n\n### Token Efficiency\n\n```\n⭐ GitHub Repositories       ██████████████░░░░░░░░░░░    8,745 tokens\n                             vs JSON (-42.3%)           15,145\n                             vs JSON compact (-23.7%)   11,455\n                             vs YAML (-33.4%)           13,129\n                             vs XML (-48.8%)            17,095\n\n📈 Daily Analytics           ██████████░░░░░░░░░░░░░░░    4,507 tokens\n                             vs JSON (-58.9%)           10,977\n                             vs JSON compact (-35.7%)    7,013\n                             vs YAML (-48.8%)            8,810\n                             vs XML (-65.7%)            13,128\n\n🛒 E-Commerce Order          ████████████████░░░░░░░░░      166 tokens\n                             vs JSON (-35.4%)              257\n                             vs JSON compact (-2.9%)       171\n                             vs YAML (-15.7%)              197\n                             vs XML (-38.7%)               271\n\n─────────────────────────────────────────────────────────────────────\nTotal                        ██████████████░░░░░░░░░░░   13,418 tokens\n                             vs JSON (-49.1%)           26,379\n                             vs JSON compact (-28.0%)   18,639\n                             vs YAML (-39.4%)           22,136\n                             vs XML (-56.0%)            30,494\n```\n\n<details>\n<summary><strong>Show detailed examples</strong></summary>\n\n#### ⭐ GitHub Repositories\n\n**Configuration:** Top 100 GitHub repositories with stars, forks, and metadata\n\n**Savings:** 6,400 tokens (42.3% reduction vs JSON)\n\n**JSON** (15,145 tokens):\n\n```json\n{\n  \"repositories\": [\n    {\n      \"id\": 28457823,\n      \"name\": \"freeCodeCamp\",\n      \"repo\": \"freeCodeCamp/freeCodeCamp\",\n      \"de",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-01T02:28:33.052953"
  },
  {
    "basic_info": {
      "name": "superpowers",
      "full_name": "obra/superpowers",
      "owner": "obra",
      "description": "Claude Code superpowers: core skills library",
      "url": "https://github.com/obra/superpowers",
      "clone_url": "https://github.com/obra/superpowers.git",
      "ssh_url": "git@github.com:obra/superpowers.git",
      "homepage": null,
      "created_at": "2025-10-09T19:45:18Z",
      "updated_at": "2025-11-01T02:24:05Z",
      "pushed_at": "2025-10-31T18:17:01Z"
    },
    "stats": {
      "stars": 5490,
      "forks": 384,
      "watchers": 5490,
      "open_issues": 19,
      "size": 244
    },
    "tech_info": {
      "language": "JavaScript",
      "languages": {
        "JavaScript": 13429,
        "Shell": 6289,
        "TypeScript": 5054
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# Superpowers\n\nA comprehensive skills library of proven techniques, patterns, and workflows for AI coding assistants.\n\n## What You Get\n\n- **Testing Skills** - TDD, async testing, anti-patterns\n- **Debugging Skills** - Systematic debugging, root cause tracing, verification\n- **Collaboration Skills** - Brainstorming, planning, code review, parallel agents\n- **Development Skills** - Git worktrees, finishing branches, subagent workflows\n- **Meta Skills** - Creating, testing, and sharing skills\n\nPlus:\n- **Slash Commands** - `/superpowers:brainstorm`, `/superpowers:write-plan`, `/superpowers:execute-plan`\n- **Automatic Integration** - Skills activate automatically when relevant\n- **Consistent Workflows** - Systematic approaches to common engineering tasks\n\n## Learn More\n\nRead the introduction: [Superpowers for Claude Code](https://blog.fsck.com/2025/10/09/superpowers/)\n\n## Installation\n\n### Claude Code (via Plugin Marketplace)\n\n```bash\n# In Claude Code\n/plugin marketplace add obra/superpowers-marketplace\n/plugin install superpowers@superpowers-marketplace\n```\n\n### Verify Installation\n\n```bash\n# Check that commands appear\n/help\n\n# Should see:\n# /superpowers:brainstorm - Interactive design refinement\n# /superpowers:write-plan - Create implementation plan\n# /superpowers:execute-plan - Execute plan in batches\n```\n\n### Codex (Experimental)\n\n**Note:** Codex support is experimental and may require refinement based on user feedback.\n\nTell Codex to fetch https://raw.githubusercontent.com/obra/superpowers/refs/heads/main/.codex/INSTALL.md and follow the instructions.\n\n## Quick Start\n\n### Using Slash Commands\n\n**Brainstorm a design:**\n```\n/superpowers:brainstorm\n```\n\n**Create an implementation plan:**\n```\n/superpowers:write-plan\n```\n\n**Execute the plan:**\n```\n/superpowers:execute-plan\n```\n\n### Automatic Skill Activation\n\nSkills activate automatically when relevant. For example:\n- `test-driven-development` activates when implementing features\n- `systematic-debugging` activates when debugging issues\n- `verification-before-completion` activates before claiming work is done\n\n## What's Inside\n\n### Skills Library\n\n**Testing** (`skills/testing/`)\n- **test-driven-development** - RED-GREEN-REFACTOR cycle\n- **condition-based-waiting** - Async test patterns\n- **testing-anti-patterns** - Common pitfalls to avoid\n\n**Debugging** (`skills/debugging/`)\n- **systematic-debugging** - 4-phase root cause process\n- **root-cause-tracing** - Find the real problem\n- **verification-before-completion** - Ensure it's actually fixed\n- **defense-in-depth** - Multiple validation layers\n\n**Collaboration** (`skills/collaboration/`)\n- **brainstorming** - Socratic design refinement\n- **writing-plans** - Detailed implementation plans\n- **executing-plans** - Batch execution with checkpoints\n- **dispatching-parallel-agents** - Concurrent subagent workflows\n- **requesting-code-review** - Pre-review checklist\n- **receiving-code-review** - Responding to feedback\n- **using-git-worktrees** - Parallel development branches\n- **finishing-a-development-branch** - Merge/PR decision workflow\n- **subagent-driven-development** - Fast iteration with quality gates\n\n**Meta** (`skills/meta/`)\n- **writing-skills** - Create new skills following best practices\n- **sharing-skills** - Contribute skills back via branch and PR\n- **testing-skills-with-subagents** - Validate skill quality\n- **using-superpowers** - Introduction to the skills system\n\n### Commands\n\nAll commands are thin wrappers that activate the corresponding skill:\n\n- **brainstorm.md** - Activates the `brainstorming` skill\n- **write-plan.md** - Activates the `writing-plans` skill\n- **execute-plan.md** - Activates the `executing-plans` skill\n\n## How It Works\n\n1. **SessionStart Hook** - Loads the `using-superpowers` skill at session start\n2. **Skills System** - Uses Claude Code's first-party skills system\n3. **Automatic Discovery** - Claude finds and uses relevant skills for your task\n4. **Mandatory Workflows** - When a skill exists for your task, using it becomes required\n\n## Philosophy\n\n- **Test-Driven Development** - Write tests first, always\n- **Systematic over ad-hoc** - Process over guessing\n- **Complexity reduction** - Simplicity as primary goal\n- **Evidence over claims** - Verify before declaring success\n- **Domain over implementation** - Work at problem level, not solution level\n\n## Contributing\n\nSkills live directly in this repository. To contribute:\n\n1. Fork the repository\n2. Create a branch for your skill\n3. Follow the `writing-skills` skill for creating new skills\n4. Use the `testing-skills-with-subagents` skill to validate quality\n5. Submit a PR\n\nSee `skills/meta/writing-skills/SKILL.md` for the complete guide.\n\n## Updating\n\nSkills update automatically when you update the plugin:\n\n```bash\n/plugin update superpowers\n```\n\n## License\n\nMIT License - see LICENSE file for details\n\n## Support\n\n- **Issues**: https://github.com/obra/superpowers/issues\n- **Marketplace**: https://github.com/obra/superpowers-marketplace\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-01T02:28:34.183153"
  },
  {
    "basic_info": {
      "name": "TinyRecursiveModels",
      "full_name": "SamsungSAILMontreal/TinyRecursiveModels",
      "owner": "SamsungSAILMontreal",
      "description": null,
      "url": "https://github.com/SamsungSAILMontreal/TinyRecursiveModels",
      "clone_url": "https://github.com/SamsungSAILMontreal/TinyRecursiveModels.git",
      "ssh_url": "git@github.com:SamsungSAILMontreal/TinyRecursiveModels.git",
      "homepage": null,
      "created_at": "2025-10-07T13:24:28Z",
      "updated_at": "2025-11-01T02:27:09Z",
      "pushed_at": "2025-10-08T19:46:47Z"
    },
    "stats": {
      "stars": 5335,
      "forks": 741,
      "watchers": 5335,
      "open_issues": 29,
      "size": 1266
    },
    "tech_info": {
      "language": "Python",
      "languages": {
        "Python": 147529
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# Less is More: Recursive Reasoning with Tiny Networks\n\nThis is the codebase for the paper: \"Less is More: Recursive Reasoning with Tiny Networks\". TRM is a recursive reasoning approach that achieves amazing scores of 45% on ARC-AGI-1 and 8% on ARC-AGI-2 using a tiny 7M parameters neural network.\n\n[Paper](https://arxiv.org/abs/2510.04871)\n\n### Motivation\n\nTiny Recursion Model (TRM) is a recursive reasoning model that achieves amazing scores of 45% on ARC-AGI-1 and 8% on ARC-AGI-2 with a tiny 7M parameters neural network. The idea that one must rely on massive foundational models trained for millions of dollars by some big corporation in order to achieve success on hard tasks is a trap. Currently, there is too much focus on exploiting LLMs rather than devising and expanding new lines of direction. With recursive reasoning, it turns out that “less is more”: you don’t always need to crank up model size in order for a model to reason and solve hard problems. A tiny model pretrained from scratch, recursing on itself and updating its answers over time, can achieve a lot without breaking the bank.\n\nThis work came to be after I learned about the recent innovative Hierarchical Reasoning Model (HRM). I was amazed that an approach using small models could do so well on hard tasks like the ARC-AGI competition (reaching 40% accuracy when normally only Large Language Models could compete). But I kept thinking that it is too complicated, relying too much on biological arguments about the human brain, and that this recursive reasoning process could be greatly simplified and improved. Tiny Recursion Model (TRM) simplifies recursive reasoning to its core essence, which ultimately has nothing to do with the human brain, does not require any mathematical (fixed-point) theorem, nor any hierarchy.\n\n### How TRM works\n\n<p align=\"center\">\n  <img src=\"https://AlexiaJM.github.io/assets/images/TRM_fig.png\" alt=\"TRM\"  style=\"width: 30%;\">\n</p>\n\nTiny Recursion Model (TRM) recursively improves its predicted answer y with a tiny network. It starts with the embedded input question x and initial embedded answer y and latent z. For up to K improvements steps, it tries to improve its answer y. It does so by i) recursively updating n times its latent z given the question x, current answer y, and current latent z (recursive reasoning), and then ii) updating its answer y given the current answer y and current latent z. This recursive process allows the model to progressively improve its answer (potentially addressing any errors from its previous answer) in an extremely parameter-efficient manner while minimizing overfitting.\n\n### Requirements\n\n- Python 3.10 (or similar)\n- Cuda 12.6.0 (or similar)\n\n```bash\npip install --upgrade pip wheel setuptools\npip install --pre --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu126 # install torch based on your cuda version\npip install -r requirements.txt # install requirements\npip install --no-cache-dir --no-build-isolation adam-atan2 \nwandb login YOUR-LOGIN # login if you want the logger to sync results to your Weights & Biases (https://wandb.ai/)\n```\n\n### Dataset Preparation\n\n```bash\n# ARC-AGI-1\npython -m dataset.build_arc_dataset \\\n  --input-file-prefix kaggle/combined/arc-agi \\\n  --output-dir data/arc1concept-aug-1000 \\\n  --subsets training evaluation concept \\\n  --test-set-name evaluation\n\n# ARC-AGI-2\npython -m dataset.build_arc_dataset \\\n  --input-file-prefix kaggle/combined/arc-agi \\\n  --output-dir data/arc2concept-aug-1000 \\\n  --subsets training2 evaluation2 concept \\\n  --test-set-name evaluation2\n\n## Note: You cannot train on both ARC-AGI-1 and ARC-AGI-2 and evaluate them both because ARC-AGI-2 training data contains some ARC-AGI-1 eval data\n\n# Sudoku-Extreme\npython dataset/build_sudoku_dataset.py --output-dir data/sudoku-extreme-1k-aug-1000  --subsample-size 1000 --num-aug 1000  # 1000 examples, 1000 augments\n\n# Maze-Hard\npython dataset/build_maze_dataset.py # 1000 examples, 8 augments\n```\n\n## Experiments\n\n### ARC-AGI-1 (assuming 4 H-100 GPUs):\n\n```bash\nrun_name=\"pretrain_att_arc1concept_4\"\ntorchrun --nproc-per-node 4 --rdzv_backend=c10d --rdzv_endpoint=localhost:0 --nnodes=1 pretrain.py \\\narch=trm \\\ndata_paths=\"[data/arc1concept-aug-1000]\" \\\narch.L_layers=2 \\\narch.H_cycles=3 arch.L_cycles=4 \\\n+run_name=${run_name} ema=True\n\n```\n\n*Runtime:* ~3 days\n\n### ARC-AGI-2 (assuming 4 H-100 GPUs):\n\n```bash\nrun_name=\"pretrain_att_arc2concept_4\"\ntorchrun --nproc-per-node 4 --rdzv_backend=c10d --rdzv_endpoint=localhost:0 --nnodes=1 pretrain.py \\\narch=trm \\\ndata_paths=\"[data/arc2concept-aug-1000]\" \\\narch.L_layers=2 \\\narch.H_cycles=3 arch.L_cycles=4 \\\n+run_name=${run_name} ema=True\n\n```\n\n*Runtime:* ~3 days\n\n### Sudoku-Extreme (assuming 1 L40S GPU):\n\n```bash\nrun_name=\"pretrain_mlp_t_sudoku\"\npython pretrain.py \\\narch=trm \\\ndata_paths=\"[data/sudoku-extreme-1k-aug-1000]\" \\\nevaluators=\"[]\" \\\nepochs=50000 eval_interval=5000 \\\nlr=1e-4 puzzle_emb_lr=1e-4 weight_decay=1.0 puzzle",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-01T02:28:35.320229"
  },
  {
    "basic_info": {
      "name": "neutts-air",
      "full_name": "neuphonic/neutts-air",
      "owner": "neuphonic",
      "description": "On-device TTS model by Neuphonic",
      "url": "https://github.com/neuphonic/neutts-air",
      "clone_url": "https://github.com/neuphonic/neutts-air.git",
      "ssh_url": "git@github.com:neuphonic/neutts-air.git",
      "homepage": null,
      "created_at": "2025-10-02T12:48:55Z",
      "updated_at": "2025-11-01T01:03:01Z",
      "pushed_at": "2025-10-29T15:07:08Z"
    },
    "stats": {
      "stars": 3753,
      "forks": 365,
      "watchers": 3753,
      "open_issues": 22,
      "size": 1905
    },
    "tech_info": {
      "language": "Python",
      "languages": {
        "Python": 14928
      },
      "license": "Apache License 2.0",
      "topics": []
    },
    "content": {
      "readme": "# NeuTTS Air ☁️\n\nHuggingFace 🤗: [Model](https://huggingface.co/neuphonic/neutts-air), [Q8 GGUF](https://huggingface.co/neuphonic/neutts-air-q8-gguf), [Q4 GGUF](https://huggingface.co/neuphonic/neutts-air-q4-gguf) [Spaces](https://huggingface.co/spaces/neuphonic/neutts-air)\n\n[Demo Video](https://github.com/user-attachments/assets/020547bc-9e3e-440f-b016-ae61ca645184)\n\n_Created by [Neuphonic](http://neuphonic.com/) - building faster, smaller, on-device voice AI_\n\nState-of-the-art Voice AI has been locked behind web APIs for too long. NeuTTS Air is the world’s first super-realistic, on-device, TTS speech language model with instant voice cloning. Built off a 0.5B LLM backbone, NeuTTS Air brings natural-sounding speech, real-time performance, built-in security and speaker cloning to your local device - unlocking a new category of embedded voice agents, assistants, toys, and compliance-safe apps.\n\n## Key Features\n\n- 🗣Best-in-class realism for its size - produces natural, ultra-realistic voices that sound human\n- 📱Optimised for on-device deployment - provided in GGML format, ready to run on phones, laptops, or even Raspberry Pis\n- 👫Instant voice cloning - create your own speaker with as little as 3 seconds of audio\n- 🚄Simple LM + codec architecture built off a 0.5B backbone - the sweet spot between speed, size, and quality for real-world applications\n\n> [!CAUTION]\n> Websites like neutts.com are popping up and they're not affliated with Neuphonic, our github or this repo.\n>\n> We are on neuphonic.com only. Please be careful out there! 🙏\n\n## Model Details\n\nNeuTTS Air is built off Qwen 0.5B - a lightweight yet capable language model optimised for text understanding and generation - as well as a powerful combination of technologies designed for efficiency and quality:\n\n- **Supported Languages**: English\n- **Audio Codec**: [NeuCodec](https://huggingface.co/neuphonic/neucodec) - our 50hz neural audio codec that achieves exceptional audio quality at low bitrates using a single codebook\n- **Context Window**: 2048 tokens, enough for processing ~30 seconds of audio (including prompt duration)\n- **Format**: Available in GGML format for efficient on-device inference\n- **Responsibility**: Watermarked outputs\n- **Inference Speed**: Real-time generation on mid-range devices\n- **Power Consumption**: Optimised for mobile and embedded devices\n\n## Get Started\n\n> [!NOTE]\n> We have added a [streaming example](examples/basic_streaming_example.py) using the `llama-cpp-python` library as well as a [finetuning script](examples/finetune.py). For finetuning, please refer to the [finetune guide](TRAINING.md) for more details.\n\n1. **Clone Git Repo**\n\n   ```bash\n   git clone https://github.com/neuphonic/neutts-air.git\n   cd neutts-air\n   ```\n\n2. **Install `espeak` (required dependency)**\n\n   Please refer to the following link for instructions on how to install `espeak`:\n\n   https://github.com/espeak-ng/espeak-ng/blob/master/docs/guide.md\n\n   ```bash\n   # Mac OS\n   brew install espeak\n\n   # Ubuntu/Debian\n   sudo apt install espeak\n\n   # Windows install\n   # via chocolatey (https://community.chocolatey.org/packages?page=1&prerelease=False&moderatorQueue=False&tags=espeak)\n   choco install espeak-ng\n   # via wingit\n   winget install -e --id eSpeak-NG.eSpeak-NG\n   # via msi (need to add to path or folow the \"Windows users who installed via msi\" below)\n   # find the msi at https://github.com/espeak-ng/espeak-ng/releases\n   ```\n\n   Mac users may need to put the following lines at the top of the neutts.py file.\n\n   ```python\n   from phonemizer.backend.espeak.wrapper import EspeakWrapper\n   _ESPEAK_LIBRARY = '/opt/homebrew/Cellar/espeak/1.48.04_1/lib/libespeak.1.1.48.dylib'  #use the Path to the library.\n   EspeakWrapper.set_library(_ESPEAK_LIBRARY)\n   ```\n\n   Windows users who installed via msi / do not have their install on path need to run the following (see https://github.com/bootphon/phonemizer/issues/163)\n   ```pwsh\n   $env:PHONEMIZER_ESPEAK_LIBRARY = \"c:\\Program Files\\eSpeak NG\\libespeak-ng.dll\"\n   $env:PHONEMIZER_ESPEAK_PATH = \"c:\\Program Files\\eSpeak NG\"\n   setx PHONEMIZER_ESPEAK_LIBRARY \"c:\\Program Files\\eSpeak NG\\libespeak-ng.dll\"\n   setx PHONEMIZER_ESPEAK_PATH \"c:\\Program Files\\eSpeak NG\"\n   ```\n\n3. **Install Python dependencies**\n\n   The requirements file includes the dependencies needed to run the model with PyTorch.\n   When using an ONNX decoder or a GGML model, some dependencies (such as PyTorch) are no longer required.\n\n   The inference is compatible and tested on `python>=3.11`.\n\n   ```bash\n   pip install -r requirements.txt\n   ```\n\n4. **(Optional) Install Llama-cpp-python to use the `GGUF` models.**\n\n   ```bash\n   pip install llama-cpp-python\n   ```\n\n   To run llama-cpp with GPU suport (CUDA, MPS) support please refer to:\n   https://pypi.org/project/llama-cpp-python/\n\n5. **(Optional) Install onnxruntime to use the `.onnx` decoder.**\n   If you want to run the onnxdecoder\n   ```bash\n   pip install onnxruntime\n   ```\n\n## Running the Mo",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-01T02:28:36.441306"
  },
  {
    "basic_info": {
      "name": "nofx",
      "full_name": "tinkle-community/nofx",
      "owner": "tinkle-community",
      "description": "Multi-exchange AI trading platform (Binance/Hyperliquid/Aster) with multi-AI competition(deepseek/qwen/claude), self-evolution, and real-time dashboard",
      "url": "https://github.com/tinkle-community/nofx",
      "clone_url": "https://github.com/tinkle-community/nofx.git",
      "ssh_url": "git@github.com:tinkle-community/nofx.git",
      "homepage": "https://x.com/nofx_ai",
      "created_at": "2025-10-28T07:17:53Z",
      "updated_at": "2025-11-01T02:28:28Z",
      "pushed_at": "2025-10-31T18:42:42Z"
    },
    "stats": {
      "stars": 3250,
      "forks": 807,
      "watchers": 3250,
      "open_issues": 67,
      "size": 36528
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 203035,
        "TypeScript": 121127,
        "Shell": 14926,
        "CSS": 9474,
        "JavaScript": 1344,
        "HTML": 384
      },
      "license": null,
      "topics": [
        "ai-trading",
        "aster",
        "cryptocurrency",
        "deepseek",
        "futures-trading",
        "hyperliquid",
        "llm",
        "llm-trading",
        "nof1ai",
        "qwen",
        "trading-bot"
      ]
    },
    "content": {
      "readme": "# 🤖 NOFX - AI-Driven Crypto Futures Auto Trading Competition System\n\n[![Go Version](https://img.shields.io/badge/Go-1.21+-00ADD8?style=flat&logo=go)](https://golang.org/)\n[![React](https://img.shields.io/badge/React-18+-61DAFB?style=flat&logo=react)](https://reactjs.org/)\n[![TypeScript](https://img.shields.io/badge/TypeScript-5.0+-3178C6?style=flat&logo=typescript)](https://www.typescriptlang.org/)\n[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)\n\n**Languages:** [English](README.md) | [中文](README.zh-CN.md) | [Українська](README.uk.md) | [Русский](README.ru.md)\n\n---\n\nAn automated crypto futures trading system powered by **DeepSeek/Qwen AI**, supporting **Binance, Hyperliquid, and Aster DEX exchanges**, **multi-AI model live trading competition**, featuring comprehensive market analysis, AI decision-making, **self-learning mechanism**, and professional Web monitoring interface.\n\n> ⚠️ **Risk Warning**: This system is experimental. AI auto-trading carries significant risks. Strongly recommended for learning/research purposes or testing with small amounts only!\n\n## 👥 Developer Community\n\nJoin our Telegram developer community to discuss, share ideas, and get support:\n\n**💬 [NOFX Developer Community](https://t.me/nofx_dev_community)**\n\n---\n\n## 🆕 What's New (Latest Update)\n\n### 🚀 Multi-Exchange Support!\n\nNOFX now supports **three major exchanges**: Binance, Hyperliquid, and Aster DEX!\n\n#### **Hyperliquid Exchange**\n\nA high-performance decentralized perpetual futures exchange!\n\n**Key Features:**\n- ✅ Full trading support (long/short, leverage, stop-loss/take-profit)\n- ✅ Automatic precision handling (order size & price)\n- ✅ Unified trader interface (seamless exchange switching)\n- ✅ Support for both mainnet and testnet\n- ✅ No API keys needed - just your Ethereum private key\n\n**Why Hyperliquid?**\n- 🔥 Lower fees than centralized exchanges\n- 🔒 Non-custodial - you control your funds\n- ⚡ Fast execution with on-chain settlement\n- 🌍 No KYC required\n\n**Quick Start:**\n1. Get your MetaMask private key (remove `0x` prefix)\n2. Set `\"exchange\": \"hyperliquid\"` in config.json\n3. Add `\"hyperliquid_private_key\": \"your_key\"`\n4. Start trading!\n\nSee [Configuration Guide](#-alternative-using-hyperliquid-exchange) for details.\n\n#### **Aster DEX Exchange** (NEW! v2.0.2)\n\nA Binance-compatible decentralized perpetual futures exchange!\n\n**Key Features:**\n- ✅ Binance-style API (easy migration from Binance)\n- ✅ Web3 wallet authentication (secure and decentralized)\n- ✅ Full trading support with automatic precision handling\n- ✅ Lower trading fees than CEX\n- ✅ EVM-compatible (Ethereum, BSC, Polygon, etc.)\n\n**Why Aster?**\n- 🎯 **Binance-compatible API** - minimal code changes required\n- 🔐 **API Wallet System** - separate trading wallet for security\n- 💰 **Competitive fees** - lower than most centralized exchanges\n- 🌐 **Multi-chain support** - trade on your preferred EVM chain\n\n**Quick Start:**\n1. Visit [Aster API Wallet](https://www.asterdex.com/en/api-wallet)\n2. Connect your main wallet and create an API wallet\n3. Copy the API Signer address and Private Key\n4. Set `\"exchange\": \"aster\"` in config.json\n5. Add `\"aster_user\"`, `\"aster_signer\"`, and `\"aster_private_key\"`\n\n---\n\n## 📸 Screenshots\n\n### 🏆 Competition Mode - Real-time AI Battle\n![Competition Page](screenshots/competition-page.png)\n*Multi-AI leaderboard with real-time performance comparison charts showing Qwen vs DeepSeek live trading battle*\n\n### 📊 Trader Details - Complete Trading Dashboard\n![Details Page](screenshots/details-page.png)\n*Professional trading interface with equity curves, live positions, and AI decision logs with expandable input prompts & chain-of-thought reasoning*\n\n---\n\n## ✨ Core Features\n\n### 🏆 Multi-AI Competition Mode\n- **Qwen vs DeepSeek** live trading battle\n- Independent account management and decision logs\n- Real-time performance comparison charts\n- ROI PK and win rate statistics\n\n### 🧠 AI Self-Learning Mechanism (NEW!)\n- **Historical Feedback**: Analyzes last 20 cycles of trading performance before each decision\n- **Smart Optimization**:\n  - Identifies best/worst performing coins\n  - Calculates win rate, profit/loss ratio, average profit\n  - Avoids repeating mistakes (consecutive losing coins)\n  - Reinforces successful strategies (high win rate patterns)\n- **Dynamic Adjustment**: AI autonomously adjusts trading style based on historical performance\n\n### 📊 Intelligent Market Analysis\n- **3-minute K-line**: Real-time price, EMA20, MACD, RSI(7)\n- **4-hour K-line**: Long-term trend, EMA20/50, ATR, RSI(14)\n- **Open Interest Analysis**: Market sentiment, capital flow judgment\n- **OI Top Tracking**: Top 20 coins with fastest growing open interest\n- **AI500 Coin Pool**: Automatic high-score coin screening\n- **Liquidity Filter**: Auto-filters low liquidity coins (<15M USD position value)\n\n### 🎯 Professional Risk Control\n- **Per-Coin Position Limit**:\n  - Altcoins ≤ 1.5x account equity\n  - BTC/ETH ≤ 10x account equity\n- **Configurable Leverage** (v2.0.3+)",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-01T02:28:37.559915"
  },
  {
    "basic_info": {
      "name": "Skill_Seekers",
      "full_name": "yusufkaraaslan/Skill_Seekers",
      "owner": "yusufkaraaslan",
      "description": "Convert documentation websites, GitHub repositories, and PDFs into Claude AI skills with automatic conflict detection",
      "url": "https://github.com/yusufkaraaslan/Skill_Seekers",
      "clone_url": "https://github.com/yusufkaraaslan/Skill_Seekers.git",
      "ssh_url": "git@github.com:yusufkaraaslan/Skill_Seekers.git",
      "homepage": "",
      "created_at": "2025-10-17T14:43:48Z",
      "updated_at": "2025-11-01T02:14:19Z",
      "pushed_at": "2025-10-29T19:17:51Z"
    },
    "stats": {
      "stars": 3031,
      "forks": 309,
      "watchers": 3031,
      "open_issues": 118,
      "size": 694
    },
    "tech_info": {
      "language": "Python",
      "languages": {
        "Python": 644789,
        "Shell": 7544
      },
      "license": "MIT License",
      "topics": [
        "ai-tools",
        "ast-parser",
        "automation",
        "claude-ai",
        "claude-skills",
        "code-analysis",
        "conflict-detection",
        "documentation",
        "documentation-generator",
        "github",
        "github-scraper",
        "mcp",
        "mcp-server",
        "multi-source",
        "ocr",
        "pdf",
        "python",
        "web-scraping"
      ]
    },
    "content": {
      "readme": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/yusufkaraaslan-skill-seekers-badge.png)](https://mseep.ai/app/yusufkaraaslan-skill-seekers)\n\n# Skill Seeker\n\n[![Version](https://img.shields.io/badge/version-2.0.0-blue.svg)](https://github.com/yusufkaraaslan/Skill_Seekers/releases/tag/v2.0.0)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)\n[![MCP Integration](https://img.shields.io/badge/MCP-Integrated-blue.svg)](https://modelcontextprotocol.io)\n[![Tested](https://img.shields.io/badge/Tests-299%20Passing-brightgreen.svg)](tests/)\n[![Project Board](https://img.shields.io/badge/Project-Board-purple.svg)](https://github.com/users/yusufkaraaslan/projects/2)\n\n**Automatically convert documentation websites, GitHub repositories, and PDFs into Claude AI skills in minutes.**\n\n> 📋 **[View Development Roadmap & Tasks](https://github.com/users/yusufkaraaslan/projects/2)** - 134 tasks across 10 categories, pick any to contribute!\n\n## What is Skill Seeker?\n\nSkill Seeker is an automated tool that transforms documentation websites, GitHub repositories, and PDF files into production-ready [Claude AI skills](https://www.anthropic.com/news/skills). Instead of manually reading and summarizing documentation, Skill Seeker:\n\n1. **Scrapes** multiple sources (docs, GitHub repos, PDFs) automatically\n2. **Analyzes** code repositories with deep AST parsing\n3. **Detects** conflicts between documentation and code implementation\n4. **Organizes** content into categorized reference files\n5. **Enhances** with AI to extract best examples and key concepts\n6. **Packages** everything into an uploadable `.zip` file for Claude\n\n**Result:** Get comprehensive Claude skills for any framework, API, or tool in 20-40 minutes instead of hours of manual work.\n\n## Why Use This?\n\n- 🎯 **For Developers**: Create skills from documentation + GitHub repos with conflict detection\n- 🎮 **For Game Devs**: Generate skills for game engines (Godot docs + GitHub, Unity, etc.)\n- 🔧 **For Teams**: Combine internal docs + code repositories into single source of truth\n- 📚 **For Learners**: Build comprehensive skills from docs, code examples, and PDFs\n- 🔍 **For Open Source**: Analyze repos to find documentation gaps and outdated examples\n\n## Key Features\n\n### 🌐 Documentation Scraping\n- ✅ **llms.txt Support** - Automatically detects and uses LLM-ready documentation files (10x faster)\n- ✅ **Universal Scraper** - Works with ANY documentation website\n- ✅ **Smart Categorization** - Automatically organizes content by topic\n- ✅ **Code Language Detection** - Recognizes Python, JavaScript, C++, GDScript, etc.\n- ✅ **8 Ready-to-Use Presets** - Godot, React, Vue, Django, FastAPI, and more\n\n### 📄 PDF Support (**v1.2.0**)\n- ✅ **Basic PDF Extraction** - Extract text, code, and images from PDF files\n- ✅ **OCR for Scanned PDFs** - Extract text from scanned documents\n- ✅ **Password-Protected PDFs** - Handle encrypted PDFs\n- ✅ **Table Extraction** - Extract complex tables from PDFs\n- ✅ **Parallel Processing** - 3x faster for large PDFs\n- ✅ **Intelligent Caching** - 50% faster on re-runs\n\n### 🐙 GitHub Repository Scraping (**v2.0.0**)\n- ✅ **Deep Code Analysis** - AST parsing for Python, JavaScript, TypeScript, Java, C++, Go\n- ✅ **API Extraction** - Functions, classes, methods with parameters and types\n- ✅ **Repository Metadata** - README, file tree, language breakdown, stars/forks\n- ✅ **GitHub Issues & PRs** - Fetch open/closed issues with labels and milestones\n- ✅ **CHANGELOG & Releases** - Automatically extract version history\n- ✅ **Conflict Detection** - Compare documented APIs vs actual code implementation\n- ✅ **MCP Integration** - Natural language: \"Scrape GitHub repo facebook/react\"\n\n### 🔄 Unified Multi-Source Scraping (**NEW - v2.0.0**)\n- ✅ **Combine Multiple Sources** - Mix documentation + GitHub + PDF in one skill\n- ✅ **Conflict Detection** - Automatically finds discrepancies between docs and code\n- ✅ **Intelligent Merging** - Rule-based or AI-powered conflict resolution\n- ✅ **Transparent Reporting** - Side-by-side comparison with ⚠️ warnings\n- ✅ **Documentation Gap Analysis** - Identifies outdated docs and undocumented features\n- ✅ **Single Source of Truth** - One skill showing both intent (docs) and reality (code)\n- ✅ **Backward Compatible** - Legacy single-source configs still work\n\n### 🤖 AI & Enhancement\n- ✅ **AI-Powered Enhancement** - Transforms basic templates into comprehensive guides\n- ✅ **No API Costs** - FREE local enhancement using Claude Code Max\n- ✅ **MCP Server for Claude Code** - Use directly from Claude Code with natural language\n\n### ⚡ Performance & Scale\n- ✅ **Async Mode** - 2-3x faster scraping with async/await (use `--async` flag)\n- ✅ **Large Documentation Support** - Handle 10K-40K+ page docs with intelligent splitting\n- ✅ **Router/Hub Skills** - Intelligent routing to specialized sub-skills\n-",
      "default_branch": "development"
    },
    "fetched_at": "2025-11-01T02:28:38.667336"
  },
  {
    "basic_info": {
      "name": "agentic-design-patterns-cn",
      "full_name": "ginobefun/agentic-design-patterns-cn",
      "owner": "ginobefun",
      "description": "《Agentic Design Patterns》中文翻译版",
      "url": "https://github.com/ginobefun/agentic-design-patterns-cn",
      "clone_url": "https://github.com/ginobefun/agentic-design-patterns-cn.git",
      "ssh_url": "git@github.com:ginobefun/agentic-design-patterns-cn.git",
      "homepage": null,
      "created_at": "2025-10-09T04:36:28Z",
      "updated_at": "2025-11-01T02:06:36Z",
      "pushed_at": "2025-10-31T16:17:00Z"
    },
    "stats": {
      "stars": 2743,
      "forks": 287,
      "watchers": 2743,
      "open_issues": 2,
      "size": 8318
    },
    "tech_info": {
      "language": "Python",
      "languages": {
        "Python": 114397
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/ginobefun-agentic-design-patterns-cn-badge.png)](https://mseep.ai/app/ginobefun-agentic-design-patterns-cn)\n\n# Agentic Design Patterns | <mark>智能体设计模式</mark>\n\n## A Hands-On Guide to Building Intelligent Systems | <mark>构建智能系统的实践指南</mark>\n\n[![License: CC BY-NC 4.0](https://img.shields.io/badge/License-CC%20BY--NC%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc/4.0/)\n[![GitHub stars](https://img.shields.io/github/stars/ginobefun/agentic-design-patterns-cn)](https://github.com/ginobefun/agentic-design-patterns-cn/stargazers)\n[![GitHub forks](https://img.shields.io/github/forks/ginobefun/agentic-design-patterns-cn)](https://github.com/ginobefun/agentic-design-patterns-cn/network)\n\n**原书作者 (Author)**: [Antonio Gulli](https://www.linkedin.com/in/searchguy/)\n\n**原书链接 (Original Book)**: [Amazon](https://www.amazon.com/Agentic-Design-Patterns-Hands-Intelligent/dp/3032014018/)\n\n**原始文档链接 (Original Book Link)**: [Google Docs](https://docs.google.com/document/d/1rsaK53T3Lg5KoGwvf8ukOUvbELRtH-V0LnOIFDxBryE/preview?tab=t.0#heading=h.pxcur8v2qagu)\n\n---\n\n## 📖 项目简介 | Project Description\n\n本项目是对 Antonio Gulli 所著《Agentic Design Patterns: A Hands-On Guide to Building Intelligent Systems》的**中英文对照翻译**。该书是一部全面的技术指南，涵盖了现代人工智能系统中智能体 (Agent) 设计的核心概念和实践方法。\n\nThis project is a **bilingual Chinese-English translation** of \"Agentic Design Patterns: A Hands-On Guide to Building Intelligent Systems\" by Antonio Gulli. The book is a comprehensive technical guide covering core concepts and practical approaches to agent design in modern AI systems.\n\n---\n\n## 🎯 项目特色 | Key Features\n\n- 📚 **中英文对照** - 完整的双语对照翻译\n- 🎨 **高亮显示** - 中文内容使用黄色高亮，易于区分\n- 📝 **格式规范** - 严格遵循 Markdown 标准和翻译规范\n- 🔗 **代码链接** - 保留所有原书代码示例链接\n- ⚡ **持续更新** - 逐章翻译，持续更新进度\n\n---\n\n## 📋 翻译进度 | Translation Progress\n\n**<mark>总页数：424 页</mark>** | **Total: 424 Pages**\n\n### 前置内容 | Front Matter\n\n| 章节 | 概述 | 负责人 | AI 翻译 | 人工评审 | 交叉评审 |\n|------|------|--------|---------|----------|----------|\n| [献辞](01-Dedication.md) | 作者的献辞与致敬 | @ginobefun | ✅ | ✅ | ⏳ |\n| [致谢](02-Acknowledgment.md) | 致谢与感谢名单 | @ginobefun | ✅ | ✅ | ⏳ |\n| [序言](03-Foreword.md) | 本书的序言与背景介绍 | @ginobefun | ✅ | ✅ | ⏳ |\n| [思想领袖的洞见](04-Thought-Leader.md) | 权力与责任的深度思考 | @ginobefun | ✅ | ✅ | ⏳ |\n| [介绍](05-Introduction.md) | 全书引言与核心概念 | @ginobefun | ✅ | ✅ | ⏳ |\n| [什么是\"智能体\"？](06-What-Makes-Agent.md) | 定义 AI 系统的\"智能体\"特征 | @ginobefun | ✅ | ✅ | ⏳ |\n\n### 第一部分：核心设计模式 | Part One: Core Patterns (103 页)\n\n| 章节 | 设计模式概述 | 负责人 | AI 翻译 | 人工评审 | 交叉评审 |\n|------|-------------|--------|---------|----------|----------|\n| [第 1 章：提示链](07-Chapter-01-Prompt-Chaining.md) | 分而治之的任务分解模式，将复杂任务分解为处理流水线 | @ginobefun | ✅ | ✅ | ⏳ |\n| [第 2 章：路由](08-Chapter-02-Routing.md) | 智能决策与动态分发，根据情境选择最佳行动路径 | @ginobefun | ✅ | ✅ | ⏳ |\n| [第 3 章：并行化](09-Chapter-03-Parallelization.md) | 并发执行与性能提升，同时执行多个独立任务 | @ginobefun | ✅ | ✅ | ⏳ |\n| [第 4 章：反思](10-Chapter-04-Reflection.md) | 自我评估和迭代改进，通过反馈循环优化输出质量 | @ginobefun | ✅ | ✅ | ⏳ |\n| [第 5 章：工具使用](11-Chapter-05-Tool-Use.md) | 外部工具与 API 集成，扩展智能体能力边界 | @ginobefun | ✅ | ✅ | ⏳ |\n| [第 6 章：规划](12-Chapter-06-Planning.md) | 多步骤计划制定与执行，实现复杂目标分解 | @ginobefun | ✅ | ✅ | ⏳ |\n| [第 7 章：多智能体协作](13-Chapter-07-Multi-Agent-Collaboration.md) | 协同工作架构，多个智能体配合完成任务 | @ginobefun | ✅  | ✅ | ⏳ |\n\n### 第二部分：高级设计模式 | Part Two: Advanced Patterns (61 页)\n\n| 章节 | 设计模式概述 | 负责人 | AI 翻译 | 人工评审 | 交叉评审 |\n|------|-------------|--------|---------|----------|----------|\n| [第 8 章：记忆管理](14-Chapter-08-Memory-Management.md) | 短期和长期记忆管理，维持上下文连续性 | @郑涛 | ✅ | ✅ | ❌ |\n| [第 9 章：学习与适应](15-Chapter-09-Learning-and-Adaptation.md) | 从经验中学习，持续优化智能体行为 | @陈诗中 | ⏳ | ❌ | ❌ |\n| [第 10 章：模型上下文协议](16-Chapter-10-Model-Context-Protocol.md) | 标准化交互协议，规范智能体通信方式 | @郑涛 | ⏳ | ❌ | ❌ |\n| [第 11 章：目标设定与监控](17-Chapter-11-Goal-Setting-and-Monitoring.md) | 动态目标管理，实时追踪任务进展 | [@李浪溪](https://github.com/seabornlee) | ✅ | ✅ | ⏳ |\n\n### 第三部分：集成设计模式 | Part Three: Integration Patterns (34 页)\n\n| 章节 | 设计模式概述 | 负责人 | AI 翻译 | 人工评审 | 交叉评审 |\n|------|-------------|--------|---------|----------|----------|\n| [第 12 章：异常处理与恢复](18-Chapter-12-Exception-Handling-and-Recovery.md) | 优雅错误处理，确保系统稳定性 | @EE | ❌ | ❌ | ❌ |\n| [第 13 章：人机协作](19-Chapter-13-Human-in-the-Loop.md) | 人机协作决策，融合人类智慧与 AI 能力 | @曾汉 | ✅ | ✅ | ⏳ |\n| [第 14 章：知识检索 (RAG)](20-Chapter-14-Knowledge-Retrieval.md) | 检索增强生成技术，结合外部知识库 | @EE | ✅ | ✅ | ⏳ |\n\n### 第四部分：生产设计模式 | Part Four: Production Patterns (114 页)\n\n| 章节 | 设计模式概述 | 负责人 | AI 翻译 | 人工评审 | 交叉评审 |\n|------|-------------|--------|---------|----------|----------|\n| [第 15 章：智能体间通信 (A2A)](21-Chapter-15-Inter-Agent-Communication.md) | 智能体通信协议，实现智能体间高效交互 | @朵朵肥 | ✅ | ✅ | ❌ |\n| [第 16 章：资源感知优化](22-Chapter-16-Resource-Aware-Optimization.md) | 资源优化管理，平衡性能与成本 | @IsaacZhaoo | ✅ | ✅ | ⏳ |\n| [第 17 章：推理技术](23-Chapter-17-Reasoning-Techniques.md) | 增强推理能力，提升决策质量 | @Diqing | ❌ | ❌ | ❌ |\n| [第 18 章：护栏/安全模式](24-Chapter-18-Guardrails-Safety-Patterns.md) | 安全保障机制，防止不当行为 | @IsaacZhaoo | ⏳ | ❌ | ❌ |\n| [第 19 章：评估与监控](25-Chapter-19-Evaluation-and-Monitoring.md) | 性能评估体系，量化智能体表现 | @朵朵肥 | ❌ | ❌ ",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-01T02:28:39.765801"
  },
  {
    "basic_info": {
      "name": "bentopdf",
      "full_name": "alam00000/bentopdf",
      "owner": "alam00000",
      "description": "A Privacy First PDF Toolkit",
      "url": "https://github.com/alam00000/bentopdf",
      "clone_url": "https://github.com/alam00000/bentopdf.git",
      "ssh_url": "git@github.com:alam00000/bentopdf.git",
      "homepage": "https://bentopdf.com/",
      "created_at": "2025-10-12T13:30:08Z",
      "updated_at": "2025-11-01T02:03:03Z",
      "pushed_at": "2025-10-31T21:26:46Z"
    },
    "stats": {
      "stars": 2666,
      "forks": 166,
      "watchers": 2666,
      "open_issues": 42,
      "size": 1125
    },
    "tech_info": {
      "language": "TypeScript",
      "languages": {
        "TypeScript": 539900,
        "HTML": 99199,
        "CSS": 9983,
        "JavaScript": 4438,
        "Dockerfile": 1148
      },
      "license": "GNU Affero General Public License v3.0",
      "topics": [
        "bentopdf",
        "hacktoberfest",
        "hacktoberfest-accepted",
        "javascript",
        "jpgtopdf",
        "pdf",
        "pdf-converter",
        "pdf-document",
        "pdf-document-processor",
        "pdf-generation",
        "pdf-viewer",
        "pdffiller",
        "privacy",
        "toolkit",
        "typescript"
      ]
    },
    "content": {
      "readme": "# BentoPDF\n\n**BentoPDF** is a powerful, privacy-first, client-side PDF toolkit that allows you to manipulate, edit, merge, and process PDF files directly in your browser. No server-side processing is required, ensuring your files remain secure and private.\n\n![Docker Pulls](https://img.shields.io/docker/pulls/bentopdf/bentopdf) [![Ko-fi](https://img.shields.io/badge/Buy%20me%20a%20Coffee-yellow?logo=kofi&style=flat-square)](https://ko-fi.com/alio0) ![GitHub Stars](https://img.shields.io/github/stars/alam00000/bentopdf?style=social)\n[![Sponsor me on GitHub](https://img.shields.io/badge/Sponsor-%E2%9D%A4-ff69b4)](https://github.com/sponsors/alam00000)\n\n## ⭐ Stargazers over time\n\n[![Star History Chart](https://api.star-history.com/svg?repos=alam00000/bentopdf&type=Date)](https://star-history.com/#alam00000/bentopdf&Date)\n\n---\n\n## ✨ Why BentoPDF?\n\n- **Privacy First**: All processing happens in your browser. Your files are never uploaded to a server, guaranteeing 100% privacy.\n- **No Limits**: Manipulate as many files as you want, as often you want. There are no restrictions or upload limits.\n- **High Performance**: Built with modern web technologies, BentoPDF is fast and efficient, handling even large PDF files with ease.\n- **Completely Free**: BentoPDF is a free and open-source tool for everyone.\n\n---\n\n## 🛠️ Features / Tools Supported\n\nBentoPDF offers a comprehensive suite of tools to handle all your PDF needs.\n\n### Organize & Manage PDFs\n\n| Tool Name                 | Description                                                                |\n| :------------------------ | :------------------------------------------------------------------------- |\n| **Merge PDFs**            | Combine multiple PDF files into one.                                       |\n| **Split PDFs**            | Extract specific pages or divide a document into smaller files.            |\n| **Organize Pages**        | Reorder, duplicate, or delete pages with a simple drag-and-drop interface. |\n| **Extract Pages**         | Save a specific range of pages as a new PDF.                               |\n| **Delete Pages**          | Remove unwanted pages from your document.                                  |\n| **Rotate PDF**            | Rotate individual or all pages in a document.                              |\n| **N-Up PDF**              | Combine multiple pages onto a single page.                                 |\n| **View PDF**              | A powerful, integrated PDF viewer.                                         |\n| **Alternate & Mix pages** | Merge pages by alternating pages from each PDF.                            |\n| **Posterize PDF**         | Split a PDF into multiple smaller pages for print.                         |\n\n### Edit & Modify PDFs\n\n| Tool Name              | Description                                                 |\n| :--------------------- | :---------------------------------------------------------- |\n| **PDF Editor**         | A comprehensive editor to modify your PDFs.                 |\n| **Add Page Numbers**   | Easily add page numbers with customizable formatting.       |\n| **Add Watermark**      | Add text or image watermarks to protect your documents.     |\n| **Header & Footer**    | Add customizable headers and footers.                       |\n| **Crop PDF**           | Crop specific pages or the entire document.                 |\n| **Invert Colors**      | Invert the colors of your PDF pages for better readability. |\n| **Change Background**  | Modify the background color of your PDF.                    |\n| **Change Text Color**  | Change the color of text content within the PDF.            |\n| **Fill Forms**         | Fill out PDF forms directly in your browser.                |\n| **Flatten PDF**        | Flatten form fields and annotations into static content.    |\n| **Remove Annotations** | Remove comments, highlights, and other annotations.         |\n| **Remove Blank Pages** | Auto detect and remove blank pages in a PDF.                |\n\n### Convert to PDF\n\n| Tool Name           | Description                                                     |\n| :------------------ | :-------------------------------------------------------------- |\n| **Image to PDF**    | Convert JPG, PNG, WebP, SVG, BMP, HEIC, and TIFF images to PDF. |\n| **Markdown to PDF** | Convert `.md` files into professional PDF documents.            |\n| **Text to PDF**     | Convert plain text files into a PDF.                            |\n\n### Convert from PDF\n\n| Tool Name            | Description                                                                    |\n| :------------------- | :----------------------------------------------------------------------------- |\n| **PDF to Image**     | Convert PDF pages to JPG, PNG, WebP, BMP, or TIFF formats.                     |\n| **PDF to Greyscale** | Convert a color PDF into a black-and-white version.                            |\n| **OCR PDF**          | Make scanned PDFs searchable and copyable ",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-01T02:28:40.883583"
  },
  {
    "basic_info": {
      "name": "dexter",
      "full_name": "virattt/dexter",
      "owner": "virattt",
      "description": "An autonomous agent for deep financial research",
      "url": "https://github.com/virattt/dexter",
      "clone_url": "https://github.com/virattt/dexter.git",
      "ssh_url": "git@github.com:virattt/dexter.git",
      "homepage": null,
      "created_at": "2025-10-14T21:02:00Z",
      "updated_at": "2025-11-01T01:13:21Z",
      "pushed_at": "2025-10-30T23:05:01Z"
    },
    "stats": {
      "stars": 2614,
      "forks": 323,
      "watchers": 2614,
      "open_issues": 8,
      "size": 28
    },
    "tech_info": {
      "language": "Python",
      "languages": {
        "Python": 63702,
        "JavaScript": 228
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# Dexter 🤖\n\nDexter is an autonomous financial research agent that thinks, plans, and learns as it works. It performs analysis using task planning, self-reflection, and real-time market data. Think Claude Code, but built specifically for financial research.\n\n\n<img width=\"979\" height=\"651\" alt=\"Screenshot 2025-10-14 at 6 12 35 PM\" src=\"https://github.com/user-attachments/assets/5a2859d4-53cf-4638-998a-15cef3c98038\" />\n\n## Overview\n\nDexter takes complex financial questions and turns them into clear, step-by-step research plans. It runs those tasks using live market data, checks its own work, and refines the results until it has a confident, data-backed answer.  \n\nIt’s not just another chatbot.  It’s an agent that plans ahead, verifies its progress, and keeps iterating until the job is done.\n\n**Key Capabilities:**\n- **Intelligent Task Planning**: Automatically decomposes complex queries into structured research steps\n- **Autonomous Execution**: Selects and executes the right tools to gather financial data\n- **Self-Validation**: Checks its own work and iterates until tasks are complete\n- **Real-Time Financial Data**: Access to income statements, balance sheets, and cash flow statements\n- **Safety Features**: Built-in loop detection and step limits to prevent runaway execution\n\n[![Twitter Follow](https://img.shields.io/twitter/follow/virattt?style=social)](https://twitter.com/virattt)\n\n### Prerequisites\n\n- Python 3.10 or higher\n- [uv](https://github.com/astral-sh/uv) package manager\n- OpenAI API key (get [here](https://platform.openai.com/api-keys))\n- Financial Datasets API key (get [here](https://financialdatasets.ai))\n\n### Installation\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/virattt/dexter.git\ncd dexter\n```\n\n2. Install dependencies with uv:\n```bash\nuv sync\n```\n\n3. Set up your environment variables:\n```bash\n# Copy the example environment file\ncp env.example .env\n\n# Edit .env and add your API keys\n# OPENAI_API_KEY=your-openai-api-key\n# FINANCIAL_DATASETS_API_KEY=your-financial-datasets-api-key\n```\n\n### Usage\n\nRun Dexter in interactive mode:\n```bash\nuv run dexter-agent\n```\n\n### Example Queries\n\nTry asking Dexter questions like:\n- \"What was Apple's revenue growth over the last 4 quarters?\"\n- \"Compare Microsoft and Google's operating margins for 2023\"\n- \"Analyze Tesla's cash flow trends over the past year\"\n- \"What is Amazon's debt-to-equity ratio based on recent financials?\"\n\nDexter will automatically:\n1. Break down your question into research tasks\n2. Fetch the necessary financial data\n3. Perform calculations and analysis\n4. Provide a comprehensive, data-rich answer\n\n## Architecture\n\nDexter uses a multi-agent architecture with specialized components:\n\n- **Planning Agent**: Analyzes queries and creates structured task lists\n- **Action Agent**: Selects appropriate tools and executes research steps\n- **Validation Agent**: Verifies task completion and data sufficiency\n- **Answer Agent**: Synthesizes findings into comprehensive responses\n\n## Project Structure\n\n```\ndexter/\n├── src/\n│   ├── dexter/\n│   │   ├── agent.py      # Main agent orchestration logic\n│   │   ├── model.py      # LLM interface\n│   │   ├── tools.py      # Financial data tools\n│   │   ├── prompts.py    # System prompts for each component\n│   │   ├── schemas.py    # Pydantic models\n│   │   ├── utils/        # Utility functions\n│   │   └── cli.py        # CLI entry point\n├── pyproject.toml\n└── uv.lock\n```\n\n## Configuration\n\nDexter supports configuration via the `Agent` class initialization:\n\n```python\nfrom dexter.agent import Agent\n\nagent = Agent(\n    max_steps=20,              # Global safety limit\n    max_steps_per_task=5       # Per-task iteration limit\n)\n```\n\n## How to Contribute\n\n1. Fork the repository\n2. Create a feature branch\n3. Commit your changes\n4. Push to the branch\n5. Create a Pull Request\n\n**Important**: Please keep your pull requests small and focused.  This will make it easier to review and merge.\n\n\n## License\n\nThis project is licensed under the MIT License.\n\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-01T02:28:41.998336"
  },
  {
    "basic_info": {
      "name": "nof0",
      "full_name": "wquguru/nof0",
      "owner": "wquguru",
      "description": "nof1.ai完整复刻版（持续开发）",
      "url": "https://github.com/wquguru/nof0",
      "clone_url": "https://github.com/wquguru/nof0.git",
      "ssh_url": "git@github.com:wquguru/nof0.git",
      "homepage": "https://nof0.wqu.guru",
      "created_at": "2025-10-22T16:30:45Z",
      "updated_at": "2025-11-01T02:22:00Z",
      "pushed_at": "2025-11-01T01:52:34Z"
    },
    "stats": {
      "stars": 2326,
      "forks": 351,
      "watchers": 2326,
      "open_issues": 11,
      "size": 5713
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 241623,
        "TypeScript": 239202,
        "CSS": 7723,
        "JavaScript": 6050,
        "Shell": 5233,
        "Makefile": 1645,
        "Dockerfile": 739,
        "PLpgSQL": 331
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# NOF0 - 开箱即用的Agentic Trading项目\n\n> **终极目标**: 完整复刻 [NOF1.ai](https://nof1.ai) Alpha Arena，打造开源的AI交易竞技平台\n\n让 AI + Crypto 走向大众视野：用真实数据和清晰可视化，回答\"哪个模型更会赚\"的朴素问题。\n\n\n## 项目简介\n\nNOF0 是一个让多个AI模型在真实加密货币市场中进行交易竞赛的平台。每个AI从$10,000起步，实时展示谁赚的多、谁亏的惨。本项目复刻 nof1.ai 的完整功能，让任何人都能部署自己的AI交易竞技场。\n\n## 项目愿景\n\n### 终极目标\n完整开源复刻 [NOF1.ai](https://nof1.ai) Alpha Arena\n\n### 当前进度\n\n- 前端：100%（可独立运行，不依赖后端）\n- 后端：20%\n- AI Agent：0%\n\n## 项目结构\n\n```\nnof0/\n├── web/          # [前端] Next.js + React + Recharts\n├── go/           # [后端] Go-Zero + REST API\n├── mcp/          # [MCP数据] MCP浏览器截图、JSON静态数据等\n└── agents/       # [AI引擎] (规划中)\n```\n\n## 快速开始\n\n### 初始化项目\n\n克隆项目后，配置 Git 自动递归处理子模块：\n\n```bash\ngit clone <repo>\ncd nof0\ngit config submodule.recurse true\n```\n\n此后 `git pull` 会自动更新子模块（包括 `go/etc/prompts/base`），无需手动执行 `git submodule update`。\n\n### 启动前端\n\n```bash\ncd web\nnpm install\nnpm run dev\n```\n\n访问 `http://localhost:3000`\n\n**前端核心特性**:\n- 账户总资产曲线\n- 持仓情况\n- 成交纪录\n- 模型对话（Model Chat）\n- 排行榜\n- 模型详情\n\n### 启动后端\n\n```bash\ncd go\ngo build -o nof0-api ./nof0.go\n./nof0-api -f etc/nof0.yaml\n```\n\n服务运行在 `http://localhost:8888`\n\n完整后端文档见 [go/README.md](go/README.md)\n\n## 技术栈\n\n### 前端 (web/)\n- **框架**: Next.js 15 + React 19 + TypeScript\n- **图表**: Recharts（自定义图例与末端标记）\n- **状态**: Zustand\n- **样式**: CSS Variables 主题系统（避免SSR/CSR水合差异）\n- **状态**: 开发完毕\n\n**技术亮点**:\n- 在 `src/lib/model/meta.ts` 统一配置品牌色与白色版 Logo\n- `globals.css` 使用 CSS 变量驱动主题（`--panel-bg`、`--muted-text`、`--axis-tick` 等）\n- 开发规范：参考 `web/docs/theme.md`，避免 `isDark` 分支判断\n\n### 后端 (go/)\n- **框架**: Go-Zero 微服务框架\n- **特性**: 7个REST端点、88%测试覆盖、响应时间 <10ms\n- **状态**: 开发中\n\n详细文档见 [go/README.md](go/README.md)\n\n## 数据快照工具\n\n一键下载 nof1.ai 的上游接口原始数据，离线保存：\n\n```bash\ncd web\nnpm run snapshot:nof1\n```\n\n**生成内容**:\n- 生成目录：`snapshots/nof1/<ISO时间戳>/*.json` 与 `index.json`\n- 已包含：crypto-prices、positions、trades、account-totals、since-inception-values、leaderboard、analytics、conversations\n- 默认不提交到仓库（见 `.gitignore`）\n\n## 相关资源\n\n- [NOF1 官方网站](https://nof1.ai/)\n- [后端完整文档](go/README.md)\n- [Go-Zero框架](https://go-zero.dev/)\n\n## 许可证\n\nMIT License",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-01T02:28:43.085960"
  },
  {
    "basic_info": {
      "name": "surf",
      "full_name": "deta/surf",
      "owner": "deta",
      "description": "Personal AI Notebooks. Organize files & webpages and generate notes from them. Open source, local & open data, open model choice (incl. local).",
      "url": "https://github.com/deta/surf",
      "clone_url": "https://github.com/deta/surf.git",
      "ssh_url": "git@github.com:deta/surf.git",
      "homepage": "https://deta.surf",
      "created_at": "2025-10-20T15:09:57Z",
      "updated_at": "2025-11-01T00:02:12Z",
      "pushed_at": "2025-10-31T14:58:30Z"
    },
    "stats": {
      "stars": 2306,
      "forks": 150,
      "watchers": 2306,
      "open_issues": 17,
      "size": 274887
    },
    "tech_info": {
      "language": "TypeScript",
      "languages": {
        "TypeScript": 1873675,
        "Svelte": 1613261,
        "Rust": 675921,
        "JavaScript": 39662,
        "SCSS": 39395,
        "CSS": 18112,
        "HTML": 4089,
        "NSIS": 3077,
        "Handlebars": 972,
        "Shell": 369
      },
      "license": "Apache License 2.0",
      "topics": [
        "claude",
        "deepseek",
        "gemma",
        "knowledge-base",
        "knowledge-management",
        "llm",
        "local",
        "local-llm",
        "ollama",
        "openai",
        "productivity",
        "rust",
        "svelte",
        "typescript"
      ]
    },
    "content": {
      "readme": "<div align=\"center\">\n  \n![splash](./docs/assets/repo-header.png)\n\n[**Website**](https://deta.surf) - [**Discord**](https://deta.surf/discord)\n\n</div>\n\n<br>\n\n# Deta Surf: Your AI Notebook\n\nDeta Surf is an AI notebook that brings all your files and the web directly into your stream of thought.\n\nIt’s meant for simultaneous research and thinking that minimizes the grunt work: manually searching, opening windows & tabs, scrolling, copying and pasting into a document editor.\n\nSurf is primarily built in Svelte, TypeScript and Rust, runs on MacOS, Windows & Linux, stores data locally in open formats, and is open source.\n\n![split](./docs/assets/split-note.webp)\n\n## Motivation\n\nMost applications are focused on a single task, or a single media type: notes, websites, or PDFs. Real thinking requires juggling media across sources to make connections and synthesize ideas. We want to help people think better, across all their media.\n\nSurf is built to be personal and open, in service of the user. This means local first data, open data formats, open source, and openness with respect to AI models. [Read more](https://deta.surf/motivation).\n\n## Installation\n\nCheckout the [GitHub releases](https://github.com/deta/surf/releases) for the latest stable version of Surf for MacOS, Windows and Linux.\n\nYou can also download Surf with some managed & additional features (e.g. AI) from the [Deta website](https://deta.surf). That version is subject to different terms.\n\nFor building from source and local development, see [CONTRIBUTING.md](CONTRIBUTING.md).\n\n## TL;DR - Things to try\n\n- _YouTube Notes_: visit a YouTube video and ask a question\n- _PDF Notes_: open a PDF and ask a question\n- _Create an applet_: use the \"app generation\" tool and ask for an app\n- _Notes that search the web_: use the \"web search\" tool and ask a question with \"search\" in it\n\n## Features\n\n### Multi-Media Library & Notebooks\n\n![notebooks](./docs/assets/readme/notebook-grid.png)\n\nStore almost any media in a private library on your computer, in an open and transparent format.\n\n- Support for local files, sites & links from the web (YouTube, Tweets & more), or create media directly in Surf.\n- Organize this library into Notebooks.\n- Open and use much of your library offline.\n- Use your library to power Surf’s AI features.\n\nSurf's library is built on a local storage engine called SFFS (Surf Flat File System), which stores data in open and transparent formats.\n\n[Details on the library](/docs/LIBRARY.md).\n\n### Smart Notes\n\n![smart-notes](./docs/assets/readme/smart-notes.png)\n\nExplore and think across your digital stuff without opening up a bunch of windows, clicking, scrolling and copying & pasting into your document (or chatbot).\n\n- `@-mention` and auto-generate from any tab, website or any resource in your [library](./docs/LIBRARY.md).\n- Trigger [web searches](./docs/SMART_NOTES.md#web-search) to do research, and bring the results back in your notes.\n- Integrated [citations](./docs/SMART_NOTES.md#citations) deeplinked to original sources, whether a section on a webpage, a timestamp in a video, or a page in a PDF.\n- Generate interactive applications without writing code using [Surflets](./docs/Surflets.md).\n- Paste in images, tables or data from other applications and have Surf understand and incorporate them.\n- Use rich formating, code blocks, to-do lists and more in your notes.\n\n[Read more](/docs/SMART_NOTES.md).\n\n### Tabs, Split View & Sidebar\n\n![split](./docs/assets/another-split.webp)\n\nSurf is built around tabs, split view and a sidebar for easy navigation.\n\n- Open local notes, files or web pages in tabs.\n- Split view allows you to view and interact with multiple resources side by side.\n- The sidebar provides quick access to your Notebooks & notes.\n\n### Surflets (App Generation)\n\n![surflets](./docs/assets/readme/surflets.png)\n\nSurf can code interactive applets to help you visualize, understand or explore concepts or data that are aided with code.\n\n[Read more](./docs/SURFLETS.md).\n\n### AI\n\n![models.png](./docs/assets/readme/models.png)\n\n[Surf’s notes](./docs/SMART_NOTES.md) and [Surflets](./docs/SURFLETS.md) are powered by large language models of your choice.\n\n- Bring your own key for popular models\n- Add a cloud model\n- Use Local Language Models\n\n[Read more](./docs/AI_MODELS.md).\n\n### Shortcuts\n\nFind the most common shortcuts [here](./docs/SHORTCUTS.md).\n\n## Security\n\n_To report a security concern, please see_ https://github.com/deta/surf/security/policy\n\n## Contributing\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md) for details on contributing to the project and an overview of the codebase.\n\n## Code of Conduct\n\nSee [CODE_OF_CONDUCT.md](CODE_OF_CONDUCT.md) for details on our code of conduct.\n\n## License\n\nThe source code for this project is licensed under the Apache 2.0 license, with the following exceptions:\n\n1. Our patch for the @ghostery/adblocker-electron package is licensed under the Mozilla Public License 2.0 (MPL-2.0), consistent with the upstream project's licensing.",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-01T02:28:44.181606"
  },
  {
    "basic_info": {
      "name": "beads",
      "full_name": "steveyegge/beads",
      "owner": "steveyegge",
      "description": "Beads - A memory upgrade for your coding agent",
      "url": "https://github.com/steveyegge/beads",
      "clone_url": "https://github.com/steveyegge/beads.git",
      "ssh_url": "git@github.com:steveyegge/beads.git",
      "homepage": "",
      "created_at": "2025-10-12T03:09:46Z",
      "updated_at": "2025-11-01T02:22:01Z",
      "pushed_at": "2025-11-01T02:21:57Z"
    },
    "stats": {
      "stars": 2231,
      "forks": 137,
      "watchers": 2231,
      "open_issues": 23,
      "size": 16178
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 1605326,
        "Python": 208303,
        "Shell": 31852,
        "PowerShell": 9844,
        "Nix": 1327
      },
      "license": "MIT License",
      "topics": [
        "agents",
        "claude-code",
        "coding"
      ]
    },
    "content": {
      "readme": "# bd - Beads Issue Tracker 🔗\n\n[![Go Version](https://img.shields.io/github/go-mod/go-version/steveyegge/beads)](https://go.dev/)\n[![Release](https://img.shields.io/github/v/release/steveyegge/beads)](https://github.com/steveyegge/beads/releases)\n[![CI](https://img.shields.io/github/actions/workflow/status/steveyegge/beads/ci.yml?branch=main&label=tests)](https://github.com/steveyegge/beads/actions/workflows/ci.yml)\n[![Go Report Card](https://goreportcard.com/badge/github.com/steveyegge/beads)](https://goreportcard.com/report/github.com/steveyegge/beads)\n[![License](https://img.shields.io/github/license/steveyegge/beads)](LICENSE)\n[![PyPI](https://img.shields.io/pypi/v/beads-mcp)](https://pypi.org/project/beads-mcp/)\n\n**Give your coding agent a memory upgrade**\n\n> ## 🎉 **v0.20.1: Multi-Worker Support Unlocked!** 🎉\n>\n> **Hash-based IDs eliminate merge conflicts and collision issues!**\n>\n> Previous versions used sequential IDs (bd-1, bd-2, bd-3...) which caused frequent collisions when multiple agents or branches created issues concurrently. Version 0.20.1 switches to **hash-based IDs** (bd-a1b2, bd-f14c, bd-3e7a...) that are collision-resistant and merge-friendly.\n>\n> **What's new:** ✅ Multi-clone, multi-branch, multi-agent workflows now work reliably  \n> **What changed:** Issue IDs are now short hashes instead of sequential numbers  \n> **Migration:** Run `bd migrate` to upgrade existing databases (optional - old DBs still work)\n>\n> Hash IDs use progressive length scaling (4/5/6 characters) with birthday paradox math to keep collisions extremely rare while maintaining human readability. See \"Hash-Based Issue IDs\" section below for details.\n\n> **⚠️ Alpha Status**: This project is in active development. The core features work well, but expect API changes before 1.0. Use for development/internal projects first.\n\nBeads is a lightweight memory system for coding agents, using a graph-based issue tracker. Four kinds of dependencies work to chain your issues together like beads, making them easy for agents to follow for long distances, and reliably perform complex task streams in the right order.\n\nDrop Beads into any project where you're using a coding agent, and you'll enjoy an instant upgrade in organization, focus, and your agent's ability to handle long-horizon tasks over multiple compaction sessions. Your agents will use issue tracking with proper epics, rather than creating a swamp of rotten half-implemented markdown plans.\n\nInstant start:\n\n```bash\ncurl -fsSL https://raw.githubusercontent.com/steveyegge/beads/main/scripts/install.sh | bash\n```\n\nThen tell your coding agent to start using the `bd` tool instead of markdown for all new work, somewhere in your `AGENTS.md` or `CLAUDE.md`. That's all there is to it!\n\nYou don't use Beads directly as a human. Your coding agent will file and manage issues on your behalf. They'll file things they notice automatically, and you can ask them at any time to add or update issues for you.\n\nBeads gives agents unprecedented long-term planning capability, solving their amnesia when dealing with complex nested plans. They can trivially query the ready work, orient themselves, and land on their feet as soon as they boot up.\n\nAgents using Beads will no longer silently pass over problems they notice due to lack of context space -- instead, they will automatically file issues for newly-discovered work as they go. No more lost work, ever.\n\nBeads issues are backed by git, but through a clever design it manages to act like a managed, centrally hosted SQL database shared by all of the agents working on a project (repo), even across machines.\n\nBeads even improves work auditability. The issue tracker has a sophisticated audit trail, which agents can use to reconstruct complex operations that may have spanned multiple sessions.\n\nAgents report that they enjoy working with Beads, and they will use it spontaneously for both recording new work and reasoning about your project in novel ways. Whether you are a human or an AI, Beads lets you have more fun and less stress with agentic coding.\n\n![AI Agent using Beads](https://raw.githubusercontent.com/steveyegge/beads/main/.github/images/agent-using-beads.jpg)\n\n## Features\n\n- ✨ **Zero setup** - `bd init` creates project-local database (and your agent will do it)\n- 🔗 **Dependency tracking** - Four dependency types (blocks, related, parent-child, discovered-from)\n- 📋 **Ready work detection** - Automatically finds issues with no open blockers\n- 🤖 **Agent-friendly** - `--json` flags for programmatic integration\n- 📦 **Git-versioned** - JSONL records stored in git, synced across machines\n- 🌍 **Distributed by design** - Agents on multiple machines share one logical database via git\n- 🏗️ **Extensible** - Add your own tables to the SQLite database\n- 🔍 **Multi-project isolation** - Each project gets its own database, auto-discovered by directory\n- 🌲 **Dependency trees** - Visualize full dependency graphs\n- 🎨 **Beautiful CLI** - Colored output for humans, JSON f",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-01T02:28:45.284508"
  },
  {
    "basic_info": {
      "name": "kimi-cli",
      "full_name": "MoonshotAI/kimi-cli",
      "owner": "MoonshotAI",
      "description": "Kimi CLI is your next CLI agent.",
      "url": "https://github.com/MoonshotAI/kimi-cli",
      "clone_url": "https://github.com/MoonshotAI/kimi-cli.git",
      "ssh_url": "git@github.com:MoonshotAI/kimi-cli.git",
      "homepage": null,
      "created_at": "2025-10-15T12:58:03Z",
      "updated_at": "2025-11-01T02:25:11Z",
      "pushed_at": "2025-10-31T17:47:43Z"
    },
    "stats": {
      "stars": 2156,
      "forks": 158,
      "watchers": 2156,
      "open_issues": 43,
      "size": 1581
    },
    "tech_info": {
      "language": "Python",
      "languages": {
        "Python": 457207,
        "Makefile": 2817
      },
      "license": "Apache License 2.0",
      "topics": []
    },
    "content": {
      "readme": "# Kimi CLI\n\n[![Commit Activity](https://img.shields.io/github/commit-activity/w/MoonshotAI/kimi-cli)](https://github.com/MoonshotAI/kimi-cli/graphs/commit-activity)\n[![Checks](https://img.shields.io/github/check-runs/MoonshotAI/kimi-cli/main)](https://github.com/MoonshotAI/kimi-cli/actions)\n[![Version](https://img.shields.io/pypi/v/kimi-cli)](https://pypi.org/project/kimi-cli/)\n[![Downloads](https://img.shields.io/pypi/dw/kimi-cli)](https://pypistats.org/packages/kimi-cli)\n\n[中文](https://www.kimi.com/coding/docs/kimi-cli.html)\n\nKimi CLI is a new CLI agent that can help you with your software development tasks and terminal operations.\n\n> [!IMPORTANT]\n> Kimi CLI is currently in technical preview.\n\n## Key features\n\n- Shell-like UI and raw shell command execution\n- Zsh integration\n- [Agent Client Protocol] support\n- MCP support\n- And more to come...\n\n[Agent Client Protocol]: https://github.com/agentclientprotocol/agent-client-protocol\n\n## Installation\n\n> [!IMPORTANT]\n> Kimi CLI currently only supports macOS and Linux. Windows support is coming soon.\n\nKimi CLI is published as a Python package on PyPI. We highly recommend installing it with [uv](https://docs.astral.sh/uv/). If you have not installed uv yet, please follow the instructions [here](https://docs.astral.sh/uv/getting-started/installation/) to install it first.\n\nOnce uv is installed, you can install Kimi CLI with:\n\n```sh\nuv tool install --python 3.13 kimi-cli\n```\n\nRun `kimi --help` to check if Kimi CLI is installed successfully.\n\n> [!IMPORTANT]\n> Due to the security checks on macOS, the first time you run `kimi` command may take 10 seconds or more depending on your system environment.\n\n## Upgrading\n\nUpgrade Kimi CLI to the latest version with:\n\n```sh\nuv tool upgrade kimi-cli --no-cache\n```\n\n## Usage\n\nRun `kimi` command in the directory you want to work on, then send `/setup` to setup Kimi CLI:\n\n![](./docs/images/setup.png)\n\nAfter setup, Kimi CLI will be ready to use. You can send `/help` to get more information.\n\n## Features\n\n### Shell mode\n\nKimi CLI is not only a coding agent, but also a shell. You can switch the mode by pressing `Ctrl-X`. In shell mode, you can directly run shell commands without leaving Kimi CLI.\n\n> [!NOTE]\n> Built-in shell commands like `cd` are not supported yet.\n\n### Zsh integration\n\nYou can use Kimi CLI together with Zsh, to empower your shell experience with AI agent capabilities.\n\nInstall the [zsh-kimi-cli](https://github.com/MoonshotAI/zsh-kimi-cli) plugin via:\n\n```sh\ngit clone https://github.com/MoonshotAI/zsh-kimi-cli.git \\\n  ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/kimi-cli\n```\n\n> [!NOTE]\n> If you are using a plugin manager other than Oh My Zsh, you may need to refer to the plugin's README for installation instructions.\n\nThen add `kimi-cli` to your Zsh plugin list in `~/.zshrc`:\n\n```sh\nplugins=(... kimi-cli)\n```\n\nAfter restarting Zsh, you can switch to agent mode by pressing `Ctrl-X`.\n\n### ACP support\n\nKimi CLI supports [Agent Client Protocol] out of the box. You can use it together with any ACP-compatible editor or IDE.\n\nFor example, to use Kimi CLI with [Zed](https://zed.dev/), add the following configuration to your `~/.config/zed/settings.json`:\n\n```json\n{\n  \"agent_servers\": {\n    \"Kimi CLI\": {\n      \"command\": \"kimi\",\n      \"args\": [\"--acp\"],\n      \"env\": {}\n    }\n  }\n}\n```\n\nThen you can create Kimi CLI threads in Zed's agent panel.\n\n### Using MCP tools\n\nKimi CLI supports the well-established MCP config convention. For example:\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"url\": \"https://mcp.context7.com/mcp\",\n      \"headers\": {\n        \"CONTEXT7_API_KEY\": \"YOUR_API_KEY\"\n      }\n    },\n    \"chrome-devtools\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"chrome-devtools-mcp@latest\"]\n    }\n  }\n}\n```\n\nRun `kimi` with `--mcp-config-file` option to connect to the specified MCP servers:\n\n```sh\nkimi --mcp-config-file /path/to/mcp.json\n```\n\n## Development\n\nTo develop Kimi CLI, run:\n\n```sh\ngit clone https://github.com/MoonshotAI/kimi-cli.git\ncd kimi-cli\n\nmake prepare  # prepare the development environment\n```\n\nThen you can start working on Kimi CLI.\n\nRefer to the following commands after you make changes:\n\n```sh\nuv run kimi  # run Kimi CLI\n\nmake format  # format code\nmake check  # run linting and type checking\nmake test  # run tests\nmake help  # show all make targets\n```\n\n## Contributing\n\nWe welcome contributions to Kimi CLI! Please refer to [CONTRIBUTING.md](./CONTRIBUTING.md) for more information.\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-01T02:28:46.422708"
  },
  {
    "basic_info": {
      "name": "awesome-claude-skills",
      "full_name": "BehiSecc/awesome-claude-skills",
      "owner": "BehiSecc",
      "description": "A curated list of Claude Skills.",
      "url": "https://github.com/BehiSecc/awesome-claude-skills",
      "clone_url": "https://github.com/BehiSecc/awesome-claude-skills.git",
      "ssh_url": "git@github.com:BehiSecc/awesome-claude-skills.git",
      "homepage": null,
      "created_at": "2025-10-17T15:05:35Z",
      "updated_at": "2025-11-01T02:27:39Z",
      "pushed_at": "2025-10-31T12:43:44Z"
    },
    "stats": {
      "stars": 1792,
      "forks": 127,
      "watchers": 1792,
      "open_issues": 1,
      "size": 29
    },
    "tech_info": {
      "language": null,
      "languages": {},
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# Awesome Claude Skills\n\n## 📚 Table of Contents  \n- [Document Skills](#-document-skills)  \n- [Development & Code Tools](#-development--code-tools)  \n- [Data & Analysis](#-data--analysis)  \n- [Scientific & Research Tools](#-scientific--research-tools)  \n- [Writing & Research](#-writing--research)  \n- [Learning & Knowledge](#-learning--knowledge)  \n- [Media & Content](#-media--content)  \n- [Collaboration & Project Management](#-collaboration--project-management)  \n- [Security & Web Testing](#-security--web-testing)  \n- [Utility & Automation](#-utility--automation)\n\n\n\n## 📄 Document Skills  \n- [docx](https://github.com/anthropics/skills/tree/main/document-skills/docx) - Create, edit, analyze Word docs with tracked changes, comments, formatting.  \n- [pdf](https://github.com/anthropics/skills/tree/main/document-skills/pdf) - Extract text, tables, metadata, merge & annotate PDFs.  \n- [pptx](https://github.com/anthropics/skills/tree/main/document-skills/pptx) - Read, generate, and adjust slides, layouts, templates.  \n- [xlsx](https://github.com/anthropics/skills/tree/main/document-skills/xlsx) - Spreadsheet manipulation: formulas, charts, data transformations.  \n\n\n\n## 🛠 Development & Code Tools\n- [artifacts-builder](https://github.com/anthropics/skills/tree/main/artifacts-builder) - Suite of tools for creating elaborate, multi-component claude.ai HTML artifacts using modern frontend web technologies (React, Tailwind CSS, shadcn/ui).\n- [test-driven-development](https://github.com/obra/superpowers/tree/main/skills/test-driven-development) - Use when implementing any feature or bugfix, before writing implementation code\n- [using-git-worktrees](https://github.com/obra/superpowers/blob/main/skills/using-git-worktrees/) - Creates isolated git worktrees with smart directory selection and safety verification.\n- [finishing-a-development-branch](https://github.com/obra/superpowers/tree/main/skills/finishing-a-development-branch) - Guides completion of development work by presenting clear options and handling chosen workflow.\n- [pypict-claude-skill](https://github.com/omkamal/pypict-claude-skill) - Design comprehensive test cases using PICT (Pairwise Independent Combinatorial Testing) for requirements or code, generating optimized test suites with pairwise coverage.\n- [aws-skills](https://github.com/zxkane/aws-skills) - AWS development with CDK best practices, cost optimization MCP servers, and serverless/event-driven architecture patterns.\n- [move-code-quality-skill](https://github.com/1NickPappas/move-code-quality-skill) - Analyzes Move language packages against the official Move Book Code Quality Checklist for Move 2024 Edition compliance and best practices.\n\n\n\n## 📊 Data & Analysis  \n- [root-cause-tracing](https://github.com/obra/superpowers/tree/main/skills/root-cause-tracing) - Use when errors occur deep in execution and you need to trace back to find the original trigger \n- [csv-data-summarizer-claude-skill](https://github.com/coffeefuelbump/csv-data-summarizer-claude-skill) - Automatically analyzes CSVs: columns, distributions, missing data, correlations.\n\n\n\n## 🔬 Scientific & Research Tools\n- [scientific-databases](https://github.com/K-Dense-AI/claude-scientific-skills/tree/main/scientific-databases) - Access to 26 scientific databases including PubMed, PubChem, UniProt, ChEMBL, and AlphaFold DB.\n- [scientific-integrations](https://github.com/K-Dense-AI/claude-scientific-skills/tree/main/scientific-integrations) - Platform integrations for lab automation and workflow management (Benchling, DNAnexus, Opentrons, and more).\n- [scientific-packages](https://github.com/K-Dense-AI/claude-scientific-skills/tree/main/scientific-packages) - 58 specialized Python packages for bioinformatics, cheminformatics, machine learning, and data analysis.\n- [scientific-thinking](https://github.com/K-Dense-AI/claude-scientific-skills/tree/main/scientific-thinking) - Analysis tools and document processing for scientific writing, visualization, and methodology.\n\n\n\n## ✍️ Writing & Research  \n- [article-extractor](https://github.com/michalparkola/tapestry-skills-for-claude-code/tree/main/article-extractor) - Extract full article text and metadata from web pages.\n- [content-research-writer](https://github.com/ComposioHQ/awesome-claude-skills/tree/master/content-research-writer) - Assists in writing high-quality content by conducting research, adding citations, improving hooks, iterating on outlines, and providing real-time feedback on each section\n-  [internal-comms](https://github.com/anthropics/skills/tree/main/internal-comms) - Create internal communications\t(status reports, leadership updates, etc)\n- [brainstorming](https://github.com/obra/superpowers/tree/main/skills/brainstorming) - Transform rough ideas into fully-formed designs through structured questioning and alternative exploration.\n- [family-history-research](https://github.com/emaynard/claude-family-history-research-skill) - Provides assistance with planning family history and genea",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-01T02:28:47.532517"
  },
  {
    "basic_info": {
      "name": "open-agent-builder",
      "full_name": "firecrawl/open-agent-builder",
      "owner": "firecrawl",
      "description": "🔥 Visual workflow builder for AI agents powered by Firecrawl - drag-and-drop web scraping pipelines with real-time execution",
      "url": "https://github.com/firecrawl/open-agent-builder",
      "clone_url": "https://github.com/firecrawl/open-agent-builder.git",
      "ssh_url": "git@github.com:firecrawl/open-agent-builder.git",
      "homepage": null,
      "created_at": "2025-10-16T15:34:46Z",
      "updated_at": "2025-10-31T20:23:24Z",
      "pushed_at": "2025-10-20T15:15:47Z"
    },
    "stats": {
      "stars": 1712,
      "forks": 292,
      "watchers": 1712,
      "open_issues": 9,
      "size": 1104
    },
    "tech_info": {
      "language": "TypeScript",
      "languages": {
        "TypeScript": 1583973,
        "CSS": 48176,
        "JavaScript": 4757
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# Open Agent Builder\n\n<p align=\"center\">\n  <img src=\"https://media4.giphy.com/media/v1.Y2lkPTc5MGI3NjExcGNoY25xY2ptZTZtcDN6czBmdXJ2dnpkdWVjcXlqNXNhdjgyZXpkaiZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/tWtopK29eXAbvaDpi5/giphy.gif\" alt=\"Demo\" width=\"100%\" />\n</p>\n\n<div align=\"center\">\n\n**Build, test, and deploy AI agent workflows with a visual no-code interface**\n\n[![MIT License](https://img.shields.io/badge/License-MIT-green.svg)](https://choosealicense.com/licenses/mit/)\n[![Firecrawl](https://img.shields.io/badge/Powered%20by-Firecrawl-orange)](https://firecrawl.dev)\n\n[Documentation](#documentation) • [Examples](#example-workflows)\n\n</div>\n\n---\n\n## What is Open Agent Builder?\n\nOpen Agent Builder is a visual workflow builder for creating AI agent pipelines powered by [Firecrawl](https://firecrawl.dev). Design complex agent workflows with a drag-and-drop interface, then execute them with real-time streaming updates.\n\n**Perfect for:**\n- Web scraping and data extraction workflows\n- Multi-step AI agent pipelines\n- Automated research and content generation\n- Data transformation and analysis\n- Web automation with human-in-the-loop approvals\n\n> **Note:** This project is actively under development. Some features are still in progress and we welcome contributions and PRs!\n\n---\n\n## Key Features\n\n### Visual Workflow Builder\n- **Drag-and-drop interface** for building agent workflows\n- **Real-time execution** with streaming updates\n- **8 core node types**: Start, Agent, MCP Tools, Transform, If/Else, While Loop, User Approval, End\n- **Template library** with pre-built workflows\n- **MCP protocol support** for extensible tool integration\n\n### Powered by Firecrawl\n- **Native Firecrawl integration** for web scraping and searching\n\n### Enterprise Features\n- **LangGraph execution engine** for reliable state management\n- **Clerk authentication** for secure multi-user access\n- **Convex database** for persistent storage\n- **API endpoints** for programmatic execution\n- **Human-in-the-loop** approvals for sensitive operations\n\n---\n\n## Tech Stack\n\n| Technology | Purpose |\n|-----------|---------|\n| **[Firecrawl](https://firecrawl.dev)** | Web scraping API for converting websites into LLM-ready data |\n| **[Next.js 16 (canary)](https://nextjs.org/)** | React framework with App Router for frontend and API routes |\n| **[TypeScript](https://www.typescriptlang.org/)** | Type-safe development across the stack |\n| **[LangGraph](https://github.com/langchain-ai/langgraph)** | Workflow orchestration engine with state management, conditional routing, and human-in-the-loop support |\n| **[Convex](https://convex.dev)** | Real-time database with automatic reactivity for workflows, executions, and user data |\n| **[Clerk](https://clerk.com)** | Authentication and user management with JWT integration |\n| **[Tailwind CSS](https://tailwindcss.com/)** | Utility-first CSS framework for responsive UI |\n| **[React Flow](https://reactflow.dev/)** | Visual workflow builder canvas with drag-and-drop nodes |\n| **[Anthropic](https://www.anthropic.com/)** | Claude AI integration with native MCP support (Claude Haiku 4.5 & Sonnet 4.5) |\n| **[OpenAI](https://platform.openai.com/)** | gpt-5 integration (MCP support coming soon) |\n| **[Groq](https://groq.com/)** | Fast inference for open models (MCP support coming soon) |\n| **[E2B](https://e2b.dev)** | Sandboxed code execution for secure transform nodes |\n| **[Vercel](https://vercel.com)** | Deployment platform with edge functions |\n\n---\n\n## Prerequisites\n\nBefore you begin, you'll need:\n\n1. **Node.js 18+** installed on your machine\n2. **Firecrawl API key** (Required for web scraping) - [Get one here](https://firecrawl.dev)\n3. **Convex account** - [Sign up free](https://convex.dev)\n4. **Clerk account** - [Sign up free](https://clerk.com)\n\n> **Note:** LLM API keys can be added directly in the UI via Settings → API Keys after setup. For MCP tool support, Anthropic Claude (Haiku 4.5 or Sonnet 4.5) is currently recommended as the default option.\n\n---\n\n## Installation & Setup\n\n### 1. Clone the Repository\n\n```bash\ngit clone https://github.com/firecrawl/open-agent-builder.git\ncd open-agent-builder\nnpm install\n```\n\n### 2. Set Up Convex (Database)\n\nConvex handles all workflow and execution data persistence.\n\n```bash\n# Install Convex CLI globally\nnpm install -g convex\n\n# Initialize Convex project\nnpx convex dev\n```\n\nThis will:\n- Open your browser to create/link a Convex project\n- Generate a `NEXT_PUBLIC_CONVEX_URL` in your `.env.local`\n- Start the Convex development server\n\nKeep the Convex dev server running in a separate terminal.\n\n### 3. Set Up Clerk (Authentication)\n\nClerk provides secure user authentication and management.\n\n1. Go to [clerk.com](https://clerk.com) and create a new application\n2. In your Clerk dashboard:\n   - Go to **API Keys**\n   - Copy your keys\n3. Go to **JWT Templates** → **Convex**:\n   - Click \"Apply\"\n   - Copy the issuer URL\n\nAdd to your `.env.local`:\n\n```bash\n# Clerk Authentication\nNEXT_PUBLIC_CLERK_PUBLI",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-01T02:28:48.654832"
  },
  {
    "basic_info": {
      "name": "coralnpu",
      "full_name": "google-coral/coralnpu",
      "owner": "google-coral",
      "description": "A machine learning accelerator core designed for energy-efficient AI at the edge.",
      "url": "https://github.com/google-coral/coralnpu",
      "clone_url": "https://github.com/google-coral/coralnpu.git",
      "ssh_url": "git@github.com:google-coral/coralnpu.git",
      "homepage": null,
      "created_at": "2025-10-02T22:32:37Z",
      "updated_at": "2025-11-01T00:18:42Z",
      "pushed_at": "2025-10-31T22:59:25Z"
    },
    "stats": {
      "stars": 1680,
      "forks": 162,
      "watchers": 1680,
      "open_issues": 8,
      "size": 7850
    },
    "tech_info": {
      "language": "Emacs Lisp",
      "languages": {
        "Emacs Lisp": 8645255,
        "SystemVerilog": 3382583,
        "C++": 1035586,
        "Scala": 981036,
        "Python": 548626,
        "Starlark": 243246,
        "Tcl": 26057,
        "Perl": 22959,
        "Makefile": 20836,
        "Verilog": 19561,
        "Assembly": 14383,
        "Shell": 12186,
        "Linker Script": 6045,
        "Smarty": 3934,
        "Dockerfile": 3599,
        "C": 3107,
        "Forth": 1624
      },
      "license": "Apache License 2.0",
      "topics": []
    },
    "content": {
      "readme": "# Coral NPU\n\nCoral NPU is a hardware accelerator for ML inferencing. Coral NPU is an Open Source IP designed by Google Research and is freely available for integration into ultra-low-power System-on-Chips (SoCs) targeting wearable devices such as hearables, augmented reality (AR) glasses and smart watches.\n\nCoral NPU is a neural processing unit (NPU), also known as an AI accelerator or deep-learning processor. Coral NPU is based on the 32-bit RISC-V Instruction Set Architecture (ISA).\n\nCoral NPU includes three distinct processor components that work together: matrix, vector (SIMD), and scalar.\n\n![Coral NPU Archicture](doc/images/arch_overview_alpha.png)\n[Coral NPU Architecture Datasheet](https://developers.google.com/coral/guides/hardware/datasheet)\n\n## Coral NPU Features\nCoral NPU offers the following top-level feature set:\n\n* RV32IMF_Zve32x RISC-V instruction set (specifically `rv32imf_zve32x_zicsr_zifencei_zbb`)\n* 32-bit address space for applications and operating system kernels\n* Four-stage processor, in-order dispatch, out-of-order retire\n* Four-way scalar, two-way vector dispatch\n* 128-bit SIMD, 256-bit (future) pipeline\n* 8 KB ITCM memory (tightly-coupled memory for instructions)\n* 32 KB DTCM memory (tightly-coupled memory for data)\n* Both memories are single-cycle-latency SRAM, more efficient than cache memory\n* AXI4 bus interfaces, functioning as both manager and subordinate, to interact with external memory and allow external CPUs to configure Coral NPU\n\n## System Requirements\n\n* Bazel 6.2.1\n* Python 3.9-3.12 (3.13 support is in progress)\n\n## Quick Start\n\n```bash\n# Ensure that test suite passes\nbazel run //tests/cocotb:core_mini_axi_sim_cocotb\n\n# Build a binary\nbazel build //examples:coralnpu_v2_hello_world_add_floats\n\n# Build the Simulator (non-RVV for shorter build time):\nbazel build //tests/verilator_sim:core_mini_axi_sim\n\n# Run the binary on the simulator:\nbazel-bin/tests/verilator_sim/core_mini_axi_sim --binary bazel-out/k8-fastbuild-ST-dd8dc713f32d/bin/examples/coralnpu_v2_hello_world_add_floats.elf\n```\n\n\n![](doc/images/Coral_Logo_200px-2x.png)\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-01T02:28:49.767769"
  },
  {
    "basic_info": {
      "name": "openai-apps-sdk-examples",
      "full_name": "openai/openai-apps-sdk-examples",
      "owner": "openai",
      "description": "Example apps for the Apps SDK",
      "url": "https://github.com/openai/openai-apps-sdk-examples",
      "clone_url": "https://github.com/openai/openai-apps-sdk-examples.git",
      "ssh_url": "org-14957082@github.com:openai/openai-apps-sdk-examples.git",
      "homepage": null,
      "created_at": "2025-10-06T05:28:01Z",
      "updated_at": "2025-10-31T21:27:37Z",
      "pushed_at": "2025-10-24T18:10:15Z"
    },
    "stats": {
      "stars": 1584,
      "forks": 297,
      "watchers": 1584,
      "open_issues": 44,
      "size": 75
    },
    "tech_info": {
      "language": "JavaScript",
      "languages": {
        "JavaScript": 90169,
        "CSS": 64226,
        "TypeScript": 28507,
        "Python": 18640
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# Apps SDK Examples Gallery\n\n[![MIT License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)\n\nThis repository showcases example UI components to be used with the Apps SDK, as well as example MCP servers that expose a collection of components as tools.\nIt is meant to be used as a starting point and source of inspiration to build your own apps for ChatGPT.\n\n## MCP + Apps SDK overview\n\nThe Model Context Protocol (MCP) is an open specification for connecting large language model clients to external tools, data, and user interfaces. An MCP server exposes tools that a model can call during a conversation and returns results according to the tool contracts. Those results can include extra metadata—such as inline HTML—that the Apps SDK uses to render rich UI components (widgets) alongside assistant messages.\n\nWithin the Apps SDK, MCP keeps the server, model, and UI in sync. By standardizing the wire format, authentication, and metadata, it lets ChatGPT reason about your connector the same way it reasons about built-in tools. A minimal MCP integration for Apps SDK implements three capabilities:\n\n1. **List tools** – Your server advertises the tools it supports, including their JSON Schema input/output contracts and optional annotations (for example, `readOnlyHint`).\n2. **Call tools** – When a model selects a tool, it issues a `call_tool` request with arguments that match the user intent. Your server executes the action and returns structured content the model can parse.\n3. **Return widgets** – Alongside structured content, return embedded resources in the response metadata so the Apps SDK can render the interface inline in the Apps SDK client (ChatGPT).\n\nBecause the protocol is transport agnostic, you can host the server over Server-Sent Events or streaming HTTP—Apps SDK supports both.\n\nThe MCP servers in this demo highlight how each tool can light up widgets by combining structured payloads with `_meta.openai/outputTemplate` metadata returned from the MCP servers.\n\n## Repository structure\n\n- `src/` – Source for each widget example.\n- `assets/` – Generated HTML, JS, and CSS bundles after running the build step.\n- `pizzaz_server_node/` – MCP server implemented with the official TypeScript SDK.\n- `pizzaz_server_python/` – Python MCP server that returns the Pizzaz widgets.\n- `solar-system_server_python/` – Python MCP server for the 3D solar system widget.\n- `build-all.mts` – Vite build orchestrator that produces hashed bundles for every widget entrypoint.\n\n## Prerequisites\n\n- Node.js 18+\n- pnpm (recommended) or npm/yarn\n- Python 3.10+ (for the Python MCP server)\n- pre-commit for formatting\n\n## Install dependencies\n\nClone the repository and install the workspace dependencies:\n\n```bash\npnpm install\npre-commit install\n```\n\n> Using npm or yarn? Install the root dependencies with your preferred client and adjust the commands below accordingly.\n\n## Build the components gallery\n\nThe components are bundled into standalone assets that the MCP servers serve as reusable UI resources.\n\n```bash\npnpm run build\n```\n\nThis command runs `build-all.mts`, producing versioned `.html`, `.js`, and `.css` files inside `assets/`. Each widget is wrapped with the CSS it needs so you can host the bundles directly or ship them with your own server.\n\nTo iterate on your components locally, you can also launch the Vite dev server:\n\n```bash\npnpm run dev\n```\n\n## Serve the static assets\n\nIf you want to preview the generated bundles without the MCP servers, start the static file server after running a build:\n\n```bash\npnpm run serve\n```\n\nThe assets are exposed at [`http://localhost:4444`](http://localhost:4444) with CORS enabled so that local tooling (including MCP inspectors) can fetch them.\n\n## Run the MCP servers\n\nThe repository ships several demo MCP servers that highlight different widget bundles:\n\n- **Pizzaz (Node & Python)** – pizza-inspired collection of tools and components\n- **Solar system (Python)** – 3D solar system viewer\n\nEvery tool response includes plain text content, structured JSON, and `_meta.openai/outputTemplate` metadata so the Apps SDK can hydrate the matching widget.\n\n### Pizzaz Node server\n\n```bash\ncd pizzaz_server_node\npnpm start\n```\n\n### Pizzaz Python server\n\n```bash\npython -m venv .venv\nsource .venv/bin/activate\npip install -r pizzaz_server_python/requirements.txt\nuvicorn pizzaz_server_python.main:app --port 8000\n```\n\n### Solar system Python server\n\n```bash\npython -m venv .venv\nsource .venv/bin/activate\npip install -r solar-system_server_python/requirements.txt\nuvicorn solar-system_server_python.main:app --port 8000\n```\n\nYou can reuse the same virtual environment for all Python servers—install the dependencies once and run whichever entry point you need.\n\n## Testing in ChatGPT\n\nTo add these apps to ChatGPT, enable [developer mode](https://platform.openai.com/docs/guides/developer-mode), and add your apps in Settings > Connectors.\n\nTo add your local server without deploying it, you can use a tool like [ngrok](https:",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-01T02:28:50.890964"
  }
]