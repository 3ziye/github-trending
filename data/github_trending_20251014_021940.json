[
  {
    "basic_info": {
      "name": "beads",
      "full_name": "steveyegge/beads",
      "owner": "steveyegge",
      "description": "Beads - A memory upgrade for your coding agent",
      "url": "https://github.com/steveyegge/beads",
      "clone_url": "https://github.com/steveyegge/beads.git",
      "ssh_url": "git@github.com:steveyegge/beads.git",
      "homepage": "",
      "created_at": "2025-10-12T03:09:46Z",
      "updated_at": "2025-10-14T02:15:59Z",
      "pushed_at": "2025-10-13T08:06:05Z"
    },
    "stats": {
      "stars": 563,
      "forks": 23,
      "watchers": 563,
      "open_issues": 8,
      "size": 691
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 197325,
        "Shell": 5487
      },
      "license": "MIT License",
      "topics": [
        "agents",
        "claude-code",
        "coding"
      ]
    },
    "content": {
      "readme": "# bd - Beads Issue Tracker 🔗\n\n**Give your coding agent a memory upgrade**\n\n> **⚠️ Alpha Status**: This project is in active development. The core features work well, but expect API changes before 1.0. Use for development/internal projects first.\n\nBeads is a lightweight memory system for coding agents, using a graph-based issue tracker. Four kinds of dependencies work to chain your issues together like beads, making them easy for agents to follow for long distances, and reliably perform complex task streams in the right order.\n\nDrop Beads into any project where you're using a coding agent, and you'll enjoy an instant upgrade in organization, focus, and your agent's ability to handle long-horizon tasks over multiple compaction sessions. Your agents will use issue tracking with proper epics, rather than creating a swamp of rotten half-implemented markdown plans.\n\nInstant start:\n\n```bash\ncurl -fsSL https://raw.githubusercontent.com/steveyegge/beads/main/install.sh | bash\n```\n\nThen tell your coding agent to start using the `bd` tool instead of markdown for all new work, somewhere in your `AGENTS.md` or `CLAUDE.md`. That's all there is to it!\n\nYou don't use Beads directly as a human. Your coding agent will file and manage issues on your behalf. They'll file things they notice automatically, and you can ask them at any time to add or update issues for you.\n\nBeads gives agents unprecedented long-term planning capability, solving their amnesia when dealing with complex nested plans. They can trivially query the ready work, orient themselves, and land on their feet as soon as they boot up.\n\nAgents using Beads will no longer silently pass over problems they notice due to lack of context space -- instead, they will automatically file issues for newly-discovered work as they go. No more lost work, ever.\n\nBeads issues are backed by git, but through a clever design it manages to act like a managed, centrally hosted SQL database shared by all of the agents working on a project (repo), even across machines.\n\nBeads even improves work auditability. The issue tracker has a sophisticated audit trail, which agents can use to reconstruct complex operations that may have spanned multiple sessions.\n\nAgents report that they enjoy working with Beads, and they will use it spontaneously for both recording new work and reasoning about your project in novel ways. Whether you are a human or an AI, Beads lets you have more fun and less stress with agentic coding.\n\n![AI Agent using Beads](https://raw.githubusercontent.com/steveyegge/beads/main/.github/images/agent-using-beads.jpg)\n\n## Features\n\n- ✨ **Zero setup** - `bd init` creates project-local database (and your agent will do it)\n- 🔗 **Dependency tracking** - Four dependency types (blocks, related, parent-child, discovered-from)\n- 📋 **Ready work detection** - Automatically finds issues with no open blockers\n- 🤖 **Agent-friendly** - `--json` flags for programmatic integration\n- 📦 **Git-versioned** - JSONL records stored in git, synced across machines\n- 🌍 **Distributed by design** - Agents on multiple machines share one logical database via git\n- 🏗️ **Extensible** - Add your own tables to the SQLite database\n- 🔍 **Multi-project isolation** - Each project gets its own database, auto-discovered by directory\n- 🌲 **Dependency trees** - Visualize full dependency graphs\n- 🎨 **Beautiful CLI** - Colored output for humans, JSON for bots\n- 💾 **Full audit trail** - Every change is logged\n\n## Installation\n\n### Quick Install (Recommended)\n\n```bash\ncurl -fsSL https://raw.githubusercontent.com/steveyegge/beads/main/install.sh | bash\n```\n\nThe installer will:\n- Detect your platform (macOS/Linux, amd64/arm64)\n- Install via `go install` if Go is available\n- Fall back to building from source if needed\n- Guide you through PATH setup if necessary\n\n### Manual Install\n\n```bash\n# Using go install (requires Go 1.21+)\ngo install github.com/steveyegge/beads/cmd/bd@latest\n\n# Or build from source\ngit clone https://github.com/steveyegge/beads\ncd beads\ngo build -o bd ./cmd/bd\nsudo mv bd /usr/local/bin/  # or anywhere in your PATH\n```\n\n## Quick Start\n\n### For Humans\n\nBeads is designed for **AI coding agents** to use on your behalf. As a human, you typically just:\n\n```bash\n# 1. Initialize beads in your project\nbd init\n\n# 2. Add a note to your agent instructions (CLAUDE.md, AGENTS.md, etc.)\necho \"We track work in Beads instead of Markdown. Run \\`bd quickstart\\` to see how.\" >> CLAUDE.md\n\n# 3. Let agents handle the rest!\n```\n\nMost tasks will be created and managed by agents during conversations. You can check on things with:\n\n```bash\nbd list                  # See what's being tracked\nbd show <issue-id>       # Review a specific issue\nbd ready                 # See what's ready to work on\nbd dep tree <issue-id>   # Visualize dependencies\n```\n\n### For AI Agents\n\nRun the interactive guide to learn the full workflow:\n\n```bash\nbd quickstart\n```\n\nQuick reference for agent workflows:\n\n```bash\n# Find ready work\nbd ready --json | jq",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-14T02:19:41.147787"
  },
  {
    "basic_info": {
      "name": "blades",
      "full_name": "go-kratos/blades",
      "owner": "go-kratos",
      "description": "Blades is a Go-based multimodal AI Agent framework.",
      "url": "https://github.com/go-kratos/blades",
      "clone_url": "https://github.com/go-kratos/blades.git",
      "ssh_url": "git@github.com:go-kratos/blades.git",
      "homepage": "",
      "created_at": "2025-09-15T16:43:22Z",
      "updated_at": "2025-10-13T07:04:08Z",
      "pushed_at": "2025-10-13T17:29:54Z"
    },
    "stats": {
      "stars": 526,
      "forks": 55,
      "watchers": 526,
      "open_issues": 17,
      "size": 628
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 100718
      },
      "license": "MIT License",
      "topics": [
        "agent",
        "agentic-framework",
        "agentic-workflow",
        "ai",
        "golang",
        "workflow"
      ]
    },
    "content": {
      "readme": "## Blades\nBlades is a multimodal AI Agent framework in Go, supporting custom models, tools, memory, middleware, and more. It is well-suited for multi-turn conversations, chain reasoning, and structured output.\n> The name comes from the game God of War, set in Greek mythology, which tells the story of Kratos, who becomes a god of war and embarks on a divine slaughter. Blades are Kratos's iconic weapons.\n\n## Architecture Design\nBlades leverages the characteristics of Go to provide a flexible and efficient AI Agent solution. Its core lies in achieving high decoupling and extensibility through a unified interface and pluggable components. The overall architecture is as follows:\n![architecture](./docs/images/architecture.png)\n\n- **Go Idiomatic**: Built entirely in the Go way, the code style and user experience make Go developers feel at home.\n- **Easy to Use**: Through concise code, define an AI Agent and quickly deliver requirements, making complex logic clear, easy to manage, and maintain.\n- **Middleware Ecosystem**: Drawing inspiration from Kratos’s middleware design philosophy, features like Observability, Guardrails, and others can be easily integrated into the AI Agent.\n- **Highly Extensible**: Through a unified interface and pluggable components, achieve high decoupling and extensibility, making it easy to integrate different LLM models and external tools.\n\n## Core Concepts\nThe Blades framework achieves its powerful functionality and flexibility through a series of well-designed core components. These components work together to build the intelligent behavior of the Agent:\n\n* **Agent (Intelligent Entity)**: The core unit that executes tasks, capable of invoking models and tools.\n* **Prompt (Prompt Text)**: A templated text used to interact with LLMs, supporting dynamic variable substitution and complex context construction.\n* **Chain (Chain)**: Links multiple Agents or other Chains to form complex workflows.\n* **ModelProvider (Model)**: A pluggable LLM interface, allowing you to easily switch and integrate different language model services (such as OpenAI).\n* **Tool (Tool)**: External capabilities that the Agent can use, such as calling APIs, querying databases, accessing file systems, etc.\n* **Memory (Memory)**: Provides short-term or long-term memory capabilities for the Agent, enabling context-aware continuous conversations.\n* **Middleware (Middleware)**: Similar to middleware in web frameworks, it can implement cross-cutting control over the Agent.\n\n### Runner\n`Runner` is the most core interface in the Blades framework, defining the basic behavior of all executable components. Its design aims to provide a unified execution paradigm, achieving **decoupling, standardization, and high composability** of various functional modules within the framework through the `Run` and `RunStream` methods. Components such as `Agent`, `Chain`, and `ModelProvider` all implement this interface, unifying their execution logic and allowing different components to be flexibly combined like LEGO bricks to build complex AI Agents.\n\n```go\n// Runner represents an entity that can process prompts and generate responses.\ntype Runner interface {\n    // Run performs a synchronous, non-streaming operation, returning a complete Generation result.\n    Run(context.Context, *Prompt, ...ModelOption) (*Generation, error)\n    // RunStream performs an asynchronous, streaming operation, returning a Streamer for receiving Generation results step by step.\n    RunStream(context.Context, *Prompt, ...ModelOption) (Streamer[*Generation], error)\n}\n```\n![runner](docs/images/runner.png)\n\n### ModelProvider\n`ModelProvider` is the core abstraction layer in the `Blades` framework for interacting with underlying large language models (LLMs). Its design goal is to achieve **decoupling and extensibility** through a unified interface, separating the framework's core logic from the implementation details of specific models (such as OpenAI, DeepSeek, Gemini, etc.). It acts as an adapter, responsible for converting standardized requests within the framework into the format required by the native API of the model and converting the model's response back into the framework's standard format, thus allowing developers to easily switch and integrate different LLMs.\n\n```go\ntype ModelProvider interface {\n    // Generate performs a complete generation request and returns the result at once. Suitable for scenarios where real-time feedback is not needed.\n    Generate(context.Context, *ModelRequest, ...ModelOption) (*ModelResponse, error)\n    // NewStream initiates a streaming request. This method immediately returns a Streamer object, through which the caller can receive the generated content from the model step by step, suitable for building real-time, typewriter-effect conversation applications.\n    NewStream(context.Context, *ModelRequest, ...ModelOption) (Streamer[*ModelResponse], error)\n}\n```\n![ModelProvider](./docs/images/model.png)\n\n### Agent\n`Agent` is the core or",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-14T02:19:42.415528"
  },
  {
    "basic_info": {
      "name": "pgmcp",
      "full_name": "subnetmarco/pgmcp",
      "owner": "subnetmarco",
      "description": "An MCP server to query any Postgres database in natural language.",
      "url": "https://github.com/subnetmarco/pgmcp",
      "clone_url": "https://github.com/subnetmarco/pgmcp.git",
      "ssh_url": "git@github.com:subnetmarco/pgmcp.git",
      "homepage": "",
      "created_at": "2025-09-16T19:45:03Z",
      "updated_at": "2025-10-14T01:15:14Z",
      "pushed_at": "2025-09-25T18:19:25Z"
    },
    "stats": {
      "stars": 482,
      "forks": 48,
      "watchers": 482,
      "open_issues": 1,
      "size": 90
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 146324,
        "Shell": 4707,
        "Dockerfile": 259
      },
      "license": "Other",
      "topics": [
        "agent",
        "agentic-ai",
        "ai",
        "analytics",
        "artificial-intelligence",
        "data-analysis",
        "database",
        "kong",
        "mcp",
        "mcp-server",
        "postgres",
        "postgresql"
      ]
    },
    "content": {
      "readme": "[![ci](https://github.com/subnetmarco/pgmcp/actions/workflows/ci.yml/badge.svg)](https://github.com/subnetmarco/pgmcp/actions/workflows/ci.yml)\n[![Go Report Card](https://goreportcard.com/badge/github.com/subnetmarco/pgmcp)](https://goreportcard.com/report/github.com/subnetmarco/pgmcp)\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n\n# PGMCP - PostgreSQL Model Context Protocol Server\n\nPGMCP connects AI assistants to **any PostgreSQL database** through natural language queries. Ask questions in plain English and get structured SQL results with automatic streaming and robust error handling.\n\n**Works with**: Cursor, Claude Desktop, VS Code extensions, and any [MCP-compatible client](https://modelcontextprotocol.io/)\n\n## Quick Start\n\nPGMCP connects to **your existing PostgreSQL database** and makes it accessible to AI assistants through natural language queries.\n\n### Prerequisites\n- PostgreSQL database (existing database with your schema)\n- OpenAI API key (optional, for AI-powered SQL generation)\n\n### Basic Usage\n\n```bash\n# Set up environment variables\nexport DATABASE_URL=\"postgres://user:password@localhost:5432/your-existing-db\"\nexport OPENAI_API_KEY=\"your-api-key\"  # Optional\n\n# Run server (using pre-compiled binary)\n./pgmcp-server\n\n# Test with client in another terminal\n./pgmcp-client -ask \"What tables do I have?\" -format table\n./pgmcp-client -ask \"Who is the customer that has placed the most orders?\" -format table\n./pgmcp-client -search \"john\" -format table\n```\n\nHere is how it works:\n\n```\n👤 User / AI Assistant\n         │\n         │ \"Who are the top customers?\"\n         ▼\n┌─────────────────────────────────────────────────────────────┐\n│                    Any MCP Client                           │\n│                                                             │\n│  PGMCP CLI  │  Cursor  │  Claude Desktop  │  VS Code  │ ... │\n│  JSON/CSV   │  Chat    │  AI Assistant    │  Editor   │     │\n└─────────────────────────────────────────────────────────────┘\n         │\n         │ Streamable HTTP / MCP Protocol\n         ▼\n┌─────────────────────────────────────────────────────────────┐\n│                    PGMCP Server                             │\n│                                                             │\n│  🔒 Security    🧠 AI Engine      🌊 Streaming               │\n│  • Input Valid  • Schema Cache    • Auto-Pagination         │\n│  • Audit Log    • OpenAI API      • Memory Management       │\n│  • SQL Guard    • Error Recovery  • Connection Pool         │\n└─────────────────────────────────────────────────────────────┘\n         │\n         │ Read-Only SQL Queries\n         ▼\n┌─────────────────────────────────────────────────────────────┐\n│                Your PostgreSQL Database                     │\n│                                                             │\n│  Any Schema: E-commerce, Analytics, CRM, etc.               │\n│  Tables • Views • Indexes • Functions                       │\n└─────────────────────────────────────────────────────────────┘\n\nExternal AI Services:\nOpenAI API • Anthropic • Local LLMs (Ollama, etc.)\n\nKey Benefits:\n✅ Works with ANY PostgreSQL database (no assumptions about schema)\n✅ No schema modifications required  \n✅ Read-only access (100% safe)\n✅ Automatic streaming for large results\n✅ Intelligent query understanding (singular vs plural)\n✅ Robust error handling (graceful AI failure recovery)\n✅ PostgreSQL case sensitivity support (mixed-case tables)\n✅ Production-ready security and performance\n✅ Universal database compatibility\n✅ Multiple output formats (table, JSON, CSV)\n✅ Free-text search across all columns\n✅ Authentication support\n✅ Comprehensive testing suite\n```\n\n## Features\n\n- **Natural Language to SQL**: Ask questions in plain English\n- **Automatic Streaming**: Handles large result sets automatically  \n- **Safe Read-Only Access**: Prevents any write operations\n- **Text Search**: Search across all text columns\n- **Multiple Output Formats**: Table, JSON, and CSV\n- **PostgreSQL Case Sensitivity**: Handles mixed-case table names correctly\n- **Universal Compatibility**: Works with any PostgreSQL database\n\n### Environment Variables\n\n**Required:**\n- `DATABASE_URL`: PostgreSQL connection string to your existing database\n\n**Optional:**\n- `OPENAI_API_KEY`: OpenAI API key for AI-powered SQL generation\n- `OPENAI_MODEL`: Model to use (default: \"gpt-4o-mini\")\n- `HTTP_ADDR`: Server address (default: \":8080\")\n- `HTTP_PATH`: MCP endpoint path (default: \"/mcp\")\n- `AUTH_BEARER`: Bearer token for authentication\n\n## Installation\n\n### Download Pre-compiled Binaries\n\n1. Go to [GitHub Releases](https://github.com/subnetmarco/pgmcp/releases)\n2. Download the binary for your platform (Linux, macOS, Windows)\n3. Extract and run:\n\n```bash\n# Example for macOS/Linux\ntar xzf pgmcp_*.tar.gz\ncd pgmcp_*\n./pgmcp-server\n```\n\n### Alternative Options\n\n```bash\n# Homebrew (macOS/Linux) - Available after first release\nbrew tap subnetmarco/homebrew-tap\nbrew inst",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-14T02:19:43.686607"
  },
  {
    "basic_info": {
      "name": "blaze",
      "full_name": "wizenheimer/blaze",
      "owner": "wizenheimer",
      "description": "Full Text Search Engine - built for Hackers not Hyperscalers",
      "url": "https://github.com/wizenheimer/blaze",
      "clone_url": "https://github.com/wizenheimer/blaze.git",
      "ssh_url": "git@github.com:wizenheimer/blaze.git",
      "homepage": "https://wizenheimer.github.io/blaze",
      "created_at": "2025-10-07T07:28:01Z",
      "updated_at": "2025-10-14T01:57:46Z",
      "pushed_at": "2025-10-13T16:06:44Z"
    },
    "stats": {
      "stars": 398,
      "forks": 8,
      "watchers": 398,
      "open_issues": 1,
      "size": 1161
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 241240,
        "Makefile": 3689
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# Blaze\n\n<div align=\"center\">\n  <img alt=\"image\" src=\"./media/image.png\" />\n  <p>\n    <a href=\"https://wizenheimer.github.io/blaze/\"><strong>Docs </strong> </a>\n  </p>\n</div>\n\n**Built for hackers, not hyperscalers.**  \nA tiny, hackable full-text search engine you can actually fit in your head. Features inverted indexing, boolean queries, phrase search, proximity queries, and BM25 ranking—powered by a flexible query engine, roaring bitmaps, and skip lists.\n\n## Table of Contents\n\n- [Overview](#overview)\n- [Features](#features)\n- [Not for Everyone](#not-for-everyone)\n- [Installation](#installation)\n- [Quick Start](#quick-start)\n- [Core Concepts](#core-concepts)\n  - [Inverted Index](#inverted-index)\n  - [Skip Lists](#skip-lists)\n  - [Text Analysis Pipeline](#text-analysis-pipeline)\n  - [Search Operations](#search-operations)\n- [Query Builder API](#query-builder-api)\n  - [Why Use Builder Pattern](#why-use-builder-pattern)\n  - [Quick Start](#query-builder-quick-start)\n  - [Core Methods](#query-builder-core-methods)\n  - [Boolean Operations](#boolean-operations)\n  - [Query Patterns](#query-patterns)\n  - [Performance](#query-builder-performance)\n  - [Best Practices](#query-builder-best-practices)\n- [API Reference](#api-reference)\n- [Examples](#examples)\n- [Performance Characteristics](#performance-characteristics)\n- [Configuration](#configuration)\n- [Use Cases](#use-cases)\n- [Testing](#testing)\n- [Architecture](#architecture)\n- [Best Practices](#best-practices)\n- [Contributing](#contributing)\n- [Related Projects](#related-projects)\n- [License](#license)\n\n## Overview\n\nBlaze is a Go engine that provides fast, full-text search capabilities through an inverted index implementation. It's designed for applications that need to search through text documents efficiently without relying on external search engines.\n\n> **Looking for hybrid search indexes?** Check out [Comet](https://github.com/wizenheimer/comet) - a companion project for hybrid vector search that brings together BM25, Flat, HNSW, IVF, PQ and IVFPQ indexes. It pairs hybrid retrieval with reciprocal rank fusion, autocut, pre-filtering, semantic search, full-text search, and multi-KNN searches, and multi-query operations — all in pure Go.\n>\n> Understand search internals from the inside out. Built for hackers, not hyperscalers.\n\n**Key Highlights:**\n\n- **Inverted Index**: Maps terms to document positions for instant lookups\n- **Skip Lists**: Probabilistic data structure providing O(log n) operations\n- **Query Builder**: Type-safe, fluent API for boolean queries with roaring bitmaps\n- **Advanced Search**: Phrase search, BM25 ranking, proximity ranking, and boolean queries\n- **BM25 Algorithm**: Industry-standard relevance scoring with IDF and length normalization\n- **Text Analysis**: Tokenization, stemming, stopword filtering, and case normalization\n- **Thread-Safe**: Concurrent indexing with mutex protection\n- **Serialization**: Efficient binary format for persistence\n\n## Features\n\n### Search Capabilities\n\n- **Term Search**: Find documents containing specific terms\n- **Phrase Search**: Exact multi-word matching (\"quick brown fox\")\n- **Boolean Queries**: Type-safe AND, OR, NOT operations with query builder\n- **BM25 Ranking**: Industry-standard relevance scoring (used by Elasticsearch, Solr)\n- **Proximity Ranking**: Score results by term proximity\n- **Position Tracking**: Track exact word positions within documents\n- **Roaring Bitmaps**: Compressed bitmap operations for fast boolean queries\n\n### Text Processing\n\n- **Tokenization**: Unicode-aware text splitting\n- **Stemming**: Snowball (Porter2) stemmer for English\n- **Stopword Filtering**: Remove common words (the, a, is, etc.)\n- **Case Normalization**: Case-insensitive search\n- **Configurable Pipeline**: Customize analysis behavior\n\n### Data Structures\n\n- **Skip Lists**: O(log n) search, insert, and delete operations\n- **Inverted Index**: Efficient term-to-position mapping\n- **Binary Serialization**: Compact storage format\n\n## Not for Everyone\n\nWe'd admit, Blaze isn't for everyone. If you're looking for a production-ready, battle-tested full-text search engine, check out [Bleve](https://github.com/blevesearch/bleve) - a modern, feature-rich indexing library in Go.\n\nIf you need **vector search** or **hybrid search** capabilities, check out [Comet](https://github.com/wizenheimer/comet) - **built for hackers, not hyperscalers**. It's a high-performance hybrid vector index written in Go that brings together multiple indexing strategies and search modalities. Comet supports:\n\n- **Multiple Index Types**: Flat (exact), HNSW (graph), IVF (clustering), PQ (quantization), and IVFPQ (hybrid)\n- **Full-Text Search**: BM25 ranking with tokenization and normalization\n- **Metadata Filtering**: Fast filtering using Roaring Bitmaps and Bit-Sliced Indexes\n- **Hybrid Retrieval**: Reciprocal Rank Fusion, semantic search, multi-KNN, and multi-query operations\n- **Advanced Features**: Quantization, reranking, autocut, pre-filtering, soft d",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-14T02:19:44.996513"
  },
  {
    "basic_info": {
      "name": "better-curl-saul",
      "full_name": "DeprecatedLuar/better-curl-saul",
      "owner": "DeprecatedLuar",
      "description": "Did you know you have rights? The FOSS says you do... Better Curl Saul is my homemade CLI 'http client' to make api reusability simple.",
      "url": "https://github.com/DeprecatedLuar/better-curl-saul",
      "clone_url": "https://github.com/DeprecatedLuar/better-curl-saul.git",
      "ssh_url": "git@github.com:DeprecatedLuar/better-curl-saul.git",
      "homepage": "",
      "created_at": "2025-09-18T09:00:50Z",
      "updated_at": "2025-10-14T02:12:28Z",
      "pushed_at": "2025-10-13T18:13:19Z"
    },
    "stats": {
      "stars": 247,
      "forks": 7,
      "watchers": 247,
      "open_issues": 2,
      "size": 1607
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 130497,
        "Shell": 6284,
        "Nix": 1524
      },
      "license": "MIT License",
      "topics": [
        "api",
        "api-client",
        "cli-tool",
        "curl",
        "curl-commands",
        "golang",
        "http",
        "http-client",
        "http-requests",
        "linux",
        "macos",
        "windows"
      ]
    },
    "content": {
      "readme": "<h3 align=\"center\">When HTTP gets complicated...</h3>\n<p align=\"center\">\n  <img src=\"other/assets/saul-logo (1).png\" width=\"600\"/>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/DeprecatedLuar/better-curl-saul/stargazers\">\n    <img src=\"https://img.shields.io/github/stars/DeprecatedLuar/better-curl-saul?style=for-the-badge&logo=github&color=1f6feb&logoColor=white&labelColor=black\"/>\n  </a>\n  <a href=\"https://github.com/DeprecatedLuar/better-curl-saul/releases\">\n    <img src=\"https://img.shields.io/github/v/release/DeprecatedLuar/better-curl-saul?style=for-the-badge&logo=go&color=00ADD8&logoColor=white&labelColor=black\"/>\n  </a>\n  <a href=\"https://github.com/DeprecatedLuar/homebrew-tap\">\n    <img src=\"https://img.shields.io/badge/Homebrew-tap-FBB040?style=for-the-badge&logo=homebrew&logoColor=white&labelColor=black\"/>\n  </a>\n  <a href=\"/nix-saul\">\n    <img src=\"https://img.shields.io/badge/Nix-flake-5277C3?style=for-the-badge&logo=nixos&logoColor=white&labelColor=black\"/>\n  </a>\n  <a href=\"https://github.com/DeprecatedLuar/better-curl-saul/blob/main/LICENSE\">\n    <img src=\"https://img.shields.io/github/license/DeprecatedLuar/better-curl-saul?style=for-the-badge&color=green&labelColor=black\"/>\n  </a>\n</p>\n\n**v0.3.0 Try out the new curl import/exporting**: `saul myapi set --raw` and `saul myapi get --raw` \n\n---\n\n\n<p align=\"center\">\n  <img src=\"other/assets/saul-catboy-final.png\" width=\"700\"/>\n</p>\n\n<p align=\"center\"> Better Curl Saul is a way to simplify and organize api re-callability (if that's a word)</p>\n \n ---\n\n## **In a nutshell,** this is... not my favorite UX:\n```bash\ncurl -X POST \"https://company.atlassian.net/rest/api/3/issue\" \\\n  -H \"Authorization: Basic $(echo -n 'user@company.com:api-token-here' | base64)\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Accept: application/json\" \\\n  -H \"X-Atlassian-Token: no-check\" \\\n  -d '{\n    \"fields\": {\n      \"project\": {\"key\": \"PROJ\"},\n      \"summary\": \"API Bug: Users can'\\''t login after deployment\",\n      \"description\": \"Steps:\\n1. Deploy v2.1.0\\n2. Try login\\n3. Gets 500 error\\n\\nExpected: Login works\\nActual: Server error\",\n      \"issuetype\": {\"name\": \"Bug\"},\n      \"priority\": {\"name\": \"High\"},\n      \"assignee\": {\"accountId\": \"123456:abcd-efgh-ijkl\"},\n      \"labels\": [\"api\", \"login\", \"production\"],\n      \"customfield_10001\": \"2024-01-15\",\n      \"customfield_10002\": {\"value\": \"Backend Team\"}\n    }\n  }'\n```\n\n# Try this instead\n<p align=\"center\">\n  <img src=\"other/assets/demo.gif\" alt=\"Better-Curl Demo\" width=\"800\"/>\n</p>\n\n---\n\n## The nice features you've never seen before\n\n- **Workspace-based** - Each API gets its own organized folder (reusable)\n- **Inline editor** - the `edit` command for any given field also supports `$EDITOR`\n- **Smart variables** - `{@token}` persists,`{?name}` prompts every time\n- **Response filtering** - Show only the fields you care about\n- **Git-friendly** - Store the preset workspaces on git\n- **Unix composable** - Script it, pipe it, shell it\n- **TOML converter** - JSON gets reorganized into TOML for readability\n- **Saul Goodman** - It has Saul Goodman on it.\n  \n<img src=\"other/assets/saul-hd-wide.png\" width=\"1000\"/>\n\n\n# Installation\n\n![macOS](https://img.shields.io/badge/macOS-black?style=flat-square&logo=apple&logoColor=white) ![Linux](https://img.shields.io/badge/Linux-FCC624?style=flat-square&logo=linux&logoColor=black) ![Windows](https://img.shields.io/badge/Windows-0078D4?style=flat-square&logo=windows11&logoColor=white) ![Nix](https://img.shields.io/badge/Nix-5277C3?style=flat-square&logo=nixos&logoColor=white)\n\n### Universal\n```bash\ncurl -sSL https://raw.githubusercontent.com/DeprecatedLuar/better-curl-saul/main/install.sh | bash\n```\n\n### Homebrew\n```bash\nbrew install deprecatedluar/tap/better-curl-saul\n```\n\n### NixOS\n```bash\nnix profile install github:DeprecatedLuar/better-curl-saul?dir=nix-saul\n```\n\n<details>\n<summary>Other Install Methods</summary>\n\n<br>\n\n**Manual Install**\n1. Download binary for your OS from [releases](https://github.com/DeprecatedLuar/better-curl-saul/releases)\n2. Make executable: `chmod +x saul-*`\n3. Move to PATH: `sudo mv saul-* /usr/local/bin/saul`\n\n---\n\n**From Source** (for try-harders)\n```bash\ngit clone https://github.com/DeprecatedLuar/better-curl-saul.git\ncd better-curl-saul\n./other/install-local.sh  # Local development build\n```\n\n---\n\n**In case you already have Saul** (basically gambling at this point)\n```bash\nsaul temp set url https://raw.githubusercontent.com/DeprecatedLuar/better-curl-saul/main/install.sh && saul temp call --raw | bash\n```\n\n>[!NOTE]\n> Quick install auto-detects your system and downloads binaries or builds from source as fallback.\n> Windows users: I don't know powershell I expect you to have bash 👍\n\n</details>\n\n<br>\n\n---\n\n## Commands\n\n| Action | Targets                                                            | Description                              | Example                                    |\n|--------|----------------------------------------------------------",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-14T02:19:46.245275"
  },
  {
    "basic_info": {
      "name": "resterm",
      "full_name": "unkn0wn-root/resterm",
      "owner": "unkn0wn-root",
      "description": "Terminal REST client for .http/.rest files with HTTP, GraphQL and gRPC support.",
      "url": "https://github.com/unkn0wn-root/resterm",
      "clone_url": "https://github.com/unkn0wn-root/resterm.git",
      "ssh_url": "git@github.com:unkn0wn-root/resterm.git",
      "homepage": "",
      "created_at": "2025-09-30T11:47:23Z",
      "updated_at": "2025-10-13T22:50:03Z",
      "pushed_at": "2025-10-13T22:50:00Z"
    },
    "stats": {
      "stars": 242,
      "forks": 4,
      "watchers": 242,
      "open_issues": 0,
      "size": 5679
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 757516,
        "Shell": 847
      },
      "license": "Apache License 2.0",
      "topics": [
        "go",
        "golang",
        "rest",
        "rest-api",
        "rest-client",
        "tui",
        "tui-app"
      ]
    },
    "content": {
      "readme": "<h1 align=\"center\">Resterm</h1>\n\n<p align=\"center\">\n  <em>a terminal-based REST/GraphQL/gRPC client.</em>\n</p>\n\n<p align=\"center\">\n  <img src=\"_media/resterm.png\" alt=\"Screenshot of resterm TUI\" width=\"720\" />\n</p>\n\n<p align=\"center\">\n  <img src=\"_media/resterm2.png\" alt=\"Screenshot of resterm workflow run\" width=\"720\" />\n</p>\n\n> [!NOTE]\n> See the documentation [`docs/resterm.md`](./docs/resterm.md) for a complete breakdown of all technical aspects and features.\n\n## Overview\n\nResterm is a terminal-first client for working **HTTP**, **GraphQL**, and **gRPC** services. It pairs a Vim-like-style editor with a workspace explorer, response diff, history and scripting so you can iterate on requests without leaving the keyboard.\n\n## Highlights\n- **Editor** with inline syntax highlighting, search (`Ctrl+F`), and clipboard motions.\n- **Workspace** navigator that filters `.http` / `.rest` files, supports recursion and keeps request lists in sync as you edit.\n- **Inline** requests and curl import for one-off calls (`Ctrl+Enter` on a URL or curl block).\n- **Pretty/Raw/Header/Diff/History** views with optional split panes and pinned comparisons.\n- **Variable** scopes, captures, JavaScript hooks, and multi-step workflows with per-step expectations and overrides.\n- **GraphQL** helpers (`@graphql`, `@variables`, `@query`) and gRPC directives (`@grpc`, `@grpc-descriptor`, reflection, metadata).\n- **Built-in** OAuth 2.0 client plus support for basic, bearer, API key, and custom header auth.\n- **Latency** with `@profile` to benchmark endpoints and render histograms right inside the TUI.\n- **Multi-step workflows** let you compose several named requests into one workflow (`@workflow` + `@step`), override per-step variables, and review aggregated results in History.\n\n## Documentation\n\nThe full reference, including request syntax, metadata, directive tables, scripting APIs, transport settings and advanced workflows, lives in [`docs/resterm.md`](./docs/resterm.md).\n\n## Installation\n\n> [!NOTE]\n> The install helper uses `curl` and `jq`. Install `jq` with your package manager (`brew install jq`, `sudo apt install jq`, etc.).\n\n### Linux / macOS\n\n```bash\n# Detect latest tag\nLATEST_TAG=$(curl -fsSL https://api.github.com/repos/unkn0wn-root/resterm/releases/latest | jq -r .tag_name)\n\n# Download the matching binary (Darwin/Linux + amd64/arm64)\ncurl -fL -o resterm \"https://github.com/unkn0wn-root/resterm/releases/download/${LATEST_TAG}/resterm_$(uname -s)_$(uname -m)\"\n\n# Make it executable and move it onto your PATH\nchmod +x resterm\nsudo install -m 0755 resterm /usr/local/bin/resterm\n```\n\n### Windows (PowerShell)\n\n```powershell\n$latest = Invoke-RestMethod https://api.github.com/repos/unkn0wn-root/resterm/releases/latest\n$asset  = $latest.assets | Where-Object { $_.name -like 'resterm_Windows_*' } | Select-Object -First 1\nInvoke-WebRequest -Uri $asset.browser_download_url -OutFile resterm.exe\n# Optionally relocate to a directory on PATH, e.g.:\nMove-Item resterm.exe \"$env:USERPROFILE\\bin\\resterm.exe\"\n```\n\n### From source\n\n```bash\ngo install github.com/unkn0wn-root/resterm/cmd/resterm@latest\n```\n\n## Quick Start\n\n1. Create or open a directory that contains `.http` / `.rest` files (see `_examples/` for samples). If you want to start right away without any .http - just open resterm...\n2. ... or launch Resterm: `resterm --workspace path/to/project` (or if your .http/.rest file is in the same dir. - just type `resterm` and it will be autodiscovered).\n3. Pick a request from the sidebar and press `Ctrl+Enter` to send it. Responses appear in the right pane. If you don't have any .http file, just switch to the editor (`Tab`) and type `https://<some_url_dot_something>` and press `Ctrl+Enter`.\n4. Move between panes with `Tab` / `Shift+Tab`, jump directly with `g+r` (requests), `g+i` (editor), `g+p` (response), and adjust the editor/response width with `g+h` / `g+l`.\n5. Use `Ctrl+E` to switch environments, `Ctrl+G` to inspect captured globals, and `Ctrl+V` / `Ctrl+U` to split the response pane when comparing calls.\n\nA minimal request file:\n\n```http\n### Status check\n# @name status\nGET https://httpbin.org/status/204\nUser-Agent: resterm\n\n### Authenticated echo\n# @name bearerEcho\n# @auth bearer {{auth.token}}\nGET https://httpbin.org/bearer\nAccept: application/json\n```\n\n## Workflows\n\n- Combine existing requests with `@workflow` + `@step` blocks to build repeatable scenarios that run inside the TUI.\n- Set per-step assertions (`expect.status`, `expect.statuscode`) and pass data between steps via `vars.request.*` and `vars.workflow.*` namespaces.\n- View progress in the sidebar, and inspect the aggregated summary in History after the run.\n- See [`docs/resterm.md`](./docs/resterm.md#workflows-multi-step-workflows) for the full reference and `_examples/workflows.http` for a runnable sample workflow.\n\n## Quick Configuration Overview\n\n- Environment files: `resterm.env.json` (or legacy `rest-client.env.json`) discovered in the file directory, workspace root, or curren",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-14T02:19:47.556752"
  },
  {
    "basic_info": {
      "name": "tunn",
      "full_name": "strandnerd/tunn",
      "owner": "strandnerd",
      "description": "SSH tunnels made simple: Launch and monitor SSH tunnels from a single YAML config and your existing OpenSSH setup.",
      "url": "https://github.com/strandnerd/tunn",
      "clone_url": "https://github.com/strandnerd/tunn.git",
      "ssh_url": "git@github.com:strandnerd/tunn.git",
      "homepage": "",
      "created_at": "2025-09-23T03:13:27Z",
      "updated_at": "2025-10-13T04:45:06Z",
      "pushed_at": "2025-09-24T02:21:54Z"
    },
    "stats": {
      "stars": 233,
      "forks": 8,
      "watchers": 233,
      "open_issues": 3,
      "size": 46
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 64829,
        "Shell": 2298
      },
      "license": "MIT License",
      "topics": [
        "golang",
        "ssh",
        "ssh-tunnel",
        "tunneling"
      ]
    },
    "content": {
      "readme": "![GitHub License](https://img.shields.io/github/license/strandnerd/tunn) ![GitHub Actions Workflow Status](https://img.shields.io/github/actions/workflow/status/strandnerd/tunn/ci.yml) ![GitHub Release](https://img.shields.io/github/v/release/strandnerd/tunn) ![GitHub Issues or Pull Requests](https://img.shields.io/github/issues/strandnerd/tunn)\n\n\n\n# tunn - SSH Tunnel Manager\n\n`tunn` is a developer-friendly wrapper around OpenSSH that makes it easy to manage multiple SSH tunnels defined in a simple configuration file\n\n<img width=\"1536\" height=\"649\" alt=\"tunn-gophers\" src=\"https://github.com/user-attachments/assets/9b88aa87-721b-4577-b0c1-2cf61af4d160\" />\n\n## Features\n\n- 🚀 **Simple Configuration**: Define all your tunnels in a single YAML file\n- 🔧 **Selective Tunnels**: Run all tunnels or specific ones by name\n- 🔌 **Multiple Ports**: Support for multiple port mappings per tunnel\n- 🔐 **SSH Integration**: Leverages your existing SSH configuration\n- ⚡ **Parallel Execution**: All tunnels run concurrently\n- 🧩 **Daemon Mode**: Background service with status reporting via IPC\n- 🧼 **Lean Go Module**: Depends only on `gopkg.in/yaml.v3`, keeping builds clean and portable\n- 🔧 **Native SSH Sessions**: Spawns the system `ssh` binary for each mapping, so keys and config behave exactly like your shell\n- 🎚️ **Per-Port Processes**: Launches one PID per port to pave the way for fine-grained lifecycle controls\n\n\n\n![Screencast from 2025-09-23 22-19-13 (online-video-cutter com)](https://github.com/user-attachments/assets/dbce86b1-c40c-47b9-a89c-6e188ad6e4ee)\n\n\n\n\n## Installation\n\n### Quick Install\n\n```bash\ncurl -sSL https://raw.githubusercontent.com/strandnerd/tunn/main/scripts/install.sh | sudo sh\n```\n\n### From Go Install\n\n```bash\ngo install github.com/strandnerd/tunn@latest\n```\n\n### Build Locally\n\n```bash\ngit clone https://github.com/strandnerd/tunn.git\ncd tunn\ngo build -o tunn\nsudo mv tunn /usr/local/bin/\n```\n\n## Configuration\n\nCreate a `~/.tunnrc` file in your home directory:\n\n```yaml\ntunnels:\n  api:\n    host: myserver          # SSH host from ~/.ssh/config\n    ports:\n      - 3000:3000           # local:remote port mapping\n      - 4000:4001\n    user: apiuser           # optional: SSH user\n    identity_file: ~/.ssh/id_rsa  # optional: SSH key\n\n  db:\n    host: database\n    ports:\n      - 3306:3306           # MySQL\n      - 5432:5432           # PostgreSQL\n    user: dbadmin           # optional: overrides SSH config\n\n  cache:\n    host: cacheserver\n    ports:\n      - 6379:6379           # Redis\n```\n\n### Configuration Fields\n\n- `tunnels`: Map of tunnel names\n- `host`: SSH host alias from `~/.ssh/config`\n- `ports`: List of port mappings in `local:remote` format\n- `user` (optional): SSH username (overrides `~/.ssh/config`)\n- `identity_file` (optional): Path to SSH private key\n\n## Usage\n\n### Run All Tunnels\n\n```bash\ntunn\n```\n\n### Run Specific Tunnels\n\n```bash\n# Single tunnel\ntunn api\n\n# Multiple tunnels\ntunn api db\n\n# All database-related tunnels\ntunn db cache\n```\n\n### Run Tunnels in the Background\n\n```bash\ntunn --detach\n\n# Or only specific tunnels\ntunn --detach api db\n```\n\nThe CLI respawns itself as a daemon, stores metadata under `$XDG_RUNTIME_DIR/tunn` (or `~/.cache/tunn` when the runtime dir is unavailable), and immediately returns control to the terminal.\n\n### Check Daemon Status\n\n```bash\ntunn status\n```\n\nThe status command contacts the daemon's Unix socket, reporting the PID, mode, and the latest port states for each managed tunnel. If no daemon is running, a friendly message is printed instead.\n\n### Stop the Daemon\n\n```bash\ntunn stop\n```\n\nThe stop command asks the daemon to shut down cleanly, waits for it to exit, and reports success.\n\n### Output Example\n\n```\nTunnels Ready\n\n[api]\n    3000 ➜ 3000 [active]\n    4000 ➜ 4001 [active]\n[db]\n    3306 ➜ 3306 [connecting]\n    5432 ➜ 5432 [active]\n```\n\n## SSH Configuration\n\n`tunn` uses your system's SSH configuration. Make sure your hosts are defined in `~/.ssh/config`:\n\n```ssh\nHost myserver\n    HostName 192.168.1.100\n    User myuser\n    Port 22\n\nHost database\n    HostName db.example.com\n    User dbuser\n    IdentityFile ~/.ssh/db_key\n```\n\n## Requirements\n\n- Go 1.21 or higher (for building)\n- OpenSSH client (`ssh` command)\n- Valid SSH configuration\n- macOS and Linux are supported today; Windows support is planned but not available yet\n\n## Daemon Runtime Files\n\nWhile running in detached mode, `tunn` stores the following files in its runtime directory:\n\n- `daemon.pid` – PID of the active daemon; used to prevent duplicate launches.\n- `daemon.sock` – Unix domain socket for control commands (e.g., `tunn status`).\n- `daemon.log` – Aggregated stdout/stderr from the daemon process.\n\nThe directory is created with `0700` permissions, and files are cleaned up automatically when the daemon exits or when stale state is detected on the next launch.\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-14T02:19:48.887167"
  },
  {
    "basic_info": {
      "name": "auditkit",
      "full_name": "guardian-nexus/auditkit",
      "owner": "guardian-nexus",
      "description": "AuditKit - Multi-Cloud Compliance Scanner & Evidence Collection",
      "url": "https://github.com/guardian-nexus/auditkit",
      "clone_url": "https://github.com/guardian-nexus/auditkit.git",
      "ssh_url": "git@github.com:guardian-nexus/auditkit.git",
      "homepage": "https://auditkit.io/",
      "created_at": "2025-09-19T03:34:03Z",
      "updated_at": "2025-10-13T21:33:32Z",
      "pushed_at": "2025-10-13T21:33:44Z"
    },
    "stats": {
      "stars": 184,
      "forks": 26,
      "watchers": 184,
      "open_issues": 1,
      "size": 1521
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 499332,
        "Shell": 1049,
        "Makefile": 827
      },
      "license": "Other",
      "topics": [
        "aws",
        "azure",
        "compliance",
        "golang",
        "pci-dss",
        "security",
        "soc2"
      ]
    },
    "content": {
      "readme": "# AuditKit - Open-Source Compliance Scanner\n\n**Scan AWS, Azure, and M365 for SOC2, PCI-DSS, HIPAA, and CMMC compliance. Get audit-ready reports in minutes.**\n\n[![GitHub stars](https://img.shields.io/github/stars/guardian-nexus/auditkit)](https://github.com/guardian-nexus/auditkit/stargazers)\n[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n[![Version](https://img.shields.io/badge/version-v0.6.6-green.svg)](https://github.com/guardian-nexus/auditkit/releases)\n[![Newsletter](https://img.shields.io/badge/Newsletter-Subscribe-orange)](https://auditkit.substack.com)\n---\n\n## Quick Start\n\n```bash\n# Install\ngit clone https://github.com/guardian-nexus/auditkit\ncd auditkit/scanner\ngo build ./cmd/auditkit\n\n# Scan AWS for SOC2\naws configure\n./auditkit scan -provider aws -framework soc2\n\n# Generate PDF report\n./auditkit scan -provider aws -framework soc2 -format pdf -output report.pdf\n```\n\n**That's it.** You'll get a compliance score and list of what needs fixing.\n\n---\n\n## What It Does\n\nAuditKit automates the **technical controls** for compliance audits:\n\n- Scans your cloud infrastructure (AWS, Azure, M365)\n- Checks ~150 automated controls per framework\n- Shows exact CLI commands to fix issues\n- Generates PDF/HTML reports auditors understand\n- Tracks your progress over time\n\n**What it doesn't do:** Replace your auditor, scan for vulnerabilities, or handle organizational policies.\n\n---\n\n## Examples and Sample Reports\n\n### Terminal Output\n\nHere's what you see when running AuditKit against your cloud environment:\n\n![Terminal Scan Output](./docs/examples/screenshots/azure-cmmc-scan-console-output-sample.png)\n\n### HTML Report Preview\n\nInteractive HTML reports with compliance scores, automated vs manual check breakdowns, and evidence collection guides:\n\n![HTML Report - Compliance Score](./docs/examples/screenshots/html-report-score.png)\n\n![HTML Report - Disclaimer](./docs/examples/screenshots/html-report-disclaimer.png)\n\n![HTML Report - Evidence Guide](./docs/examples/screenshots/html-report-evidence.png)\n\n### Available Sample Reports\n\n**AWS Compliance Reports:**\n- [AWS SOC2 Report (PDF)](./docs/examples/reports/sample-aws-soc2-report.pdf)\n- [AWS SOC2 Report (HTML)](https://guardian-nexus.github.io/auditkit/examples/reports/sample-aws-soc2-report.html)\n- [AWS PCI-DSS Report (PDF)](./docs/examples/reports/sample-aws-pci-report.pdf)\n- [AWS CMMC Report (PDF)](./docs/examples/reports/sample-aws-cmmc-report.pdf)\n\n**Azure Compliance Reports:**\n- [Azure CMMC Report (PDF)](./docs/examples/reports/sample-azure-cmmc-report.pdf)\n- [Azure CMMC Report (HTML)](https://guardian-nexus.github.io/auditkit/examples/reports/sample-azure-cmmc-report.html)\n\n[View all examples](./docs/examples/)\n\n---\n\n## Supported Frameworks\n\n| Framework | AWS | Azure | M365 | Status |\n|-----------|-----|-------|------|--------|\n| **SOC2** | 64 controls | 64 controls | 100+ rules | Production |\n| **PCI-DSS v4.0** | 30 controls | 30 controls | Mapped | Production |\n| **CMMC Level 1** | 17 practices | 17 practices | Mapped | Production |\n| **HIPAA** | ~10 controls | ~10 controls | Basic | Experimental |\n| **CMMC Level 2** | 110 practices | 110 practices | Mapped | [Pro Only](https://auditkit.io/pro) |\n\n---\n\n## Why Use AuditKit?\n\n### For Startups\n- Free SOC2 preparation without consultants\n- Audit-ready PDF reports for your CPA firm\n- Most technical issues fixed in hours\n\n### For DoD Contractors\n- CMMC Level 1 assessment (17 practices)\n- November 10, 2025 deadline compliance\n- Self-assessment before C3PAO review\n\n### For Enterprises\n- Single tool for AWS, Azure, and M365\n- Track compliance improvement over time\n- Replace multiple expensive tools\n\n---\n\n## Installation\n\n### Download Binary\nSee [Releases](https://github.com/guardian-nexus/auditkit/releases) for pre-built binaries.\n\n### From Source\n```bash\ngit clone https://github.com/guardian-nexus/auditkit\ncd auditkit/scanner\ngo build ./cmd/auditkit\n./auditkit scan\n```\n\n### Using Go\n```bash\ngo install github.com/guardian-nexus/auditkit/scanner/cmd/auditkit@latest\n```\n\n**Requirements:**\n- Go 1.19+\n- Cloud credentials configured (AWS CLI, Azure CLI, or M365 via ScubaGear)\n- Read-only permissions to cloud resources\n\n---\n\n## Examples\n\n### Basic Scanning\n\n```bash\n# SOC2 scan\nauditkit scan -provider aws -framework soc2\n\n# PCI-DSS scan\nauditkit scan -provider azure -framework pci\n\n# CMMC Level 1 scan\nauditkit scan -provider aws -framework cmmc\n\n# See all controls (no truncation)\nauditkit scan -provider aws -framework soc2 --full\n```\n\n### Generate Reports\n\n```bash\n# PDF report for auditors\nauditkit scan -format pdf -output report.pdf\n\n# Interactive HTML report\nauditkit scan -format html -output report.html\n\n# JSON output for automation\nauditkit scan -format json -output results.json\n```\n\n### M365 Integration\n\n```bash\n# Step 1: Run ScubaGear (Windows PowerShell)\nInstall-Module -Name ScubaGear\nInvoke-SCuBA -ProductNames aad,exo,sharepoint,teams -OutPath ./ScubaResu",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-14T02:19:50.143621"
  },
  {
    "basic_info": {
      "name": "ByteCaster",
      "full_name": "Print3M/ByteCaster",
      "owner": "Print3M",
      "description": "Swiss Army Knife for payload encryption, obfuscation, and conversion to byte arrays – all in a single command (14 output formats supported)! ☢️",
      "url": "https://github.com/Print3M/ByteCaster",
      "clone_url": "https://github.com/Print3M/ByteCaster.git",
      "ssh_url": "git@github.com:Print3M/ByteCaster.git",
      "homepage": "",
      "created_at": "2025-09-17T14:45:28Z",
      "updated_at": "2025-10-14T01:37:44Z",
      "pushed_at": "2025-09-20T13:08:55Z"
    },
    "stats": {
      "stars": 170,
      "forks": 26,
      "watchers": 170,
      "open_issues": 0,
      "size": 10756
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 13941
      },
      "license": null,
      "topics": [
        "encryption-tool",
        "golang",
        "maldev",
        "malware-builder",
        "malware-development",
        "obfuscation-script",
        "redteam",
        "security",
        "security-tools",
        "shellcode",
        "shellcode-convert",
        "shellcode-development",
        "shellcode-encoder",
        "shellcode-injection"
      ]
    },
    "content": {
      "readme": "# ByteCaster\n\nSwiss Army Knife for payload encryption, obfuscation, and conversion to byte arrays – all in a single command!\n\nIt supports 3 encryption algorithms, 4 encoding / obfuscation algorithms and 14 output formats.\n\n![ByteCaster order of opretaions](_img/img-1.png)\n\n## Installation\n\n[Download the compiled binary](https://github.com/Print3M/ByteCaster/releases/tag/1.0.0) or compile Go source code.\n\n## Usage\n\nExample:\n\n```bash\n# Convert .bin file into C bytes array with XOR encryption and IPv4Fuscation\n./ByteCaster -i shellcode.bin -f c -x xor -k 'Test123' -e ipv4\n\n# Convert .bin file into base64 string with XOR encryption\n./ByteCaster -i shellcode.bin -x xor -k 'Test123' -e base64\n```\n\n![ByteCaster demo](_img/img-2.png)\n\n> **NOTE**: The sequence of operations is always the same:\n>\n> 1. Encryption\n> 2. Encoding\n> 3. Output formatting\n\n**`-i / --input <path>`** [required]\n\nBinary input file.\n\n**`-f / --format <value>`** [optional, default: `raw`]\n\nOutput format of the processed data. This generates the final data as an array of bytes in the selected programming language. Output is always sent to STDOUT.\n\nTo avoid applying any formatting output, use the `raw` value (default).\n\nAvailable values: `raw`, `hex`, `c`, `go`, `powershell`, `php`, `js`, `rust`, `csharp`, `nim`, `zig`, `ruby`, `python`, `java`\n\n**`-x / --enc-alg <value>` + `-k / --enc-key <string>`** [optional]\n\nData encryption. Both parameters, the encryption algorithm and the key string, must be provided.\n\nAvailabe values: `xor`, `aes256`, `rc4`\n\nAll supported encryption algorithms are described in details below.\n\n**`-e / --encoding <value>`** [optional]\n\nData encoding. Often used as obfuscation to confuse analysis or changes in the entropy level of data.\n\nAvailable values: `base32`, `base64`, `ipv4`, `mac`\n\nAll supported encoding algorithms are described in details below.\n\n## Supported encryption algorithms\n\n#### **`xor`** [0% overhead]\n\nTypical simple XOR encryption (`a^b`). Each byte is XORed with the byte from the key.\n\n#### **`aes256`** [28 bytes overhead]\n\nAES-256-GCM with the 32-bytes long key derived from SHA-256 hash function.\n\nCiphertext format: `nonce || ciphertext`. Nonce is stored in the first 12 bytes, followed by the encrypted data and authentication tag (the tag is appended automatically by GCM inside ciphertext).\n\nStandard Go implementation of AES encryption:`crypto/aes`\nStandard Go implementation of SHA-256 key derivation: `crypto/sha256`\n\n#### **`rc4`** [0% overhead]\n\nStandard Go implementation of RC4 encryption: `crypto/rc4`\n\n## Supported encoding algorithms\n\n#### **`base32`** [60–65% overhead]\n\nStandard Go implementation of Base32 encoding: `encoding/base32`\n\n#### **`base64`** [33%-37% overhead]\n\nStandard Go implementation of Base64 encoding: `encoding/base64`\n\n#### **`ipv4`** [100%-300% overhead]\n\nThis is known as the _IPv4Fuscation_ technique. Each output byte is converted to one octet in the IPv4 address as a decimal number.\n\nExample data:\n\n```text\n{ 0xe9, 0x36, 0x17, 0xbb, 0xbd, 0x7f, 0x22, 0x10 }\n```\n\nThe output (array of bytes) looks exactly like this in memory:\n\n`233.54.23.187\\0189.127.34.16\\0` ...\n\n> NOTE:\n>\n> - Each IP address ends with a null byte!\n> - If the number of bytes is not divisible by 4, the missing bytes added to the last IP address are 255.\n\n#### **`mac`** [200% overhead]\n\nThis is known as the _MACFuscation_ technique. Each output byte is converted to one octet in the MAC address as a hexadecimal number (lowercase).\n\nExample data:\n\n```text\n{ 0xe9, 0x36, 0x17, 0xbb, 0xbd, 0x7f, 0x22, 0x10, 0x84, 0xA7, 0x6f, 0xcc }\n```\n\nThe output (array of bytes) looks exactly like this in memory:\n\n`e9:36:17:bb:bd:7f\\022:10:84:a7:6f:cc\\0`\n\n> NOTE:\n>\n> - Each MAC address ends with a null byte!\n> - Hexadecimal numbers are lowercase.\n> - If the number of bytes is not divisible by 6, the missing bytes added to the last MAC address are 255 (`ff`).\n\n## Credits\n\n- [HellShell](https://github.com/NUL0x4C/HellShell) - inspired me to implement _IPv4Fuscation_ and _MACFuscation_.\n\n## TODO\n\n- Add base32 encoding\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-14T02:19:51.437042"
  },
  {
    "basic_info": {
      "name": "friendly-potato",
      "full_name": "bingcicle/friendly-potato",
      "owner": "bingcicle",
      "description": "jsonl-tool",
      "url": "https://github.com/bingcicle/friendly-potato",
      "clone_url": "https://github.com/bingcicle/friendly-potato.git",
      "ssh_url": "git@github.com:bingcicle/friendly-potato.git",
      "homepage": null,
      "created_at": "2025-09-29T15:09:04Z",
      "updated_at": "2025-10-08T01:04:18Z",
      "pushed_at": "2025-09-29T15:11:09Z"
    },
    "stats": {
      "stars": 152,
      "forks": 0,
      "watchers": 152,
      "open_issues": 2,
      "size": 7
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 2030
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# jsonl-tool\nMerge or filter JSON Lines.\n\n## Build & Run\n```bash\ngo build -o jsonl-tool\n./jsonl-tool --mode merge --in a.jsonl,b.jsonl > merged.jsonl\n./jsonl-tool --mode filter --in merged.jsonl --field exchange --eq bybit\n./jsonl-tool --mode filter --in merged.jsonl --field symbol --rex \"BTC|ETH\"\n```\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-14T02:19:52.762223"
  },
  {
    "basic_info": {
      "name": "konbini",
      "full_name": "whyrusleeping/konbini",
      "owner": "whyrusleeping",
      "description": null,
      "url": "https://github.com/whyrusleeping/konbini",
      "clone_url": "https://github.com/whyrusleeping/konbini.git",
      "ssh_url": "git@github.com:whyrusleeping/konbini.git",
      "homepage": null,
      "created_at": "2025-10-03T20:20:00Z",
      "updated_at": "2025-10-13T01:05:16Z",
      "pushed_at": "2025-10-12T05:48:01Z"
    },
    "stats": {
      "stars": 130,
      "forks": 11,
      "watchers": 130,
      "open_issues": 0,
      "size": 325
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 198061,
        "TypeScript": 56069,
        "CSS": 25038,
        "HTML": 1719,
        "Dockerfile": 1010
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# Konbini - A Cozy Bluesky AppView\n\nKonbini is a partially indexed bluesky appview. It's aim is to provide a \"Friends of Friends\" experience to the bluesky network.\n\nIt is currently _very_ jank and I really just hacked this together in a day. More work to come when I get time.\n\n## Prerequisites\n\n- Go 1.25.1 or later\n- PostgreSQL database\n- Node.js and npm (for frontend)\n- Docker (optional, for easy PostgreSQL setup)\n- Bluesky account credentials\n\n## Quick Start with Docker Compose\n\nThe easiest way to run Konbini is with Docker Compose, which will start PostgreSQL, the backend, and frontend all together.\n\n### Prerequisites\n\n- Docker and Docker Compose installed\n- Creating an app password (via: https://bsky.app/settings/app-passwords)\n\n### Setup\n\n1. Create a `.env` file with your credentials:\n\n```bash\ncp .env.example .env\n# Edit .env and add:\n# - BSKY_HANDLE=your-handle.bsky.social\n# - BSKY_PASSWORD=your-app-password\n```\n\n2. Start all services:\n\n```bash\ndocker-compose up -d\n```\n\n3. Wait for the backend to index posts from the firehose (this may take a few minutes for initial indexing)\n\n4. Open your browser to http://localhost:3000\n\n### Stopping the services\n\n```bash\ndocker-compose down\n```\n\nTo also remove the database volume:\n\n```bash\ndocker-compose down -v\n```\n\n## Manual Setup\n\n### 1. PostgreSQL Database Setup\n\n#### Using Docker (Recommended)\n\n```bash\n# Start PostgreSQL container\ndocker run --name konbini-postgres \\\n  -e POSTGRES_DB=konbini \\\n  -e POSTGRES_USER=konbini \\\n  -e POSTGRES_PASSWORD=your_password \\\n  -p 5432:5432 \\\n  -d postgres:15\n\n# The database will be available at: postgresql://konbini:your_password@localhost:5432/konbini\n```\n\n### 2. Environment Configuration\n\nSet the following environment variables:\n\n```bash\n# Database connection\nexport DATABASE_URL=\"postgresql://konbini:your_password@localhost:5432/konbini\"\n\n# Bluesky credentials\nexport BSKY_HANDLE=\"your-handle.bsky.social\"\nexport BSKY_PASSWORD=\"your-app-password\"\n```\n\n### 3. Build and Run the Go Application\n\n```bash\ngo build\n\n# Run with environment variables\n./konbini\n```\n\n### 4. Frontend Setup\n\n```bash\n# Navigate to frontend directory\ncd frontend\n\n# Install dependencies\nnpm install\n\n# Start the development server\nnpm start\n```\n\nThe frontend will be available at http://localhost:3000 and will connect to the API at http://localhost:4444.\n\n## Running the Bluesky App against Konbini\n\nKonbini implements a large portion of the app.bsky.\\* appview endpoints that\nare required for pointing the main app to it and having it work reasonably\nwell.\n\nTo accomplish this you will need a few things:\n\n### Service DID\n\nYou will need a DID, preferably a did:web for your appview that points at a\npublic endpoint where your appview is accessible via https.\nI'll get into the https proxy next, but for the did, I've just pointed a domain\nI own (in my case appview1.bluesky.day) to a VPS, and used caddy to host a file\nat `/.well-known/did.json`.\nThat file should look like this:\n\n```json\n{\n  \"@context\": [\n    \"https://www.w3.org/ns/did/v1\",\n    \"https://w3id.org/security/multikey/v1\"\n  ],\n  \"id\": \"did:web:appview1.bluesky.day\",\n  \"verificationMethod\": [\n    {\n      \"id\": \"did:web:api.bsky.app#atproto\",\n      \"type\": \"Multikey\",\n      \"controller\": \"did:web:api.bsky.app\",\n      \"publicKeyMultibase\": \"zQ3shpRzb2NDriwCSSsce6EqGxG23kVktHZc57C3NEcuNy1jg\"\n    }\n  ],\n  \"service\": [\n    {\n      \"id\": \"#bsky_notif\",\n      \"type\": \"BskyNotificationService\",\n      \"serviceEndpoint\": \"YOUR APPVIEW HTTPS URL\"\n    },\n    {\n      \"id\": \"#bsky_appview\",\n      \"type\": \"BskyAppView\",\n      \"serviceEndpoint\": \"YOUR APPVIEW HTTPS URL\"\n    }\n  ]\n}\n```\n\nThe verificationMethod isn't used but i'm not sure if _something_ is required\nthere or not, so i'm just leaving that there, it works on my machine.\n\n### HTTPS Endpoint\n\nI've been using ngrok to proxy traffic from a publicly accessible https url to my appview.\nYou can simply run `ngrok http 4446` and it will give you an https url that you\ncan then put in your DID doc above.\n\n### The Social App\n\nNow, clone and build the social app:\n\n```\ngit clone https://github.com/bluesky-social/social-app\ncd social-app\nyarn\n```\n\nAnd then set this environment variable that tells it to use your appview:\n\n```\nexport EXPO_PUBLIC_BLUESKY_PROXY_DID=did:web:YOURDIDWEB\n```\n\nAnd finally run the app:\n\n```\nyarn web\n```\n\nThis takes a while on first load since its building everything.\nAfter that, load the localhost url it gives you and it _should_ work.\n\n## Selective Backfill\n\nIf you'd like to backfill a particular repo, just hit the following endpoint:\n\n```\ncurl http://localhost:4444/rescan/<DID OR HANDLE>\n\n```\n\nIt will take a minute but it should pull all records from that user.\n\n## License\n\nMIT (whyrusleeping)\n\n```\n\n```\n",
      "default_branch": "master"
    },
    "fetched_at": "2025-10-14T02:19:54.050617"
  },
  {
    "basic_info": {
      "name": "piraterf",
      "full_name": "psyb0t/piraterf",
      "owner": "psyb0t",
      "description": "PIrateRF transforms your Raspberry Pi Zero W into a portable RF signal generator that spawns its own WiFi hotspot. Control everything from FM broadcasts to digital modes through your browser - hack the airwaves from anywhere! 📡⚡",
      "url": "https://github.com/psyb0t/piraterf",
      "clone_url": "https://github.com/psyb0t/piraterf.git",
      "ssh_url": "git@github.com:psyb0t/piraterf.git",
      "homepage": "https://ciprian.51k.eu/piraterf-turning-a-20-raspberry-pi-zero-into-an-rf-tx-swiss-army-knife/",
      "created_at": "2025-09-17T06:35:29Z",
      "updated_at": "2025-10-13T18:49:15Z",
      "pushed_at": "2025-10-07T02:50:01Z"
    },
    "stats": {
      "stars": 125,
      "forks": 24,
      "watchers": 125,
      "open_issues": 0,
      "size": 27816
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 188667,
        "JavaScript": 140943,
        "Shell": 76111,
        "HTML": 37391,
        "CSS": 30497,
        "Makefile": 1585
      },
      "license": "Do What The F*ck You Want To Public License",
      "topics": [
        "access-point",
        "carrier",
        "fm",
        "golang",
        "hack-the-planet",
        "pirate",
        "pizero",
        "portable-radio-transmission",
        "portable-tx",
        "radio",
        "raspberrypi",
        "rf",
        "rfhacking",
        "sdr",
        "software-defined-radio",
        "spectrum",
        "transmission",
        "tx",
        "websocket",
        "wifi"
      ]
    },
    "content": {
      "readme": "# 🏴‍☠️ PIrateRF - Software-Defined Radio Transmission Platform\n\n![PIrateRF](./assets/piraterf.png)\n\n**PIrateRF** transforms your **Raspberry Pi Zero W** into a portable RF signal generator that spawns its own WiFi hotspot. Control everything from FM broadcasts to digital modes through your browser - hack the airwaves from anywhere! 📡⚡\n\n**[🎬 Click here for PIrateRF Promo Video](https://www.youtube.com/watch?v=hnYkvDLOi70)**\n\n**[📺 Click here for PIrateRF Showcase Video](https://www.youtube.com/watch?v=7DeMhe47aNQ)**\n\n---\n\n**⚠️ LEGAL NOTICE**\n\nPIrateRF is designed for amateur radio experimentation and education - including safe indoor testing without external antennas. Built for engineers who understand that good RF practices matter more than arbitrary administrative boundaries. Users are responsible for compliance with all local RF regulations and licensing requirements. I am not responsible for any of your stupid fuckin' decisions!\n\n**All demonstration images and testing in this documentation were performed indoors without an antenna, with a maximum range of approximately 5 meters.**\n\n---\n\n## 📋 Table of Contents\n\n- [🎯 11 Different Transmission Modes](#-11-different-transmission-modes)\n- [🚀 Quick Setup Guide](#-quick-setup-guide)\n  - [Prerequisites](#prerequisites)\n  - [Option 1: Pre-Built Image (Recommended)](#option-1-pre-built-image-recommended)\n  - [Option 2: Manual Build Setup](#option-2-manual-build-setup)\n    - [🚨 IMPORTANT: Pi Zero Setup First!](#-important-pi-zero-setup-first)\n    - [1. Initial Setup](#1-initial-setup)\n    - [2. Complete Pi Setup](#2-complete-pi-setup)\n    - [3. Connect and Use](#3-connect-and-use)\n- [🎉 Pirate Crew Mode](#-pirate-crew-mode)\n- [🔌 Antenna Setup](#-antenna-setup)\n- [📡 Transmission Modes Explained](#-transmission-modes-explained)\n  - [🎵 FM Station](#-fm-station)\n  - [🎙️ Live Microphone Broadcast](#️-live-microphone-broadcast)\n  - [📟 FT8](#-ft8)\n  - [📠 RTTY](#-rtty)\n  - [📊 FSK](#-fsk)\n  - [📱 POCSAG](#-pocsag)\n  - [📻 Morse Code](#-morse-code)\n  - [🎛️ Carrier Wave](#️-carrier-wave)\n  - [🌊 Frequency Sweep](#-frequency-sweep)\n  - [📺 SSTV](#-sstv)\n  - [🎨 Spectrum Paint](#-spectrum-paint)\n- [🛠️ Development Commands](#️-development-commands)\n  - [Local Development](#local-development)\n  - [Pi Management](#pi-management)\n- [📁 Project Structure](#-project-structure)\n- [🏴‍☠️ Legal and Safety Notice](#️-legal-and-safety-notice)\n  - [Amateur Radio License Required](#amateur-radio-license-required)\n  - [Frequency Regulations](#frequency-regulations)\n  - [Hardware Requirements (for proper use)](#hardware-requirements-for-proper-use)\n  - [Geographic Restrictions](#geographic-restrictions)\n  - [🏠 Indoor Testing & Experimentation](#-indoor-testing--experimentation)\n- [📡 Standard Operating Frequencies](#-standard-operating-frequencies)\n  - [HF Amateur Bands (3-30 MHz)](#hf-amateur-bands-3-30-mhz)\n  - [VHF/UHF Amateur Bands](#vhfuhf-amateur-bands)\n  - [FT8 Standard Frequencies (USB mode)](#ft8-standard-frequencies-usb-mode)\n  - [RTTY Standard Frequencies (USB mode)](#rtty-standard-frequencies-usb-mode)\n  - [SSTV Standard Frequencies](#sstv-standard-frequencies)\n  - [FM Repeater Standard Splits](#fm-repeater-standard-splits)\n- [🔗 Core Dependencies](#-core-dependencies)\n- [📝 License](#-license)\n- [TODO](#todo)\n\n## 🎯 11 Different Transmission Modes\n\n- **🎵 FM Station** - Full FM broadcasting with RDS metadata, playlists, and audio processing\n- **🎙️ Live Microphone Broadcast** - Real-time microphone streaming with configurable modulation (AM/DSB/USB/LSB/FM/RAW)\n- **📟 FT8** - Long-range digital mode for weak-signal communication on HF bands\n- **📠 RTTY** - Radio teletype using Baudot code and FSK modulation\n- **📊 FSK** - Frequency Shift Keying for digital data transmission\n- **📱 POCSAG** - Digital pager messaging system\n- **📻 Morse Code** - CW transmission with configurable WPM\n- **🎛️ Carrier Wave** - Simple carrier generation for testing\n- **🌊 Frequency Sweep** - RF sweeps for antenna testing and analysis\n- **📺 SSTV** - Slow Scan Television image transmission\n- **🎨 Spectrum Paint** - Convert images to RF spectrum art\n\nAll controlled through a **standalone WiFi access point** - connect any device and start transmitting like the RF rebel you were meant to be! Perfect for international waters operations and regions with more... flexible spectrum policies.\n\n## 🚀 Quick Setup Guide\n\n### Prerequisites\n\n- **Raspberry Pi Zero 1 W** (original model) with 4GB+ SD card\n  - **⚠️ Pi Zero 2 W does NOT work** - rpitx requires the BCM2835 chip (Pi Zero 1 W) for predictable clock timing. The Pi Zero 2 W uses BCM2710A1 which breaks rpitx's timing assumptions.\n\n### Option 1: Pre-Built Image (Recommended)\n\nSkip all the build bullshit and get straight to RF chaos:\n\n1. **Download** the pre-built image: [PIrateRF Image v2025-10-06](https://archive.org/download/piraterf-2025-10-06-12-19-14-20251006092641/piraterf_2025-10-06_12-19-14.img)\n2. **Flash** to SD card using:\n   - **Raspberry Pi Imager** (recommended): Select \"U",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-14T02:19:55.342889"
  },
  {
    "basic_info": {
      "name": "soloops-cli",
      "full_name": "Desmond-Osy/soloops-cli",
      "owner": "Desmond-Osy",
      "description": "SoloOps CLI",
      "url": "https://github.com/Desmond-Osy/soloops-cli",
      "clone_url": "https://github.com/Desmond-Osy/soloops-cli.git",
      "ssh_url": "git@github.com:Desmond-Osy/soloops-cli.git",
      "homepage": null,
      "created_at": "2025-09-30T05:01:35Z",
      "updated_at": "2025-10-13T05:35:59Z",
      "pushed_at": "2025-10-07T23:44:54Z"
    },
    "stats": {
      "stars": 101,
      "forks": 46,
      "watchers": 101,
      "open_issues": 0,
      "size": 76
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 46560,
        "Shell": 7097,
        "JavaScript": 5932,
        "HTML": 5179,
        "CSS": 4339,
        "PowerShell": 4208,
        "Python": 3475,
        "Makefile": 3239,
        "Dockerfile": 1349
      },
      "license": "Apache License 2.0",
      "topics": []
    },
    "content": {
      "readme": "# SoloOps CLI\n\n[![CI](https://github.com/Desmond-Osy/soloops-cli/workflows/CI/badge.svg)](https://github.com/Desmond-Osy/soloops-cli/actions)\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)\n[![Go Report Card](https://goreportcard.com/badge/github.com/Desmond-Osy/soloops-cli)](https://goreportcard.com/report/github.com/Desmond-Osy/soloops-cli)\n\nSoloOps is a command-line tool for scaffolding, validating, and managing infrastructure blueprints described in a YAML manifest (`soloops.yaml`). It generates Terraform code from your declarative configuration, making it easy to provision cloud resources with best practices built-in.\n\n## Features\n\n- **Declarative Infrastructure**: Define your infrastructure in a simple YAML manifest\n- **Blueprint System**: Pre-built templates for common patterns (serverless APIs, static sites, databases)\n- **Multi-Cloud Support**: AWS, GCP, and Azure (AWS fully implemented in MVP)\n- **Budget Aware**: Automatic budget alerts and cost controls\n- **Security First**: Built-in WAF, HTTPS enforcement, and compliance policies\n- **Terraform Generation**: Generates clean, readable Terraform code\n- **Easy to Use**: Simple CLI commands for the entire lifecycle\n\n## Quick Start\n\n### Installation\n\n**No Go installation required!** Choose your preferred method:\n\n#### One-Line Installer (Recommended)\n\n**Linux/macOS:**\n```bash\ncurl -fsSL https://raw.githubusercontent.com/Desmond-Osy/soloops-cli/main/scripts/install.sh | bash\n```\n\n**Windows (PowerShell):**\n```powershell\nirm https://raw.githubusercontent.com/Desmond-Osy/soloops-cli/main/scripts/install.ps1 | iex\n```\n\n#### Manual Download\n\nDownload pre-built binaries from the [releases page](https://github.com/Desmond-Osy/soloops-cli/releases):\n\n```bash\n# Linux (amd64)\nwget https://github.com/Desmond-Osy/soloops-cli/releases/latest/download/soloops-linux-amd64.tar.gz\ntar xzf soloops-linux-amd64.tar.gz\nsudo mv soloops-linux-amd64 /usr/local/bin/soloops\n\n# macOS (Apple Silicon)\nwget https://github.com/Desmond-Osy/soloops-cli/releases/latest/download/soloops-darwin-arm64.tar.gz\ntar xzf soloops-darwin-arm64.tar.gz\nsudo mv soloops-darwin-arm64 /usr/local/bin/soloops\n\n# Windows: Download soloops-windows-amd64.zip from releases and extract\n```\n\n#### Using Docker\n\n```bash\ndocker pull soloops/soloops-cli:latest\ndocker run --rm -v $(pwd):/workspace soloops/soloops-cli:latest init\n```\n\n#### Build from Source (for developers)\n\n```bash\ngit clone https://github.com/Desmond-Osy/soloops-cli.git\ncd soloops-cli\nmake build\n# Or: go install github.com/Desmond-Osy/soloops-cli/cmd/soloops@latest\n```\n\n### Basic Usage\n\n1. **Initialize a new project**:\n\n```bash\nsoloops init\n```\n\nThis creates a `soloops.yaml` manifest with sensible defaults.\n\n2. **Customize your configuration**:\n\nEdit `soloops.yaml` to define your infrastructure:\n\n```yaml\nproject: my-awesome-app\ncloud: aws\nenvironments:\n  - name: prod\n    region: us-east-1\n    budget_usd: 150\n    blueprints:\n      web_api:\n        runtime: node18\n        ingress: edge\n      static_site:\n        domain: myapp.com\npolicies:\n  require_https: true\n  deny_public_s3: true\n```\n\n3. **Validate your configuration**:\n\n```bash\nsoloops validate\n```\n\n4. **Generate Terraform code**:\n\n```bash\nsoloops generate\n```\n\nThis creates Terraform files in the `infra/` directory.\n\n5. **Preview changes**:\n\n```bash\nsoloops preview\n```\n\nShows what infrastructure will be created (runs `terraform plan`).\n\n6. **Apply changes**:\n\n```bash\nsoloops apply\n```\n\nProvisions your infrastructure (runs `terraform apply`).\n\n7. **Destroy when done**:\n\n```bash\nsoloops destroy\n```\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `soloops init` | Create a new soloops.yaml manifest |\n| `soloops validate` | Validate the configuration |\n| `soloops generate` | Generate Terraform files |\n| `soloops preview` | Preview infrastructure changes |\n| `soloops apply` | Provision infrastructure |\n| `soloops destroy` | Destroy infrastructure |\n| `soloops version` | Show version information |\n\n### Global Flags\n\n- `--file, -f`: Path to soloops.yaml (default: `soloops.yaml`)\n- `--env, -e`: Target environment (defaults to first in manifest)\n\n## Configuration\n\n### Project Structure\n\n```\nmy-project/\n├── soloops.yaml          # Your infrastructure manifest\n├── infra/                # Generated Terraform files\n│   ├── provider.tf\n│   ├── variables.tf\n│   ├── main.tf\n│   ├── budget.tf\n│   └── outputs.tf\n└── terraform.tfstate     # Terraform state (created after apply)\n```\n\n### Example soloops.yaml\n\n```yaml\nproject: acme-api\ncloud: aws\nenvironments:\n  - name: prod\n    region: us-east-1\n    budget_usd: 150\n    blueprints:\n      web_api:\n        runtime: node18\n        ingress: edge\n      static_site:\n        domain: acme.com\n      database:\n        type: aurora_serverless_v2\npolicies:\n  require_https: true\n  deny_public_s3: true\n```\n\n## Supported Blueprints\n\n### Web API (AWS)\n\nCreates a serverless API with:\n- AWS Lambda function\n- API Gateway HTTP API\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-14T02:19:56.637823"
  },
  {
    "basic_info": {
      "name": "SLiteIO",
      "full_name": "beankeji-cloud/SLiteIO",
      "owner": "beankeji-cloud",
      "description": "SLiteIO is a cloud-native block storage solution for Kubernetes, using LVM and SPDK to provide both local volumes and high-performance NVMe-oF remote volumes. Its minimal I/O path delivers excellent performance even with standard SSDs, enabling dynamic block device provisioning in hyper-converged clusters.",
      "url": "https://github.com/beankeji-cloud/SLiteIO",
      "clone_url": "https://github.com/beankeji-cloud/SLiteIO.git",
      "ssh_url": "git@github.com:beankeji-cloud/SLiteIO.git",
      "homepage": "",
      "created_at": "2025-09-26T02:18:16Z",
      "updated_at": "2025-10-10T03:15:01Z",
      "pushed_at": "2025-10-01T01:21:13Z"
    },
    "stats": {
      "stars": 91,
      "forks": 11,
      "watchers": 91,
      "open_issues": 0,
      "size": 1488
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 947455,
        "Shell": 9780,
        "Makefile": 6080
      },
      "license": "Apache License 2.0",
      "topics": []
    },
    "content": {
      "readme": "<p align=\"center\"><img src=doc/image/logo.png alt=\"logo.png\" width=\"300\" /></p>\n<p align=\"center\"><b>云原生存储解决方案</b></p>\n<p align=\"center\">\n  [<a href=\"README.md\">中文</a>] | [<a href=\"README-en.md\">English</a>] \n</p>\n\n\n\n# SLiteIO \n本项目基于[eosphoros-ai/liteio]开发，遵循Apache-2.0 license协议。\n**SLiteIO** 是一款云原生有状态容器化的存储解决方案，依赖于LVM存储引擎，可作为本地卷直接使用，也可通过SPDK导出NVME-OF远端卷。由于其极简的存储IO路径，即使是普通SSD也能发挥出不错的性能。该方案专为超融合架构下的 Kubernetes 设计，可实现集群范围的块设备动态供给。\n\n## 特性\n\n1. **低门槛**: 不仅支持NVME和RDMA网络，满足对极致高性能的追求；还支持普通SSD和网络，也能提供不俗的性能，为初创企业或者设备利旧提供便利。                                                                                                                                                                                                      \n2. **云原生**: SLiteIO通过CSI控制器和驱动实现与Kubernetes集成，提供云原生用户接口。用户可以通过PVC动态分配和销毁SLiteIO卷。\n3. **易安装**: 除了一些少量的配置依赖，SLiteIO可以通过一条命令行快速的安装部署。\n4. **极稳定**: 直接利用LVM作为数据引擎，本地卷直接访问，远端卷通过SPDK导出。整个运行时数据链路非常简单，从而带来极致的稳定。\n5. **省成本**: 支持精简模式，可以做到存储空间用多少分配多少，避免过多分配带来的存储空间浪费。\n6. **丰富的调度策略**: 支持跨节点、跨机柜、跨接入等多种高可用调度策略，满足不同等级的生产系统高可用要求。\n\n## 目的\n\n当前有很多系统运行在虚机或者物理机上，在集群到达一定规模后，存在大量的资源利用率失衡：比如有的节点出现CPU或内存不足，却有大量的存储闲置资源。因此在做容器化改造时，有状态的系统比如数据库采用哪种存储方案，充分利用这些闲置存储资源，成为新的难题。为解决这一问题，我们的目标是开发一种系统，能够在保持接近本地磁盘性能的同时，有效整合这些碎片化的存储资源。\n\n## 架构\n\nSLiteIO由六个组件组成：\n\n1. **Disk-Agent**: Disk-Agent安装在每个后端节点上，并且管理该节点上的存储池，该模块与数据引擎交互，实现卷与快照的创建与删除功能。额外的，Disk-Agent还给控制节点上报了存储池状态并给Prometheus提供卷统计信息。\n2. **Disk-Controller**: Disk-Controller掌握了集群种所有的存储池和卷的全局状态信息。它的主要任务时将卷调度到合适的存储池。\n3. **nvme-tcp**: nvme-tcp是一个内核模块，提供了基于TCP的NVME-OF协议。\n4. **nvmf_tgt**: nvmf_tgt提供了将LVM卷导出成nvme target，从而实现远端卷。\n5. **CSI-Driver**: CSI-Driver实现了Kubernetes CSI标准接口，并以Pod形式部署在计算节点上。它通过lvm和nvme-cli工具链实现与后端存储的连接。\n6. **CSI-Controller**: CSI-Controller是个中心化服务，提供PV的创建于删除处理。 \n\n总体而言，SLiteIO架构为云原生块存储提供了一种可扩展且高效的实现方案。通过多组件协同与接口抽象，该架构能够灵活适配不同存储场景的需求。\n\n![](doc/image/architecture.jpg)\n\n## 快速开始\n\n快速开始指南帮助您快速安装一个K8s集群，并在上面部署SLiteio。\n\n- [快速开始](doc/zh/install.md)\n- [使用kubeadm安装K8s](doc/zh/kubeadm-install.md)\n\n## MYSQL数据库场景性能测试\n**测试环境**：40C/256G，7 * 900GB SSD Raid5，2 * 10Gb   3台                    \n**测试工具**：Sysbench               \n**测试方法**：通过Kubernetes容器化场景和KVM虚拟化场景进行对比测试                                                                                               \n**性能测试场景**：K8S + SLiteIO 本地卷 、K8S + SLiteIO 远端卷、KVM 本地卷\n\n创建5对一主一从8C/16G/75GB的MYSQL实例，初始创建300张表，每张表插入100万条测试数据，通过Sysbentch模拟8、16、32、64、128线程并发分别进行只读、只写和混合读写的测试，测试时长180S。 \n\n### 只读（oltp_read_only）     \n\nUnit: TPS\n\n|    Threads  |  K8S + SLiteIO Local | K8S + SLiteIO Remote | KVM Local |\n|-------------|-------------|----------|----------|\n| 8   | 8441.26       | 8452.56   | 2659.97  |\n| 16  | 9533.01       | 9597.72   | 3478.41  |\n| 32  | 9656.76       | 9625.8    | 4082.99  |\n| 64  | 9843          | 9850      | 4577.7   |\n| 128 | 9623.68       | 9623.37   | 5002.31  |\n\n### 只写（oltp_write_only）\n\nUnit: TPS\n\n|    Threads  |  K8S + SLiteIO Local | K8S + SLiteIO Remote | KVM Local |\n|-------------|-------------|----------|----------|\n| 8   | 13409.11     | 7926.2   | 8694.35  |\n| 16  | 17677.05     | 12203.34 | 12237.73 |\n| 32  | 20760.74     | 17277.57 | 15532.35 |\n| 64  | 21864.19     | 20428.38 | 17265.81 |\n| 128 | 25056.6      | 24343.81 | 19032.64 |\n\n### 读写（oltp_read_write）\n\nUnit: TPS\n\n|    Threads  |  K8S + SLiteIO Local | K8S + SLiteIO Remote | KVM Local |\n|-------------|-------------|----------|----------|\n| 8   | 5159.63     | 4355.29  | 2077.54|\n| 16  | 6115.72     | 5908.65  | 2499.74|\n| 32  | 6339.87     | 6365.55  | 2904.73|\n| 64  | 6861.48     | 6851.73  | 3254.35|\n| 128 | 6997.42     | 6989.52  | 3658.97|\n\n总体来说，MYSQL容器化使用SLiteIO存储方案，在并发较高时，本地卷和远程卷的性能几乎持平。并且容器化后的性能远超出虚拟化场景。\n\n\n## 应用场景\n区别于传统分布式存储，Sliteio本身没有做数据冗余，因此适用于业务或上层中间件自身有数据冗余机制的场景下，比如数据库、分布式缓存等。Sliteio特别适合容器化的场景的有状态服务，预算有限需要利旧传统服务器，可以充分的利用和分配存储资源，并获得不错的性能。\n\n\n\n## 高级主题\n\n- [构建指南](doc/zh/build.md)\n- [插件定制指南](doc/zh/plugins.md)\n\n\n## 发展路线\n\n\n## 联系我们\n\n**邮箱**：13515105030@163.com\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-14T02:19:58.011038"
  },
  {
    "basic_info": {
      "name": "devbox",
      "full_name": "itzCozi/devbox",
      "owner": "itzCozi",
      "description": "Create and manage isolated development environments using Docker with ease.",
      "url": "https://github.com/itzCozi/devbox",
      "clone_url": "https://github.com/itzCozi/devbox.git",
      "ssh_url": "git@github.com:itzCozi/devbox.git",
      "homepage": "https://devbox.ar0.eu",
      "created_at": "2025-09-16T21:43:21Z",
      "updated_at": "2025-10-05T19:24:06Z",
      "pushed_at": "2025-10-13T15:01:28Z"
    },
    "stats": {
      "stars": 84,
      "forks": 2,
      "watchers": 84,
      "open_issues": 3,
      "size": 624
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 225727,
        "Python": 13149,
        "Shell": 6481,
        "Makefile": 3403
      },
      "license": "MIT License",
      "topics": [
        "cli",
        "debian",
        "developer-tools",
        "development",
        "devops",
        "docker",
        "golang",
        "tools",
        "ubuntu-server"
      ]
    },
    "content": {
      "readme": "# devbox\n\n**Isolated development environments for anything**\n\n[![CI](https://github.com/itzcozi/devbox/workflows/CI/badge.svg)](https://github.com/itzcozi/devbox/actions)\n[![Go Report Card](https://goreportcard.com/badge/github.com/itzcozi/devbox)](https://goreportcard.com/report/github.com/itzcozi/devbox)\n[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)\n\ndevbox creates isolated development environments, contained in a project's Docker box (container). Each project operates in its own disposable environment, while your code remains neatly organized in a simple, flat folder on the host machine.\n\n## Features\n\n- 🚀 **Instant Setup** - Create isolated development environments in seconds\n- 🐳 **Docker-based** - Leverage the power of boxes (containers) for consistent environments\n- 📁 **Clean Organization** - Keep your code organized in simple, flat folders\n- 🔧 **Configurable** - Define your environment with simple JSON configuration\n- 🗑️ **Disposable** - Easily destroy and recreate environments as needed\n- 🛡️ **Isolated** - Each project runs in its own box, preventing conflicts\n- 🔄 **Docker-in-Docker** - Use Docker within your devbox environments by default\n- 🐧 **Linux-only** - Officially supported on Debian/Ubuntu systems\n- 🧪 **Well Tested** - Comprehensive test suite on Linux\n\n## Why devbox?\n\ndevbox focuses on fast, disposable, Docker-native development environments with simple, commit-friendly config.\n\n- Minimal config: a small JSON file, no heavy frameworks\n- Clean host workspace: flat folders, no complex mounts\n- Reproducible: isolated per-project boxes you can destroy/recreate anytime\n- Docker-in-Docker ready: use Docker inside your environment out of the box\n- Designed for Linux/WSL: optimized for Debian/Ubuntu workflows\n\n## Installation\n\n```bash\n# Using the install script\ncurl -fsSL https://devbox.ar0.eu/install.sh | bash\n# Or manually: https://devbox.ar0.eu/docs/install/#manual-build-from-source\n```\n\nNote: devbox supports Linux environments only (Debian/Ubuntu). On Windows, use WSL2 with an Ubuntu distribution.\n\n## Quick Start\n\n1. **Initialize a new project**\n   ```bash\n   devbox init my-project\n   ```\n\n2. **Enter the development environment**\n   ```bash\n   devbox shell my-project\n   ```\n\n3. **Run commands in the environment**\n   ```bash\n   devbox run my-project \"python --version\"\n   ```\n\n4. **List your environments**\n   ```bash\n   devbox list\n   ```\n\n5. **Clean up when done**\n   ```bash\n   devbox destroy my-project\n   ```\n\n### Shared configs\n\nCommit a `devbox.json` to your repo so teammates can just:\n\n```bash\ndevbox up\n```\n\nOptional: mount your local dotfiles into the box\n\n```bash\ndevbox up --dotfiles ~/.dotfiles\n```\n\n## Documentation\n\nFor detailed documentation, guides, and examples, visit:\n\n**📖 [devbox.ar0.eu](https://devbox.ar0.eu)**\n\n## License\n\nThis project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.\n\n\n**Created by BadDeveloper with 💚**\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-14T02:19:59.311577"
  },
  {
    "basic_info": {
      "name": "ssh-dashboard",
      "full_name": "AlpinDale/ssh-dashboard",
      "owner": "AlpinDale",
      "description": "Monitor GPU/CPU Usage on SSH servers, with NVIDIA and AMD support.",
      "url": "https://github.com/AlpinDale/ssh-dashboard",
      "clone_url": "https://github.com/AlpinDale/ssh-dashboard.git",
      "ssh_url": "git@github.com:AlpinDale/ssh-dashboard.git",
      "homepage": "",
      "created_at": "2025-10-12T13:09:29Z",
      "updated_at": "2025-10-14T01:50:08Z",
      "pushed_at": "2025-10-13T22:32:52Z"
    },
    "stats": {
      "stars": 84,
      "forks": 5,
      "watchers": 84,
      "open_issues": 2,
      "size": 238
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 48320,
        "Makefile": 2207,
        "Shell": 1225
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# SSH Dashboard\n\nMonitor CPU, GPU, RAM, and disk usage on your remote servers with a live-updating terminal dashboard.\n\n<div align=\"center\">\n  <img src=\"assets/screenshot.png\" alt=\"SSH Dashboard Screenshot\" width=\"800\">\n</div>\n\n## Installation\n\n### Pre-built Binaries\n\nDownload the latest release for your platform from the [Releases page](https://github.com/AlpinDale/ssh-dashboard/releases).\n\n**Quick install (Linux/macOS):**\n```bash\n# Download the binary for your platform\n# Example for Linux AMD64:\ncurl -L -o ssh-dashboard https://github.com/AlpinDale/ssh-dashboard/releases/download/v0.0.1/ssh-dashboard-v0.0.1-linux-amd64\n\n# Make it executable and move to PATH\nchmod +x ssh-dashboard\nsudo mv ssh-dashboard /usr/local/bin/\n```\n\n**Supported platforms:**\n- `linux-amd64`, `linux-arm64`\n- `darwin-amd64` (Intel Mac), `darwin-arm64` (Apple Silicon)\n- `windows-amd64.exe`, `windows-arm64.exe`\n\n### From Source\n\n```bash\ngit clone https://github.com/AlpinDale/ssh-dashboard.git\ncd ssh-dashboard\nmake install\n```\n\nThis will install to `~/.local/bin`. Make sure this directory is in your PATH (it usually is):\n\n```bash\nexport PATH=\"$HOME/.local/bin:$PATH\"\n```\n\n### Prerequisites\n\n- Go 1.21 or higher\n- SSH access to remote hosts\n- SSH keys loaded in your SSH agent\n\n## Usage\n\nSimply run:\n\n```bash\nssh-dashboard\n```\n\nThe tool will:\n1. Scan your `~/.ssh/config` for available hosts\n2. Present an interactive list to select from\n3. Connect and display a live dashboard\n4. Update stats every 5 seconds (configurable)\n\n**Multi-host workflow:**\n- Start by selecting one or more hosts (use `Space` to toggle selection)\n- Press `Enter` to connect and view the dashboard\n- While in the dashboard, press `c` to return to host selection to add/remove hosts\n- Press `n` to cycle through connected hosts (like tmux sessions)\n- Press `t` to toggle overview mode, showing all selected hosts at once with GPU pressure summaries\n- Press `s` to exit the dashboard and drop into an interactive SSH shell with the current host\n- All connections remain active - no need to reconnect!\n\n### Configuration\n\n**Update Interval:**\n\nControl how often the dashboard refreshes in seconds (default: 5). Supports decimal values for sub-second updates:\n\n```bash\n# Update every second\nssh-dashboard -n 1\n\n# Update 10 times per second (100ms)\nssh-dashboard -n 0.1\n\n# or with an env var\nexport SSH_DASHBOARD_INTERVAL=0.5\nssh-dashboard\n```\n\n**Keybindings:**\n- `q` or `Ctrl+C` - Quit\n- `Space` - Select/deselect hosts (in host selection screen)\n- `Enter` - Connect to selected host(s)\n- `n` - Switch to next host (when multiple hosts selected)\n- `t` - Toggle overview screen (shows all hosts at once)\n- `s` - Exit and SSH into current host\n- `c` - Add hosts (from dashboard, returns to host selection)\n\n## SSH Configuration\n\nMake sure your `~/.ssh/config` is properly configured:\n\n```\nHost myserver\n    HostName 192.168.1.100\n    User username\n    Port 22  # optional\n    IdentityFile ~/.ssh/id_rsa  # optional\n\nHost gpu-server\n    HostName gpu.example.com\n    User admin\n    IdentityFile ~/.ssh/id_ed25519  # optional\n```\n\n### SSH Agent\n\nThe dashboard uses SSH agent for authentication. Make sure your keys are loaded:\n\n```bash\nssh-add ~/.ssh/id_rsa\nssh-add ~/.ssh/id_ed25519\n\n# verify\nssh-add -l\n```\n\n## Remote Requirements\n\nThe remote hosts should have these commands available:\n- `lscpu` - CPU information\n- `top` - CPU usage\n- `free` - RAM information\n- `df` - Disk usage\n- `nvidia-smi` - GPU information (NVIDIA GPUs only)\n- `amd-smi` or `rocm-smi` - GPU information (AMD GPUs only)\n\nMost Linux distributions include these by default.\n\n## Development\n\n### Build\n\n```bash\nmake build\n```\n\n### Run\n\n```bash\nmake run\n```\n\n### Build for Multiple Platforms\n\nThe project uses [GoReleaser](https://goreleaser.com/) for multi-platform builds and releases.\n\n**Test the release locally:**\n```bash\ngoreleaser release --snapshot --clean\n```\n\n**Build all platforms with Make:**\n```bash\nmake build-all\n```\n\nThis creates binaries for:\n- Linux (amd64, arm64)\n- macOS (amd64, arm64)\n- Windows (amd64, arm64)\n\n### Clean\n\n```bash\nmake clean\n```\n\n## License\n\nMIT License - see LICENSE file for details.\n\n## Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n## Troubleshooting\n\n### Connection Issues\n- Verify your SSH config is correct\n- Test manual connection: `ssh hostname`\n- Ensure SSH keys are loaded: `ssh-add -l`\n\n### Missing GPU Information\n- (NVIDIA) Verify NVIDIA drivers are installed: `ssh hostname nvidia-smi`\n- (AMD) Verify AMD drivers are installed: `ssh hostname amd-smi` or `ssh hostname rocm-smi`\n\n### Permission Denied\n- Check SSH key permissions (should be 600)\n- Verify the user has appropriate access rights\n\n## Acknowledgments\n\nBuilt with:\n- [Bubble Tea](https://github.com/charmbracelet/bubbletea) - TUI framework\n- [Lipgloss](https://github.com/charmbracelet/lipgloss) - Terminal styling\n- [Bubbles](https://github.com/charmbracelet/bubbles) - TUI components\n",
      "default_branch": "master"
    },
    "fetched_at": "2025-10-14T02:20:00.734165"
  },
  {
    "basic_info": {
      "name": "tuppr",
      "full_name": "home-operations/tuppr",
      "owner": "home-operations",
      "description": "Kubernetes controller to upgrade Talos and Kubernetes",
      "url": "https://github.com/home-operations/tuppr",
      "clone_url": "https://github.com/home-operations/tuppr.git",
      "ssh_url": "git@github.com:home-operations/tuppr.git",
      "homepage": "",
      "created_at": "2025-09-16T22:01:48Z",
      "updated_at": "2025-10-13T03:20:54Z",
      "pushed_at": "2025-10-10T22:23:46Z"
    },
    "stats": {
      "stars": 82,
      "forks": 0,
      "watchers": 82,
      "open_issues": 2,
      "size": 503
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 161578,
        "Makefile": 16229,
        "Smarty": 13610,
        "Dockerfile": 1256,
        "Shell": 603
      },
      "license": "GNU Affero General Public License v3.0",
      "topics": [
        "kubernetes",
        "talos"
      ]
    },
    "content": {
      "readme": "# tuppr - Talos Linux Upgrade Controller\n\nA Kubernetes controller for managing automated upgrades of Talos Linux and Kubernetes.\n\n## ✨ Features\n\n### Core Capabilities\n\n- 🚀 **Automated Talos node upgrades** with intelligent orchestration\n- 🎯 **Kubernetes upgrades** - upgrade Kubernetes to newer versions\n- 🔒 **Safe upgrade execution** - upgrades always run from healthy nodes (never self-upgrade)\n- 📊 **Built-in health checks** - CEL-based expressions for custom cluster validation\n- 🔄 **Configurable reboot modes** - default or powercycle options\n- 📋 **Comprehensive status tracking** with real-time progress reporting\n- ⚡ **Resilient job execution** with automatic retry and pod replacement\n- 📈 **Prometheus metrics** - detailed monitoring of upgrade progress and health\n\n## 🚀 Quick Start\n\n### Prerequisites\n\n1. **Talos cluster** with API access configured\n2. **Namespace** for the controller (e.g., `system-upgrade`)\n\n### Installation\n\nAllow Talos API access to the desired namespace by applying this config to all of you nodes:\n\n```yaml\nmachine:\n  features:\n    kubernetesTalosAPIAccess:\n      allowedKubernetesNamespaces:\n        - system-upgrade # or the namespace the controller will be installed to\n      allowedRoles:\n        - os:admin\n      enabled: true\n```\n\nInstall the Helm chart:\n\n```bash\n# Install via Helm\nhelm install tuppr oci://ghcr.io/home-operations/charts/tuppr \\\n  --version 0.1.0 \\\n  --namespace system-upgrade\n```\n\n### Basic Usage\n\n#### Talos Node Upgrades\n\nCreate a `TalosUpgrade` resource:\n\n```yaml\napiVersion: tuppr.home-operations.com/v1alpha1\nkind: TalosUpgrade\nmetadata:\n  name: cluster\nspec:\n  talos:\n    # renovate: datasource=docker depName=ghcr.io/siderolabs/installer\n    version: v1.11.0  # Required - target Talos version\n\n  policy:\n    debug: true          # Optional, verbose logging\n    force: false         # Optional, skip etcd health checks\n    rebootMode: default  # Optional, default|powercycle\n    placement: soft      # Optional, hard|soft\n\n  # Custom health checks (optional)\n  healthChecks:\n    - apiVersion: v1\n      kind: Node\n      expr: status.conditions.exists(c, c.type == \"Ready\" && c.status == \"True\")\n\n  # Talosctl configuration (optional)\n  talosctl:\n    image:\n      repository: ghcr.io/siderolabs/talosctl  # Optional, default\n      tag: v1.11.0                             # Optional, auto-detected\n      pullPolicy: IfNotPresent                 # Optional, default\n```\n\n#### Kubernetes Upgrades\n\nCreate a `KubernetesUpgrade` resource:\n\n```yaml\napiVersion: tuppr.home-operations.com/v1alpha1\nkind: KubernetesUpgrade\nmetadata:\n  name: kubernetes\nspec:\n  kubernetes:\n    # renovate: datasource=docker depName=ghcr.io/siderolabs/kubelet\n    version: v1.34.0  # Required - target Kubernetes version\n\n  # Custom health checks (optional)\n  healthChecks:\n    - apiVersion: v1\n      kind: Node\n      expr: status.conditions.exists(c, c.type == \"Ready\" && c.status == \"True\")\n      timeout: 10m\n\n  # Talosctl configuration (optional)\n  talosctl:\n    image:\n      repository: ghcr.io/siderolabs/talosctl  # Optional, default\n      tag: v1.11.0                             # Optional, auto-detected\n      pullPolicy: IfNotPresent                 # Optional, default\n```\n\n## 🎯 Advanced Configuration\n\n### Health Checks\n\nDefine custom health checks using [CEL expressions](https://cel.dev/). These health checks are evaluated before each upgrade and run concurrently.\n\n```yaml\nhealthChecks:\n  # Check all nodes are ready\n  - apiVersion: v1\n    kind: Node\n    expr: |\n      status.conditions.filter(c, c.type == \"Ready\").all(c, c.status == \"True\")\n    timeout: 10m\n\n  # Check specific deployment replicas\n  - apiVersion: apps/v1\n    kind: Deployment\n    name: critical-app\n    namespace: production\n    expr: status.readyReplicas == status.replicas\n\n  # Check custom resources\n  - apiVersion: ceph.rook.io/v1\n    kind: CephCluster\n    name: rook-ceph\n    namespace: rook-ceph\n    expr: status.ceph.health in [\"HEALTH_OK\"]\n```\n\n### Upgrade Policies (TalosUpgrade only)\n\nFine-tune upgrade behavior:\n\n```yaml\npolicy:\n  # Enable debug logging for troubleshooting\n  debug: true\n\n  # Force upgrade even if etcd is unhealthy (dangerous!)\n  force: true\n\n  # Controls how strictly upgrade jobs avoid the target node\n  placement: hard  # or \"soft\"\n\n  # Use powercycle reboot for problematic nodes\n  rebootMode: powercycle  # or \"default\"\n```\n\n## 📊 Monitoring & Metrics\n\n### Prometheus Metrics\n\nTuppr exposes comprehensive Prometheus metrics for monitoring upgrade progress, health check performance, and job execution:\n\n#### Talos Upgrade Metrics\n\n```prometheus\n# Current phase of Talos upgrades (0=Pending, 1=InProgress, 2=Completed, 3=Failed)\ntuppr_talos_upgrade_phase{name=\"cluster\", phase=\"InProgress\"} 1\n\n# Node counts for Talos upgrades\ntuppr_talos_upgrade_nodes_total{name=\"cluster\"} 5\ntuppr_talos_upgrade_nodes_completed{name=\"cluster\"} 3\ntuppr_talos_upgrade_nodes_failed{name=\"cluster\"} 0\n\n# Duration of Talos upgrade phases (histogram)\ntuppr_talos_up",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-14T02:20:02.044011"
  },
  {
    "basic_info": {
      "name": "brrtfetch",
      "full_name": "ferrebarrat/brrtfetch",
      "owner": "ferrebarrat",
      "description": "Render animated ASCII art from a GIF for your sysinfo fetcher of choice.",
      "url": "https://github.com/ferrebarrat/brrtfetch",
      "clone_url": "https://github.com/ferrebarrat/brrtfetch.git",
      "ssh_url": "git@github.com:ferrebarrat/brrtfetch.git",
      "homepage": "",
      "created_at": "2025-10-05T19:04:58Z",
      "updated_at": "2025-10-13T22:03:17Z",
      "pushed_at": "2025-10-07T09:43:47Z"
    },
    "stats": {
      "stars": 82,
      "forks": 2,
      "watchers": 82,
      "open_issues": 3,
      "size": 126605
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 9370,
        "Nix": 811
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "<h3 align=\"center\"><img src=\"./docs/readme-md-brrtfetch-main-textlogo.png\" alt=\"logo\" height=\"100px\"></h3>\n<p align=\"center\"><img src=\"./docs/readme-md-main.gif\" height=\"400px\"></p>\n<p align=\"center\"><i>Fastfetch config: https://github.com/xerolinux/xero-layan-git</i></p>\n\n**Brrtfetch** is an animated system information fetcher written mainly in Go. Please keep in mind that it is still in it's very early stage of development. It displays the user specified **GIF rendered as animated ASCII art** alongside the system information from your favourite fetcher.\n\nThink of it like a renderer that replaces the ASCII art for your fetcher with **animated** art. You only need to provide a .gif file.\n\nBroken on MacOS. It does not display sysinfo. I do not own any Apple devices so apologies if this takes a while to fix.\n\nIn the next version I plan to use a new way of deciding what to put where in the terminal. It should be way more stable. No more color bugs, already confirmed hyfetch works(no workaround needed),the issue with illegal flags for the script binary on MacOS will also be resolved in the upcoming release. You can also expect a very cool new feature which I have not seen on any other animated fetchers when the new update is released.\n\n---\n \n## ✨ Features\n\n* Render animated GIFs as **colorful ASCII art** directly in your terminal.\n* Side-by-side system information via `fastfetch`, `neofetch`, or your fetcher of choice. I have only tested with `fastfetch`, `neofetch` and `hyfetch`. Hyfetch requires a small workaround and even then it's still a bit buggy with hyfetch. See examples below. \n* **True color (24-bit ANSI)** support with optional white monochrome mode via `-color=false`.\n* **Multithreaded prerendering** for smooth playback.\n* Configurable:\n\n  * Width / height to render at\n  * FPS to render at (impacts animation speed)\n  * Brightness multiplier (controls density of ASCII mapping)\n  * Vertical offset for aligning sysinfo height relative to  ASCII art\n* Attempts to preserves **ANSI color codes** from sysinfo commands (broken for hyfetch and Windows CMD/Powershell. WSL does show color for the sysinfo. Only tested this with Ubuntu for WSL).\n* If you can somehow render DOOM in GIF format you could technically use this to play DOOM in your fetcher. It would only be (re)rendered in brrtfetch, not actually run inside of it, at least for now ;)\n\n---\n\n## 📦 Installation\n\nMore comprehensive instructions for different distros and support for various package managers will be coming soon.\n\nDebian/Ubuntu based steps only for the initial release, it should work on any linux system as long as you replace apt with your package manager for the dependencies. You can install it on Windows and Mac if you want. Just translate the steps to Windows. Will try to add Winget support later so i don't have to make an install script/instructions for Powershell. I will also attempt to add support for all major Linux package managers and Brew.\n\n\n### Prerequisites\n\n* A terminal that supports ANSI colors and escape sequences. Almost all modern terminals do.\n* `Script` (Linux only) \n\n  Optional but highly recommended for sysinfo color support. Part of the **bsdutils** package. Comes by default on most systems. Check with \"which script\"\n* `Unbuffer` (Linux only)\n\n  Optional but recommended. Part of the `expect` package. Install with \"apt install expect\" or any other package manager. Brrtfetch will attempt to fallback on `unbuffer` if `script` is not available. \n* A fetch application with an option to omit the ASCII art.\n\n  * [fastfetch](https://github.com/fastfetch-cli/fastfetch) (default)\n  * [hyfetch](https://github.com/hykilpikonna/hyfetch)\n  * Or any command you like, it can be specified with `-info \"neofetch --off\"` or even `-info \"echo $USER\"` or anything custom if you want.\n\n  ```bash\n  apt install fastfetch # only works on Debian 13+, see fastfetch docs for other version and distros\n  apt install bsdutils expect\n  ```\n\n### Build from source\n\nAdditional prerequisite:\n* Go 1.20+ (I used Go 1.23.3, will assume 1.20+ works)\n\n  ```bash\n  # Install Go (replace apt with your package manager like brew, yum, pacman etc)\n  sudo apt install golang\n\n  # Build\n  git clone https://github.com/ferrebarrat/brrtfetch\n  cd brrtfetch \n  go build -o ./bin/brrtfetch ./go/main.go && chmod +x ./bin/brrtfetch\n\n  # Add to path\n  sudo cp ./bin/brrtfetch /usr/local/bin/brrtfetch\n\n  # Optional - Save gifs from repo before cleanup\n  mkdir -p /home/$USER/Pictures/brrtfetch/gifs\n  cp -r ./gifs/* /home/$USER/Pictures/brrtfetch/gifs\n\n  # Cleanup\n  cd .. && rm -rf brrtfetch\n  ```\n\n---\n\n## 🎮 Usage\n\n  ```bash\n  brrtfetch [options] /path/to/file.gif\n  ```\n\n* **Ctrl-C** → attempts to exit the animation gracefully, clears and restores terminal, prints first frame with sysinfo and returns you to your prompt as if it was just a static fetcher.\n* Animation loops endlessly until interrupted with **CTRL-C**.\n\n<p><img src=\"./docs/readme-md-example-run.gif\" height=\"300px\"></p>\n\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-14T02:20:03.368446"
  },
  {
    "basic_info": {
      "name": "frankenphp-grpc",
      "full_name": "dunglas/frankenphp-grpc",
      "owner": "dunglas",
      "description": " A PHP extension to write gRPC servers using the official gRPC library written in Go ",
      "url": "https://github.com/dunglas/frankenphp-grpc",
      "clone_url": "https://github.com/dunglas/frankenphp-grpc.git",
      "ssh_url": "git@github.com:dunglas/frankenphp-grpc.git",
      "homepage": null,
      "created_at": "2025-09-15T13:46:34Z",
      "updated_at": "2025-10-10T10:27:09Z",
      "pushed_at": "2025-10-09T22:26:50Z"
    },
    "stats": {
      "stars": 81,
      "forks": 2,
      "watchers": 81,
      "open_issues": 3,
      "size": 171
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 3751
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# FrankenPHP gRPC Server\n\nA [FrankenPHP](https://frankenphp.dev) extension that allows you to run a [gRPC](https://grpc.io/) server triggering code written either in PHP or Go.\nUnder the hood, this extension uses the [gRPC for Go](https://grpc.io/docs/languages/go/) library and FrankenPHP's [Go extension support](https://frankenphp.dev/docs/extensions/).\n\n> [!WARNING]\n>\n> This extension is highly experimental and not recommended for production use.\n> The public API may change at any time without notice.\n\n## Features\n\n* Run a high performance gRPC server with FrankenPHP (the PHP part is executed in a worker loop)\n* Write gRPC service handlers in PHP\n* Write gRPC service handlers in Go\n* Write gRPC service handlers in a mix of PHP and Go 🤯\n* All features supported by the [gRPC for Go](https://grpc.io/docs/languages/go/) library\n* Entirely written in Go, no C code!\n* [API Platform](https://api-platform.com) compatibility!\n\n## Prerequisites\n\n* FrankenPHP extensions prerequisites: https://frankenphp.dev/docs/extensions/#prerequisites\n* gRPC for Go prerequisites: https://grpc.io/docs/languages/go/quickstart/#prerequisites\n\n## Usage\n\n### Create a Go module\n\n```console\ngo mod init example.com/mygrpcserver \n```\n\n### Create a Protobuf Definition:\n\nCreate a `.proto` file describing your gRPC service and messages.\n\nExample (in a `helloworld/helloworld.proto` file):\n\n```protobuf\nsyntax = \"proto3\";\n\noption go_package = \"example.com/mygrpcserver/helloworld\";\n\npackage helloworld;\n\nservice Greeter {\n  rpc SayHello (HelloRequest) returns (HelloReply) {}\n}\n\nmessage HelloRequest {\n  string name = 1;\n}\n\nmessage HelloReply {\n  string message = 1;\n}\n```\n\nGenerate the Go code:\n\n```console\nprotoc --go_out=. --go_opt=paths=source_relative --go-grpc_out=. --go-grpc_opt=paths=source_relative helloworld/helloworld.proto\n```\n\n### Implement the gRPC Server in Go\n\n```go\npackage mygrpcserver\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\n\tpb \"example.com/mygrpcserver/helloworld\"\n\t\"github.com/dunglas/frankenphp\"\n\tphpGrpc \"github.com/dunglas/frankenphp-grpc\"\n\t\"github.com/go-viper/mapstructure/v2\"\n\t\"google.golang.org/grpc\"\n\t\"google.golang.org/grpc/reflection\"\n)\n\nfunc init() {\n\tphpGrpc.RegisterGrpcServerFactory(func() *grpc.Server {\n\t\ts := grpc.NewServer()\n\t\tpb.RegisterGreeterServer(s, &server{})\n\t\treflection.Register(s)\n\n\t\treturn s\n\t})\n}\n\ntype server struct {\n\tpb.UnimplementedGreeterServer\n}\n\n// SayHello implements helloworld.GreeterServer\nfunc (s *server) SayHello(_ context.Context, in *pb.HelloRequest) (*pb.HelloReply, error) {\n\tif in.Name == \"\" {\n\t\treturn nil, fmt.Errorf(\"the Name field is required\")\n\t}\n\n    // Convert the request to a map[string]any\n\tvar phpRequest map[string]any\n\tif err := mapstructure.Decode(in, &phpRequest); err != nil {\n\t\treturn nil, err\n\t}\n\n    // Call the PHP code, pass the map as a PHP associative array\n\tphpResponse := phpGrpc.HandleRequest(phpRequest)\n\n    // Convert the PHP response (a map) back to a HelloReply struct\n\tvar response pb.HelloReply\n\tif err := mapstructure.Decode(phpResponse.(frankenphp.AssociativeArray).Map, &response); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &response, nil\n}\n```\n\nRefer to the [gRPC for Go documentation](https://grpc.io/docs/languages/go/) for more details on how to implement your gRPC service in Go.\nRfer to the [FrankenPHP extensions documentation](https://frankenphp.dev/docs/extensions/) for more details on how to pass data from Go to PHP and vice versa.\n\n### Implement the gRPC Service Handler in PHP\n\nCreate a file named `grpc-worker.php` in the same directory as the FrankenPHP binary we'll build later:\n\n```php\n<?php\n\n// Require the Composer autoloader here if needed (API Platform, Symfony, etc.)\n//require __DIR__ . '/vendor/autoload.php';\n\n// Handler outside the loop for better performance (doing less work)\n$handler = static function (array $request): array  {\n\t// Do something with the gRPC request\n\n    return ['message' => \"Hello, {$request['Name']}\"];\n};\n\n$maxRequests = (int)($_SERVER['MAX_REQUESTS'] ?? 0);\nfor ($nbRequests = 0; !$maxRequests || $nbRequests < $maxRequests; ++$nbRequests) {\n    $keepRunning = \\frankenphp_handle_request($handler);\n\n    // Call the garbage collector to reduce the chances of it being triggered in the middle of the handling of a request\n    gc_collect_cycles();\n\n    if (!$keepRunning) {\n      break;\n    }\n}\n```\n\n### Create the `Caddyfile`\n\nCreate a `Caddyfile` in the same directory as the FrankenPHP binary we'll build later:\n\n```caddyfile\n{\n\tfrankenphp\n\tgrpc {\n\t\taddress :50051 # Optional\n\t\tworker grpc-worker.php # Optional\n\t\tmin_threads 50 # Optional, defaults to runtime.NumCPU()\n\t}\n}\n```\n\n### Build and Run the FrankenPHP Binary with the gRPC Extension\n\nRun the server:\n\n```console\nXCADDY_DEBUG=1\n    CGO_ENABLED=1 \\\n\tCGO_CFLAGS=\"$(php-config --includes) -I/opt/homebrew/include/\" \\\n\tCGO_LDFLAGS=\"$(php-config --ldflags) $(php-config --libs) -L/opt/homebrew/lib/ -L/usr/lib\" \\\n\txcaddy build\n\n./caddy run\n```\n\nYour gRPC server should now be running on `localhost:50051`.\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-14T02:20:04.628105"
  },
  {
    "basic_info": {
      "name": "go-shirei",
      "full_name": "hasenj/go-shirei",
      "owner": "hasenj",
      "description": "Go based GUI framework: practical, immediate mode, flexbox model",
      "url": "https://github.com/hasenj/go-shirei",
      "clone_url": "https://github.com/hasenj/go-shirei.git",
      "ssh_url": "git@github.com:hasenj/go-shirei.git",
      "homepage": "https://judi.systems/shirei/",
      "created_at": "2025-09-30T04:56:54Z",
      "updated_at": "2025-10-12T19:54:27Z",
      "pushed_at": "2025-10-06T11:18:15Z"
    },
    "stats": {
      "stars": 73,
      "forks": 1,
      "watchers": 73,
      "open_issues": 1,
      "size": 138
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 154677
      },
      "license": "zlib License",
      "topics": [
        "gioui",
        "gui",
        "imgui",
        "immediate-mode"
      ]
    },
    "content": {
      "readme": "shi•rei\n\nGUI framework for utility style programs\n\n* Immediate Mode: describe what the UI looks like each frame\n* Cross Platform: same UI code works on macOS, Linux, and Windows\n* Complex Text: shaping and bidirectional layout\n* Flexbox: containers arrange items horizontally or vertically, with options for\n  padding, gaps, alignment, wrapping, floating, scrolling, and size expansion.\n\nGetting started documentation available at: https://judi.systems/shirei\n",
      "default_branch": "master"
    },
    "fetched_at": "2025-10-14T02:20:05.904139"
  }
]