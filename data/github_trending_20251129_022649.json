[
  {
    "basic_info": {
      "name": "Valdi",
      "full_name": "Snapchat/Valdi",
      "owner": "Snapchat",
      "description": "Valdi is a cross-platform UI framework that delivers native performance without sacrificing developer velocity.",
      "url": "https://github.com/Snapchat/Valdi",
      "clone_url": "https://github.com/Snapchat/Valdi.git",
      "ssh_url": "git@github.com:Snapchat/Valdi.git",
      "homepage": "https://discord.gg/uJyNEeYX2U",
      "created_at": "2025-11-06T17:33:28Z",
      "updated_at": "2025-11-29T02:18:41Z",
      "pushed_at": "2025-11-27T00:20:58Z"
    },
    "stats": {
      "stars": 14379,
      "forks": 471,
      "watchers": 14379,
      "open_issues": 47,
      "size": 82201
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 8527623,
        "TypeScript": 4865748,
        "JavaScript": 2334883,
        "Swift": 1834904,
        "C": 1666128,
        "Kotlin": 1182282,
        "Objective-C": 1005392,
        "Objective-C++": 564284,
        "Starlark": 421554,
        "Java": 43300,
        "Shell": 38517,
        "Smarty": 6827,
        "HTML": 4271,
        "Python": 3905,
        "Pug": 645,
        "Makefile": 426,
        "Dockerfile": 235,
        "Linker Script": 171,
        "CSS": 140,
        "Go": 86,
        "SCSS": 20
      },
      "license": "Other",
      "topics": [
        "android",
        "cross-platform",
        "ios",
        "typescript",
        "valdi"
      ]
    },
    "content": {
      "readme": "# Valdi\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](./LICENSE.md)\n[![Platforms](https://img.shields.io/badge/platform-iOS%20%7C%20Android%20%7C%20macOS-lightgrey)](./docs/INSTALL.md)\n[![Status](https://img.shields.io/badge/status-beta-yellow)]()\n[![Discord](https://img.shields.io/discord/1285677307163574322?color=7289da&label=Discord&logo=discord&logoColor=white)](https://discord.gg/uJyNEeYX2U)\n[![TypeScript](https://img.shields.io/badge/TypeScript-5.x-blue?logo=typescript)](https://www.typescriptlang.org/)\n[![Documentation](https://img.shields.io/badge/docs-available-brightgreen)](./docs/README.md)\n[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](./CONTRIBUTING.md)\n\n> [!NOTE]\n> **Beta Status:** Valdi has been widely used in Snap's production apps for the last 8 years. We're calling this a beta because our tools and documentation need more battle testing in the open source world. Valdi will exit beta when we're happy with the developer experience.\n\n**Valdi is a cross-platform UI framework that delivers native performance without sacrificing developer velocity.** Write your UI once in declarative TypeScript, and it compiles directly to native views on iOS, Android, and macOS‚Äîno web views, no JavaScript bridges. \n\n## Quick Example\n\nA basic Valdi component:\n\n```tsx\nimport { Component } from 'valdi_core/src/Component';\n\nclass HelloWorld extends Component {\n  onRender() {\n    const message = 'Hello World! üëª';\n    <view backgroundColor='#FFFC00' padding={30}>\n      <label color='black' value={message} />\n    </view>;\n  }\n}\n```\n\n<p align=\"center\">\n  <img src=\"./docs/docs/assets/start-about/IMG_1445.jpg\" width=\"400\" alt=\"Hello World example running on iOS\" />\n</p>\n\n## Quick Start\n\n**Prerequisites:** Xcode (macOS only) - everything else is automatic!\n\n```bash\n# Install Valdi CLI\nnpm install -g @snap/valdi\n\n# One-command setup (installs all dependencies)\nvaldi dev_setup\n\n# Create your first project\nmkdir my_project && cd my_project\nvaldi bootstrap\nvaldi install ios  # or android\n```\n\n> [!TIP]\n> **Editor Extensions:** For the best development experience, install the [Valdi VSCode/Cursor extensions](./docs/INSTALL.md#vscodecursor-setup-optional-but-recommended) for syntax highlighting, debugging, and device logs during hot reload.\n\n## Quick Links\n\n- [Getting Started Guide](./docs/INSTALL.md)\n- [Documentation](./docs/README.md)\n- [Codelabs](./docs/docs/start-code-lab.md)\n- [API Reference](./docs/api/api-quick-reference.md)\n- [Frequently Asked Questions](./docs/docs/faq.md)\n- [Component Library](https://github.com/Snapchat/Valdi_Widgets)\n\n## Why Choose Valdi?\n\nValdi is a cross-platform UI framework designed to solve the fundamental problem of cross-platform development: velocity vs. runtime performance. For 8 years, it has powered a large portion of Snap's production apps.\n\n### True Native Performance\n\nUnlike frameworks that rely on web views or JavaScript bridges, Valdi compiles declaratively rendered TypeScript components into platform-native views. Valdi also includes several other performance advantages:\n\n- **[Automatic view recycling](./docs/docs/performance-view-recycling.md)** - Global view pooling system reuses native views across all screens, dramatically reducing inflation latency\n- **Optimized component rendering** - Components re-render independently without triggering parent re-renders, enabling fast incremental updates\n- **Optimized layout engine** - C++ layout engine runs on the main thread with minimal marshalling overhead\n- **Viewport-aware rendering** - Only visible views are inflated, making infinite scrolling performant by default\n\nLearn more in our [Performance Optimization Guide](./docs/docs/performance-optimization.md).\n\n### Developer Experience Built for Speed\n\nValdi eliminates the traditional compile-test-debug cycle that slows native development:\n\n- **Instant hot reload** - See changes in milliseconds on iOS, Android, or desktop without recompiling\n- **[Full VSCode debugging](./docs/docs/workflow-hermes-debugger.md)** - Set breakpoints, inspect variables, profile performance, and capture heap dumps directly in VSCode\n- **Familiar syntax** - TSX components with TypeScript for type safety\n\n### Flexible Adoption Model\n\nValdi integrates easily into existing apps - start small and scale as needed:\n\n- **[Embed Valdi in native](./docs/docs/native-bindings.md)** - Drop Valdi components into existing UIKit or Android view hierarchies\n- **[Embed native in Valdi](./docs/docs/native-customviews.md)** - Use platform-specific views within Valdi layouts via `<custom-view>`\n- **[Polyglot modules](./docs/docs/native-polyglot.md)** - Write performance-critical code in C++, Swift, Kotlin, or Objective-C with type-safe bindings to TypeScript\n- **[Full-stack architecture](./docs/docs/advanced-full-stack.md)** - Build entire features in Valdi with worker threads for background processing, eliminating platform-specific bridge code\n\n### Deep Native Integration\n\nValdi ",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-29T02:26:50.449601"
  },
  {
    "basic_info": {
      "name": "llm-council",
      "full_name": "karpathy/llm-council",
      "owner": "karpathy",
      "description": "LLM Council works together to answer your hardest questions",
      "url": "https://github.com/karpathy/llm-council",
      "clone_url": "https://github.com/karpathy/llm-council.git",
      "ssh_url": "git@github.com:karpathy/llm-council.git",
      "homepage": "",
      "created_at": "2025-11-22T23:24:14Z",
      "updated_at": "2025-11-29T02:23:37Z",
      "pushed_at": "2025-11-22T23:35:21Z"
    },
    "stats": {
      "stars": 7505,
      "forks": 1141,
      "watchers": 7505,
      "open_issues": 42,
      "size": 262
    },
    "tech_info": {
      "language": "Python",
      "languages": {
        "Python": 24729,
        "JavaScript": 20694,
        "CSS": 9346,
        "Shell": 625,
        "HTML": 357
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# LLM Council\n\n![llmcouncil](header.jpg)\n\nThe idea of this repo is that instead of asking a question to your favorite LLM provider (e.g. OpenAI GPT 5.1, Google Gemini 3.0 Pro, Anthropic Claude Sonnet 4.5, xAI Grok 4, eg.c), you can group them into your \"LLM Council\". This repo is a simple, local web app that essentially looks like ChatGPT except it uses OpenRouter to send your query to multiple LLMs, it then asks them to review and rank each other's work, and finally a Chairman LLM produces the final response.\n\nIn a bit more detail, here is what happens when you submit a query:\n\n1. **Stage 1: First opinions**. The user query is given to all LLMs individually, and the responses are collected. The individual responses are shown in a \"tab view\", so that the user can inspect them all one by one.\n2. **Stage 2: Review**. Each individual LLM is given the responses of the other LLMs. Under the hood, the LLM identities are anonymized so that the LLM can't play favorites when judging their outputs. The LLM is asked to rank them in accuracy and insight.\n3. **Stage 3: Final response**. The designated Chairman of the LLM Council takes all of the model's responses and compiles them into a single final answer that is presented to the user.\n\n## Vibe Code Alert\n\nThis project was 99% vibe coded as a fun Saturday hack because I wanted to explore and evaluate a number of LLMs side by side in the process of [reading books together with LLMs](https://x.com/karpathy/status/1990577951671509438). It's nice and useful to see multiple responses side by side, and also the cross-opinions of all LLMs on each other's outputs. I'm not going to support it in any way, it's provided here as is for other people's inspiration and I don't intend to improve it. Code is ephemeral now and libraries are over, ask your LLM to change it in whatever way you like.\n\n## Setup\n\n### 1. Install Dependencies\n\nThe project uses [uv](https://docs.astral.sh/uv/) for project management.\n\n**Backend:**\n```bash\nuv sync\n```\n\n**Frontend:**\n```bash\ncd frontend\nnpm install\ncd ..\n```\n\n### 2. Configure API Key\n\nCreate a `.env` file in the project root:\n\n```bash\nOPENROUTER_API_KEY=sk-or-v1-...\n```\n\nGet your API key at [openrouter.ai](https://openrouter.ai/). Make sure to purchase the credits you need, or sign up for automatic top up.\n\n### 3. Configure Models (Optional)\n\nEdit `backend/config.py` to customize the council:\n\n```python\nCOUNCIL_MODELS = [\n    \"openai/gpt-5.1\",\n    \"google/gemini-3-pro-preview\",\n    \"anthropic/claude-sonnet-4.5\",\n    \"x-ai/grok-4\",\n]\n\nCHAIRMAN_MODEL = \"google/gemini-3-pro-preview\"\n```\n\n## Running the Application\n\n**Option 1: Use the start script**\n```bash\n./start.sh\n```\n\n**Option 2: Run manually**\n\nTerminal 1 (Backend):\n```bash\nuv run python -m backend.main\n```\n\nTerminal 2 (Frontend):\n```bash\ncd frontend\nnpm run dev\n```\n\nThen open http://localhost:5173 in your browser.\n\n## Tech Stack\n\n- **Backend:** FastAPI (Python 3.10+), async httpx, OpenRouter API\n- **Frontend:** React + Vite, react-markdown for rendering\n- **Storage:** JSON files in `data/conversations/`\n- **Package Management:** uv for Python, npm for JavaScript\n",
      "default_branch": "master"
    },
    "fetched_at": "2025-11-29T02:26:51.712226"
  },
  {
    "basic_info": {
      "name": "claude-code-infrastructure-showcase",
      "full_name": "diet103/claude-code-infrastructure-showcase",
      "owner": "diet103",
      "description": "Examples of my Claude Code infrastructure with skill auto-activation, hooks, and agents",
      "url": "https://github.com/diet103/claude-code-infrastructure-showcase",
      "clone_url": "https://github.com/diet103/claude-code-infrastructure-showcase.git",
      "ssh_url": "git@github.com:diet103/claude-code-infrastructure-showcase.git",
      "homepage": null,
      "created_at": "2025-10-30T03:12:16Z",
      "updated_at": "2025-11-29T01:28:35Z",
      "pushed_at": "2025-10-31T01:41:31Z"
    },
    "stats": {
      "stars": 7288,
      "forks": 951,
      "watchers": 7288,
      "open_issues": 13,
      "size": 214
    },
    "tech_info": {
      "language": "Shell",
      "languages": {
        "Shell": 19297,
        "JavaScript": 12798
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# Claude Code Infrastructure Showcase\n\n**A curated reference library of production-tested Claude Code infrastructure.**\n\nBorn from 6 months of real-world use managing a complex TypeScript microservices project, this showcase provides the patterns and systems that solved the \"skills don't activate automatically\" problem and scaled Claude Code for enterprise development.\n\n> **This is NOT a working application** - it's a reference library. Copy what you need into your own projects.\n\n---\n\n## What's Inside\n\n**Production-tested infrastructure for:**\n- ‚úÖ **Auto-activating skills** via hooks\n- ‚úÖ **Modular skill pattern** (500-line rule with progressive disclosure)\n- ‚úÖ **Specialized agents** for complex tasks\n- ‚úÖ **Dev docs system** that survives context resets\n- ‚úÖ **Comprehensive examples** using generic blog domain\n\n**Time investment to build:** 6 months of iteration\n**Time to integrate into your project:** 15-30 minutes\n\n---\n\n## Quick Start - Pick Your Path\n\n### ü§ñ Using Claude Code to Integrate?\n\n**Claude:** Read [`CLAUDE_INTEGRATION_GUIDE.md`](CLAUDE_INTEGRATION_GUIDE.md) for step-by-step integration instructions tailored for AI-assisted setup.\n\n### üéØ I want skill auto-activation\n\n**The breakthrough feature:** Skills that actually activate when you need them.\n\n**What you need:**\n1. The skill-activation hooks (2 files)\n2. A skill or two relevant to your work\n3. 15 minutes\n\n**üëâ [Setup Guide: .claude/hooks/README.md](.claude/hooks/README.md)**\n\n### üìö I want to add ONE skill\n\nBrowse the [skills catalog](.claude/skills/) and copy what you need.\n\n**Available:**\n- **backend-dev-guidelines** - Node.js/Express/TypeScript patterns\n- **frontend-dev-guidelines** - React/TypeScript/MUI v7 patterns\n- **skill-developer** - Meta-skill for creating skills\n- **route-tester** - Test authenticated API routes\n- **error-tracking** - Sentry integration patterns\n\n**üëâ [Skills Guide: .claude/skills/README.md](.claude/skills/README.md)**\n\n### ü§ñ I want specialized agents\n\n10 production-tested agents for complex tasks:\n- Code architecture review\n- Refactoring assistance\n- Documentation generation\n- Error debugging\n- And more...\n\n**üëâ [Agents Guide: .claude/agents/README.md](.claude/agents/README.md)**\n\n---\n\n## What Makes This Different?\n\n### The Auto-Activation Breakthrough\n\n**Problem:** Claude Code skills just sit there. You have to remember to use them.\n\n**Solution:** UserPromptSubmit hook that:\n- Analyzes your prompts\n- Checks file context\n- Automatically suggests relevant skills\n- Works via `skill-rules.json` configuration\n\n**Result:** Skills activate when you need them, not when you remember them.\n\n### Production-Tested Patterns\n\nThese aren't theoretical examples - they're extracted from:\n- ‚úÖ 6 microservices in production\n- ‚úÖ 50,000+ lines of TypeScript\n- ‚úÖ React frontend with complex data grids\n- ‚úÖ Sophisticated workflow engine\n- ‚úÖ 6 months of daily Claude Code use\n\nThe patterns work because they solved real problems.\n\n### Modular Skills (500-Line Rule)\n\nLarge skills hit context limits. The solution:\n\n```\nskill-name/\n  SKILL.md                  # <500 lines, high-level guide\n  resources/\n    topic-1.md              # <500 lines each\n    topic-2.md\n    topic-3.md\n```\n\n**Progressive disclosure:** Claude loads main skill first, loads resources only when needed.\n\n---\n\n## Repository Structure\n\n```\n.claude/\n‚îú‚îÄ‚îÄ skills/                 # 5 production skills\n‚îÇ   ‚îú‚îÄ‚îÄ backend-dev-guidelines/  (12 resource files)\n‚îÇ   ‚îú‚îÄ‚îÄ frontend-dev-guidelines/ (11 resource files)\n‚îÇ   ‚îú‚îÄ‚îÄ skill-developer/         (7 resource files)\n‚îÇ   ‚îú‚îÄ‚îÄ route-tester/\n‚îÇ   ‚îú‚îÄ‚îÄ error-tracking/\n‚îÇ   ‚îî‚îÄ‚îÄ skill-rules.json    # Skill activation configuration\n‚îú‚îÄ‚îÄ hooks/                  # 6 hooks for automation\n‚îÇ   ‚îú‚îÄ‚îÄ skill-activation-prompt.*  (ESSENTIAL)\n‚îÇ   ‚îú‚îÄ‚îÄ post-tool-use-tracker.sh   (ESSENTIAL)\n‚îÇ   ‚îú‚îÄ‚îÄ tsc-check.sh        (optional, needs customization)\n‚îÇ   ‚îî‚îÄ‚îÄ trigger-build-resolver.sh  (optional)\n‚îú‚îÄ‚îÄ agents/                 # 10 specialized agents\n‚îÇ   ‚îú‚îÄ‚îÄ code-architecture-reviewer.md\n‚îÇ   ‚îú‚îÄ‚îÄ refactor-planner.md\n‚îÇ   ‚îú‚îÄ‚îÄ frontend-error-fixer.md\n‚îÇ   ‚îî‚îÄ‚îÄ ... 7 more\n‚îî‚îÄ‚îÄ commands/               # 3 slash commands\n    ‚îú‚îÄ‚îÄ dev-docs.md\n    ‚îî‚îÄ‚îÄ ...\n\ndev/\n‚îî‚îÄ‚îÄ active/                 # Dev docs pattern examples\n    ‚îî‚îÄ‚îÄ public-infrastructure-repo/\n```\n\n---\n\n## Component Catalog\n\n### üé® Skills (5)\n\n| Skill | Lines | Purpose | Best For |\n|-------|-------|---------|----------|\n| [**skill-developer**](.claude/skills/skill-developer/) | 426 | Creating and managing skills | Meta-development |\n| [**backend-dev-guidelines**](.claude/skills/backend-dev-guidelines/) | 304 | Express/Prisma/Sentry patterns | Backend APIs |\n| [**frontend-dev-guidelines**](.claude/skills/frontend-dev-guidelines/) | 398 | React/MUI v7/TypeScript | React frontends |\n| [**route-tester**](.claude/skills/route-tester/) | 389 | Testing authenticated routes | API testing |\n| [**error-tracking**](.claude/skills/error-tracking/) | ~250 | Sentry integration | Error monitoring |\n\n**All skills follow the modular pattern** - main",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-29T02:26:53.003192"
  },
  {
    "basic_info": {
      "name": "Depth-Anything-3",
      "full_name": "ByteDance-Seed/Depth-Anything-3",
      "owner": "ByteDance-Seed",
      "description": "Depth Anything 3",
      "url": "https://github.com/ByteDance-Seed/Depth-Anything-3",
      "clone_url": "https://github.com/ByteDance-Seed/Depth-Anything-3.git",
      "ssh_url": "git@github.com:ByteDance-Seed/Depth-Anything-3.git",
      "homepage": "https://depth-anything-3.github.io/",
      "created_at": "2025-11-12T08:44:03Z",
      "updated_at": "2025-11-29T01:56:08Z",
      "pushed_at": "2025-11-28T11:01:29Z"
    },
    "stats": {
      "stars": 2977,
      "forks": 227,
      "watchers": 2977,
      "open_issues": 74,
      "size": 22598
    },
    "tech_info": {
      "language": "Jupyter Notebook",
      "languages": {
        "Jupyter Notebook": 650520,
        "Python": 646939
      },
      "license": "Apache License 2.0",
      "topics": []
    },
    "content": {
      "readme": "<div align=\"center\">\n<h1 style=\"border-bottom: none; margin-bottom: 0px \">Depth Anything 3: Recovering the Visual Space from Any Views</h1>\n<!-- <h2 style=\"border-top: none; margin-top: 3px;\">Recovering the Visual Space from Any Views</h2> -->\n\n\n[**Haotong Lin**](https://haotongl.github.io/)<sup>&ast;</sup> ¬∑ [**Sili Chen**](https://github.com/SiliChen321)<sup>&ast;</sup> ¬∑ [**Jun Hao Liew**](https://liewjunhao.github.io/)<sup>&ast;</sup> ¬∑ [**Donny Y. Chen**](https://donydchen.github.io)<sup>&ast;</sup> ¬∑ [**Zhenyu Li**](https://zhyever.github.io/) ¬∑ [**Guang Shi**](https://scholar.google.com/citations?user=MjXxWbUAAAAJ&hl=en) ¬∑ [**Jiashi Feng**](https://scholar.google.com.sg/citations?user=Q8iay0gAAAAJ&hl=en)\n<br>\n[**Bingyi Kang**](https://bingykang.github.io/)<sup>&ast;&dagger;</sup>\n\n&dagger;project lead&emsp;&ast;Equal Contribution\n\n<a href=\"https://arxiv.org/abs/2511.10647\"><img src='https://img.shields.io/badge/arXiv-Depth Anything 3-red' alt='Paper PDF'></a>\n<a href='https://depth-anything-3.github.io'><img src='https://img.shields.io/badge/Project_Page-Depth Anything 3-green' alt='Project Page'></a>\n<a href='https://huggingface.co/spaces/depth-anything/Depth-Anything-3'><img src='https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Demo-blue'></a>\n<!-- <a href='https://huggingface.co/datasets/depth-anything/VGB'><img src='https://img.shields.io/badge/Benchmark-VisGeo-yellow' alt='Benchmark'></a> -->\n<!-- <a href='https://huggingface.co/datasets/depth-anything/data'><img src='https://img.shields.io/badge/Benchmark-xxx-yellow' alt='Data'></a> -->\n\n</div>\n\nThis work presents **Depth Anything 3 (DA3)**, a model that predicts spatially consistent geometry from\narbitrary visual inputs, with or without known camera poses.\nIn pursuit of minimal modeling, DA3 yields two key insights:\n- üíé A **single plain transformer** (e.g., vanilla DINO encoder) is sufficient as a backbone without architectural specialization,\n- ‚ú® A singular **depth-ray representation** obviates the need for complex multi-task learning.\n\nüèÜ DA3 significantly outperforms\n[DA2](https://github.com/DepthAnything/Depth-Anything-V2) for monocular depth estimation,\nand [VGGT](https://github.com/facebookresearch/vggt) for multi-view depth estimation and pose estimation.\nAll models are trained exclusively on **public academic datasets**.\n\n<!-- <p align=\"center\">\n  <img src=\"assets/images/da3_teaser.png\" alt=\"Depth Anything 3\" width=\"100%\">\n</p> -->\n<p align=\"center\">\n  <img src=\"assets/images/demo320-2.gif\" alt=\"Depth Anything 3 - Left\" width=\"70%\">\n</p>\n<p align=\"center\">\n  <img src=\"assets/images/da3_radar.png\" alt=\"Depth Anything 3\" width=\"100%\">\n</p>\n\n\n## üì∞ News\n- **25-11-2025:** Add [Awesome DA3 Projects](#-awesome-da3-projects), a community-driven section featuring DA3-based applications.\n- **14-11-2025:** Paper, project page, code and models are all released.\n\n## ‚ú® Highlights\n\n### üèÜ Model Zoo\nWe release three series of models, each tailored for specific use cases in visual geometry.\n\n- üåü **DA3 Main Series** (`DA3-Giant`, `DA3-Large`, `DA3-Base`, `DA3-Small`) These are our flagship foundation models, trained with a unified depth-ray representation. By varying the input configuration, a single model can perform a wide range of tasks:\n  + üåä **Monocular Depth Estimation**: Predicts a depth map from a single RGB image.\n  + üåä **Multi-View Depth Estimation**: Generates consistent depth maps from multiple images for high-quality fusion.\n  + üéØ **Pose-Conditioned Depth Estimation**: Achieves superior depth consistency when camera poses are provided as input.\n  + üì∑ **Camera Pose Estimation**:  Estimates camera extrinsics and intrinsics from one or more images.\n  + üü° **3D Gaussian Estimation**: Directly predicts 3D Gaussians, enabling high-fidelity novel view synthesis.\n\n- üìê **DA3 Metric Series** (`DA3Metric-Large`) A specialized model fine-tuned for metric depth estimation in monocular settings, ideal for applications requiring real-world scale.\n\n- üîç **DA3 Monocular Series** (`DA3Mono-Large`). A dedicated model for high-quality relative monocular depth estimation. Unlike disparity-based models (e.g.,  [Depth Anything 2](https://github.com/DepthAnything/Depth-Anything-V2)), it directly predicts depth, resulting in superior geometric accuracy.\n\nüîó Leveraging these available models, we developed a **nested series** (`DA3Nested-Giant-Large`). This series combines a any-view giant model with a metric model to reconstruct visual geometry at a real-world metric scale.\n\n### üõ†Ô∏è Codebase Features\nOur repository is designed to be a powerful and user-friendly toolkit for both practical application and future research.\n- üé® **Interactive Web UI & Gallery**: Visualize model outputs and compare results with an easy-to-use Gradio-based web interface.\n- ‚ö° **Flexible Command-Line Interface (CLI)**: Powerful and scriptable CLI for batch processing and integration into custom workflows.\n- üíæ **Multiple Export Formats**: Save your results in various formats, including `g",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-29T02:26:54.282245"
  },
  {
    "basic_info": {
      "name": "gitlogue",
      "full_name": "unhappychoice/gitlogue",
      "owner": "unhappychoice",
      "description": "A cinematic Git commit replay tool for the terminal, turning your Git history into a living, animated story.",
      "url": "https://github.com/unhappychoice/gitlogue",
      "clone_url": "https://github.com/unhappychoice/gitlogue.git",
      "ssh_url": "git@github.com:unhappychoice/gitlogue.git",
      "homepage": "",
      "created_at": "2025-11-08T21:22:33Z",
      "updated_at": "2025-11-29T02:16:05Z",
      "pushed_at": "2025-11-28T17:59:32Z"
    },
    "stats": {
      "stars": 2747,
      "forks": 52,
      "watchers": 2747,
      "open_issues": 8,
      "size": 81053
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 192737,
        "Tree-sitter Query": 21004,
        "JavaScript": 19194,
        "Shell": 8335,
        "Nix": 2428,
        "Ruby": 1231,
        "Handlebars": 464
      },
      "license": "ISC License",
      "topics": [
        "cli",
        "cli-tool",
        "code-animation",
        "commit-history",
        "developer-tools",
        "git",
        "git-history",
        "git-visualization",
        "productivity",
        "ratatui",
        "rust",
        "screensaver",
        "syntax-highlighting",
        "terminal",
        "terminal-app",
        "terminal-based",
        "terminal-screensaver",
        "tree-sitter",
        "tui",
        "visualization"
      ]
    },
    "content": {
      "readme": "# gitlogue\n\n<a title=\"This tool is Tool of The Week on Terminal Trove, The $HOME of all things in the terminal\" href=\"https://terminaltrove.com/gitlogue/\"><img src=\"https://cdn.terminaltrove.com/media/badges/tool_of_the_week/svg/terminal_trove_tool_of_the_week_green_on_black_bg.svg\" alt=\"Terminal Trove Tool of The Week\" height=\"48\" /></a>\n\n<p align=\"center\">\n  <img src=\"docs/assets/demo.gif\" alt=\"gitlogue demo\" style=\"max-width: 100%; width: 800px;\" />\n</p>\n\nA cinematic Git commit replay tool for the terminal, turning your Git history into a living, animated story.\n\nWatch commits unfold with realistic typing animations, syntax highlighting, and file tree transitions, transforming code changes into a visual experience.\n\n## Installation\n\n### Using Install Script (Recommended)\n\n```bash\ncurl -fsSL https://raw.githubusercontent.com/unhappychoice/gitlogue/main/install.sh | bash\n```\n\n### Using Homebrew\n\n```bash\nbrew install gitlogue\n```\n\n### Using Cargo\n\n```bash\ncargo install gitlogue\n```\n\n### On Arch Linux\n\n```bash\npacman -S gitlogue\n```\n\n### Using Nix\n\n```bash\n# Run directly without installation\nnix run github:unhappychoice/gitlogue\n\n# Or install to your profile\nnix profile install github:unhappychoice/gitlogue\n\n# For flake-based configurations, add to your inputs:\n# inputs.gitlogue.url = \"github:unhappychoice/gitlogue\";\n# Then use: inputs.gitlogue.packages.${system}.default\n```\n\n### From Source\n\n```bash\ngit clone https://github.com/unhappychoice/gitlogue.git\ncd gitlogue\ncargo install --path .\n```\n\nSee the [Installation Guide](docs/installation.md) for more options and troubleshooting.\n\n## Features\n\nüé¨ **Commit Replay as Animation** ‚Äî Realistic typing, cursor movement, deletions, and file operations  \nüé® **Tree-sitter Syntax Highlighting** ‚Äî 29 languages supported  \nüå≥ **Project File Tree** ‚Äî Directory structure with change statistics  \nüñ•Ô∏è **Screensaver Mode** ‚Äî Endless random commit playback  \nüé≠ **Themes** ‚Äî 9 built-in themes + full customization support  \n‚ö° **Fast & Lightweight** ‚Äî Built with Rust for performance  \n\n## Usage\n\n### Popular Use Cases\n\nüñ•Ô∏è  **Screensaver** ‚Äî Ambient coding display for your workspace  \nüéì **Education** ‚Äî Visualize how code evolved over time  \nüì∫ **Presentations** ‚Äî Replay real commit histories live  \nüé¨ **Content Creation** ‚Äî Record demos with VHS or asciinema  \nüé® **Desktop Ricing** ‚Äî A living decoration for your terminal  \nüíº **Look Busy Mode** ‚Äî Appear productive during meetings\n\n> [!WARNING]\n> **Not a True Screensaver** ‚Äî gitlogue does not include traditional screensaver functions like power management or screen blanking. It's purely a visual display tool.\n>\n> **OLED Burn-in Risk** ‚Äî Static elements (like the editor background and border lines) may cause burn-in on OLED displays over extended periods. LCD displays are generally safe from this issue.\n\n### Quick Start\n\n```bash\n# Start the cinematic screensaver\ngitlogue\n\n# View a specific commit\ngitlogue --commit abc123\n\n# Replay a range of commits\ngitlogue --commit HEAD~5..HEAD\n\n# Replay commits in chronological order (oldest first)\ngitlogue --order asc\n\n# Loop a specific commit continuously\ngitlogue --commit abc123 --loop\n\n# Loop through a commit range\ngitlogue --commit HEAD~10..HEAD --loop\n\n# Filter commits by author or email (case-insensitive partial match)\ngitlogue --author \"john\"\n\n# Filter commits by date\ngitlogue --after \"2024-01-01\"\ngitlogue --before \"1 week ago\"\ngitlogue --after \"2024-06-01\" --before \"2024-07-01\"\n\n# Use a different theme\ngitlogue --theme dracula\n\n# Adjust typing speed (ms per character)\ngitlogue --speed 20\n\n# Ignore specific file patterns (e.g., notebooks, lock files)\ngitlogue --ignore \"*.ipynb\" --ignore \"poetry.lock\"\n\n# Use an ignore file\ngitlogue --ignore-file .gitlogue-ignore\n\n# List available themes\ngitlogue theme list\n\n# Set default theme\ngitlogue theme set dracula\n\n# Combine options\ngitlogue --commit HEAD~5 --author \"john\" --theme nord --speed 15 --ignore \"*.ipynb\"\n```\n\n## Configuration\n\ngitlogue can be configured via `~/.config/gitlogue/config.toml`.  \nYou can set the default theme, typing speed, and background preferences.\n\nSee the [Configuration Guide](docs/configuration.md) for full options and examples.\n\n## Supported Languages\n\nBash, C, C#, C++, Clojure, CSS, Dart, Elixir, Erlang, Go, Haskell, HTML, Java, JavaScript, JSON, Kotlin, Lua, Markdown, PHP, Python, Ruby, Rust, Scala, Svelte, Swift, TypeScript, XML, YAML, Zig\n\n## Documentation\n\n[Installation Guide](docs/installation.md)  \n[Usage Guide](docs/usage.md)  \n[Configuration Guide](docs/configuration.md)  \n[Theme Customization](docs/themes.md)  \n[Contributing Guidelines](docs/CONTRIBUTING.md)  \n[Architecture Overview](docs/ARCHITECTURE.md)\n\n## Related Projects\n\n### Git Visualization & Coding\n\n- [**GitType**](https://github.com/unhappychoice/gittype) - A CLI code-typing game that turns your source code into typing challenges\n\n### Terminal Screensavers\n\n- [**tarts**](https://github.com/oiwn/tarts) - Collection of terminal screensavers in Rust (Matrix, Ga",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-29T02:26:55.608578"
  },
  {
    "basic_info": {
      "name": "misaka26",
      "full_name": "straight-tamago/misaka26",
      "owner": "straight-tamago",
      "description": "iOS /iPadOS 16.0 - 26.1, An ultimate customization tool, uilitizing the bug that makes TrollRestore possible. ",
      "url": "https://github.com/straight-tamago/misaka26",
      "clone_url": "https://github.com/straight-tamago/misaka26.git",
      "ssh_url": "git@github.com:straight-tamago/misaka26.git",
      "homepage": "",
      "created_at": "2025-11-16T14:48:46Z",
      "updated_at": "2025-11-29T01:53:56Z",
      "pushed_at": "2025-11-19T13:53:41Z"
    },
    "stats": {
      "stars": 2739,
      "forks": 113,
      "watchers": 2739,
      "open_issues": 259,
      "size": 21
    },
    "tech_info": {
      "language": null,
      "languages": {},
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# misaka26\nAn ultimate customization tool, uilitizing the bug that makes [TrollRestore](https://github.com/JJTech0130/TrollRestore) possible.\n### iOS /iPadOS 16.0 - 26.1 & 26.2 beta 1\n**Supported iOS 16.0 ~ 26.1 & 26.2 beta 1**\n\n> [!NOTE]\n> **Use this tool at your own risk. There is a chance you may bootloop, so create a backup before using.**\n\nDevelopers: [@34306](https://github.com/34306) [@straight-tamago](https://github.com/straight-tamago)\n\n<a href=\"https://github.com/straight-tamago/misaka26/releases/latest\"><img src=\"https://img.shields.io/github/v/release/straight-tamago/misaka26?color=d774d5\" /></a>\n<a href=\"https://github.com/straight-tamago/misaka26/releases\"><img src=\"https://img.shields.io/github/downloads/straight-tamago/misaka26/total?color=d774d5\" /></a>\n\n## Join Discord Support üçâ \n‚Ä¢ Misaka Support ‚ú® **(Sever 1)**:   \n<a href='https://discord.gg/KSExeZVAGX'><img align='center' alt='Discord' src='https://img.shields.io/discord/1156843198799421490?color=36309d&label=DISCORD&logo=discord&logoColor=white&style=for-the-badge'></a>  \n‚Ä¢ Misaka Support ‚ú® **(Sever 2)**:  \n<a href='https://discord.gg/mVrPxY3X6W'><img align='center' alt='Discord' src='https://img.shields.io/discord/1074625970029477919?color=36309d&label=DISCORD&logo=discord&logoColor=white&style=for-the-badge'></a>   \n\n### Installation:\nTo fix permission issues on macOS, run:\n```bash\nxattr -c /path/to/misaka26.app\n```\n\n## How to Use\n\nDownload lastest misaka26 on Release tab, place it to `/Applications`\nWhen open it, go to System Settings > Privacy and Security > Security > Allow running this Application > Open anyway\n\n1. Generate your MobileGestalt by using this [Shortcut](https://routinehub.co/shortcut/23246/#/login)\n2. AirDrop or send it to macOS\n3. Select it in misaka26 application\n4. Enable features\n5. Apply\n6. Profit?\n\n## Supported Features\n- **TrollPad (MultiTasking)** (NEW, require macOS)\n(iOS 18.0+) (need respring, read below)\n- **Enable PWM (iOS 26.0+)**\n- **Enable Security Research Device (SRD) mode (iOS 26.0+)**\n- **Allow Install M chip/Pro chip games on AppStore (eg: RE4) (iOS 26.0+)**\n\n\n- **TrollStore Installer (iOS 15.2 ~ 16.7RC (20H18) & 17.0)**\n- **Dynamic Island** (iOS 16.0+)\n- **Charge Limit** (iOS 17.0+)\n- **Boot Chime** (iOS 17.0+)\n- **Stage Manager** (iOS 16.0+)\n- **Shutter Sound** (iOS 16.0+)  \nPlease do not use camera silence for the purpose of voyeurism. For photographing pets, etc.\n- **Always-on Display (AoD)** (iOS 18.0+)\n- **Apple Pencil** (iOS 18.0+)\n- **Action Button** (iOS 17.0+)\n- **Internal Storage** (iOS 17.0+)\n- **Clock UI** (iOS 18.0+)\n- **SOS Collision** (iOS 18.0+)\n- **TapToWake** (iPhone SE 2/3, iOS 18.0+)\n- **Apple Intelligence** (iOS 18.1 Beta, ALL DEVICES ON 18.1)\n- **Landscape FaceID** (iOS 17.0+)\n- **Old Photo UI** (iOS 18.0+)\n- **iPad Apps Support** (iOS 16.0+)\n- **Developer Mode & Metal HUD** (iOS 16.0+)\n- **CameraControl** (18.0+)\n- **AoD Vibrancy** (may affect others tweak, iOS 18.0+)\n- **Sleep apnea** (iOS 18.0+)\n- **Find My Friend (KH/A devices)**\n\n**Some upcoming features:** ‚ù§Ô∏è\n- **Disable call record greetings**\n- **Allow modify custom path**\n\n\n**You will need to do a respring to take effect, download this [ipa](https://github.com/34306/mdc0/releases/download/1.0/respringapp.ipa) to respring**\n\n## icon\n\n## Credit\n- [Duy Tran](https://github.com/khanhduytran0) for the exploit writeup\n- [hanakim3945](https://github.com/hanakim3945)\n- pengubow for those new flags\n\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-29T02:26:56.969125"
  },
  {
    "basic_info": {
      "name": "sbox-public",
      "full_name": "Facepunch/sbox-public",
      "owner": "Facepunch",
      "description": "s&box is a modern game engine, built on Valve's Source 2 and the latest .NET technology, it provides a modern intuitive editor for creating games",
      "url": "https://github.com/Facepunch/sbox-public",
      "clone_url": "https://github.com/Facepunch/sbox-public.git",
      "ssh_url": "git@github.com:Facepunch/sbox-public.git",
      "homepage": "https://sbox.game",
      "created_at": "2025-11-24T08:18:33Z",
      "updated_at": "2025-11-29T02:21:45Z",
      "pushed_at": "2025-11-28T17:49:33Z"
    },
    "stats": {
      "stars": 2663,
      "forks": 144,
      "watchers": 2663,
      "open_issues": 36,
      "size": 10372
    },
    "tech_info": {
      "language": "C#",
      "languages": {
        "C#": 16039797,
        "HLSL": 721742,
        "HTML": 262740,
        "SCSS": 163456,
        "ReScript": 46444,
        "CSS": 20572,
        "Python": 3675,
        "Batchfile": 261
      },
      "license": "Other",
      "topics": [
        "gamedev",
        "sbox",
        "source2"
      ]
    },
    "content": {
      "readme": "<div align=\"center\">\n  <img src=\"https://sbox.game/img/sbox-logo-square.svg\" width=\"80px\" alt=\"s&box logo\">\n\n  [Website] | [Getting Started] | [Forums] | [Documentation] | [Contributing]\n</div>\n\n[Website]: https://sbox.game/\n[Getting Started]: https://sbox.game/dev/doc/about/getting-started/first-steps/\n[Forums]: https://sbox.game/f/\n[Documentation]: https://sbox.game/dev/doc/\n[Contributing]: CONTRIBUTING.md\n\n# s&box\n\ns&box is a modern game engine, built on Valve's Source 2 and the latest .NET technology, it provides a modern intuitive editor for creating games.\n\n![s&box editor](https://files.facepunch.com/matt/1b2211b1/sbox-dev_FoZ5NNZQTi.jpg)\n\nIf your goal is to create games using s&box, please start with the [getting started guide](https://sbox.game/dev/doc/about/getting-started/first-steps/).\nThis repository is for building the engine from source for those who want to contribute to the development of the engine.\n\n## Getting the Engine\n\n### Steam\n\nYou can download and install the s&box editor directly from [Steam](https://sbox.game/give-me-that).\n\n### Compiling from Source\n\nIf you want to build from source, this repository includes all the necessary files to compile the engine yourself.\n\n#### Prerequisites\n\n* [Git](https://git-scm.com/install/windows)\n* [Visual Studio 2026](https://visualstudio.microsoft.com/)\n* [.NET 10 SDK](https://dotnet.microsoft.com/en-us/download)\n\n#### Building\n\n```bash\n# Clone the repo\ngit clone https://github.com/Facepunch/sbox-public.git\n```\n\nOnce you've cloned the repo simply run `Bootstrap.bat` which will download dependencies and build the engine.\n\nThe game and editor can be run from the binaries in the game folder.\n\n## Contributing\n\nIf you would like to contribute to the engine, please see the [contributing guide](CONTRIBUTING.md).\n\nIf you want to report bugs or request new features, see [sbox-issues](https://github.com/Facepunch/sbox-issues/).\n\n## Documentation\n\nFull documentation, tutorials, and API references are available at [sbox.game/dev/](https://sbox.game/dev/).\n\n## License\n\nThe s&box engine source code is licensed under the [MIT License](LICENSE.md).\n\nCertain native binaries in `game/bin` are not covered by the MIT license. These binaries are distributed under the s&box EULA. You must agree to the terms of the EULA to use them.\n\nThis project includes third-party components that are separately licensed.\nThose components are not covered by the MIT license above and remain subject\nto their original licenses as indicated in `game/thirdpartylegalnotices`.",
      "default_branch": "master"
    },
    "fetched_at": "2025-11-29T02:26:58.241238"
  },
  {
    "basic_info": {
      "name": "react-native-godot",
      "full_name": "borndotcom/react-native-godot",
      "owner": "borndotcom",
      "description": "React Native Godot - Embed Godot Engine in React Native apps",
      "url": "https://github.com/borndotcom/react-native-godot",
      "clone_url": "https://github.com/borndotcom/react-native-godot.git",
      "ssh_url": "git@github.com:borndotcom/react-native-godot.git",
      "homepage": "",
      "created_at": "2025-11-01T10:54:51Z",
      "updated_at": "2025-11-28T22:09:47Z",
      "pushed_at": "2025-11-07T13:56:23Z"
    },
    "stats": {
      "stars": 2441,
      "forks": 101,
      "watchers": 2441,
      "open_issues": 10,
      "size": 43456
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 96704,
        "Objective-C++": 44758,
        "TypeScript": 31195,
        "Java": 29411,
        "JavaScript": 13042,
        "C": 6699,
        "Ruby": 4547,
        "Objective-C": 4216,
        "Python": 4120,
        "Shell": 3800,
        "GDScript": 3456,
        "Kotlin": 2881,
        "CMake": 2267,
        "Swift": 1232
      },
      "license": "MIT License",
      "topics": [
        "android",
        "godot",
        "godot-engine",
        "ios",
        "react-native"
      ]
    },
    "content": {
      "readme": "![Cover-21](https://github.com/user-attachments/assets/770e4972-84f7-433e-87db-6391601256ba)\nBorn React Native Godot\n-----------------------\n\nReact Native Godot allows embedding the Godot Engine into React Native applications.\n\nBorn React Native Godot was created by [Born](https://born.com) and developed by [Migeran](https://migeran.com), in close collaboration between the two teams.\n\n# Main Features\n\n* Supports Android and iOS, built on [LibGodot](https://github.com/migeran/libgodot).\n* Stable implementation serving millions of users in [Born](https://born.com)'s applications.\n* Supports starting, stopping and restarting the Godot Engine. [(docs)](#initialize-the-godot-instance)\n* When restarting, the engine can be reconfigured, so a different Godot app may be loaded each time. [(docs)](#stop-the-godot-instance)\n* It is also possible to pause and resume the running Godot instance. [(docs)](#pause-the-godot-instance)\n* Godot is running on a separate thread, so it does not affect the main thread of the application nor the React Native JavaScript thread. [(docs)](#threading-and-javascript-in-react-native)\n* The Godot main window and any subwindows created by the Godot app may be embedded into the React Native application either on the same screen, or on separate screens (see [example app](example/)).\n* The whole Godot API is accessible from TypeScript / JavaScript. It is possible to instantiate objects, call methods, get and set properties, attach JS functions to signals, provide JS functions as callables to Godot methods ... etc. [(docs)](#godot-api-usage)\n\n<p align=\"center\">\n  <video src=\"https://github.com/user-attachments/assets/33266f05-d733-4c1d-ab49-edaaf426e3e1\" width=\"600\" controls></video>\n</p>\n\n# Getting Started with the Example App\n\nThe [example app](example/) shows the main features of React Native Godot in action.\n\n## Install Prerequisites\n\nDuring development we use [ASDF](https://asdf-vm.com/) to manage most external dependencies required for React Native development, like Node, Java, Gradle or Ruby. If you also use ASDF, just run:\n\n```sh\nasdf install\n```\n    \nThis will make sure that all the dependencies are the same like in our environment. Otherwise you may also install React Native prerequisites using any other method.\n\n## Export the Godot app\n\nRun the following scripts for either platform you plan to test (or both):\n\n```sh\ncd example\n./export_godot_GodotTest.sh android\n./export_godot_GodotTest.sh ios\n./export_godot_GodotTest2.sh android\n./export_godot_GodotTest2.sh ios\n```\n\nThe script is configured to look for Godot in the standard system wide installation folder on macOS. If your Godot is installed elsewhere, or you are on Linux, just point the `GODOT_EDITOR`\nenvironment variable to your Godot editor prior to running the above scripts:\n\n```sh\nexport GODOT_EDITOR=/path/to/godot_editor\n```\n\n## Configure and download LibGodot\n\n```sh\ncd example\nyarn\nyarn download-prebuilt\n```\n\nThese commands will resolve all the React Native and other dependencies from npm. The second one will download the prebuilt LibGodot release from GitHub.\n\n## Run on the iOS Simulator\n\n```sh\ncd example/ios\nbundle install\nbundle exec pod install\ncd ..\nyarn ios\n```\n\n## Run on the Android Emulator\n\n```sh\ncd example\nyarn android\n```\n\n## Use your native IDEs\n\nYou may use Xcode and Android Studio the same way as with any other project. Just open:\n\n* ``ios/GodotTest.xcworkspace`` from Xcode\n* ``android`` from Android Studio\n\n> [!note]\n> If you are using ASDF to manage your Java and Node dependencies, you should start Android Studio from under the `react-native-godot` (or `example`) folder, so it can find these tools. For example on macOS:\n\n```sh\ncd example\nopen -a \"Android Studio\"\n```\n\n## Convenience script for dependency management\n\nThere is an `update_deps.sh` script included in the example app's folder. It will execute all the setup commands for both iOS and Android in one step, so you may start your work immediately.\n\n```sh\ncd example\n./update_deps.sh\nyarn ios # or yarn android\n```\n\n# Your first React Native Godot App\n\nBorn React Native Godot is distributed on npm.\n\nJust follow these steps to add it to your React Native application:\n\n## Update `package.json`\n\n```sh\nyarn add @borndotcom/react-native-godot\n```\n\n## Download the prebuilt LibGodot packages\n\nThe LibGodot packages used by React Native Godot are not distributed on npm. Instead, they are downloaded separately by issuing the following command:\n\n```sh\nyarn download-prebuilt\n```\n\nThis way React Native Godot can be updated independently from LibGodot, and also local, customized builds of LibGodot are supported.\n\n## Import React Native Godot in your App code\n\n```typescript\nimport { RTNGodot, RTNGodotView, runOnGodotThread } from \"@borndotcom/react-native-godot\";\n```\n\n## Add the Godot View to your view, e.g.\n\n```tsx\nconst App = () => {\n  return (\n    <View>\n      <RTNGodotView style={...}/>\n    </View>\n  );\n};\n```\n\nIf no `windowName` property is specified, that view is fo",
      "default_branch": "master"
    },
    "fetched_at": "2025-11-29T02:26:59.552496"
  },
  {
    "basic_info": {
      "name": "omnilingual-asr",
      "full_name": "facebookresearch/omnilingual-asr",
      "owner": "facebookresearch",
      "description": "Omnilingual ASR Open-Source Multilingual SpeechRecognition for 1600+ Languages",
      "url": "https://github.com/facebookresearch/omnilingual-asr",
      "clone_url": "https://github.com/facebookresearch/omnilingual-asr.git",
      "ssh_url": "git@github.com:facebookresearch/omnilingual-asr.git",
      "homepage": null,
      "created_at": "2025-11-06T22:38:00Z",
      "updated_at": "2025-11-28T19:33:45Z",
      "pushed_at": "2025-11-19T18:07:58Z"
    },
    "stats": {
      "stars": 2308,
      "forks": 187,
      "watchers": 2308,
      "open_issues": 19,
      "size": 1026
    },
    "tech_info": {
      "language": "Python",
      "languages": {
        "Python": 295799
      },
      "license": "Other",
      "topics": []
    },
    "content": {
      "readme": "<div align=\"center\">\n  <img src=\"./omniASR_header.jpg\" alt=\"Header image with a collage of on-the-ground photos from the transcription gathering efforts in Pakistan and Liberia.\" width=\"100%\" />\n  <p><i>Photographs captured during corpus creation efforts in Pakistan and Liberia.</i></p>\n</div>\n\n# Omnilingual ASR: Open-Source Multilingual Speech Recognition for 1600+ Languages\n\nOmnilingual ASR is an open-source speech recognition system supporting over 1,600 languages ‚Äî including hundreds never previously covered by any ASR technology. Designed for broad accessibility, it enables new languages to be added with just a few paired examples without requiring specialized expertise or large datasets. By combining scalable zero-shot learning with a flexible model family, Omnilingual ASR aims to make speech technology more inclusive and adaptable for communities and researchers worldwide.\n\n* [Huggingface Demo](https://huggingface.co/spaces/facebook/omniasr-transcriptions)\n* [Huggingface Dataset](https://huggingface.co/datasets/facebook/omnilingual-asr-corpus)\n* [Paper](https://ai.meta.com/research/publications/omnilingual-asr-open-source-multilingual-speech-recognition-for-1600-languages/)\n* [Blogpost](http://ai.meta.com/blog/omnilingual-asr-advancing-automatic-speech-recognition)\n\n<div align=\"center\">\n  <img src=\"./result_table.png\" alt=\"Performance results table\" width=\"100%\" />\n  <p><i>Our 7B-LLM-ASR system achieves state-of-the-art performance across 1,600+ languages, with character error rates (CER) below 10 for 78% of those languages.</i></p>\n</div>\n\n\n## Documentation\n\n### Quick Start\n- **[Installation & Basic Usage](#installation)** - Setup and first transcription\n- **[Inference Pipeline](src/omnilingual_asr/models/inference/README.md)** - Comprehensive transcription guide with batch processing, language conditioning, and context examples\n- **[Supported Languages](#supported-languages)** - View the complete list of 1600+ supported languages\n\n\n### Models & Architecture\n- **[Model Specifications](#model-architectures)** - Available models, parameters, and memory requirements\n- **[Architecture Overview](src/omnilingual_asr/models/README.md)** - Technical details on W2V, CTC, and LLM model families\n- **[Asset Management](src/omnilingual_asr/cards/README.md)** - Configuration system for models, tokenizers, and datasets\n\n### Training & Data Pipeline\n- **[Data Preparation](workflows/dataprep/README.md)** - End-to-end guide for multilingual dataset preparation, HuggingFace integration, and parquet processing\n- **[Training Recipes](workflows/recipes/wav2vec2/asr/README.md)** - Pre-configured workflows for CTC and LLM model training\n\n---\n\n## Installation\n\nThe models were developed using [fairseq2](https://github.com/facebookresearch/fairseq2), a research-focused sequence modeling toolkit. While we provide a **reference** inference pipeline that works across platforms, audio support requires [libsndfile](https://github.com/facebookresearch/fairseq2?tab=readme-ov-file#system-dependencies) (Mac: `brew install libsndfile`; Windows may need an additional [setup](https://github.com/facebookresearch/fairseq2?tab=readme-ov-file#installing-on-windows)).\n\n```bash\n# using pip\npip install omnilingual-asr\n\n# using uv\nuv add omnilingual-asr\n```\n\n## Inference\n\n```python\nfrom omnilingual_asr.models.inference.pipeline import ASRInferencePipeline\n\npipeline = ASRInferencePipeline(model_card=\"omniASR_LLM_7B\")\n\naudio_files = [\"/path/to/eng_audio1.flac\", \"/path/to/deu_audio2.wav\"]\nlang = [\"eng_Latn\", \"deu_Latn\"]\ntranscriptions = pipeline.transcribe(audio_files, lang=lang, batch_size=2)\n```\n\nMore details on running specific models can be found in the [src/omnilingual_asr/models/inference](/src/omnilingual_asr/models/inference/README.md) directory.\n\n> **‚ö†Ô∏è Important:** Currently only audio files shorter than 40 seconds are accepted for inference. We plan to add support for transcribing unlimited-length audio files shortly.\n\n### Supported Languages\n\nTo view the full list of 1600+ supported languages, you can access the language list [programmatically](/src/omnilingual_asr/models/wav2vec2_llama/lang_ids.py):\n\n```python\nfrom omnilingual_asr.models.wav2vec2_llama.lang_ids import supported_langs\n\n# Print all supported languages\nprint(f\"Total supported languages: {len(supported_langs)}\")\nprint(supported_langs)\n\n# Check if a specific language is supported\nif \"eng_Latn\" in supported_langs:\n    print(\"English (Latin script) is supported!\")\n```\n\nLanguages follow the format `{language_code}_{script}`, for example `eng_Latn` - English (Latin script), `cmn_Hans` - Mandarin Chinese (Simplified), ...\n\n### Using the HuggingFace Dataset ü§ó\n\nWe provide a large-scale multilingual speech dataset on HuggingFace under CC-BY-4.0 License: [`facebook/omnilingual-asr-corpus`](https://huggingface.co/datasets/facebook/omnilingual-asr-corpus).\nThis dataset can be directly used with our inference pipeline for evaluation or testing:\n\n```bash\npip install \"omnilingual-asr[dat",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-29T02:27:00.846405"
  },
  {
    "basic_info": {
      "name": "reader3",
      "full_name": "karpathy/reader3",
      "owner": "karpathy",
      "description": "Quick illustration of how one can easily read books together with LLMs. It's great and I highly recommend it.",
      "url": "https://github.com/karpathy/reader3",
      "clone_url": "https://github.com/karpathy/reader3.git",
      "ssh_url": "git@github.com:karpathy/reader3.git",
      "homepage": null,
      "created_at": "2025-11-18T02:37:00Z",
      "updated_at": "2025-11-28T23:40:11Z",
      "pushed_at": "2025-11-18T02:37:51Z"
    },
    "stats": {
      "stars": 2279,
      "forks": 259,
      "watchers": 2279,
      "open_issues": 9,
      "size": 271
    },
    "tech_info": {
      "language": "Python",
      "languages": {
        "Python": 13925,
        "HTML": 8921
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# reader 3\n\n![reader3](reader3.png)\n\nA lightweight, self-hosted EPUB reader that lets you read through EPUB books one chapter at a time. This makes it very easy to copy paste the contents of a chapter to an LLM, to read along. Basically - get epub books (e.g. [Project Gutenberg](https://www.gutenberg.org/) has many), open them up in this reader, copy paste text around to your favorite LLM, and read together and along.\n\nThis project was 90% vibe coded just to illustrate how one can very easily [read books together with LLMs](https://x.com/karpathy/status/1990577951671509438). I'm not going to support it in any way, it's provided here as is for other people's inspiration and I don't intend to improve it. Code is ephemeral now and libraries are over, ask your LLM to change it in whatever way you like.\n\n## Usage\n\nThe project uses [uv](https://docs.astral.sh/uv/). So for example, download [Dracula EPUB3](https://www.gutenberg.org/ebooks/345) to this directory as `dracula.epub`, then:\n\n```bash\nuv run reader3.py dracula.epub\n```\n\nThis creates the directory `dracula_data`, which registers the book to your local library. We can then run the server:\n\n```bash\nuv run server.py\n```\n\nAnd visit [localhost:8123](http://localhost:8123/) to see your current Library. You can easily add more books, or delete them from your library by deleting the folder. It's not supposed to be complicated or complex.\n\n## License\n\nMIT",
      "default_branch": "master"
    },
    "fetched_at": "2025-11-29T02:27:02.106358"
  },
  {
    "basic_info": {
      "name": "smart-excalidraw-next",
      "full_name": "liujuntao123/smart-excalidraw-next",
      "owner": "liujuntao123",
      "description": "A smart, powerful, and beautiful excalidraw drawing tool.Draw Professional Charts with Natural Language",
      "url": "https://github.com/liujuntao123/smart-excalidraw-next",
      "clone_url": "https://github.com/liujuntao123/smart-excalidraw-next.git",
      "ssh_url": "git@github.com:liujuntao123/smart-excalidraw-next.git",
      "homepage": "https://smart-excalidraw.aizhi.site",
      "created_at": "2025-10-30T02:12:40Z",
      "updated_at": "2025-11-29T01:36:36Z",
      "pushed_at": "2025-11-27T07:00:01Z"
    },
    "stats": {
      "stars": 2100,
      "forks": 263,
      "watchers": 2100,
      "open_issues": 19,
      "size": 322
    },
    "tech_info": {
      "language": "JavaScript",
      "languages": {
        "JavaScript": 185429,
        "CSS": 471
      },
      "license": null,
      "topics": [
        "ai",
        "chart",
        "excalidraw"
      ]
    },
    "content": {
      "readme": "# Smart Excalidraw\n> **Áî®Ëá™ÁÑ∂ËØ≠Ë®ÄÔºåÁªòÂà∂‰∏ì‰∏öÂõæË°®**\n\n\nüöÄüöÄüöÄÂÖ®Èù¢ÂçáÁ∫ßÁöÑÊñ∞ÁâàÊú¨ÔºåÊõ¥Âº∫Â§ßÂ•ΩÁî®ÁöÑÁªòÂõæÂ∑•ÂÖ∑\n\nhttps://smart-draw.aizhi.site\n\nüöÄüöÄüöÄÊñ∞ÁâàÊú¨githubÂú∞ÂùÄÔºö\n\nhttps://github.com/liujuntao123/smart-draw\n\n\n‰∏ÄÂõæ‰ªãÁªç\n\n<img width=\"2816\" height=\"1536\" alt=\"Gemini_Generated_Image_2drs882drs882drs\" src=\"https://github.com/user-attachments/assets/42d7a2ec-b56b-420c-becb-c598179d4541\" />\n\n\n\nüöÄ ÈôêÊó∂Á¶èÂà©\n\nÊ∑ªÂä†Â∫ïÈÉ®‰ΩúËÄÖÂæÆ‰ø°ËøõÁæ§ÂèØÈ¢ÜÂèñÂÖçË¥πclaude-4.5-sonnet key\n\n## English Version\nRead the English version: [README_EN.md](README_EN.md)\n\n## ÊïàÊûúÈ¢ÑËßà\nÊìç‰ΩúÁïåÈù¢\n<img width=\"2330\" height=\"1255\" alt=\"PixPin_2025-10-31_17-14-27\" src=\"https://github.com/user-attachments/assets/5319ad5c-c507-42e0-b67a-e9dfb2d7ecfa\" />\nÊäÄÊúØÊû∂ÊûÑÂõæ\n<img width=\"1920\" height=\"1134\" alt=\"Untitled-2025-11-03-1105\" src=\"https://github.com/user-attachments/assets/d2e01c4e-d300-4c20-bd98-d056e4f02102\" />\n‰ø°ÊÅØÂõæ\n<img width=\"2183\" height=\"828\" alt=\"Untitled-2025-11-03-1054\" src=\"https://github.com/user-attachments/assets/0e46e8da-fe64-40a9-911b-f6c0e5589bae\" />\n\n\n\n## ‚ú® Ê†∏ÂøÉÁâπÊÄß\n\n### üéØ AI È©±Âä®ÔºåÊïàÊûúÂá∫‰ºó\nÈÄöËøáÂÖàËøõÁöÑÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁêÜËß£‰Ω†ÁöÑÈúÄÊ±ÇÔºåÁîüÊàêÁªìÊûÑÊ∏ÖÊô∞„ÄÅÂ∏ÉÂ±ÄÂêàÁêÜÁöÑ‰∏ì‰∏öÁ∫ßÂõæË°®„ÄÇ\n\n### üîó Áã¨ÂàõËøûÊé•ÁÆóÊ≥ï\nÈááÁî®Áã¨ÂàõÁöÑÊô∫ËÉΩÁÆ≠Â§¥‰ºòÂåñÁÆóÊ≥ïÔºåËá™Âä®ËÆ°ÁÆóÊúÄ‰Ω≥ËøûÊé•ÁÇπÔºåÁ°Æ‰øùÂõæË°®‰∫ïÁÑ∂ÊúâÂ∫è„ÄÅÈÄªËæëÊ∏ÖÊô∞ÔºåÂëäÂà´Ê∑∑‰π±ÁöÑÁ∫øÊù°‰∫§Âèâ„ÄÇ\n\n### üìä ‰∏∞ÂØåÂõæË°®Á±ªÂûã\nÊîØÊåÅ 20+ ÁßçÂõæË°®Á±ªÂûãÔºåÂåÖÊã¨ÊµÅÁ®ãÂõæ„ÄÅÊû∂ÊûÑÂõæ„ÄÅÊó∂Â∫èÂõæ„ÄÅER Âõæ„ÄÅÊÄùÁª¥ÂØºÂõæÁ≠â„ÄÇ‰πüÂèØ‰ª•ËÆ©AIÊ†πÊçÆ‰Ω†ÁöÑÊèèËø∞Ëá™Âä®ÈÄâÊã©ÊúÄÂêàÈÄÇÁöÑÂõæË°®Á±ªÂûã„ÄÇ\n\n### üé® ÂÆåÁæé Excalidraw ÈõÜÊàê\nÁîüÊàêÁöÑÂõæË°®ÂÆåÂÖ®Âü∫‰∫é Excalidraw Ê†ºÂºèÔºåÂèØ‰ª•Âú®ÁîªÂ∏É‰∏äËá™Áî±ÁºñËæë„ÄÅË∞ÉÊï¥Ê†∑Âºè„ÄÅÊ∑ªÂä†ÁªÜËäÇÔºåÂÆûÁé∞ AI ÁîüÊàê‰∏éÊâãÂä®Á≤æ‰øÆÁöÑÂÆåÁæéÁªìÂêà„ÄÇ\n\n### ‚ö° ÂºÄÁÆ±Âç≥Áî®\nÂè™ÈúÄÈÖçÁΩÆ‰∏Ä‰∏™ AI API ÂØÜÈí•Âç≥ÂèØÂºÄÂßã‰ΩøÁî®ÔºåÊó†ÈúÄÂ§çÊùÇÁöÑÁéØÂ¢ÉÊê≠Âª∫„ÄÇÊâÄÊúâÈÖçÁΩÆ‰øùÂ≠òÂú®Êú¨Âú∞ÊµèËßàÂô®ÔºåÈöêÁßÅÂÆâÂÖ®Êúâ‰øùÈöú„ÄÇ\n\n\n\n## üöÄ Âø´ÈÄüÂºÄÂßã\n\n### ÊñπÂºè‰∏ÄÔºö‰ΩøÁî®ËÆøÈóÆÂØÜÁ†Å\n\nÂ¶ÇÊûúÊúçÂä°Âô®ÁÆ°ÁêÜÂëòÂ∑≤ÈÖçÁΩÆËÆøÈóÆÂØÜÁ†ÅÔºå‰Ω†ÂèØ‰ª•Áõ¥Êé•‰ΩøÁî®ÊúçÂä°Âô®Á´ØÁöÑ LLM ÈÖçÁΩÆÔºåÊó†ÈúÄËá™Â∑±Êèê‰æõ API KeyÔºö\n\n1. ÁÇπÂáªÂè≥‰∏äËßíÁöÑ **\"ËÆøÈóÆÂØÜÁ†Å\"** ÊåâÈíÆ\n2. ËæìÂÖ•ÁÆ°ÁêÜÂëòÊèê‰æõÁöÑËÆøÈóÆÂØÜÁ†Å\n3. ÁÇπÂáª **\"È™åËØÅÂØÜÁ†Å\"** ÊµãËØïËøûÊé•\n4. ÂãæÈÄâ **\"ÂêØÁî®ËÆøÈóÆÂØÜÁ†Å\"** Âπ∂‰øùÂ≠ò\n\nÂêØÁî®ÂêéÔºåÂ∫îÁî®Â∞Ü‰ºòÂÖà‰ΩøÁî®ÊúçÂä°Âô®Á´ØÈÖçÁΩÆÔºå‰Ω†Êó†ÈúÄÈÖçÁΩÆËá™Â∑±ÁöÑ API Key Âç≥ÂèØÂºÄÂßãÂàõ‰ΩúÔºÅ\n\n### ÊñπÂºè‰∫åÔºöÈÖçÁΩÆËá™Â∑±ÁöÑ AI\n\n1. ÁÇπÂáªÂè≥‰∏äËßíÁöÑ **\"ÈÖçÁΩÆ LLM\"** ÊåâÈíÆ\n2. ÈÄâÊã©Êèê‰æõÂïÜÁ±ªÂûãÔºàOpenAI Êàñ AnthropicÔºâ\n3. Â°´ÂÖ•‰Ω†ÁöÑ API Key\n4. ÈÄâÊã©Ê®°ÂûãÔºà**Êé®Ëçê‰ΩøÁî® claude-sonnet-4.5**ÔºåÊïàÊûúÊúÄ‰Ω≥Ôºâ\n5. ‰øùÂ≠òÈÖçÁΩÆ\n\nÂ∞±Ëøô‰πàÁÆÄÂçïÔºÅÁé∞Âú®‰Ω†ÂèØ‰ª•ÂºÄÂßãÂàõ‰Ωú‰∫Ü„ÄÇ\n\n### Á¨¨‰∫åÊ≠•ÔºöÂàõÂª∫ÂõæË°®\n\nÂú®ËæìÂÖ•Ê°Ü‰∏≠Áî®Ëá™ÁÑ∂ËØ≠Ë®ÄÊèèËø∞‰Ω†ÁöÑÈúÄÊ±ÇÔºå‰æãÂ¶ÇÔºö\n- \"Áîª‰∏Ä‰∏™Áî®Êà∑ÁôªÂΩïÁöÑÊµÅÁ®ãÂõæ\"\n- \"ÂàõÂª∫‰∏Ä‰∏™ÂæÆÊúçÂä°Êû∂ÊûÑÂõæÔºåÂåÖÂê´ÁΩëÂÖ≥„ÄÅËÆ§ËØÅÊúçÂä°Âíå‰∏öÂä°ÊúçÂä°\"\n- \"ËÆæËÆ°‰∏Ä‰∏™ÁîµÂïÜÁ≥ªÁªüÁöÑÊï∞ÊçÆÂ∫ì ER Âõæ\"\n\nAI ‰ºöËá™Âä®ÁîüÊàêÂõæË°®Ôºå‰Ω†ÂèØ‰ª•Âú®ÁîªÂ∏É‰∏äÁõ¥Êé•ÁºñËæëÂíåË∞ÉÊï¥„ÄÇ\n\n## üíª Êú¨Âú∞ÈÉ®ÁΩ≤\n\nÂ¶ÇÊûú‰Ω†ÊÉ≥Âú®Êú¨Âú∞ËøêË°åÈ°πÁõÆÔºö\n\n```bash\n# ÂÖãÈöÜÈ°πÁõÆ\ngit clone <your-repo-url>\ncd smart-excalidraw-next\n\n# ÂÆâË£Ö‰æùËµñ\npnpm install\n\n# ÂêØÂä®ÂºÄÂèëÊúçÂä°Âô®\npnpm dev\n```\n\nËÆøÈóÆ http://localhost:3000 Âç≥ÂèØ‰ΩøÁî®„ÄÇ\n\n### ÈÖçÁΩÆÊúçÂä°Âô®Á´Ø LLMÔºàÂèØÈÄâÔºâ\n\nÂ¶ÇÊûú‰Ω†ÊÉ≥‰∏∫Áî®Êà∑Êèê‰æõÁªü‰∏ÄÁöÑ LLM ÈÖçÁΩÆÔºåÈÅøÂÖç‰ªñ‰ª¨Ëá™Â∑±Áî≥ËØ∑ API KeyÔºåÂèØ‰ª•ÈÖçÁΩÆÊúçÂä°Âô®Á´ØËÆøÈóÆÂØÜÁ†ÅÂäüËÉΩÔºö\n\n1. Â§çÂà∂ÁéØÂ¢ÉÂèòÈáèÁ§∫‰æãÊñá‰ª∂Ôºö\n```bash\ncp .env.example \n```\n\n2. Âú® `.env` ‰∏≠ÈÖçÁΩÆ‰ª•‰∏ãÂèòÈáèÔºö\n```bash\n# ËÆøÈóÆÂØÜÁ†ÅÔºàÁî®Êà∑ÈúÄË¶ÅËæìÂÖ•Ê≠§ÂØÜÁ†ÅÊâçËÉΩ‰ΩøÁî®ÊúçÂä°Âô®Á´Ø LLMÔºâ\nACCESS_PASSWORD=your-secure-password\n\n# LLM Êèê‰æõÂïÜÁ±ªÂûãÔºàopenai Êàñ anthropicÔºâ\nSERVER_LLM_TYPE=anthropic\n\n# API Âü∫Á°Ä URL\nSERVER_LLM_BASE_URL=https://api.anthropic.com/v1\n\n# API ÂØÜÈí•\nSERVER_LLM_API_KEY=sk-ant-your-key-here\n\n# Ê®°ÂûãÂêçÁß∞\nSERVER_LLM_MODEL=claude-sonnet-4-5-20250929\n```\n\n3. ÈáçÂêØÂºÄÂèëÊúçÂä°Âô®ÔºåÁî®Êà∑Âç≥ÂèØÈÄöËøáËÆøÈóÆÂØÜÁ†Å‰ΩøÁî®ÊúçÂä°Âô®Á´ØÈÖçÁΩÆÁöÑ LLM„ÄÇ\n\n**‰ºòÂäøÔºö**\n- Áî®Êà∑Êó†ÈúÄËá™Â∑±Áî≥ËØ∑ÂíåÈÖçÁΩÆ API Key\n- Áªü‰∏ÄÁÆ°ÁêÜ API ‰ΩøÁî®ÂíåÊàêÊú¨\n- ÈÄÇÂêàÂõ¢ÈòüÊàñÁªÑÁªáÂÜÖÈÉ®‰ΩøÁî®\n- Êèê‰æõÂÖçË¥π‰ΩìÈ™åÁªôÁî®Êà∑\n\n## ‚ùì Â∏∏ËßÅÈóÆÈ¢ò\n\n**Q: Êé®Ëçê‰ΩøÁî®Âì™‰∏™ AI Ê®°ÂûãÔºü**\nA: Âº∫ÁÉàÊé®Ëçê‰ΩøÁî® **claude-sonnet-4.5**ÔºåÂÆÉÂú®ÁêÜËß£ÈúÄÊ±ÇÂíåÁîüÊàêÂõæË°®ÊñπÈù¢Ë°®Áé∞ÊúÄ‰Ω≥„ÄÇ\n\n**Q: Êï∞ÊçÆÂÆâÂÖ®ÂêóÔºü**\nA: ÊâÄÊúâÈÖçÁΩÆ‰ø°ÊÅØ‰ªÖ‰øùÂ≠òÂú®‰Ω†ÁöÑÊµèËßàÂô®Êú¨Âú∞Ôºå‰∏ç‰ºö‰∏ä‰º†Âà∞‰ªª‰ΩïÊúçÂä°Âô®„ÄÇ\n\n**Q: ÊîØÊåÅÂì™‰∫õÂõæË°®Á±ªÂûãÔºü**\nA: ÊîØÊåÅÊµÅÁ®ãÂõæ„ÄÅÊû∂ÊûÑÂõæ„ÄÅÊó∂Â∫èÂõæ„ÄÅER Âõæ„ÄÅÊÄùÁª¥ÂØºÂõæ„ÄÅÁΩëÁªúÊãìÊâëÂõæÁ≠â 20+ ÁßçÁ±ªÂûãÔºåAI ‰ºöËá™Âä®ÈÄâÊã©ÊúÄÂêàÈÄÇÁöÑÁ±ªÂûã„ÄÇ\n\n**Q: ÁîüÊàêÁöÑÂõæË°®ÂèØ‰ª•‰øÆÊîπÂêóÔºü**\nA: ÂΩìÁÑ∂ÂèØ‰ª•ÔºÅÁîüÊàêÂêéÂèØ‰ª•Âú® Excalidraw ÁîªÂ∏É‰∏äËá™Áî±ÁºñËæëÔºåÂåÖÊã¨Ë∞ÉÊï¥‰ΩçÁΩÆ„ÄÅ‰øÆÊîπÊ†∑Âºè„ÄÅÊ∑ªÂä†ÂÖÉÁ¥†Á≠â„ÄÇ\n\n**Q: ‰ªÄ‰πàÊòØËÆøÈóÆÂØÜÁ†ÅÂäüËÉΩÔºü**\nA: ËÆøÈóÆÂØÜÁ†ÅÂäüËÉΩÂÖÅËÆ∏ÊúçÂä°Âô®ÁÆ°ÁêÜÂëòÈÖçÁΩÆÁªü‰∏ÄÁöÑ LLMÔºåÁî®Êà∑Âè™ÈúÄËæìÂÖ•ÂØÜÁ†ÅÂç≥ÂèØ‰ΩøÁî®ÔºåÊó†ÈúÄËá™Â∑±Áî≥ËØ∑ API Key„ÄÇÂêØÁî®ËÆøÈóÆÂØÜÁ†ÅÂêéÔºåÂ∞Ü‰ºòÂÖà‰ΩøÁî®ÊúçÂä°Âô®Á´ØÈÖçÁΩÆÔºåÂøΩÁï•Êú¨Âú∞ÈÖçÁΩÆ„ÄÇ\n\n**Q: ËÆøÈóÆÂØÜÁ†ÅÂíåÊú¨Âú∞ÈÖçÁΩÆÁöÑ‰ºòÂÖàÁ∫ßÊòØ‰ªÄ‰πàÔºü**\nA: Â¶ÇÊûúÂêØÁî®‰∫ÜËÆøÈóÆÂØÜÁ†ÅÔºåÁ≥ªÁªüÂ∞Ü‰ºòÂÖà‰ΩøÁî®ÊúçÂä°Âô®Á´ØÁöÑ LLM ÈÖçÁΩÆ„ÄÇÂè™ÊúâÂú®Êú™ÂêØÁî®ËÆøÈóÆÂØÜÁ†ÅÊó∂ÔºåÊâç‰ºö‰ΩøÁî®Êú¨Âú∞ÈÖçÁΩÆÁöÑ API Key„ÄÇ\n\n## üõ†Ô∏è ÊäÄÊúØÊ†à\n\nNext.js 16 ¬∑ React 19 ¬∑ Excalidraw ¬∑ Tailwind CSS 4 ¬∑ Monaco Editor\n\n## üìÑ ËÆ∏ÂèØËØÅ\n\nMIT License\n\n## ËÅîÁ≥ª‰ΩúËÄÖ\nÂæÆ‰ø°Âè∑Ôºö liujuntaoljt\n\n<img width=\"200\"  alt=\"ÂæÆ‰ø°ÂõæÁâá_20251103110224_44_85\" src=\"https://github.com/user-attachments/assets/6d8c4da2-af27-4213-b929-0d47fa51e9b5\" />\n\n## üíñ ËµûÂä©\n\nÊÑüË∞¢‰ª•‰∏ãËµûÂä©ËÄÖÂØπÊú¨È°πÁõÆÁöÑÊîØÊåÅÔºö\n\n<!-- ËµûÂä©ËÄÖÂêçÂçï -->\n- API‰∏≠ËΩ¨Á´ôÔºö[AI ÁΩëÂÖ≥ÔΩúÊèí‰ª∂‰∏ñÁïå](https://ai-router.plugins-world.cn)\n\nÂ¶ÇÊûúËøô‰∏™È°πÁõÆÂØπ‰Ω†ÊúâÂ∏ÆÂä©ÔºåÊ¨¢ËøéÈÄöËøá‰ª•‰∏ãÊñπÂºèÊîØÊåÅÔºö\n- ‚≠ê ÁªôÈ°πÁõÆÁÇπ‰∏™ Star\n- üí¨ ÂàÜ‰∫´ÁªôÊõ¥Â§öÈúÄË¶ÅÁöÑ‰∫∫\n- üí∞ Êàê‰∏∫ËµûÂä©ËÄÖÔºàËÅîÁ≥ª‰ΩúËÄÖÂæÆ‰ø°Ôºâ\n\n## ÂèãÊÉÖÈìæÊé•\n\n- https://github.com/ZhangQL2824/auto-drawio.git\n\n---\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=liujuntao123/smart-excalidraw-next&type=date&legend=top-left)](https://www.star-history.com/#liujuntao123/smart-excalidraw-next&type=date&legend=top-left)\n\n**Áî®Ëá™ÁÑ∂ËØ≠Ë®ÄÔºåÁªòÂà∂‰∏ì‰∏öÂõæË°®** - ËÆ©ÂèØËßÜÂåñÂàõ‰ΩúÂõûÂΩíÁÆÄÂçï\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-29T02:27:03.376280"
  },
  {
    "basic_info": {
      "name": "awesome-nanobanana-pro",
      "full_name": "ZeroLu/awesome-nanobanana-pro",
      "owner": "ZeroLu",
      "description": "üöÄ An awesome list of curated Nano Banana pro prompts and examples. Your go-to resource for mastering prompt engineering and exploring the creative potential of the Nano banana pro(Nano banana 2) AI image model.",
      "url": "https://github.com/ZeroLu/awesome-nanobanana-pro",
      "clone_url": "https://github.com/ZeroLu/awesome-nanobanana-pro.git",
      "ssh_url": "git@github.com:ZeroLu/awesome-nanobanana-pro.git",
      "homepage": "",
      "created_at": "2025-11-10T13:51:03Z",
      "updated_at": "2025-11-29T02:26:18Z",
      "pushed_at": "2025-11-28T02:36:37Z"
    },
    "stats": {
      "stars": 2018,
      "forks": 158,
      "watchers": 2018,
      "open_issues": 4,
      "size": 147
    },
    "tech_info": {
      "language": null,
      "languages": {},
      "license": "MIT License",
      "topics": [
        "gemini",
        "nanobanana",
        "nanobanana-pro",
        "nanobanana2",
        "nanobananapro",
        "prompt-engineering",
        "prompt-guide",
        "prompts"
      ]
    },
    "content": {
      "readme": "[Last updated on 2025.11.28: Added memory palace learning, googly eyes effects, cartoon infographics and weather card generator prompts]\n# Awesome Nano Banana Pro üçå\n\n[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome) [![License: CC BY 4.0](https://img.shields.io/badge/License-CC_BY_4.0-lightgrey.svg)](https://creativecommons.org/licenses/by/4.0/) [![GitHub stars](https://img.shields.io/github/stars/ZeroLu/awesome-nanobanana-pro?style=social)](https://github.com/ZeroLu/awesome-nanobanana-pro/stargazers)\n\n> A curated collection of the **best Nano Banana prompts**, image generation styles, and resources for advanced AI visual experiments.\n\nThis repository focuses on **high-fidelity image prompts** sourced from X (Twitter), WeChat, Replicate, and top prompt engineers. Whether you are looking for **photorealistic portraits**, **stylized aesthetics**, or complex creative experiments, you will find the most effective inputs here to unlock the full potential of the model. \n\nSimilar repo: [Awesome Gemini3](https://github.com/ZeroLu/awesome-gemini-ai/)\n\n### Consider subscribing to [this free newsletter](https://zerolu.substack.com/p/hello-there) if you want more high quality content like this.\n\n## Sponsor: [thesorawatermarkremover.com](https://thesorawatermarkremover.com)\n[<img width=\"600\" height=\"265\" alt=\"image\" src=\"https://github.com/user-attachments/assets/b087445c-d3ad-4152-8e28-33a5ca49d4b5\" />](https://thesorawatermarkremover.com)\n\n\n## üìñ Table of Contents\n\n1. [Photorealism & Aesthetics](#1-photorealism--aesthetics)\n2. [Creative Experiments](#2-creative-experiments)\n3. [Education & Knowledge](#3-education--knowledge)\n4. [E-commerce & Virtual Studio](#4-e-commerce--virtual-studio)\n5. [Workplace & Productivity](#5-workplace--productivity)\n6. [Photo Editing & Restoration](#6-photo-editing--restoration)\n7. [Interior Design](#7-interior-design)\n8. [Social Media & Marketing](#8-social-media--marketing)\n9. [Daily Life & Translation](#9-daily-life--translation)\n10. [Social Networking & Avatars](#10-social-networking--avatars)\n11. [New Additions](#11-new-additions)\n12. [Resources](#12-resources)\n13. [Contributing](#13-contributing)\n\n---\n\n## 1. Photorealism & Aesthetics\n\nOptimize your visual output with these **high-fidelity prompts**. These are designed to utilize the model's ability to render complex lighting, textures, and specific eras.\n\n### 1.1. Hyper-Realistic Crowd Composition\n*Handling complex compositions with multiple famous faces and specific lighting.*\n<img width=\"500\" alt=\"Celebrity Crowd\" src=\"https://github.com/user-attachments/assets/3a056a8d-904e-4b3e-b0d2-b5122758b7f5\" />\n\n**Prompt:**\n```text\nCreate a hyper-realistic, ultra-sharp, full-color large-format image featuring a massive group of celebrities from different eras, all standing together in a single wide cinematic frame. The image must look like a perfectly photographed editorial cover with impeccable lighting, lifelike skin texture, micro-details of hair, pores, reflections, and fabric fibers.\n\nGENERAL STYLE & MOOD: Photorealistic, 8k, shallow depth of field, soft natural fill light + strong golden rim light. High dynamic range, calibrated color grading. Skin tones perfectly accurate. Crisp fabric detail with individual threads visible. Balanced composition, slightly wide-angle lens (35mm), center-weighted. All celebrities interacting naturally, smiling, posing, or conversing. Minimal background noise, but with enough world-building to feel real.\n\nTHE ENVIRONMENT: A luxurious open-air rooftop terrace at sunset overlooking a modern city skyline. Elements include: Warm golden light wrapping around silhouettes. Polished marble.\n```\n*Source: [@SebJefferies](https://x.com/SebJefferies/status/1991531687147360728)*\n\n### 1.2. 2000s Mirror Selfie\n*A structured JSON prompt to generate an authentic early-2000s aesthetic with flash photography and nostalgic elements.*\n<img width=\"300\" height=\"400\" alt=\"Image\" src=\"https://github.com/user-attachments/assets/b71755dc-ff33-4872-8161-3f5066e0ccb6\" />\n\n**Prompt:**\n```json\nCreate a 2000s Mirror Selfie of yourself using Gemini Nano Banana.\n\n{\n  \"subject\": {\n    \"description\": \"A young woman taking a mirror selfie with very long voluminous dark waves and soft wispy bangs\",\n    \"age\": \"young adult\",\n    \"expression\": \"confident and slightly playful\",\n    \"hair\": {\n      \"color\": \"dark\",\n      \"style\": \"very long, voluminous waves with soft wispy bangs\"\n    },\n    \"clothing\": {\n      \"top\": {\n        \"type\": \"fitted cropped t-shirt\",\n        \"color\": \"cream white\",\n        \"details\": \"features a large cute anime-style cat face graphic with big blue eyes, whiskers, and a small pink mouth\"\n      }\n    },\n    \"face\": {\n      \"preserve_original\": true,\n      \"makeup\": \"natural glam makeup with soft pink dewy blush and glossy red pouty lips\"\n    }\n  },\n  \"accessories\": {\n    \"earrings\": {\n      \"type\": \"gold geometric h",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-29T02:27:04.667240"
  },
  {
    "basic_info": {
      "name": "Z-Image",
      "full_name": "Tongyi-MAI/Z-Image",
      "owner": "Tongyi-MAI",
      "description": null,
      "url": "https://github.com/Tongyi-MAI/Z-Image",
      "clone_url": "https://github.com/Tongyi-MAI/Z-Image.git",
      "ssh_url": "git@github.com:Tongyi-MAI/Z-Image.git",
      "homepage": null,
      "created_at": "2025-11-26T09:18:10Z",
      "updated_at": "2025-11-29T02:19:48Z",
      "pushed_at": "2025-11-28T13:10:03Z"
    },
    "stats": {
      "stars": 1915,
      "forks": 75,
      "watchers": 1915,
      "open_issues": 13,
      "size": 109240
    },
    "tech_info": {
      "language": null,
      "languages": {},
      "license": "Apache License 2.0",
      "topics": []
    },
    "content": {
      "readme": "<h1 align=\"center\">‚ö°Ô∏è- Image<br><sub><sup>An Efficient Image Generation Foundation Model with Single-Stream Diffusion Transformer</sup></sub></h1>\n\n<div align=\"center\">\n\n[![Official Site](https://img.shields.io/badge/Official%20Site-333399.svg?logo=homepage)](https://tongyi-mai.github.io/Z-Image-blog/)&#160;\n[![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Checkpoint-Z--Image--Turbo-yellow)](https://huggingface.co/Tongyi-MAI/Z-Image-Turbo)&#160;\n[![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Online_Demo-Z--Image--Turbo-blue)](https://huggingface.co/spaces/Tongyi-MAI/Z-Image-Turbo)&#160;\n[![ModelScope Model](https://img.shields.io/badge/ü§ñ%20Checkpoint-Z--Image--Turbo-624aff)](https://www.modelscope.cn/models/Tongyi-MAI/Z-Image-Turbo)&#160;\n[![ModelScope Space](https://img.shields.io/badge/ü§ñ%20Online_Demo-Z--Image--Turbo-17c7a7)](https://www.modelscope.cn/aigc/imageGeneration?tab=advanced&versionId=469191&modelType=Checkpoint&sdVersion=Z_IMAGE_TURBO&modelUrl=modelscope%253A%252F%252FTongyi-MAI%252FZ-Image-Turbo%253Frevision%253Dmaster%7D%7BOnline)&#160;\n[![Art Gallery PDF](https://img.shields.io/badge/%F0%9F%96%BC%20Art_Gallery-PDF-ff69b4)](assets/Z-Image-Gallery.pdf)&#160;\n[![Web Art Gallery](https://img.shields.io/badge/%F0%9F%8C%90%20Web_Art_Gallery-online-00bfff)](https://modelscope.cn/studios/Tongyi-MAI/Z-Image-Gallery/summary)&#160;\n<a href=\"http://github.com/Tongyi-MAI/Z-Image/blob/main/Z_Image_Report.pdf\" target=\"_blank\"><img src=\"https://img.shields.io/badge/Report-b5212f.svg?logo=arxiv\" height=\"21px\"></a>\n\n\nWelcome to the official repository for the Z-ImageÔºàÈÄ†Áõ∏Ôºâproject!\n\n</div>\n\n\n\n## ‚ú® Z-Image\n\nZ-Image is a powerful and highly efficient image generation model with **6B** parameters. Currently there are three variants:\n\n- üöÄ **Z-Image-Turbo** ‚Äì A distilled version of Z-Image that matches or exceeds leading competitors with only **8 NFEs** (Number of Function Evaluations). It offers **‚ö°Ô∏èsub-second inference latency‚ö°Ô∏è** on enterprise-grade H800 GPUs and fits comfortably within **16G VRAM consumer devices**. It excels in photorealistic image generation, bilingual text rendering (English & Chinese), and robust instruction adherence.\n\n- üß± **Z-Image-Base** ‚Äì The non-distilled foundation model. By releasing this checkpoint, we aim to unlock the full potential for community-driven fine-tuning and custom development.\n\n- ‚úçÔ∏è **Z-Image-Edit** ‚Äì A variant fine-tuned on Z-Image specifically for image editing tasks. It supports creative image-to-image generation with impressive instruction-following capabilities, allowing for precise edits based on natural language prompts.\n\n### üì• Model Zoo\n\n| Model | Hugging Face                                                                                                                                                                                                                                                                                                              | ModelScope                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |\n| :--- |:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|:----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| **Z-Image-Turbo** | [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Checkpoint%20-Z--Image--Turbo-yellow)](https://huggingface.co/Tongyi-MAI/Z-Image-Turbo) <br> [![Hugging Face Space](https://img.shields.io/badge/%F0%9F%A4%97%20Online%20Demo-Z--Image--Turbo-blue)](https://huggingface.co/spaces/Tongyi-MAI/Z-Image-Turbo) | [![ModelScope Model](https://img.shields.io/badge/ü§ñ%20%20Checkpoint-Z--Image--Turbo-624aff)](https://www.modelscope.cn/models/Tongyi-MAI/Z-Image-Turbo) <br> [![ModelScope Space](https://img.shields.io/badge/%F0%9F%A4%96%20Online%20Demo-Z--Image--Turbo-17c7a7)](https://www.modelscope.cn/aigc/imageGeneration?tab=advanced&versionId=469191&modelType=Checkpoint&sdVersion=Z_IMAGE_TURBO&modelUrl=modelscope%3A%2F%2FTongyi-MAI%2FZ-Image-",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-29T02:27:05.939196"
  },
  {
    "basic_info": {
      "name": "RedInk",
      "full_name": "HisMax/RedInk",
      "owner": "HisMax",
      "description": "Á∫¢Â¢® - Âü∫‰∫éüçåNano Banana Proüçå ÁöÑ‰∏ÄÁ´ôÂºèÂ∞èÁ∫¢‰π¶ÂõæÊñáÁîüÊàêÂô® „Ää‰∏ÄÂè•ËØù‰∏ÄÂº†ÂõæÁâáÁîüÊàêÂ∞èÁ∫¢‰π¶ÂõæÊñá„Äã Red Ink - A one-stop Xiaohongshu image-and-text generator based on the üçåNano Banana Proüçå, \"One Sentence, One Image: Generate Xiaohongshu Text and Images.\"",
      "url": "https://github.com/HisMax/RedInk",
      "clone_url": "https://github.com/HisMax/RedInk.git",
      "ssh_url": "git@github.com:HisMax/RedInk.git",
      "homepage": "",
      "created_at": "2025-11-25T10:12:54Z",
      "updated_at": "2025-11-29T02:21:04Z",
      "pushed_at": "2025-11-27T09:07:54Z"
    },
    "stats": {
      "stars": 1831,
      "forks": 376,
      "watchers": 1831,
      "open_issues": 9,
      "size": 19208
    },
    "tech_info": {
      "language": "Python",
      "languages": {
        "Python": 176619,
        "Vue": 124396,
        "CSS": 23861,
        "TypeScript": 22704,
        "Dockerfile": 1560,
        "HTML": 349
      },
      "license": "Other",
      "topics": []
    },
    "content": {
      "readme": "![](images/logo.png)\n\n---\n\n[![License: CC BY-NC-SA 4.0](https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc-sa/4.0/)\n[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)\n[![Vue 3](https://img.shields.io/badge/vue-3.x-green.svg)](https://vuejs.org/)\n\n# Á∫¢Â¢® - Â∞èÁ∫¢‰π¶AIÂõæÊñáÁîüÊàêÂô®\n\n> ËÆ©‰º†Êí≠‰∏çÂÜçÈúÄË¶ÅÈó®ÊßõÔºåËÆ©Âàõ‰Ωú‰ªéÊú™Â¶ÇÊ≠§ÁÆÄÂçï\n\n![](images/index.gif)\n\n<p align=\"center\">\n  <em>Á∫¢Â¢®È¶ñÈ°µ</em>\n</p>\n\n<p align=\"center\">\n  <img src=\"images/showcase-grid.png\" alt=\"‰ΩøÁî®Á∫¢Â¢®ÁîüÊàêÁöÑÂêÑÁ±ªÂ∞èÁ∫¢‰π¶Â∞ÅÈù¢\" width=\"600\"/>\n</p>\n\n<p align=\"center\">\n  <em>‰ΩøÁî®Á∫¢Â¢®ÁîüÊàêÁöÑÂêÑÁ±ªÂ∞èÁ∫¢‰π¶Â∞ÅÈù¢ - AIÈ©±Âä®ÔºåÈ£éÊ†ºÁªü‰∏ÄÔºåÊñáÂ≠óÂáÜÁ°Æ</em>\n</p>\n\n\n\n## ÂÜôÂú®ÂâçÈù¢\n\nÂâçÊÆµÊó∂Èó¥ÈªòÂ≠êÂú® Linux.do Âèë‰∫Ü‰∏Ä‰∏™Áî® Nano banana Pro ÂÅö PPT ÁöÑÂ∏ñÂ≠ê,Êî∂Ëé∑‰∫Ü 600 Â§ö‰∏™Ëµû„ÄÇÂæàÂ§ö‰∫∫Áî®üçåNano banana Pro ÂéªÂÅö‰∫ßÂìÅÂÆ£‰º†Âõæ„ÄÅÁõ¥Êé•ÁîüÊàêÊº´ÁîªÁ≠âÁ≠â„ÄÇÊàëÂ∞±Âú®ÊÉ≥:**‰∏∫‰ªÄ‰πà‰∏çÊãøüçå2Êù•ÂÅöÁÇπÊõ¥ÂäüÂà©„ÄÅÊõ¥Âà∫ÊøÄÁöÑ‰∫ãÊÉÖ?**\n\n‰∫éÊòØÂ∞±Êúâ‰∫ÜËøô‰∏™È°πÁõÆ„ÄÇ‰∏ÄÂè•ËØù‰∏ÄÂº†ÂõæÁâáÁîüÊàêÂ∞èÁ∫¢‰π¶ÂõæÊñá\n\n---\n\n## ‚ú® ÊïàÊûúÂ±ïÁ§∫\n\n### ËæìÂÖ•‰∏ÄÂè•ËØù,Â∞±ËÉΩÁîüÊàêÂÆåÊï¥ÁöÑÂ∞èÁ∫¢‰π¶ÂõæÊñá\n\n#### ÊèêÁ§∫ËØçÔºöÁßãÂ≠£ÊòæÁôΩÁæéÁî≤ÔºàÊöóÂπø‰∏Ä‰∏™ÔºöÈªòÂ≠êÁâåÁæéÁî≤ÔºâÔºåÂõæÁâá ÊòØÊàëÁöÑÂ∞èÁ∫¢‰π¶‰∏ªÈ°µ„ÄÇÁ¨¶ÂêàÊàëÁöÑÈ£éÊ†ºÁîüÊàê\n\n#### ÂêåÊó∂ÊàëËøòÊà™Âõæ‰∫ÜÊàëÁöÑÂ∞èÁ∫¢‰π¶‰∏ªÈ°µÔºåÂåÖÊã¨ÊàëÁöÑÂ§¥ÂÉèÔºåÁ≠æÂêçÔºåËÉåÊôØÔºåÂßìÂêç‰ªÄ‰πàÁöÑ\n\n![Á§∫‰æã1](./images/example-1.png)\n\n#### ÁÑ∂ÂêéÁ≠âÂæÖ10-20ÁßíÂêéÔºåÂ∞±‰ºöÊúâÊØè‰∏ÄÈ°µÁöÑÂ§ßÁ∫≤ÔºåÂ§ßÂÆ∂ÂèØ‰ª•Ê†πÊçÆÁöÑËá™Â∑±ÁöÑÈúÄÊ±ÇÂéªË∞ÉÊï¥È°µÈù¢È°∫Â∫èÔºà‰∏çÂª∫ËÆÆÔºâÔºåËá™ÂÆö‰πâÊØè‰∏Ä‰∏™È°µÈù¢ÁöÑÂÜÖÂÆπÔºàËøô‰∏™ÂæàÂª∫ËÆÆÔºâ\n\n![Á§∫‰æã2](./images/example-2.png)\n\n#### È¶ñÂÖàÁîüÊàêÁöÑÊòØÂ∞ÅÈù¢È°µ\n\n![Á§∫‰æã3](./images/example-3.png)\n\n#### ÁÑ∂ÂêéÁ®çÁ≠â‰∏Ä‰ºöÂÑøÂêéÔºå‰ºöÁîüÊàêÂêéÈù¢ÁöÑÊâÄÊúâÈ°µÈù¢ÔºàËøôÈáåÊòØÂπ∂ÂèëÁîüÊàêÁöÑÊâÄÊúâÈ°µÈù¢ÔºàÈªòËÆ§ÊòØ15‰∏™ÔºâÔºåÂ¶ÇÊûúÂ§ßÂÆ∂ÁöÑAPI‰æõÂ∫îÂïÜÊó†Ê≥ïÊîØÊåÅÈ´òÂπ∂ÂèëÁöÑËØùÔºåËÆ∞ÂæóË¶ÅÂéªÊîπ‰∏Ä‰∏ãËÆæÁΩÆÔºâ\n\n![Á§∫‰æã4](./images/example-4.png)\n\n---\n\n## üèóÔ∏è ÊäÄÊúØÊû∂ÊûÑ\n\n### ÂêéÁ´Ø\n- **ËØ≠Ë®Ä**: Python 3.11+\n- **Ê°ÜÊû∂**: Flask\n- **AI Ê®°Âûã**:\n  - Gemini 3 (ÊñáÊ°àÁîüÊàê)\n  - üçåNano banana Pro (ÂõæÁâáÁîüÊàê)\n- **ÂåÖÁÆ°ÁêÜ**: uv\n\n### ÂâçÁ´Ø\n- **Ê°ÜÊû∂**: Vue 3 + TypeScript\n- **ÊûÑÂª∫**: Vite\n- **Áä∂ÊÄÅÁÆ°ÁêÜ**: Pinia\n\n---\n\n## üì¶ Â¶Ç‰ΩïËá™Â∑±ÈÉ®ÁΩ≤\n\n### ÊñπÂºè‰∏ÄÔºöDocker ÈÉ®ÁΩ≤ÔºàÊé®ËçêÔºâ\n\n**ÊúÄÁÆÄÂçïÁöÑÈÉ®ÁΩ≤ÊñπÂºèÔºå‰∏ÄË°åÂëΩ‰ª§Âç≥ÂèØÂêØÂä®Ôºö**\n\n```bash\ndocker run -d -p 12398:12398 -v ./output:/app/output histonemax/redink:latest\n```\n\nËÆøÈóÆ http://localhost:12398ÔºåÂú® Web ÁïåÈù¢ÁöÑ**ËÆæÁΩÆÈ°µÈù¢**ÈÖçÁΩÆ‰Ω†ÁöÑ API Key Âç≥ÂèØ‰ΩøÁî®„ÄÇ\n\n**‰ΩøÁî® docker-composeÔºàÂèØÈÄâÔºâÔºö**\n\n‰∏ãËΩΩ [docker-compose.yml](https://github.com/HisMax/RedInk/blob/main/docker-compose.yml) ÂêéÔºö\n\n```bash\ndocker-compose up -d\n```\n\n**Docker ÈÉ®ÁΩ≤ËØ¥ÊòéÔºö**\n- ÂÆπÂô®ÂÜÖ‰∏çÂåÖÂê´‰ªª‰Ωï API KeyÔºåÈúÄË¶ÅÂú® Web ÁïåÈù¢ÈÖçÁΩÆ\n- ‰ΩøÁî® `-v ./output:/app/output` ÊåÅ‰πÖÂåñÁîüÊàêÁöÑÂõæÁâá\n- ÂèØÈÄâÔºöÊåÇËΩΩËá™ÂÆö‰πâÈÖçÁΩÆÊñá‰ª∂ `-v ./text_providers.yaml:/app/text_providers.yaml`\n\n---\n\n### ÊñπÂºè‰∫åÔºöÊú¨Âú∞ÂºÄÂèëÈÉ®ÁΩ≤\n\n**ÂâçÁΩÆË¶ÅÊ±ÇÔºö**\n- Python 3.11+\n- Node.js 18+\n- pnpm\n- uv\n\n### 1. ÂÖãÈöÜÈ°πÁõÆ\n```bash\ngit clone https://github.com/HisMax/RedInk.git\ncd RedInk\n```\n\n### 2. ÈÖçÁΩÆ API ÊúçÂä°\n\nÂ§çÂà∂ÈÖçÁΩÆÊ®°ÊùøÊñá‰ª∂Ôºö\n```bash\ncp text_providers.yaml.example text_providers.yaml\ncp image_providers.yaml.example image_providers.yaml\n```\n\nÁºñËæëÈÖçÁΩÆÊñá‰ª∂ÔºåÂ°´ÂÖ•‰Ω†ÁöÑ API Key ÂíåÊúçÂä°ÈÖçÁΩÆ„ÄÇ‰πüÂèØ‰ª•ÂêØÂä®ÂêéÂú® Web ÁïåÈù¢ÁöÑ**ËÆæÁΩÆÈ°µÈù¢**ËøõË°åÈÖçÁΩÆ„ÄÇ\n\n### 3. ÂÆâË£ÖÂêéÁ´Ø‰æùËµñ\n```bash\nuv sync\n```\n\n### 4. ÂÆâË£ÖÂâçÁ´Ø‰æùËµñ\n```bash\ncd frontend\npnpm install\n```\n\n### 5. ÂêØÂä®ÊúçÂä°\n\n**ÂêØÂä®ÂêéÁ´Ø:**\n```bash\nuv run python -m backend.app\n```\nËÆøÈóÆ: http://localhost:12398\n\n**ÂêØÂä®ÂâçÁ´Ø:**\n```bash\ncd frontend\npnpm dev\n```\nËÆøÈóÆ: http://localhost:5173\n\n---\n\n## üéÆ ‰ΩøÁî®ÊåáÂçó\n\n### Âü∫Á°Ä‰ΩøÁî®\n1. **ËæìÂÖ•‰∏ªÈ¢ò**: Âú®È¶ñÈ°µËæìÂÖ•ÊÉ≥Ë¶ÅÂàõ‰ΩúÁöÑ‰∏ªÈ¢ò,Â¶Ç\"Â¶Ç‰ΩïÂú®ÂÆ∂ÂÅöÊãøÈìÅ\"\n2. **ÁîüÊàêÂ§ßÁ∫≤**: AI Ëá™Âä®ÁîüÊàê 6-9 È°µÁöÑÂÜÖÂÆπÂ§ßÁ∫≤\n3. **ÁºñËæëÁ°ÆËÆ§**: ÂèØ‰ª•ÁºñËæëÂíåË∞ÉÊï¥ÊØè‰∏ÄÈ°µÁöÑÊèèËø∞\n4. **ÁîüÊàêÂõæÁâá**: ÁÇπÂáªÁîüÊàê,ÂÆûÊó∂Êü•ÁúãËøõÂ∫¶\n5. **‰∏ãËΩΩ‰ΩøÁî®**: ‰∏ÄÈîÆ‰∏ãËΩΩÊâÄÊúâÂõæÁâá\n\n### ËøõÈò∂‰ΩøÁî®\n- **‰∏ä‰º†ÂèÇËÄÉÂõæÁâá**: ÈÄÇÂêàÂìÅÁâåÊñπ,‰øùÊåÅÂìÅÁâåËßÜËßâÈ£éÊ†º\n- **‰øÆÊîπÊèèËø∞ËØç**: Á≤æÁ°ÆÊéßÂà∂ÊØè‰∏ÄÈ°µÁöÑÂÜÖÂÆπÂíåÊûÑÂõæ\n- **ÈáçÊñ∞ÁîüÊàê**: ÂØπ‰∏çÊª°ÊÑèÁöÑÈ°µÈù¢ÂçïÁã¨ÈáçÊñ∞ÁîüÊàê\n\n---\n\n## üîß ÈÖçÁΩÆËØ¥Êòé\n\n### ÈÖçÁΩÆÊñπÂºè\n\nÈ°πÁõÆÊîØÊåÅ‰∏§ÁßçÈÖçÁΩÆÊñπÂºèÔºö\n\n1. **Web ÁïåÈù¢ÈÖçÁΩÆÔºàÊé®ËçêÔºâ**ÔºöÂêØÂä®ÊúçÂä°ÂêéÔºåÂú®ËÆæÁΩÆÈ°µÈù¢ÂèØËßÜÂåñÈÖçÁΩÆ\n2. **YAML Êñá‰ª∂ÈÖçÁΩÆ**ÔºöÁõ¥Êé•ÁºñËæëÈÖçÁΩÆÊñá‰ª∂\n\n### ÊñáÊú¨ÁîüÊàêÈÖçÁΩÆ\n\nÈÖçÁΩÆÊñá‰ª∂: `text_providers.yaml`\n\n```yaml\n# ÂΩìÂâçÊøÄÊ¥ªÁöÑÊúçÂä°ÂïÜ\nactive_provider: openai\n\nproviders:\n  # OpenAI ÂÆòÊñπÊàñÂÖºÂÆπÊé•Âè£\n  openai:\n    type: openai_compatible\n    api_key: sk-xxxxxxxxxxxxxxxxxxxx\n    base_url: https://api.openai.com/v1\n    model: gpt-4o\n\n  # Google GeminiÔºàÂéüÁîüÊé•Âè£Ôºâ\n  gemini:\n    type: google_gemini\n    api_key: AIzaxxxxxxxxxxxxxxxxxxxxxxxxx\n    model: gemini-2.0-flash\n```\n\n### ÂõæÁâáÁîüÊàêÈÖçÁΩÆ\n\nÈÖçÁΩÆÊñá‰ª∂: `image_providers.yaml`\n\n```yaml\n# ÂΩìÂâçÊøÄÊ¥ªÁöÑÊúçÂä°ÂïÜ\nactive_provider: gemini\n\nproviders:\n  # Google Gemini ÂõæÁâáÁîüÊàê\n  gemini:\n    type: google_genai\n    api_key: AIzaxxxxxxxxxxxxxxxxxxxxxxxxx\n    model: gemini-3-pro-image-preview\n    high_concurrency: false  # È´òÂπ∂ÂèëÊ®°Âºè\n\n  # OpenAI ÂÖºÂÆπÊé•Âè£\n  openai_image:\n    type: image_api\n    api_key: sk-xxxxxxxxxxxxxxxxxxxx\n    base_url: https://your-api-endpoint.com\n    model: dall-e-3\n    high_concurrency: false\n```\n\n### È´òÂπ∂ÂèëÊ®°ÂºèËØ¥Êòé\n\n- **ÂÖ≥Èó≠ÔºàÈªòËÆ§Ôºâ**ÔºöÂõæÁâáÈÄêÂº†ÁîüÊàêÔºåÈÄÇÂêà GCP 300$ ËØïÁî®Ë¥¶Âè∑ÊàñÊúâÈÄüÁéáÈôêÂà∂ÁöÑ API\n- **ÂºÄÂêØ**ÔºöÂõæÁâáÂπ∂Ë°åÁîüÊàêÔºàÊúÄÂ§ö15Âº†ÂêåÊó∂ÔºâÔºåÈÄüÂ∫¶Êõ¥Âø´Ôºå‰ΩÜÈúÄË¶Å API ÊîØÊåÅÈ´òÂπ∂Âèë\n\n‚ö†Ô∏è **GCP 300$ ËØïÁî®Ë¥¶Âè∑‰∏çÂª∫ËÆÆÂêØÁî®È´òÂπ∂Âèë**ÔºåÂèØËÉΩ‰ºöËß¶ÂèëÈÄüÁéáÈôêÂà∂ÂØºËá¥ÁîüÊàêÂ§±Ë¥•„ÄÇ\n\n---\n\n## ‚ö†Ô∏è Ê≥®ÊÑè‰∫ãÈ°π\n\n1. **API ÈÖçÈ¢ùÈôêÂà∂**:\n   - Ê≥®ÊÑè Gemini ÂíåÂõæÁâáÁîüÊàê API ÁöÑË∞ÉÁî®ÈÖçÈ¢ù\n   - GCP ËØïÁî®Ë¥¶Âè∑Âª∫ËÆÆÂÖ≥Èó≠È´òÂπ∂ÂèëÊ®°Âºè\n\n2. **ÁîüÊàêÊó∂Èó¥**:\n   - ÂõæÁâáÁîüÊàêÈúÄË¶ÅÊó∂Èó¥,ËØ∑ËÄêÂøÉÁ≠âÂæÖÔºà‰∏çË¶ÅÁ¶ªÂºÄÈ°µÈù¢Ôºâ\n\n---\n\n## ü§ù ÂèÇ‰∏éË¥°ÁåÆ\n\nÊ¨¢ËøéÊèê‰∫§ Issue Âíå Pull Request!\n\nÂ¶ÇÊûúËøô‰∏™È°πÁõÆÂØπ‰Ω†ÊúâÂ∏ÆÂä©,Ê¨¢ËøéÁªô‰∏™ Star ‚≠ê\n\n### Êú™Êù•ËÆ°Âàí\n- [ ] ÊîØÊåÅÊõ¥Â§öÂõæÁâáÊ†ºÂºèÔºå‰æãÂ¶Ç‰∏ÄÂè•ËØùÁîüÊàê‰∏ÄÂ•óPPT‰ªÄ‰πàÁöÑ\n- [ ] ÂéÜÂè≤ËÆ∞ÂΩïÁÆ°ÁêÜ‰ºòÂåñ\n- [ ] ÂØºÂá∫‰∏∫ÂêÑÁßçÊ†ºÂºè(PDF„ÄÅÈïøÂõæÁ≠â)\n\n---\n\n## Êõ¥Êñ∞Êó•Âøó\n\n### v1.3.0 (2025-11-26)\n- ‚ú® Êñ∞Â¢û Docker ÊîØÊåÅÔºå‰∏ÄÈîÆÈÉ®ÁΩ≤\n- ‚ú® ÂèëÂ∏ÉÂÆòÊñπ Docker ÈïúÂÉèÂà∞ Docker Hub: `histonemax/redink`\n- üîß Flask Ëá™Âä®Ê£ÄÊµãÂâçÁ´ØÊûÑÂª∫‰∫ßÁâ©ÔºåÊîØÊåÅÂçïÂÆπÂô®ÈÉ®ÁΩ≤\n- üîß Docker ÈïúÂÉèÂÜÖÁΩÆÁ©∫ÁôΩÈÖçÁΩÆÊ®°ÊùøÔºå‰øùÊä§ API Key ÂÆâÂÖ®\n- üìù Êõ¥Êñ∞ READMEÔºåÊ∑ªÂä† Docker ÈÉ®ÁΩ≤ËØ¥Êòé\n\n### v1.2.0 (2025-11-26)\n- ‚ú® Êñ∞Â¢ûÁâàÊùÉ‰ø°ÊÅØÂ±ïÁ§∫ÔºåÊâÄÊúâÈ°µÈù¢ÊòæÁ§∫ÂºÄÊ∫êÂçèËÆÆÂíåÈ°πÁõÆÈìæÊé•\n- ‚ú® ‰ºòÂåñÂõæÁâáÈáçÊñ∞ÁîüÊàêÂäüËÉΩÔºåÊîØÊåÅÂçïÂº†ÂõæÁâáÈáçÁªò\n- ‚ú® ÈáçÊñ∞ÁîüÊàêÂõæÁâáÊó∂‰øùÊåÅÈ£éÊ†º‰∏ÄËá¥Ôºå‰º†ÈÄíÂÆåÊï¥‰∏ä‰∏ãÊñáÔºàÂ∞ÅÈù¢Âõæ„ÄÅÂ§ßÁ∫≤„ÄÅÁî®Êà∑ËæìÂÖ•Ôºâ\n- ‚ú® ‰øÆÂ§çÂõæÁâáÁºìÂ≠òÈóÆÈ¢òÔºåÈáçÊñ∞ÁîüÊàêÁöÑÂõæÁâáÁ´ãÂç≥Âà∑Êñ∞ÊòæÁ§∫\n- ‚ú® Áªü‰∏ÄÊñáÊú¨ÁîüÊàêÂÆ¢Êà∑Á´ØÊé•Âè£ÔºåÊîØÊåÅ Google Gemini Âíå OpenAI ÂÖºÂÆπÊé•Âè£Ëá™Âä®ÂàáÊç¢\n- ‚ú® Êñ∞Â¢û Web ÁïåÈù¢ÈÖçÁΩÆÂäüËÉΩÔºåÂèØËßÜÂåñÁÆ°ÁêÜ API ÊúçÂä°ÂïÜ\n- ‚ú® Êñ∞Â¢ûÈ´òÂπ∂ÂèëÊ®°ÂºèÂºÄÂÖ≥ÔºåÈÄÇÈÖç‰∏çÂêå API ÈÖçÈ¢ù\n- ‚ú® API Key ËÑ±ÊïèÊòæÁ§∫Ôºå‰øùÊä§ÂØÜÈí•ÂÆâÂÖ®\n- ‚ú® ÈÖçÁΩÆËá™Âä®‰øùÂ≠òÔºå‰øÆÊîπÂç≥Êó∂ÁîüÊïà\n- üîß Ë∞ÉÊï¥ÈªòËÆ§ max_output_tokens ‰∏∫ 8000ÔºåÂÖºÂÆπÊõ¥Â§öÊ®°ÂûãÈôêÂà∂\n- üîß ‰ºòÂåñÂâçÁ´ØË∑ØÁî±ÂíåÈ°µÈù¢Â∏ÉÂ±ÄÔºåÊèêÂçáÁî®Êà∑‰ΩìÈ™å\n- üîß ÁÆÄÂåñÈÖçÁΩÆÊñá‰ª∂ÁªìÊûÑÔºåÁßªÈô§ÂÜó‰ΩôÂèÇÊï∞\n- üîß ‰ºòÂåñÂéÜÂè≤ËÆ∞ÂΩïÂõæÁâáÊòæÁ§∫Ôºå‰ΩøÁî®Áº©Áï•ÂõæËäÇÁúÅÂ∏¶ÂÆΩ\n- üîß ÂéÜÂè≤ËÆ∞ÂΩïÈáçÊñ∞ÁîüÊàêÊó∂Ëá™Âä®‰ªéÊñá‰ª∂Á≥ªÁªüÂä†ËΩΩÂ∞ÅÈù¢Âõæ‰Ωú‰∏∫ÂèÇËÄÉ\n- üêõ ‰øÆÂ§ç `store.updateImage` ÊñπÊ≥ïÁº∫Â§±ÂØºËá¥ÁöÑÈáçÊñ∞ÁîüÊàêÂ§±Ë¥•ÈóÆÈ¢ò\n- üêõ ‰øÆÂ§çÂéÜÂè≤ËÆ∞ÂΩïÂä†ËΩΩÊó∂ÂõæÁâá URL ÊãºÊé•ÈîôËØØ\n- üêõ ‰øÆÂ§ç‰∏ãËΩΩÂäüËÉΩ‰∏≠ÂéüÂõæÂèÇÊï∞Â§ÑÁêÜÈóÆÈ¢ò\n- üêõ ‰øÆÂ§çÂõæÁâáÂä†ËΩΩ 500 ÈîôËØØÈóÆÈ¢ò\n\n---\n\n## ‰∫§ÊµÅËÆ®ËÆ∫‰∏éËµûÂä©\n\n- **GitHub Issues**",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-29T02:27:07.207122"
  },
  {
    "basic_info": {
      "name": "mgrep",
      "full_name": "mixedbread-ai/mgrep",
      "owner": "mixedbread-ai",
      "description": "A calm, CLI-native way to semantically grep everything, like code, images, pdfs and more.",
      "url": "https://github.com/mixedbread-ai/mgrep",
      "clone_url": "https://github.com/mixedbread-ai/mgrep.git",
      "ssh_url": "git@github.com:mixedbread-ai/mgrep.git",
      "homepage": "https://demo.mgrep.mixedbread.com",
      "created_at": "2025-11-06T01:01:47Z",
      "updated_at": "2025-11-29T00:54:07Z",
      "pushed_at": "2025-11-28T21:11:24Z"
    },
    "stats": {
      "stars": 1572,
      "forks": 65,
      "watchers": 1572,
      "open_issues": 15,
      "size": 556
    },
    "tech_info": {
      "language": "TypeScript",
      "languages": {
        "TypeScript": 80145,
        "Shell": 8220,
        "Python": 3116,
        "JavaScript": 1505
      },
      "license": "Apache License 2.0",
      "topics": []
    },
    "content": {
      "readme": "<div align=\"center\">\n  <a href=\"https://github.com/mixedbread-ai/mgrep\">\n    <img src=\"public/logo_mb.svg\" alt=\"mgrep\" width=\"96\" height=\"96\" />\n  </a>\n  <h1>mgrep</h1>\n  <p><em>A calm, CLI-native way to semantically grep everything, like code, images, pdfs and more.</em></p>\n  <a href=\"https://www.npmjs.com/package/@mixedbread/mgrep\"><img src=\"https://badge.fury.io/js/@mixedbread%2Fcli.svg\" alt=\"npm version\" /></a>\n  <a href=\"https://opensource.org/licenses/Apache-2.0\"><img src=\"https://img.shields.io/badge/License-Apache%202.0-blue.svg\" alt=\"License: Apache 2.0\" /></a><br>\n  <a href=\"https://demo.mgrep.mixedbread.com\">Try it out in our playground!</a>\n</div>\n\n## Why mgrep?\n- Natural-language search that feels as immediate as `grep`.\n- Semantic, multilingual & multimodal (audio, video support coming soon!)\n- Smooth background indexing via `mgrep watch`, designed to detect and keep up-to-date everything that matters inside any git repository.\n- Friendly device-login flow and first-class coding agent integrations.\n- Built for agents and humans alike, and **designed to be a helpful tool**, not a restrictive harness: quiet output, thoughtful defaults, and escape hatches everywhere.\n- Reduces the token usage of your agent by 2x while maintaining superior performance\n\n```bash\n# index once\nmgrep watch\n\n# then ask your repo things in natural language\nmgrep \"where do we set up auth?\"\n```\n\n## Quick Start\n\n1. **Install**\n   ```bash\n   npm install -g @mixedbread/mgrep    # or pnpm / bun\n   ```\n\n2. **Sign in once**\n   ```bash\n   mgrep login\n   ```\n   A browser window (or verification URL) guides you through Mixedbread authentication.\n\n   **Alternative: API Key Authentication**\n   For CI/CD or headless environments, set the `MXBAI_API_KEY` environment variable:\n   ```bash\n   export MXBAI_API_KEY=your_api_key_here\n   ```\n   This bypasses the browser login flow entirely.\n\n3. **Index a project**\n   ```bash\n   cd path/to/repo\n   mgrep watch\n   ```\n   `watch` performs an initial sync, respects `.gitignore`, then keeps the Mixedbread store updated as files change.\n\n4. **Search anything**\n   ```bash\n   mgrep \"where do we set up auth?\" src/lib\n   mgrep -m 25 \"store schema\"\n   ```\n   Searches default to the current working directory unless you pass a path.\n\n**Today, `mgrep` works great on:** code, text, PDFs, images.  \n**Coming soon:** audio & video.\n\n## Using it with Coding Agents\n\n`mgrep` supports assisted installation commands for many agents:\n- `mgrep install-claude-code` for Claude Code\n- `mgrep install-opencode` for OpenCode\n- `mgrep install-codex` for Codex\n- `mgrep install-droid` for Factory Droid\n\nThese commands sign you in (if needed) and add Mixedbread `mgrep` support to the\nagent. After that you only have to start the agent in your project folder, thats\nit.\n\n### More Agents Coming Soon\n\nMore agents (Cursor, Windsurf, etc.) are on the way‚Äîthis section will grow as soon as each integration lands.\n\n## Making your agent smarter\n\nWe plugged `mgrep` into Claude Code and ran a benchmark of 50 QA tasks to evaluate the economics of `mgrep` against `grep`.\n\n![mgrep benchmark](assets/bench.jpg)\n\nIn our 50-task benchmark, `mgrep`+Claude Code used ~2x fewer tokens than grep-based workflows at similar or better judged quality.\n\n`mgrep` finds the relevant snippets in a few semantic queries first, and the model spends its capacity on reasoning instead of scanning through irrelevant code from endless `grep` attempts. You can [Try it yourself](http://demo.mgrep.mixedbread.com).\n\n*Note: Win Rate (%) was calculated by using an LLM as a judge.*\n\n## Why we built mgrep\n\n`grep` is an amazing tool. It's lightweight, compatible with just about every machine on the planet, and will reliably surface any potential match within any target folder.\n\nBut grep is **from 1973**, and it carries the limitations of its era: you need exact patterns and it slows down considerably in the cases where you need it most, on large codebases.\n\nWorst of all, if you're looking for deeply-buried critical business logic, you cannot describe it: you have to be able to accurately guess what kind of naming patterns would have been used by the previous generations of engineers at your workplace for `grep` to find it. This will often result in watching a coding agent desperately try hundreds of patterns, filling its token window, and your upcoming invoice, with thousands of tokens. \n\nBut it doesn't have to be this way. Everything else in our toolkit is increasingly tailored to understand us, and so should our search tools. `mgrep` is our way to bring `grep` to 2025, integrating all of the advances in semantic understanding and code-search, without sacrificing anything that has made `grep` such a useful tool. \n\nUnder the hood, `mgrep` is powered by [Mixedbread Search](https://www.mixedbread.com/blog/mixedbread-search), our full-featured search solution. It combines state-of-the-art semantic retrieval models with context-aware parsing and optimized inference methods to prov",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-29T02:27:08.461975"
  },
  {
    "basic_info": {
      "name": "JiT",
      "full_name": "LTH14/JiT",
      "owner": "LTH14",
      "description": "PyTorch implementation of JiT https://arxiv.org/abs/2511.13720",
      "url": "https://github.com/LTH14/JiT",
      "clone_url": "https://github.com/LTH14/JiT.git",
      "ssh_url": "git@github.com:LTH14/JiT.git",
      "homepage": "",
      "created_at": "2025-11-10T22:37:40Z",
      "updated_at": "2025-11-29T01:26:30Z",
      "pushed_at": "2025-11-18T03:24:51Z"
    },
    "stats": {
      "stars": 1431,
      "forks": 64,
      "watchers": 1431,
      "open_issues": 17,
      "size": 67601
    },
    "tech_info": {
      "language": "Python",
      "languages": {
        "Python": 56577
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "## Just image Transformer (JiT) for Pixel-space Diffusion\n\n[![arXiv](https://img.shields.io/badge/arXiv%20paper-2511.13720-b31b1b.svg)](https://arxiv.org/abs/2511.13720)&nbsp;\n\n<p align=\"center\">\n  <img src=\"demo/visual.jpg\" width=\"100%\">\n</p>\n\n\nThis is a PyTorch/GPU re-implementation of the paper [Back to Basics: Let Denoising Generative Models Denoise](https://arxiv.org/abs/2511.13720):\n\n```\n@article{li2025jit,\n  title={Back to Basics: Let Denoising Generative Models Denoise},\n  author={Li, Tianhong and He, Kaiming},\n  journal={arXiv preprint arXiv:2511.13720},\n  year={2025}\n}\n```\n\nJiT adopts a minimalist and self-contained design for pixel-level high-resolution image diffusion. \nThe original implementation was in JAX+TPU. This re-implementation is in PyTorch+GPU.\n\n<p align=\"center\">\n  <img src=\"demo/jit.jpg\" width=\"40%\">\n</p>\n\n### Dataset\nDownload [ImageNet](http://image-net.org/download) dataset, and place it in your `IMAGENET_PATH`.\n\n### Installation\n\nDownload the code:\n```\ngit clone https://github.com/LTH14/JiT.git\ncd JiT\n```\n\nA suitable [conda](https://conda.io/) environment named `jit` can be created and activated with:\n\n```\nconda env create -f environment.yaml\nconda activate jit\n```\n\nIf you get ```undefined symbol: iJIT_NotifyEvent``` when importing ```torch```, simply\n```\npip uninstall torch\npip install torch==2.5.1 --index-url https://download.pytorch.org/whl/cu124\n```\nCheck this [issue](https://github.com/conda/conda/issues/13812#issuecomment-2071445372) for more details.\n\n### Training\nThe below training scripts have been tested on 8 H200 GPUs.\n\nExample script for training JiT-B/16 on ImageNet 256x256 for 600 epochs:\n```\ntorchrun --nproc_per_node=8 --nnodes=1 --node_rank=0 \\\nmain_jit.py \\\n--model JiT-B/16 \\\n--proj_dropout 0.0 \\\n--P_mean -0.8 --P_std 0.8 \\\n--img_size 256 --noise_scale 1.0 \\\n--batch_size 128 --blr 5e-5 \\\n--epochs 600 --warmup_epochs 5 \\\n--gen_bsz 128 --num_images 50000 --cfg 2.9 --interval_min 0.1 --interval_max 1.0 \\\n--output_dir ${OUTPUT_DIR} --resume ${OUTPUT_DIR} \\\n--data_path ${IMAGENET_PATH} --online_eval\n```\n\nExample script for training JiT-B/32 on ImageNet 512x512 for 600 epochs:\n```\ntorchrun --nproc_per_node=8 --nnodes=1 --node_rank=0 \\\nmain_jit.py \\\n--model JiT-B/32 \\\n--proj_dropout 0.0 \\\n--P_mean -0.8 --P_std 0.8 \\\n--img_size 512 --noise_scale 2.0 \\\n--batch_size 128 --blr 5e-5 \\\n--epochs 600 --warmup_epochs 5 \\\n--gen_bsz 128 --num_images 50000 --cfg 2.9 --interval_min 0.1 --interval_max 1.0 \\\n--output_dir ${OUTPUT_DIR} --resume ${OUTPUT_DIR} \\\n--data_path ${IMAGENET_PATH} --online_eval\n```\n\nExample script for training JiT-H/16 on ImageNet 256x256 for 600 epochs:\n```\ntorchrun --nproc_per_node=8 --nnodes=1 --node_rank=0 \\\nmain_jit.py \\\n--model JiT-H/16 \\\n--proj_dropout 0.2 \\\n--P_mean -0.8 --P_std 0.8 \\\n--img_size 256 --noise_scale 1.0 \\\n--batch_size 128 --blr 5e-5 \\\n--epochs 600 --warmup_epochs 5 \\\n--gen_bsz 128 --num_images 50000 --cfg 2.2 --interval_min 0.1 --interval_max 1.0 \\\n--output_dir ${OUTPUT_DIR} --resume ${OUTPUT_DIR} \\\n--data_path ${IMAGENET_PATH} --online_eval\n```\n\n### Evaluation\n\nEvaluate a trained JiT:\n```\ntorchrun --nproc_per_node=8 --nnodes=1 --node_rank=0 \\\nmain_jit.py \\\n--model JiT-B/16 \\\n--img_size 256 --noise_scale 1.0 \\\n--gen_bsz 128 --num_images 50000 --cfg 2.9 --interval_min 0.1 --interval_max 1.0 \\\n--output_dir ${CKPT_DIR} --resume ${CKPT_DIR} \\\n--data_path ${IMAGENET_PATH} --evaluate_gen\n```\n\nWe use a customized [```torch-fidelity```](https://github.com/LTH14/torch-fidelity)\nto evaluate FID and IS against a reference image folder or statistics. You can use ```prepare_ref.py```\nto prepare the reference image folder, or directly use our pre-computed reference stats\nunder ```fid_stats```.\n\n### Acknowledgements\n\nWe thank Google TPU Research Cloud (TRC) for granting us access to TPUs, and the MIT\nORCD Seed Fund Grants for supporting GPU resources.\n\n### Contact\n\nIf you have any questions, feel free to contact me through email (tianhong@mit.edu). Enjoy!\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-29T02:27:09.742743"
  },
  {
    "basic_info": {
      "name": "xiaomi-miloco",
      "full_name": "XiaoMi/xiaomi-miloco",
      "owner": "XiaoMi",
      "description": "Xiaomi Miloco",
      "url": "https://github.com/XiaoMi/xiaomi-miloco",
      "clone_url": "https://github.com/XiaoMi/xiaomi-miloco.git",
      "ssh_url": "git@github.com:XiaoMi/xiaomi-miloco.git",
      "homepage": null,
      "created_at": "2025-11-06T13:01:59Z",
      "updated_at": "2025-11-29T02:26:42Z",
      "pushed_at": "2025-11-28T13:14:55Z"
    },
    "stats": {
      "stars": 1417,
      "forks": 89,
      "watchers": 1417,
      "open_issues": 61,
      "size": 23989
    },
    "tech_info": {
      "language": "Python",
      "languages": {
        "Python": 1050918,
        "JavaScript": 506494,
        "Shell": 90272,
        "C++": 83167,
        "Less": 71704,
        "HTML": 53752,
        "CSS": 9737,
        "Dockerfile": 5505,
        "C": 2948,
        "CMake": 1813
      },
      "license": "Other",
      "topics": []
    },
    "content": {
      "readme": "# Xiaomi Miloco\n\n**Xiaomi Local Copilot** is a future exploration solution for smart homes. Using Xiaomi Home cameras as the source of visual information and a self-developed LLM as its core, it connects all IoT devices throughout the house. Based on the development paradigm of LLM, it enables users to define various family needs and rules in natural language, achieving broader and more creative smart device integration.\n\n<div align=\"center\">\n\nEnglish | [ÁÆÄ‰Ωì‰∏≠Êñá](README.zh_Hans.md)\n\n</div>\n\n## News\n\n- [2025-11] Xiaomi Miloco Framework Open Source\n\n## Key Features\n\n1. New Interaction Paradigm: Based on the development paradigm of LLM, rule-setting and complex device command control can be completed through natural language interaction.\n2. New Use for Visual Data: Using camera data streams as a source of perceptual information, the LLM is used to analyze various home scene events contained in the visual data to respond to user queries.\n3. On-Device LLM: The home scene tasks are split into two stages: planning and visual understanding. It provides Xiaomi's self-developed on-device model to realize on-device video understanding and ensure family privacy and security.\n4. Xiaomi Home Ecosystem: It connects with the Xiaomi Home ecosystem, supports the retrieval and execution of Mi Home devices and scenes, and supports sending customized content for Xiao Home notifications.\n\n    <img src=\"assets/images/ai_center.jpg\" width=\"60%\" />\n\n## Quick Start\n\n### System Requirements\n\n- **Hardware Requirements**\n```Plain Text\nCPU: x64 architecture\nGraphics Card: NVIDIA 30 series and above, 8GB VRAM minimum (recommended 12GB and above)\nStorage: Recommended 16GB or more available space (for local model storage)\n```\n\n- **Software Requirements**\n```Plain Text\nOperating System:\n  - Linux: x64 architecture, recommended Ubuntu 22.04 and above LTS versions\n  - Windows: x64 architecture, recommended Windows 10 and above, requires WSL2 support\n  - macOS: Not currently supported\nDocker: Version 20.10 and above, requires docker compose support\nNVIDIA Driver: NVIDIA driver with CUDA support\nNVIDIA Container Toolkit: For Docker GPU support\n```\n\n### Install\n\n> **Note**: Please ensure your system meets the above hardware and software requirements. Windows systems need to enter the WSL environment.\n\n**Install with Docker**  \nOne-click installation via command line\n```bash\nbash -c \"$(wget -qO- https://xiaomi-miloco.cnbj1.mi-fds.com/xiaomi-miloco/install.sh)\"\n```\nOr download the source code first, then execute the one-click installation script:\n```bash\ngit clone https://github.com/XiaoMi/xiaomi-miloco.git\n\nbash scripts/install.sh\n```\nFor detailed installation steps, please refer to the [Docker Deployment Documentation](docs/environment-setup.md).\n\n**Install with source code**  \nFor source code installation steps, please refer to the [Development Guide](docs/development/developer-setup.md).\n\n## Usage Documentation\n\nPlease refer to the [Usage Documentation](docs/usage/README.md).\n\n## Contributing\n\nPlease refer to the [Contributing Guide](CONTRIBUTING.md).\n\n## License\n\nFor license details, please see [LICENSE.md](LICENSE.md).\n\n**Important Notice**: This project is limited to non-commercial use only. Without written authorization from Xiaomi Corporation, this project may not be used for developing applications, web services, or other forms of software.\n\n## Security Issues\n\nIf you discover potential security issues in this project, or believe you may have found a security issue, please notify the [Miloco Team](xiaomi-miloco@xiaomi.com) via our vulnerability reporting email. Please do not create public GitHub Issues.\n\n## Contact Us\n\n### Issue Reporting\n\nFor issue reporting, please participate through the following methods:\n- Submit a [GitHub Issue](https://github.com/XiaoMi/xiaomi-miloco/issues/new/)\n\n### Technical Discussion\n\n- GitHub [Discussions](https://github.com/XiaoMi/xiaomi-miloco/discussions/)\n- Project Discussion Group (WeChat):\n\n  <img src=\"assets/images/miloco_wechat_group_17.jpeg\" width=\"30%\" />\n  <img src=\"assets/images/miloco_wechat_15.jpeg\" width=\"30%\" />\n  <img src=\"assets/images/miloco_wechat_group_12.jpeg\" width=\"30%\" />\n\n\n\n### Join Us\n\nThe **Xiaomi Miloco** team is hiring. Send your resume to `xiaomi-miloco@xiaomi.com`, and it will be delivered directly to the project lead.\n\n## Acknowledgments\n\nThank you to the original team members who worked hard for MilocoÔºözhaoy„ÄÅyangyongjie„ÄÅxx„ÄÅChangyu„ÄÅyyk„ÄÅjunhui„ÄÅÈÉ≠ÂÖ¥ÂÆù„ÄÅ47„ÄÅafei„ÄÇ\n\nYour passion and talent are the fundamental driving force behind Miloco's continuous innovation and progress.\n\nSpecial thanks to:\n- The [llama.cpp](https://github.com/ggml-org/llama.cpp) open source project for providing inference backend capabilities\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-29T02:27:11.026773"
  },
  {
    "basic_info": {
      "name": "NoLongerEvil-Thermostat",
      "full_name": "codykociemba/NoLongerEvil-Thermostat",
      "owner": "codykociemba",
      "description": "Breathe fresh life into your bricked Nest, now with 100% less evil!",
      "url": "https://github.com/codykociemba/NoLongerEvil-Thermostat",
      "clone_url": "https://github.com/codykociemba/NoLongerEvil-Thermostat.git",
      "ssh_url": "git@github.com:codykociemba/NoLongerEvil-Thermostat.git",
      "homepage": "https://nolongerevil.com",
      "created_at": "2025-11-02T03:30:37Z",
      "updated_at": "2025-11-29T00:39:23Z",
      "pushed_at": "2025-11-26T21:22:52Z"
    },
    "stats": {
      "stars": 1333,
      "forks": 79,
      "watchers": 1333,
      "open_issues": 24,
      "size": 38663
    },
    "tech_info": {
      "language": "C",
      "languages": {
        "C": 26428,
        "Shell": 12118,
        "Makefile": 478,
        "Nix": 114
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# Nest Thermostat Firmware Setup\n\n[![Buy Me A Coffee](https://img.shields.io/badge/Buy%20Me%20A%20Coffee-donate-yellow.svg)](https://buymeacoffee.com/codykociemba)\n[![Discord](https://img.shields.io/badge/Discord-Join%20Us-5865F2?logo=discord&logoColor=white)](https://discord.gg/hackhouse)\n[![Release](https://img.shields.io/badge/Release-v1.0.0-blue)](https://github.com/codykociemba/NoLongerEvil-Thermostat/releases/tag/v1.0.0)\n\n<div align=\"center\">\n  <a href=\"https://bounties.fulu.org/bounties/nest-learning-thermostat-gen-1-2\">\n    <img src=\"assets/fulu-bounties.png\" alt=\"FULU Bounties Winner\" width=\"500\">\n  </a>\n  <h2>üèÜ FULU Bounty Winner üèÜ</h2>\n  <p><strong><a href=\"https://hackhouse.io\">Hack House</a></strong> and this project are the official winners of the <strong><a href=\"https://bounties.fulu.org/bounties/nest-learning-thermostat-gen-1-2\">FULU Bounty for Nest Learning Thermostat Gen 1/2</a></strong></p>\n</div>\n\n**Hardware Alternative:** If you're interested in the hardware side of things, check out [https://sett.homes](https://sett.homes) for a drop-in PCB replacement option.\n\n---\n\n## Installation Options\n\nChoose the installation method that works best for you:\n\n### Option 1: Hosted (GUI Installer) - **Recommended**\n\nThe easiest way to get started. Download our GUI installer that handles everything automatically.\n\nüìñ **[View Installation Guide](https://docs.nolongerevil.com/hosted/installation)**\n\n### Option 2: Hosted (Manual)\n\nIf the GUI installer doesn't work for you, follow the manual installation steps below. This method uses command-line tools to flash the firmware.\n\n### Option 3: Self-Hosted - **Advanced Users Only**\n\nHost your own No Longer Evil server infrastructure. Requires technical expertise.\n\nüìñ **[View Self-Hosted Guide](https://docs.nolongerevil.com/self-hosted/overview)**\n\n‚ö†Ô∏è **Warning:** This option is still a work in progress and may or may not function properly. Check out the [discussion here](https://github.com/codykociemba/NoLongerEvil-Thermostat/discussions/34) for more details.\n\n---\n\n## Manual Installation (Option 2)\n\nThis directory contains the tools and firmware needed to flash custom firmware to Nest Thermostat devices using the OMAP DFU (Device Firmware Update) interface.\n\n### Prerequesites\n\nYou will need to have a Linux or MacOS computer available.\n\n‚ö†Ô∏è Please verify your Nest is compatible at **[https://docs.nolongerevil.com/compatibility](https://docs.nolongerevil.com/compatibility)** - we currently only support Nest Generation 1 and 2 at the moment.\n\n### How it Works\n\nThe custom firmware flashes the device with modified bootloader and kernel components that redirect all network traffic from the original Nest/Google servers to a server we specify. This server hosts a reverse-engineered replica of their API, allowing the thermostat to function independently while giving you complete control over your device data and settings.\n\nBy intercepting the communication layer, the thermostat believes it's communicating with the official Nest infrastructure, but instead connects to the No Longer Evil platform. This approach ensures full compatibility with the device's existing software while breaking free from Google's cloud dependency.\n\n## Quick Start\n\n### 1. Clone the Repository\n\n```bash\ngit clone https://github.com/codykociemba/NoLongerEvil-Thermostat.git\ncd NoLongerEvil-Thermostat\n```\n\n### 2. Install Prerequisites\n\nBefore building, you'll need to install some required packages:\n\n#### Linux (Debian/Ubuntu)\n\n```bash\nsudo apt-get update\nsudo apt-get install build-essential libusb-1.0-0-dev gcc pkg-config\n```\n\n#### macOS\n\nFirst, install Xcode Command Line Tools:\n\n```bash\nxcode-select --install\n```\n\nThen install libusb using Homebrew (the build script will attempt to install this automatically if missing):\n\n```bash\n# Install Homebrew if you don't have it\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n\n# Install libusb\nbrew install libusb pkg-config\n```\n\n### 3. Build the omap_loader tool\n\n```bash\nchmod +x build.sh\n./build.sh\n```\n\nThe build script will automatically detect your operating system and build the appropriate binary.\n\n### 4. Start the firmware installer\n\n**IMPORTANT: You must start the installer script BEFORE rebooting the device.**\n\n```bash\nchmod +x install.sh\n./install.sh\n```\n\n**Note for macOS:** You may need to grant USB permissions. If you encounter permission issues, check System Preferences ‚Üí Security & Privacy.\n\nThe script will wait for the device to enter DFU mode.\n\n### 5. Put your Nest device in DFU mode\n\nFollow these steps carefully:\n\n1. **Charge the device** - Ensure your Nest Thermostat is properly charged (at least 50% battery recommended)\n2. **Remove from wall** - Remove the Nest from its back plate/wall mount\n3. **Connect via USB** - Plug the Nest into your computer using a micro USB cable\n4. **Wait for the installer** - Make sure the `install.sh` script is running and waiting\n5. **Reboot the device** - Press and h",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-29T02:27:12.310254"
  },
  {
    "basic_info": {
      "name": "crypto-trading-open",
      "full_name": "cryptocj520/crypto-trading-open",
      "owner": "cryptocj520",
      "description": "crypto-trading-open",
      "url": "https://github.com/cryptocj520/crypto-trading-open",
      "clone_url": "https://github.com/cryptocj520/crypto-trading-open.git",
      "ssh_url": "git@github.com:cryptocj520/crypto-trading-open.git",
      "homepage": null,
      "created_at": "2025-11-11T12:00:02Z",
      "updated_at": "2025-11-28T13:24:25Z",
      "pushed_at": "2025-11-11T12:03:28Z"
    },
    "stats": {
      "stars": 1271,
      "forks": 687,
      "watchers": 1271,
      "open_issues": 13,
      "size": 997
    },
    "tech_info": {
      "language": "Python",
      "languages": {
        "Python": 2825921,
        "Shell": 37998
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# Â§ö‰∫§ÊòìÊâÄÁ≠ñÁï•Ëá™Âä®ÂåñÁ≥ªÁªü\n\n**Multi-Exchange Strategy Automation System**\n\n## üéØ È°πÁõÆÁÆÄ‰ªã\n\nËøôÊòØ‰∏Ä‰∏™‰ºÅ‰∏öÁ∫ßÁöÑÂ§ö‰∫§ÊòìÊâÄÂä†ÂØÜË¥ßÂ∏ÅËá™Âä®Âåñ‰∫§ÊòìÁ≥ªÁªüÔºåÊèê‰æõÈ´òÊÄßËÉΩ„ÄÅÈ´òÂèØÈù†ÊÄßÁöÑÁΩëÊ†º‰∫§Êòì„ÄÅÂà∑Èáè‰∫§Êòì„ÄÅÂ•óÂà©ÁõëÊéßÂíåÂ∏ÇÂú∫ÁõëÊéßÂäüËÉΩ„ÄÇÁ≥ªÁªüÈááÁî®‰∏•Ê†ºÁöÑÂàÜÂ±ÇÊû∂ÊûÑËÆæËÆ°ÔºåÊîØÊåÅ Hyperliquid„ÄÅBackpack„ÄÅLighter„ÄÅBinance„ÄÅOKX„ÄÅEdgeX Á≠âÂ§ö‰∏™‰∫§ÊòìÊâÄÁöÑÂÆåÊï¥ÈÄÇÈÖç„ÄÇ\n\n## üèóÔ∏è Ê†∏ÂøÉÁ≥ªÁªüÊû∂ÊûÑ\n\n### Á≥ªÁªüÁªÑ‰ª∂\n\n```\nÂ§ö‰∫§ÊòìÊâÄÁ≠ñÁï•Ëá™Âä®ÂåñÁ≥ªÁªü\n‚îú‚îÄ‚îÄ üìä ÁΩëÊ†º‰∫§ÊòìÁ≥ªÁªü (Grid Trading)\n‚îÇ   ‚îú‚îÄ‚îÄ ÊôÆÈÄöÁΩëÊ†º              # Âõ∫ÂÆö‰ª∑Ê†ºÂå∫Èó¥ÁΩëÊ†º\n‚îÇ   ‚îú‚îÄ‚îÄ È©¨‰∏ÅÁΩëÊ†º              # È©¨‰∏ÅÊ†ºÂ∞îÈÄíÂ¢ûÁ≠ñÁï•\n‚îÇ   ‚îú‚îÄ‚îÄ ‰ª∑Ê†ºÁßªÂä®ÁΩëÊ†º          # Âä®ÊÄÅË∑üÈöè‰ª∑Ê†º\n‚îÇ   ‚îú‚îÄ‚îÄ Ââ•Â§¥ÁöÆÊ®°Âºè            # Âø´ÈÄüÊ≠¢ÊçüÁ≠ñÁï•\n‚îÇ   ‚îú‚îÄ‚îÄ Êô∫ËÉΩÂâ•Â§¥ÁöÆ            # Â§öÊ¨°Ê∑±Ë∑åÊ£ÄÊµã\n‚îÇ   ‚îú‚îÄ‚îÄ Êú¨Èáë‰øùÊä§Ê®°Âºè          # Ëá™Âä®Ê≠¢Êçü‰øùÊä§\n‚îÇ   ‚îú‚îÄ‚îÄ Ê≠¢ÁõàÊ®°Âºè              # Âà∞ËææÁõÆÊ†áËá™Âä®Âπ≥‰ªì\n‚îÇ   ‚îî‚îÄ‚îÄ Áé∞Ë¥ßÈ¢ÑÁïôÁÆ°ÁêÜ          # Áé∞Ë¥ßÂ∏ÅÁßçÈ¢ÑÁïô\n‚îú‚îÄ‚îÄ üîç ÁΩëÊ†ºÊ≥¢Âä®ÁéáÊâ´ÊèèÂô® (Grid Volatility Scanner)\n‚îÇ   ‚îú‚îÄ‚îÄ ËôöÊãüÁΩëÊ†ºÊ®°Êãü          # Êó†ÈúÄÂÆûÈôÖ‰∏ãÂçïÁöÑÊ®°ÊãüÁΩëÊ†º\n‚îÇ   ‚îú‚îÄ‚îÄ ÂÆûÊó∂APRËÆ°ÁÆó           # ÂáÜÁ°ÆÈ¢ÑÊµãÂπ¥ÂåñÊî∂ÁõäÁéá\n‚îÇ   ‚îú‚îÄ‚îÄ ‰ª£Â∏ÅÊéíË°åÊ¶ú            # ÊåâÊ≥¢Âä®ÁéáÂíåAPRÊéíÂ∫è\n‚îÇ   ‚îú‚îÄ‚îÄ Êô∫ËÉΩËØÑÁ∫ßÁ≥ªÁªü          # S/A/B/C/DÁ≠âÁ∫ßËØÑ‰º∞\n‚îÇ   ‚îî‚îÄ‚îÄ ÁªàÁ´Ø UI              # Rich ÂÆûÊó∂ÁõëÊéßÁïåÈù¢\n‚îú‚îÄ‚îÄ üíπ Âà∑Èáè‰∫§ÊòìÁ≥ªÁªü (Volume Maker)\n‚îÇ   ‚îú‚îÄ‚îÄ ÊåÇÂçïÊ®°Âºè              # Èôê‰ª∑ÂçïÂà∑ÈáèÔºàBackpackÔºâ\n‚îÇ   ‚îî‚îÄ‚îÄ Â∏Ç‰ª∑Ê®°Âºè              # Â∏Ç‰ª∑ÂçïÂø´ÈÄüÂà∑ÈáèÔºàLighterÔºâ\n‚îú‚îÄ‚îÄ üîÑ Â•óÂà©ÁõëÊéßÁ≥ªÁªü (Arbitrage Monitor)\n‚îÇ   ‚îú‚îÄ‚îÄ ‰ª∑Ê†ºÁõëÊéß              # ÂÆûÊó∂‰ª∑Ê†ºÂ∑ÆÁõëÊéß\n‚îÇ   ‚îú‚îÄ‚îÄ ËµÑÈáëË¥πÁéáÁõëÊéß          # Ë∑®‰∫§ÊòìÊâÄË¥πÁéáÂ∑ÆÂºÇ\n‚îÇ   ‚îú‚îÄ‚îÄ Â•óÂà©Êú∫‰ºöËØÜÂà´          # ‰ª∑Â∑ÆÂíåË¥πÁéáÂ•óÂà©\n‚îÇ   ‚îú‚îÄ‚îÄ ÁªàÁ´Ø UI              # Rich ÂÆûÊó∂ÁõëÊéßÁïåÈù¢\n‚îÇ   ‚îî‚îÄ‚îÄ ‰∫§ÊòìÂØπËá™Âä®ÂèëÁé∞        # Â§ö‰∫§ÊòìÊâÄ‰∫§ÊòìÂØπÂåπÈÖç\n‚îú‚îÄ‚îÄ üîî ‰ª∑Ê†ºÊèêÈÜíÁ≥ªÁªü (Price Alert)\n‚îÇ   ‚îú‚îÄ‚îÄ ‰ª∑Ê†ºÁ™ÅÁ†¥ÁõëÊéß          # ‰ª∑Ê†ºËß¶ÂèäÁõÆÊ†áÊèêÈÜí\n‚îÇ   ‚îú‚îÄ‚îÄ Â§ö‰∫§ÊòìÊâÄÊîØÊåÅ          # ÊîØÊåÅÊâÄÊúâÊé•ÂÖ•ÁöÑ‰∫§ÊòìÊâÄ\n‚îÇ   ‚îú‚îÄ‚îÄ ÁªàÁ´Ø UI              # ÂÆûÊó∂‰ª∑Ê†ºÊòæÁ§∫\n‚îÇ   ‚îî‚îÄ‚îÄ Â£∞Èü≥ÊèêÈÜí              # Á™ÅÁ†¥Êó∂Â£∞Èü≥ÈÄöÁü•\n‚îú‚îÄ‚îÄ üîó ‰∫§ÊòìÊâÄÈÄÇÈÖçÂ±Ç (Exchange Adapters)\n‚îÇ   ‚îú‚îÄ‚îÄ Hyperliquid ÈÄÇÈÖçÂô®    # Ê∞∏Áª≠ÂêàÁ∫¶ + Áé∞Ë¥ß\n‚îÇ   ‚îú‚îÄ‚îÄ Backpack ÈÄÇÈÖçÂô®       # Ê∞∏Áª≠ÂêàÁ∫¶\n‚îÇ   ‚îú‚îÄ‚îÄ Lighter ÈÄÇÈÖçÂô®        # Ê∞∏Áª≠ÂêàÁ∫¶Ôºà‰ΩéÊâãÁª≠Ë¥πÔºâ\n‚îÇ   ‚îú‚îÄ‚îÄ Binance ÈÄÇÈÖçÂô®        # Áé∞Ë¥ß + Ê∞∏Áª≠ÂêàÁ∫¶\n‚îÇ   ‚îú‚îÄ‚îÄ OKX ÈÄÇÈÖçÂô®            # Áé∞Ë¥ß + Ê∞∏Áª≠ÂêàÁ∫¶\n‚îÇ   ‚îú‚îÄ‚îÄ EdgeX ÈÄÇÈÖçÂô®          # Ê∞∏Áª≠ÂêàÁ∫¶\n‚îÇ   ‚îî‚îÄ‚îÄ Áªü‰∏ÄÊé•Âè£Ê†áÂáÜ          # Ê†áÂáÜÂåñ API Êé•Âè£\n‚îî‚îÄ‚îÄ üèõÔ∏è Âü∫Á°ÄËÆæÊñΩÂ±Ç (Infrastructure)\n    ‚îú‚îÄ‚îÄ ‰æùËµñÊ≥®ÂÖ•ÂÆπÂô®          # DI ÂÆπÂô®ÁÆ°ÁêÜ\n    ‚îú‚îÄ‚îÄ ‰∫ã‰ª∂Á≥ªÁªü              # ‰∫ã‰ª∂È©±Âä®Êû∂ÊûÑ\n    ‚îú‚îÄ‚îÄ Êó•ÂøóÁ≥ªÁªü              # ÁªìÊûÑÂåñÊó•Âøó\n    ‚îú‚îÄ‚îÄ ÈÖçÁΩÆÁÆ°ÁêÜ              # YAML ÈÖçÁΩÆÁ≥ªÁªü\n    ‚îî‚îÄ‚îÄ Êï∞ÊçÆËÅöÂêàÂô®            # Â§ö‰∫§ÊòìÊâÄÊï∞ÊçÆËÅöÂêà\n```\n\n## üöÄ Âø´ÈÄüÂºÄÂßã\n\n### Á≥ªÁªüË¶ÅÊ±Ç\n\n- Python 3.8+\n- ÊîØÊåÅÁöÑÊìç‰ΩúÁ≥ªÁªüÔºöLinux„ÄÅmacOS„ÄÅWindows\n- ÂèØÈÄâÔºötmuxÔºàÁî®‰∫éÂ§öËøõÁ®ãÁÆ°ÁêÜÔºâ\n\n### ÂÆâË£Ö‰æùËµñ\n\n```bash\n# ÂÆâË£Ö Python ‰æùËµñ\npip install -r requirements.txt\n```\n\n### ÈÖçÁΩÆ API ÂØÜÈí•\n\nÂú® `config/exchanges/` ÁõÆÂΩï‰∏ãÈÖçÁΩÆÂØπÂ∫î‰∫§ÊòìÊâÄÁöÑ API ÂØÜÈí•Ôºö\n\n```bash\nconfig/exchanges/\n‚îú‚îÄ‚îÄ hyperliquid_config.yaml   # Hyperliquid ÈÖçÁΩÆ\n‚îú‚îÄ‚îÄ backpack_config.yaml       # Backpack ÈÖçÁΩÆ\n‚îú‚îÄ‚îÄ lighter_config.yaml        # Lighter ÈÖçÁΩÆ\n‚îú‚îÄ‚îÄ binance_config.yaml        # Binance ÈÖçÁΩÆ\n‚îú‚îÄ‚îÄ okx_config.yaml            # OKX ÈÖçÁΩÆ\n‚îî‚îÄ‚îÄ edgex_config.yaml          # EdgeX ÈÖçÁΩÆ\n```\n\n### Âø´ÈÄüÂêØÂä®ÂêÑÁ≥ªÁªü\n\n#### ÁΩëÊ†º‰∫§ÊòìÁ≥ªÁªü\n```bash\npython3 run_grid_trading.py config/grid/lighter-long-perp-btc.yaml\n```\n\n#### Âà∑Èáè‰∫§ÊòìÁ≥ªÁªüÔºàBackpackÊåÇÂçïÊ®°ÂºèÔºâ\n```bash\npython3 run_volume_maker.py config/volume_maker/backpack_btc_volume_maker.yaml\n```\n\n#### Âà∑Èáè‰∫§ÊòìÁ≥ªÁªüÔºàLighterÂ∏Ç‰ª∑Ê®°ÂºèÔºâ\n```bash\npython3 run_lighter_volume_maker.py config/volume_maker/lighter_volume_maker.yaml\n```\n\n#### Â•óÂà©ÁõëÊéßÁ≥ªÁªü\n```bash\npython3 run_arbitrage_monitor.py\n```\n\n#### ‰ª∑Ê†ºÊèêÈÜíÁ≥ªÁªü\n```bash\npython3 run_price_alert.py config/price_alert/binance_alert.yaml\n```\n\n#### ÁΩëÊ†ºÊ≥¢Âä®ÁéáÊâ´ÊèèÂô®\n```bash\npython3 grid_volatility_scanner/run_scanner.py\n```\n\n## üìã Ê†∏ÂøÉÂäüËÉΩËØ¶Ëß£\n\n### 1Ô∏è‚É£ ÁΩëÊ†º‰∫§ÊòìÁ≥ªÁªü\n\n#### ÂäüËÉΩÁâπÊÄß\n\n- **Â§öÁßçÁΩëÊ†ºÊ®°Âºè**ÔºöÊôÆÈÄöÁΩëÊ†º„ÄÅÈ©¨‰∏ÅÁΩëÊ†º„ÄÅ‰ª∑Ê†ºÁßªÂä®ÁΩëÊ†º\n- **Êô∫ËÉΩÁ≠ñÁï•**ÔºöÂâ•Â§¥ÁöÆ„ÄÅÊô∫ËÉΩÂâ•Â§¥ÁöÆ„ÄÅÊú¨Èáë‰øùÊä§„ÄÅÊ≠¢ÁõàÊ®°Âºè\n- **ÂÅ•Â∫∑Ê£ÄÊü•**ÔºöËá™Âä®ËÆ¢ÂçïÊ†°È™åÂíå‰øÆÂ§çÊú∫Âà∂\n- **ÁªàÁ´Ø UI**ÔºöÂÆûÊó∂ÁõëÊéßÁïåÈù¢ÔºåÊòæÁ§∫ÊåÅ‰ªì„ÄÅÁõà‰∫è„ÄÅÁΩëÊ†ºÁä∂ÊÄÅ\n- **Áé∞Ë¥ßÊîØÊåÅ**ÔºöÁé∞Ë¥ßÈ¢ÑÁïôÁÆ°ÁêÜÔºàËá™Âä®Áª¥ÊåÅÂ∏ÅÁßç‰ΩôÈ¢ùÔºâ\n- **Â§ö‰∫§ÊòìÊâÄ**ÔºöÊîØÊåÅ Hyperliquid„ÄÅBackpack„ÄÅLighter\n\n#### ÈÖçÁΩÆÊñá‰ª∂‰ΩçÁΩÆ\n\n```\nconfig/grid/\n‚îú‚îÄ‚îÄ lighter_btc_perp_long.yaml              # Lighter BTC ÂÅöÂ§ö\n‚îú‚îÄ‚îÄ lighter_btc_perp_short.yaml             # Lighter BTC ÂÅöÁ©∫\n‚îú‚îÄ‚îÄ hyperliquid_btc_perp_long.yaml          # Hyperliquid BTC ÂÅöÂ§ö\n‚îú‚îÄ‚îÄ hyperliquid_btc_perp_short.yaml         # Hyperliquid BTC ÂÅöÁ©∫\n‚îú‚îÄ‚îÄ hyperliquid_btc_spot_long.yaml          # Hyperliquid Áé∞Ë¥ßÂÅöÂ§ö\n‚îú‚îÄ‚îÄ backpack_capital_protection_long_btc.yaml   # Backpack BTC Êú¨Èáë‰øùÊä§\n‚îú‚îÄ‚îÄ backpack_capital_protection_long_eth.yaml   # Backpack ETH Êú¨Èáë‰øùÊä§\n‚îú‚îÄ‚îÄ backpack_capital_protection_long_sol.yaml   # Backpack SOL Êú¨Èáë‰øùÊä§\n‚îú‚îÄ‚îÄ backpack_capital_protection_long_bnb.yaml   # Backpack BNB Êú¨Èáë‰øùÊä§\n‚îî‚îÄ‚îÄ backpack_capital_protection_long_hype.yaml  # Backpack HYPE Êú¨Èáë‰øùÊä§\n```\n\n#### ÂêØÂä®ÊñπÂºè\n\n```bash\n# ÊñπÂºè1ÔºöÁõ¥Êé•ÂêØÂä®ÔºàÊé®ËçêÔºâ\npython3 run_grid_trading.py config/grid/lighter_btc_perp_long.yaml\npython3 run_grid_trading.py config/grid/lighter_eth_perp_long.yaml\n\n# ÊñπÂºè2ÔºöDEBUG Ê®°ÂºèÂêØÂä®ÔºàÊü•ÁúãËØ¶ÁªÜÊó•ÂøóÔºâ\npython3 run_grid_trading.py config/grid/lighter_btc_perp_long.yaml --debug\n\n# ÊñπÂºè3Ôºö‰ΩøÁî® Shell ËÑöÊú¨ÊâπÈáèÂêØÂä®ÔºàtmuxÔºâ\n./scripts/start_all_grids.sh\n```\n\n#### Ê†∏ÂøÉÊñá‰ª∂\n\n| Êñá‰ª∂Ë∑ØÂæÑ | ËØ¥Êòé |\n|---------|------|\n| `run_grid_trading.py` | ÁΩëÊ†º‰∫§ÊòìÁ≥ªÁªü‰∏ªÂêØÂä®ËÑöÊú¨ |\n| `core/services/grid/coordinator/grid_coordinator.py` | ÁΩëÊ†ºÁ≥ªÁªüÂçèË∞ÉÂô®ÔºàÊ†∏ÂøÉÈÄªËæëÔºâ |\n| `core/services/grid/implementations/grid_engine_impl.py` | ÁΩëÊ†ºÊâßË°åÂºïÊìé |\n| `core/services/grid/implementations/grid_strategy_impl.py` | ÁΩëÊ†ºÁ≠ñÁï•ÂÆûÁé∞ |\n| `core/services/grid/implementations/position_tracker_impl.py` | ÊåÅ‰ªìË∑üË∏™Âô® |\n| `core/services/grid/implementations/order_health_checker.py` | ËÆ¢ÂçïÂÅ•Â∫∑Ê£ÄÊü•Âô® |\n| `core/services/grid/scalping/scalping_manager.py` | Ââ•Â§¥ÁöÆÁÆ°ÁêÜÂô® |\n| `core/services/grid/scalping/smart_scalping_tracker.py` | Êô∫ËÉΩÂâ•Â§¥ÁöÆËøΩË∏™Âô® |\n| `core/services/grid/capital_protection/capital_protection_manager.py` | Êú¨Èáë‰øùÊä§ÁÆ°ÁêÜÂô® |\n| `core/services/grid/terminal_ui.py` | ÁªàÁ´Ø UI ÁïåÈù¢ |\n\n### 2Ô∏è‚É£ Âà∑Èáè‰∫§ÊòìÁ≥ªÁªü\n\n#### ÂäüËÉΩÁâπÊÄß\n\n- **Âèå‰∫§ÊòìÊ®°Âºè**ÔºöÊåÇÂçïÊ®°ÂºèÔºàBackpackÔºâ„ÄÅÂ∏Ç‰ª∑Ê®°ÂºèÔºàLighterÔºâ\n- **‰ø°Âè∑Ê∫êÊîØÊåÅ**ÔºöBackpack REST API„ÄÅHyperliquid WebSocket\n- **Êô∫ËÉΩÂà§Êñ≠**Ôºö‰π∞ÂçñÂçïÊï∞ÈáèÂØπÊØî„ÄÅ‰ª∑Ê†ºÂèòÂä®ÁõëÊéß\n- **ÂÆûÊó∂ÁªüËÆ°**ÔºöÊàê‰∫§Èáè„ÄÅ",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-29T02:27:13.608237"
  },
  {
    "basic_info": {
      "name": "pg_lake",
      "full_name": "Snowflake-Labs/pg_lake",
      "owner": "Snowflake-Labs",
      "description": "pg_lake: Postgres with Iceberg and data lake access",
      "url": "https://github.com/Snowflake-Labs/pg_lake",
      "clone_url": "https://github.com/Snowflake-Labs/pg_lake.git",
      "ssh_url": "git@github.com:Snowflake-Labs/pg_lake.git",
      "homepage": "https://github.com/Snowflake-Labs/pg_lake/blob/main/docs/README.md",
      "created_at": "2025-11-04T10:38:17Z",
      "updated_at": "2025-11-28T14:02:05Z",
      "pushed_at": "2025-11-28T13:24:30Z"
    },
    "stats": {
      "stars": 1268,
      "forks": 56,
      "watchers": 1268,
      "open_issues": 36,
      "size": 4975
    },
    "tech_info": {
      "language": "C",
      "languages": {
        "C": 3081516,
        "Python": 2392795,
        "C++": 162969,
        "PLpgSQL": 44929,
        "Makefile": 32433,
        "Dockerfile": 11557,
        "Shell": 10371,
        "CMake": 2392,
        "Emacs Lisp": 730
      },
      "license": "Apache License 2.0",
      "topics": []
    },
    "content": {
      "readme": "# pg_lake: Postgres for Iceberg and Data lakes\n\n`pg_lake` integrates Iceberg and data lake files into Postgres. With the `pg_lake` extensions, you can use Postgres as a stand-alone lakehouse system that supports transactions and fast queries on Iceberg tables, and can directly work with raw data files in object stores like S3.\n\nAt a high level, `pg_lake` lets you:\n\n- **Create and modify [Iceberg](https://iceberg.apache.org/)** tables directly from PostgreSQL, with full transactional guarantees and query them from other engines\n- **Query and import data files in object storage** in [Parquet](https://parquet.apache.org/), CSV, JSON, and Iceberg format\n- **Export query results back to object storage** in Parquet, CSV, or JSON formats using COPY commands\n- **Read geospatial formats** supported by GDAL, such as GeoJSON and Shapefiles\n- **Use the built-in [map type](./pg_map/README.md)** for semi-structured or key‚Äìvalue data  \n- **Combine heap, Iceberg, and external Parquet/CSV/JSON** files in the same SQL queries and modifications ‚Äî all with full transactional guarantees and no SQL limitations  \n- **Infer table columns and types** from external data sources such as Iceberg, Parquet, JSON, and CSV files\n- **Leverage DuckDB‚Äôs query engine** underneath for fast execution without leaving Postgres  \n\n## Setting up `pg_lake`\n\nThere are two ways to set up `pg_lake`:  \n- **Using Docker**, for an easy, ready-to-run test environment.  \n- **Building from source**, for a manual setup or development use.  \n\nBoth approaches include the PostgreSQL extensions, the `pgduck_server` application and setting up S3-compatible storage.\n\n### Using Docker\n\nFollow the [Docker README](./docker/README.md) to set up and run `pg_lake` with Docker.\n\n\n### Building from source\n\nOnce you‚Äôve [built and installed the required components](./docs/building-from-source.md), you can initialize `pg_lake` inside Postgres.\n\n#### Creating the extensions\n\nCreate all required extensions at once using `CASCADE`:\n\n```sql\nCREATE EXTENSION pg_lake CASCADE;\nNOTICE:  installing required extension \"pg_lake_table\"\nNOTICE:  installing required extension \"pg_lake_engine\"\nNOTICE:  installing required extension \"pg_extension_base\"\nNOTICE:  installing required extension \"pg_lake_iceberg\"\nNOTICE:  installing required extension \"pg_lake_copy\"\nCREATE EXTENSION\n```\n\n#### Running `pgduck_server`\n\n`pgduck_server` is a standalone process that implements the Postgres wire-protocol (locally), and underneath uses `DuckDB` to execute queries.\n\nWhen you run `pgduck_server` it starts listening to port `5332` on unix domain socket:\n```\npgduck_server\nLOG pgduck_server is listening on unix_socket_directory: /tmp with port 5332, max_clients allowed 10000\n```\n\nAs `pgduck_server` implements Postgres wire protocol, you can access it via `psql` on port `5332` and host `/tmp` and run commands via DuckDB. \n\nFor example, you can get the DuckDB version:\n\n```sql\npsql -p 5332 -h /tmp\n\nselect version() as duckdb_version; \nduckdb_version \n---------------- \nv1.3.2 (1 row)\n```\n\nYou can also provide some additional settings while starting the server, to see all:\n```\npgduck_server --help\n```\n\nThere are some important settings that should be adjusted, especially on production systems:\n\n\n- `--memory_limit`: Optionally specify the maximum memory of pgduck_server similar to DuckDB's memory_limit, the default is 80 percent of the system memory\n- `--init_file_path <path>`: Execute all statements in this file on start-up\n- `--cache_dir`: Specify the directory to use to cache remote files (from S3)\n\nNote that if you want to make adjustments to duckdb settings, you can use the `--init_file_path` approach OR you can\nconnect to the running pgduck_server and make changes. For example:\n\n```\n$ psql -h /tmp -p 5332\npsql (17.5, server 16.4.DuckPG)\nType \"help\" for help.\n\npostgres=> set global threads = 16;\nSET\n```\n\nThe connection above is to the pgduck_server on its port (default 5332), NOT to the postgres/pg_lake server. \n\n\n#### Connecting `pg_lake` to s3 (or compatible)\n\n`pgduck_server` relies on the DuckDB [secrets manager](https://duckdb.org/docs/stable/configuration/secrets_manager) for credentials and it follows the credentials chain by default for AWS and GCP. Make sure your cloud credentials are configured properly ‚Äî for example, by setting them in ~/.aws/credentials.  \n\nOnce you set up the credential chain, you should set the `pg_lake_iceberg.default_location_prefix`. This is the location where Iceberg tables are stored:\n\n```sql\nSET pg_lake_iceberg.default_location_prefix TO 's3://testbucketpglake';\n```\n\nYou can also set the credentials on `pgduck_server` for [local development with `minio`](docs/building-from-source.md#running-s3-compatible-service-minio-locally).\n\n## Using pg_lake\n\n### Create an Iceberg table\n\nYou can create Iceberg tables by adding `USING iceberg` to your `CREATE TABLE` statements.\n\n```sql\nCREATE TABLE iceberg_test USING iceberg \n      AS SELECT \n            i as key, 'val_'|| i  as val\n    ",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-29T02:27:14.916585"
  }
]