## ğŸ“ çƒ­ç‚¹é¡¹ç›®-20251026-python

<div style="background-color: #f5f5f5; padding: 15px; border-radius: 8px; margin: 20px 0;">
- ğŸ¤– æœ¬æŠ¥å‘ŠåŸºäº GitHub API è‡ªåŠ¨ç”Ÿæˆ
- ğŸ“… æ•°æ®æ›´æ–°æ—¶é—´: 2025-10-26 10:28:24 (ä¸Šæµ·æ—¶åŒº)
- ğŸŒŸ æ˜Ÿæ ‡æ•°ç­‰ç»Ÿè®¡ä¿¡æ¯ä¸ºç”Ÿæˆæ—¶çš„å®æ—¶æ•°æ®
- ğŸ“š é¡¹ç›®ä¿¡æ¯æ¥æºäºå„é¡¹ç›®çš„ README æ–‡æ¡£
- ğŸ’¡ çƒ­åº¦æŒ‡æ•°è®¡ç®—æ–¹å¼: æ˜Ÿæ ‡æ•° + Forkæ•° Ã— 0.5
- æœ¬æŠ¥å‘Šç”± ä¸‰å­å¶å¼€æº github-trendingé¡¹ç›®åˆ†æå·¥å…·è‡ªåŠ¨ç”Ÿæˆ
</div>

## ğŸ”— ç›¸å…³é“¾æ¥

- [GitHub API æ–‡æ¡£](https://docs.github.com/en/rest)
- [é¡¹ç›®æ•°æ®è·å–å™¨æºç ](https://github.com/3ziye/github-trending)

---

# çƒ­ç‚¹é¡¹ç›®-20251026-python

<div align="center">
ğŸ“Š <strong>ç”Ÿæˆæ—¶é—´</strong>: 2025å¹´10æœˆ26æ—¥ 10:28  â€¢  
ğŸ¯ <strong>é¡¹ç›®æ•°é‡</strong>: 20 ä¸ª  â€¢  
â±ï¸ <strong>çƒ­åº¦æ—¶é—´</strong>: æœˆæ¦œ  â€¢  
ğŸ”¥ <strong>æ•°æ®æ¥æº</strong>: GitHub API
</div>

---

## ğŸš€ çƒ­é—¨é¡¹ç›®è¯¦æƒ…

### 1. nanochat

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 34,280

**é¡¹ç›®åç§°**: [karpathy/nanochat](https://github.com/karpathy/nanochat)
**é¡¹ç›®æè¿°**: The best ChatGPT that $100 can buy.
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: MIT License
**â­ æ˜Ÿæ ‡æ•°**: 32,505
**ğŸ´ Fork æ•°**: 3,551
**ğŸ‘€ å…³æ³¨æ•°**: 32,505
**ğŸ› å¼€æ”¾é—®é¢˜**: 95
**æœ€åæ›´æ–°**: 2025-10-26 (1åˆ†é’Ÿå‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20251026-python/1-nanochat-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: æ— 

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/karpathy/nanochat.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 2. DeepSeek-OCR

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 17,651

**é¡¹ç›®åç§°**: [deepseek-ai/DeepSeek-OCR](https://github.com/deepseek-ai/DeepSeek-OCR)
**é¡¹ç›®æè¿°**: Contexts Optical Compression
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: MIT License
**â­ æ˜Ÿæ ‡æ•°**: 17,116
**ğŸ´ Fork æ•°**: 1,071
**ğŸ‘€ å…³æ³¨æ•°**: 17,116
**ğŸ› å¼€æ”¾é—®é¢˜**: 131
**æœ€åæ›´æ–°**: 2025-10-26 (6åˆ†é’Ÿå‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20251026-python/2-DeepSeek-OCR-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: æ— 

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/deepseek-ai/DeepSeek-OCR.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
- [2025/10/23]ğŸš€ğŸš€ğŸš€ DeepSeek-OCR is now officially supported in upstream [vLLM](https://docs.vllm.ai/projects/recipes/en/latest/DeepSeek/DeepSeek-OCR.html#installing-vllm). Thanks to the [vLLM](https://github.com/vllm-project/vllm) team for their help.
- [2025/10/20]ğŸš€ğŸš€ğŸš€ We release DeepSeek-OCR, a model to investigate the role of vision encoders from an LLM-centric viewpoint.
- [Install](#install)
- [vLLM Inference](#vllm-inference)
- [Transformers Inference](#transformers-inference)
- download the vllm-0.8.5 [whl](https://github.com/vllm-project/vllm/releases/tag/v0.8.5)
- VLLM:

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 3. TinyRecursiveModels

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 5,510

**é¡¹ç›®åç§°**: [SamsungSAILMontreal/TinyRecursiveModels](https://github.com/SamsungSAILMontreal/TinyRecursiveModels)
**é¡¹ç›®æè¿°**: æš‚æ— æè¿°
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: MIT License
**â­ æ˜Ÿæ ‡æ•°**: 5,165
**ğŸ´ Fork æ•°**: 691
**ğŸ‘€ å…³æ³¨æ•°**: 5,165
**ğŸ› å¼€æ”¾é—®é¢˜**: 24
**æœ€åæ›´æ–°**: 2025-10-26 (3å°æ—¶å‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20251026-python/3-TinyRecursiveModels-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: æ— 

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/SamsungSAILMontreal/TinyRecursiveModels.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
- Python 3.10 (or similar)
- Cuda 12.6.0 (or similar)

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 4. neutts-air

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 3,837

**é¡¹ç›®åç§°**: [neuphonic/neutts-air](https://github.com/neuphonic/neutts-air)
**é¡¹ç›®æè¿°**: On-device TTS model by Neuphonic
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: Apache License 2.0
**â­ æ˜Ÿæ ‡æ•°**: 3,662
**ğŸ´ Fork æ•°**: 351
**ğŸ‘€ å…³æ³¨æ•°**: 3,662
**ğŸ› å¼€æ”¾é—®é¢˜**: 32
**æœ€åæ›´æ–°**: 2025-10-26 (23åˆ†é’Ÿå‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20251026-python/4-neutts-air-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: æ— 

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/neuphonic/neutts-air.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
- ğŸ—£Best-in-class realism for its size - produces natural, ultra-realistic voices that sound human
- ğŸ“±Optimised for on-device deployment - provided in GGML format, ready to run on phones, laptops, or even Raspberry Pis
- ğŸ‘«Instant voice cloning - create your own speaker with as little as 3 seconds of audio
- ğŸš„Simple LM + codec architecture built off a 0.5B backbone - the sweet spot between speed, size, and quality for real-world applications
**Supported Languages**: English
**Audio Codec**: [NeuCodec](https://huggingface.co/neuphonic/neucodec) - our 50hz neural audio codec that achieves exceptional audio quality at low bitrates using a single codebook
**Context Window**: 2048 tokens, enough for processing ~30 seconds of audio (including prompt duration)
**Format**: Available in GGML format for efficient on-device inference

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 5. bdh

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 3,293

**é¡¹ç›®åç§°**: [pathwaycom/bdh](https://github.com/pathwaycom/bdh)
**é¡¹ç›®æè¿°**: Baby Dragon Hatchling (BDH) â€“ Architecture and Code
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: MIT License
**â­ æ˜Ÿæ ‡æ•°**: 3,224
**ğŸ´ Fork æ•°**: 138
**ğŸ‘€ å…³æ³¨æ•°**: 3,224
**ğŸ› å¼€æ”¾é—®é¢˜**: 2
**æœ€åæ›´æ–°**: 2025-10-26 (4å°æ—¶å‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20251026-python/5-bdh-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: æ— 

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/pathwaycom/bdh.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
**Scale-free network topology** mimicking biological connectivity
**Locally interacting neuron particles** with excitatory/inhibitory dynamics
**Hebbian working memory** based on synaptic plasticity, displaying monosemanticity
**GPU-friendly state-space formulation** for efficient implementation
**Interpretable activations** that are sparse and positive
- Read a

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 6. HunyuanImage-3.0

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 2,345

**é¡¹ç›®åç§°**: [Tencent-Hunyuan/HunyuanImage-3.0](https://github.com/Tencent-Hunyuan/HunyuanImage-3.0)
**é¡¹ç›®æè¿°**: HunyuanImage-3.0: A Powerful Native Multimodal Model for Image Generation
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: Other
**â­ æ˜Ÿæ ‡æ•°**: 2,297
**ğŸ´ Fork æ•°**: 96
**ğŸ‘€ å…³æ³¨æ•°**: 2,297
**ğŸ› å¼€æ”¾é—®é¢˜**: 28
**æœ€åæ›´æ–°**: 2025-10-26 (4å°æ—¶å‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20251026-python/6-HunyuanImage-3.0-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: https://hunyuan.tencent.com/image

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/Tencent-Hunyuan/HunyuanImage-3.0.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ·ï¸ é¡¹ç›®æ ‡ç­¾
- `image-generation`
- `native-multimodal-model`

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
**September 28, 2025**: ğŸ“– **HunyuanImage-3.0 Technical Report Released** - Comprehensive technical documentation now available
**September 28, 2025**: ğŸš€ **HunyuanImage-3.0 Open Source Release** - Inference code and model weights publicly available
- HunyuanImage-3.0 (Image Generation Model)
- [ğŸ”¥ğŸ”¥ğŸ”¥ News](#-news)
- [ğŸ§© Community Contributions](#-community-contributions)
- [ğŸ“‘ Open-source Plan](#-open-source-plan)
- [ğŸ“– Introduction](#-introduction)
- [âœ¨ Key Features](#-key-features)

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 7. dexter

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 2,346

**é¡¹ç›®åç§°**: [virattt/dexter](https://github.com/virattt/dexter)
**é¡¹ç›®æè¿°**: An autonomous agent for deep financial research
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: None
**â­ æ˜Ÿæ ‡æ•°**: 2,218
**ğŸ´ Fork æ•°**: 257
**ğŸ‘€ å…³æ³¨æ•°**: 2,218
**ğŸ› å¼€æ”¾é—®é¢˜**: 8
**æœ€åæ›´æ–°**: 2025-10-26 (3åˆ†é’Ÿå‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20251026-python/7-dexter-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: æ— 

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/virattt/dexter.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
**Intelligent Task Planning**: Automatically decomposes complex queries into structured research steps
**Autonomous Execution**: Selects and executes the right tools to gather financial data
**Self-Validation**: Checks its own work and iterates until tasks are complete
**Real-Time Financial Data**: Access to income statements, balance sheets, and cash flow statements
**Safety Features**: Built-in loop detection and step limits to prevent runaway execution
- Python 3.10 or higher
- [uv](https://github.com/astral-sh/uv) package manager
- OpenAI API key (get [here](https://platform.openai.com/api-keys))

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 8. DreamOmni2

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 2,168

**é¡¹ç›®åç§°**: [dvlab-research/DreamOmni2](https://github.com/dvlab-research/DreamOmni2)
**é¡¹ç›®æè¿°**: This project is the official implementation of 'DreamOmni2: Multimodal Instruction-based Editing and Generation''
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: Apache License 2.0
**â­ æ˜Ÿæ ‡æ•°**: 2,076
**ğŸ´ Fork æ•°**: 184
**ğŸ‘€ å…³æ³¨æ•°**: 2,076
**ğŸ› å¼€æ”¾é—®é¢˜**: 19
**æœ€åæ›´æ–°**: 2025-10-26 (20åˆ†é’Ÿå‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20251026-python/8-DreamOmni2-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: æ— 

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/dvlab-research/DreamOmni2.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ·ï¸ é¡¹ç›®æ ‡ç­¾
- `image-editing`
- `image-generation`
- `unified-generation-editing-model`

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
- ğŸ”¥**2025.10.10**: Release DreamOmni2 [editing demo](https://huggingface.co/spaces/wcy1122/DreamOmni2-Edit) and [generation demo](https://huggingface.co/spaces/wcy1122/DreamOmni2-Gen)
- ğŸ”¥**2025.10.10**: Release DreamOmni2 [Benchmark](https://huggingface.co/datasets/xiabs/DreamOmni2Bench).
- ğŸ”¥**2025.10.10**: Release DreamOmni2's [codes](https://github.com/dvlab-research/DreamOmni2) and [models](https://huggingface.co/xiabs/DreamOmni2).
- ğŸ”¥**2025.10.09**: Release DreamOmni2 [tech report](https://arxiv.org/html/2510.06679v1).

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 9. agentic-design-patterns-cn

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 2,168

**é¡¹ç›®åç§°**: [ginobefun/agentic-design-patterns-cn](https://github.com/ginobefun/agentic-design-patterns-cn)
**é¡¹ç›®æè¿°**: ã€ŠAgentic Design Patternsã€‹ä¸­æ–‡ç¿»è¯‘ç‰ˆ
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: None
**â­ æ˜Ÿæ ‡æ•°**: 2,052
**ğŸ´ Fork æ•°**: 233
**ğŸ‘€ å…³æ³¨æ•°**: 2,052
**ğŸ› å¼€æ”¾é—®é¢˜**: 1
**æœ€åæ›´æ–°**: 2025-10-26 (37åˆ†é’Ÿå‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20251026-python/9-agentic-design-patterns-cn-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: æ— 

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/ginobefun/agentic-design-patterns-cn.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
- ğŸ“š **ä¸­è‹±æ–‡å¯¹ç…§** - å®Œæ•´çš„åŒè¯­å¯¹ç…§ç¿»è¯‘
- ğŸ¨ **é«˜äº®æ˜¾ç¤º** - ä¸­æ–‡å†…å®¹ä½¿ç”¨é»„è‰²é«˜äº®ï¼Œæ˜“äºåŒºåˆ†
- ğŸ“ **æ ¼å¼è§„èŒƒ** - ä¸¥æ ¼éµå¾ª Markdown æ ‡å‡†å’Œç¿»è¯‘è§„èŒƒ
- ğŸ”— **ä»£ç é“¾æ¥** - ä¿ç•™æ‰€æœ‰åŸä¹¦ä»£ç ç¤ºä¾‹é“¾æ¥
- âš¡ **æŒç»­æ›´æ–°** - é€ç« ç¿»è¯‘ï¼ŒæŒç»­æ›´æ–°è¿›åº¦

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 10. Skill_Seekers

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 1,905

**é¡¹ç›®åç§°**: [yusufkaraaslan/Skill_Seekers](https://github.com/yusufkaraaslan/Skill_Seekers)
**é¡¹ç›®æè¿°**: Single powerful tool to convert ANY documentation website into a Claude skill
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: MIT License
**â­ æ˜Ÿæ ‡æ•°**: 1,818
**ğŸ´ Fork æ•°**: 175
**ğŸ‘€ å…³æ³¨æ•°**: 1,818
**ğŸ› å¼€æ”¾é—®é¢˜**: 134
**æœ€åæ›´æ–°**: 2025-10-26 (5åˆ†é’Ÿå‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20251026-python/10-Skill_Seekers-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: æ— 

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/yusufkaraaslan/Skill_Seekers.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ·ï¸ é¡¹ç›®æ ‡ç­¾
- `ai-tools`
- `automation`
- `claude-ai`
- `claude-skills`
- `documentation`
- `documentation-generator`
- `mcp`
- `mcp-server`

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
- python3 cli/pdf_scraper.py --pdf docs/encrypted.pdf --name myskill --password

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 11. RAE

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 1,368

**é¡¹ç›®åç§°**: [bytetriper/RAE](https://github.com/bytetriper/RAE)
**é¡¹ç›®æè¿°**: Official PyTorch Implementation of "Diffusion Transformers with Representation Autoencoders"
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: MIT License
**â­ æ˜Ÿæ ‡æ•°**: 1,352
**ğŸ´ Fork æ•°**: 32
**ğŸ‘€ å…³æ³¨æ•°**: 1,352
**ğŸ› å¼€æ”¾é—®é¢˜**: 3
**æœ€åæ›´æ–°**: 2025-10-26 (1å°æ—¶å‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20251026-python/11-RAE-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: æ— 

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/bytetriper/RAE.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
- A PyTorch implementation of RAE and pretrained weights.
- A PyTorch implementation of LightningDiT, DiT<sup>DH</sup> and pretrained weights.
- Training and sampling scripts for the two-stage RAE+DiT pipeline.
- A TPU implementation of RAE and pretrained weights.
- Sampling of RAE and DiT<sup>DH</sup> on TPU.

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 12. Paper2Video

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 1,331

**é¡¹ç›®åç§°**: [showlab/Paper2Video](https://github.com/showlab/Paper2Video)
**é¡¹ç›®æè¿°**: Automatic Video Generation from Scientific Papers
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: MIT License
**â­ æ˜Ÿæ ‡æ•°**: 1,251
**ğŸ´ Fork æ•°**: 160
**ğŸ‘€ å…³æ³¨æ•°**: 1,251
**ğŸ› å¼€æ”¾é—®é¢˜**: 1
**æœ€åæ›´æ–°**: 2025-10-26 (8å°æ—¶å‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20251026-python/12-Paper2Video-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: https://showlab.github.io/Paper2Video/

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/showlab/Paper2Video.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
**Input:** a paper â• an image â• an audio
**Output:** a presentation video
- [x] [2025.10.15] We update a new version without talking-head for fast generation!
- [x] [2025.10.11] Our work receives attention on [YC Hacker News](https://news.ycombinator.com/item?id=45553701).
- [x] [2025.10.9] Thanks AK for sharing our work on [Twitter](https://x.com/_akhaliq/status/1976099830004072849)!
- [x] [2025.10.9] Our work is reported by [Medium](https://medium.com/@dataism/how-ai-learned-to-make-scientific-videos-from-slides-to-a-talking-head-0d807e491b27).
- [x] [2025.10.8] Check out our demo video below!
- [x] [2025.10.7] We release the [arxiv paper](https://arxiv.org/abs/2510.05096).

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 13. kimi-cli

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 1,117

**é¡¹ç›®åç§°**: [MoonshotAI/kimi-cli](https://github.com/MoonshotAI/kimi-cli)
**é¡¹ç›®æè¿°**: Kimi CLI is your next CLI agent.
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: Apache License 2.0
**â­ æ˜Ÿæ ‡æ•°**: 1,084
**ğŸ´ Fork æ•°**: 66
**ğŸ‘€ å…³æ³¨æ•°**: 1,084
**ğŸ› å¼€æ”¾é—®é¢˜**: 32
**æœ€åæ›´æ–°**: 2025-10-26 (1åˆ†é’Ÿå‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20251026-python/13-kimi-cli-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: æ— 

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/MoonshotAI/kimi-cli.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
- ### Shell mode
- Kimi CLI is not only a coding agent, but also a shell. You can switch the mode by pressing `Ctrl-K`. In shell mode, you can directly run shell commands without leaving Kimi CLI.
- > [!NOTE]
- > Built-in shell commands like `cd` are not supported yet.

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 14. DeepSeek-V3.2-Exp

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 955

**é¡¹ç›®åç§°**: [deepseek-ai/DeepSeek-V3.2-Exp](https://github.com/deepseek-ai/DeepSeek-V3.2-Exp)
**é¡¹ç›®æè¿°**: æš‚æ— æè¿°
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: MIT License
**â­ æ˜Ÿæ ‡æ•°**: 926
**ğŸ´ Fork æ•°**: 59
**ğŸ‘€ å…³æ³¨æ•°**: 926
**ğŸ› å¼€æ”¾é—®é¢˜**: 14
**æœ€åæ›´æ–°**: 2025-10-25 (17å°æ—¶å‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20251026-python/14-DeepSeek-V3.2-Exp-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: æ— 

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/deepseek-ai/DeepSeek-V3.2-Exp.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
- DeepSeek Sparse Attention (

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 15. AgentFlow

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 970

**é¡¹ç›®åç§°**: [lupantech/AgentFlow](https://github.com/lupantech/AgentFlow)
**é¡¹ç›®æè¿°**: AgentFlow: In-the-Flow Agentic System Optimization
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: MIT License
**â­ æ˜Ÿæ ‡æ•°**: 919
**ğŸ´ Fork æ•°**: 102
**ğŸ‘€ å…³æ³¨æ•°**: 919
**ğŸ› å¼€æ”¾é—®é¢˜**: 4
**æœ€åæ›´æ–°**: 2025-10-26 (17åˆ†é’Ÿå‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20251026-python/15-AgentFlow-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: https://agentflow.stanford.edu

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/lupantech/AgentFlow.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ·ï¸ é¡¹ç›®æ ‡ç­¾
- `agentic-ai`
- `agentic-systems`
- `llms`
- `llms-reasoning`
- `multi-agent-systems`
- `reinforcement-learning`
- `tool-augmented`

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
**[2025.10.16]** ğŸ† Our paper has been accepted by [**NeurIPS 2025 Efficient Reasoning Workshop**](https://efficient-reasoning.github.io/)!
**[2025.10.13]** ğŸ“¸ Excited to have a tutorial video for AgentFlow covered by Discover AI on **[YouTube](https://www.youtube.com/watch?v=kIQbCQIH1SI)**!
**[2025.10.10]** ğŸš€ Our X [post](https://x.com/lupantech/status/1976016000345919803) received **1K+ likes**! Feel free to check out the post and join the discussion! ğŸ’¬
**[2025.10.08]** ğŸ”¥ We are honored to be featured as ğŸ¤— HuggingFace **[Daily Paper #2](https://huggingface.co/papers/2510.05592)**.

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 16. DeepAnalyze

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 918

**é¡¹ç›®åç§°**: [ruc-datalab/DeepAnalyze](https://github.com/ruc-datalab/DeepAnalyze)
**é¡¹ç›®æè¿°**: DeepAnalyze is the first agentic LLM for autonomous data science.
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: MIT License
**â­ æ˜Ÿæ ‡æ•°**: 869
**ğŸ´ Fork æ•°**: 99
**ğŸ‘€ å…³æ³¨æ•°**: 869
**ğŸ› å¼€æ”¾é—®é¢˜**: 6
**æœ€åæ›´æ–°**: 2025-10-26 (2åˆ†é’Ÿå‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20251026-python/16-DeepAnalyze-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: æ— 

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/ruc-datalab/DeepAnalyze.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ·ï¸ é¡¹ç›®æ ‡ç­¾
- `agent`
- `agentic`
- `agentic-ai`
- `ai`
- `ai-scientist`
- `chatbot`
- `chatgpt`
- `data`

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
- ğŸ›  **Entire data science pipeline**: Automatically perform any data science tasks such as data preparation, analysis, modeling, visualization, and report generation.
- ğŸ” **O

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 17. MimicKit

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 839

**é¡¹ç›®åç§°**: [xbpeng/MimicKit](https://github.com/xbpeng/MimicKit)
**é¡¹ç›®æè¿°**: Suite of motion imitation methods for training motion controllers.
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: BSD 3-Clause "New" or "Revised" License
**â­ æ˜Ÿæ ‡æ•°**: 802
**ğŸ´ Fork æ•°**: 74
**ğŸ‘€ å…³æ³¨æ•°**: 802
**ğŸ› å¼€æ”¾é—®é¢˜**: 2
**æœ€åæ›´æ–°**: 2025-10-26 (3å°æ—¶å‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20251026-python/17-MimicKit-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: æ— 

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/xbpeng/MimicKit.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
- [DeepMimic](https://xbpeng.github.io/projects/DeepMimic/index.html)
- [AMP](https://xbpeng.github.io/projects/AMP/index.html)
- [ASE](https://xbpeng.github.io/projects/ASE/index.html)
- [ADD](https://xbpeng.github.io/projects/ADD/index.html)
- [PPO](https://arxiv.org/abs/1707.06347)
- [AWR](https://xbpeng.github.io/projects/AWR/index.html)
- `--mode` selects either `train` or `test` mode.
- `--num_envs` specifies the number of parallel environments used for simulation.

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 18. Code2Video

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 819

**é¡¹ç›®åç§°**: [showlab/Code2Video](https://github.com/showlab/Code2Video)
**é¡¹ç›®æè¿°**: Video generation via code
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: MIT License
**â­ æ˜Ÿæ ‡æ•°**: 770
**ğŸ´ Fork æ•°**: 98
**ğŸ‘€ å…³æ³¨æ•°**: 770
**ğŸ› å¼€æ”¾é—®é¢˜**: 0
**æœ€åæ›´æ–°**: 2025-10-26 (8å°æ—¶å‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20251026-python/18-Code2Video-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: https://showlab.github.io/Code2Video/

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/showlab/Code2Video.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ·ï¸ é¡¹ç›®æ ‡ç­¾
- `coding`
- `education`
- `multi-agent`
- `video-generation`

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 19. LuoGen-agent

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 781

**é¡¹ç›®åç§°**: [LuoGen-AI/LuoGen-agent](https://github.com/LuoGen-AI/LuoGen-agent)
**é¡¹ç›®æè¿°**: ä¸€é”®äº§å‡ºçˆ†æ¬¾è§†é¢‘ï¼š1.è‡ªåŠ¨æå–å¯¹æ ‡æ–‡æ¡ˆ 2.è‡ªåŠ¨è¿›è¡Œæ–‡æ¡ˆä»¿å†™ 3.è‡ªåŠ¨æ ¹æ®æ–‡æ¡ˆå£°éŸ³å…‹éš† 4.è‡ªåŠ¨ç”Ÿæˆæ•°å­—äººå£æ’­ 5.è‡ªåŠ¨æ·»åŠ å­—å¹• 6.è‡ªåŠ¨æ·»åŠ èƒŒæ™¯éŸ³ä¹ 7.è‡ªåŠ¨æ·»åŠ è§†é¢‘æ ‡é¢˜ 8.è‡ªåŠ¨ç”Ÿæˆè§†é¢‘å°é¢ 9.è‡ªåŠ¨å°†è§†é¢‘å‘å¸ƒåˆ°å„å¹³å°
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: GNU General Public License v3.0
**â­ æ˜Ÿæ ‡æ•°**: 743
**ğŸ´ Fork æ•°**: 76
**ğŸ‘€ å…³æ³¨æ•°**: 743
**ğŸ› å¼€æ”¾é—®é¢˜**: 5
**æœ€åæ›´æ–°**: 2025-10-26 (9å°æ—¶å‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20251026-python/19-LuoGen-agent-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: æ— 

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/LuoGen-AI/LuoGen-agent.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
- ç”±äºä»£ç ä½“ç§¯åŠæ¨¡å‹æ–‡ä»¶è¿‡å¤§ï¼Œè¯·è¯¸ä½ç§»æ­¥ [ä»£ç åœ°å€](ä»£ç åœ°å€.txt) è¿›è¡Œä¸‹è½½ã€‚
- ç”±äºè¯¥åº”ç”¨ä¸ºæœ¬åœ°è¿è¡Œçš„å®¢æˆ·ç«¯åº”ç”¨ï¼Œä¸ºäº†è¯¸ä½çš„ä½¿ç”¨ä½“éªŒï¼Œå…ˆè¿›è¡Œ [ä½¿ç”¨å‰å¿…è£…](ä½¿ç”¨å‰å¿…è£….txt) è¿›è¡Œä¸‹è½½å®‰è£…ã€‚
- ğŸ“ **æ™ºèƒ½æ–‡æ¡ˆå¤„ç†**ï¼šè‡ªåŠ¨æå–å¯¹æ ‡æ–‡æ¡ˆ + æ™ºèƒ½ä»¿å†™ä¼˜åŒ–
- ğŸ¤ **å£°éŸ³å…‹éš†**ï¼šåŸºäº Whisper å’Œ CosyVoice å®ç°é«˜ä¿çœŸè¯­éŸ³åˆæˆ
- ğŸ‘¥ **æ•°å­—äººç”Ÿæˆ**ï¼šé›†æˆ HeyGem å®ç°è‡ªç„¶å£æ’­æ•ˆæœ
- ğŸ¬ **å…¨æµç¨‹è§†é¢‘åˆ¶ä½œ**ï¼šå­—å¹•/BGM/æ ‡é¢˜/å°é¢è‡ªåŠ¨ç”Ÿæˆ + å¤šå¹³å°å‘å¸ƒ
- [social-auto-upload](https://github.com/...) - å¤šå¹³å°å‘å¸ƒæ¡†æ¶
- [CosyVoice](https://github.com/tencent-ailab/cosyvoice) - é«˜è´¨é‡è¯­éŸ³åˆæˆ

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 20. flareprox

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 667

**é¡¹ç›®åç§°**: [MrTurvey/flareprox](https://github.com/MrTurvey/flareprox)
**é¡¹ç›®æè¿°**: Use Cloudflare to create HTTP pass-through proxies for unique IP rotation, similar to fireprox
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: MIT License
**â­ æ˜Ÿæ ‡æ•°**: 640
**ğŸ´ Fork æ•°**: 55
**ğŸ‘€ å…³æ³¨æ•°**: 640
**ğŸ› å¼€æ”¾é—®é¢˜**: 3
**æœ€åæ›´æ–°**: 2025-10-26 (4å°æ—¶å‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20251026-python/20-flareprox-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: æ— 

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/MrTurvey/flareprox.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
- **HTTP Support**: All HTTP methods (GET, POST, PUT, DELETE, PATCH, OPTIONS, HEAD)
- **Simple URL Redirection**: Provide any URL and FlareProx redirects traffic through Cloudflare
- **Global Network**: Leverage Cloudflare's worldwide CDN infrastructure
- **Free Tier**: 100,000 requests per day on Cloudflare's free plan
- **Easy Deployment**: Single command deployment and management

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---