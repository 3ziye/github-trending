[
  {
    "basic_info": {
      "name": "EDR-Freeze",
      "full_name": "TwoSevenOneT/EDR-Freeze",
      "owner": "TwoSevenOneT",
      "description": "EDR-Freeze is a tool that puts a process of EDR, AntiMalware into a coma state.",
      "url": "https://github.com/TwoSevenOneT/EDR-Freeze",
      "clone_url": "https://github.com/TwoSevenOneT/EDR-Freeze.git",
      "ssh_url": "git@github.com:TwoSevenOneT/EDR-Freeze.git",
      "homepage": null,
      "created_at": "2025-09-21T01:21:06Z",
      "updated_at": "2025-10-11T13:15:07Z",
      "pushed_at": "2025-10-11T01:32:51Z"
    },
    "stats": {
      "stars": 638,
      "forks": 123,
      "watchers": 638,
      "open_issues": 2,
      "size": 30
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 19030
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "### EDR-Freeze\n\nThis is a tool that exploits the software vulnerability of WerFaultSecure to suspend the processes of EDRs and antimalware without needing to use the BYOVD (Bring Your Own Vulnerable Driver) attack method.\n\nEDR-Freeze operates in user mode, so you don't need to install any additional drivers. It can run on the latest version of Windows.\n\n*The experiment was conducted with the latest version of Windows at the time of the project creation: __Windows 11 24H2__*\n\n### Command Line Syntax\n\n**EDR-Freeze.exe [TargetPID] [SleepTime]**\n\n*Example: __EDR-Freeze.exe 1234 10000__*\n\n*Freeze the target for 10000 milliseconds*\n\n## Links\n\n[EDR-Freeze: A Tool That Puts EDRs And Antivirus Into A Coma State](https://www.zerosalarium.com/2025/09/EDR-Freeze-Puts-EDRs-Antivirus-Into-Coma.html)\n\n[Tool to run process with PPL without driver](https://github.com/TwoSevenOneT/CreateProcessAsPPL)\n\n## How to Use EDR-Freeze Effectively\n\nInstead of running EDR-Freeze with a long sleep duration, you should incorporate it into a script with the following steps:\n\n1. Temporarily halt all Antimalware/EDR processes for a short period (1-3 seconds).\n2. Execute tasks immediately after a successful suspension.\n\nSince the GUI may become unresponsive in some cases, you should choose the shortest sleep time possible. Just make sure that the script executions are completed before the Antimalware/EDR resumes.\n\nAlternatively, it's best to insert the code you want to execute directly into the source code of EDR-Freeze:\n\n<img width=\"748\" height=\"387\" alt=\"Insert code\" src=\"https://github.com/user-attachments/assets/1c6f8819-5a21-4cc4-b72f-ea00be0fd092\" />\n\n\n## Author:\n\n[Two Seven One Three](https://x.com/TwoSevenOneT)\n",
      "default_branch": "master"
    },
    "fetched_at": "2025-10-13T02:26:38.723568"
  },
  {
    "basic_info": {
      "name": "WSASS",
      "full_name": "TwoSevenOneT/WSASS",
      "owner": "TwoSevenOneT",
      "description": "This is the tool to dump the LSASS process on modern Windows 11",
      "url": "https://github.com/TwoSevenOneT/WSASS",
      "clone_url": "https://github.com/TwoSevenOneT/WSASS.git",
      "ssh_url": "git@github.com:TwoSevenOneT/WSASS.git",
      "homepage": null,
      "created_at": "2025-09-13T03:18:26Z",
      "updated_at": "2025-10-12T18:29:55Z",
      "pushed_at": "2025-09-15T13:40:45Z"
    },
    "stats": {
      "stars": 438,
      "forks": 52,
      "watchers": 438,
      "open_issues": 1,
      "size": 39
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 15722
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "### WSASS\n\nThis is a tool that uses the old WerfaultSecure.exe program to dump the memory of processes protected by PPL (Protected Process Light), such as LSASS.EXE.\nThe output is in Windows MINIDUMP format.\n\n*This tool automatically replaces the __\"MDMP\"__ magic header with a PNG magic header.\nAfter the dump is complete, you need to restore the original 4-byte magic at the beginning of the file with the original 4 bytes: __{0x4D, 0x44, 0x4D, 0x50}__ \"MDMP\".*\n\n### Command Line Syntax\n\n**WSASS.exe path_to_werfaultsecure.exe target_PID**\n\n*Example: __WSASS.exe C:\\TMP\\WerfaultSecure.exe 888__*\n\n## Links\n\n[Using WSASS to dump LSASS](https://www.zerosalarium.com/2025/09/Dumping-LSASS-With-WER-On-Modern-Windows-11.html)\n\n[Tool to run process with PPL without driver](https://github.com/TwoSevenOneT/CreateProcessAsPPL)\n\n## Author:\n\n[Two Seven One Three](https://x.com/TwoSevenOneT)\n",
      "default_branch": "master"
    },
    "fetched_at": "2025-10-13T02:26:39.872120"
  },
  {
    "basic_info": {
      "name": "dsa-code",
      "full_name": "ghostmkg/dsa-code",
      "owner": "ghostmkg",
      "description": null,
      "url": "https://github.com/ghostmkg/dsa-code",
      "clone_url": "https://github.com/ghostmkg/dsa-code.git",
      "ssh_url": "git@github.com:ghostmkg/dsa-code.git",
      "homepage": "",
      "created_at": "2025-09-30T03:02:13Z",
      "updated_at": "2025-10-12T20:56:04Z",
      "pushed_at": "2025-10-12T05:01:30Z"
    },
    "stats": {
      "stars": 263,
      "forks": 655,
      "watchers": 263,
      "open_issues": 31,
      "size": 2538
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 553799,
        "Java": 404523,
        "Python": 221995,
        "HTML": 121761,
        "C": 62352,
        "Go": 37476,
        "JavaScript": 35639,
        "Rust": 32427,
        "Ruby": 22358,
        "Kotlin": 19650,
        "TypeScript": 13638,
        "PHP": 10218,
        "Swift": 1102
      },
      "license": "MIT License",
      "topics": [
        "hacktoberfest",
        "hacktoberfest-accepted",
        "hacktoberfest2025"
      ]
    },
    "content": {
      "readme": "# 📘 DSA-Code\n\nWelcome to **DSA-Code** 🎉\nThis repository is a collection of **Data Structures and Algorithms (DSA)** solutions implemented in multiple programming languages.\nThe goal of this repo is to help learners and contributors **explore, practice, and improve** their problem-solving skills in DSA.\n\nWelcome to **DSA-Code** 🎉  \nA community-driven repository of **Data Structures and Algorithms (DSA)** solutions implemented in multiple programming languages.  \nThe goal of this project is to help learners and contributors **explore, practice, and enhance** their problem-solving skills in DSA.  \n\n## 🚀 Features\n\n* 💻 Solutions in multiple programming languages (C, C++, Python, Java, JavaScript, etc.)\n* 🧩 Beginner-friendly problem statements and structured solutions\n* 🌍 Open-source project — everyone is welcome to contribute\n* 💪 Perfect for **Hacktoberfest**, **coding practice**, and **interview preparation**\n* 📂 Each folder contains DSA problems and solutions in the respective programming language\n\n## 🚀 Features  \n- 💡 Solutions in multiple languages — *C, C++, Python, Java, JavaScript,* and more.  \n- 🧑‍💻 Beginner-friendly problem statements with clear, structured solutions.  \n- 🗺️ **Comprehensive DSA Roadmap** to guide your journey.  \n- 🌍 Open-source project — perfect for **Hacktoberfest**, coding practice, and interviews.  \n- 🧩 Each folder contains DSA problems and solutions for the respective programming language.  \n\n---\n\n## 🤝 How to Contribute\n\n---\n\n### 1️⃣ Fork the Repository  \nClick the **Fork** button (top-right) to create your own copy.  \n\n```bash\ngit clone https://github.com/<your-username>/dsa-code.git\ncd dsa-code\n```\n\n### 3️⃣ Create a branch\n\n```bash\ngit checkout -b feature-branch-name\n4️⃣ Add Your Code\n\nNavigate to the correct folder (e.g., Python/, Java/, etc.)\n\nAdd your DSA problem solution file.\n\n### 5️⃣ Commit and push changes\n\n```bash\n\nEnsure proper file naming and comments for clarity.\n5️⃣ Commit and Push Changes\n\ngit add .\ngit commit -m \"Added solution for <problem-name> in <language>\"\ngit push origin feature-branch-name\n6️⃣ Create a Pull Request\n\nGo to the Pull Requests tab on the original repo.\n\nClick on New Pull Request.\n\n### 6️⃣ Raise a Pull Request (PR)\n\nSubmit and wait for review 🚀\n📝 Contribution Guidelines\n\n✅ Write clean, readable, and well-commented code.\n✅ Add only DSA-related problems and solutions.\n✅ Maintain folder structure and avoid duplicates.\n🚫 Do not copy-paste code without proper reference or attribution.\n📢 Join Our Community\n\nBe a part of our growing community 🌱 — learn, code, and grow together!\n\n💬 Join on Discord\n\n📢 Join on Telegram\n\n💼 Follow on LinkedIn\n\n💬 Join our WhatsApp Community\n\n📺 Subscribe on YouTube\n\n🐦 Follow on Twitter\n\n📸 Follow on Instagram\n☕ Support the Project\n\nIf you love this project and want to support future development, consider buying us a coffee:\n\n<a href=\"https://www.buymeacoffee.com/mgoshwami1c\"> <img src=\"https://cdn.buymeacoffee.com/buttons/v2/default-yellow.png\" height=\"50\" width=\"210\" alt=\"Buy Me A Coffee\"> </a>\n🏷️ GitHub Badges\n---\n\n## 🏷️ GitHub Badges  \n\n![GitHub Repo stars](https://img.shields.io/github/stars/ghostmkg/dsa-code?style=for-the-badge)  \n![GitHub forks](https://img.shields.io/github/forks/ghostmkg/dsa-code?style=for-the-badge)  \n![GitHub issues](https://img.shields.io/github/issues/ghostmkg/dsa-code?style=for-the-badge)  \n![GitHub pull requests](https://img.shields.io/github/issues-pr/ghostmkg/dsa-code?style=for-the-badge)  \n![GitHub license](https://img.shields.io/github/license/ghostmkg/dsa-code?style=for-the-badge)  \n![Contributions Welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=for-the-badge)  \n\n---\n\n**Happy Coding! 🚀**\n\n\n\nHappy Coding! 🚀\n\n---\n\n### 🔚 Last Step:\n1. Jab ye content paste kar lo, to niche **\"Mark as resolved\"** button pe click karo.  \n2. Phir “**Commit merge**” pe click karo.  \n\nBas ho gaya 🎉  \nAb tera PR **conflict-free** ho gaya hai aur Hacktoberfest ke liye **valid contribution** count ho jayega ✅  \n\n---\n\nChahe to tu mujhe ek screenshot bhej de editor ka (jab paste kar lega) — main confirm kar dunga ki sab perfect hai aur merge safe hai 👌\n\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-13T02:26:41.020237"
  },
  {
    "basic_info": {
      "name": "lidar_odometry",
      "full_name": "93won/lidar_odometry",
      "owner": "93won",
      "description": "Probabilistic Kernel Optimization for Robust State Estimation",
      "url": "https://github.com/93won/lidar_odometry",
      "clone_url": "https://github.com/93won/lidar_odometry.git",
      "ssh_url": "git@github.com:93won/lidar_odometry.git",
      "homepage": "",
      "created_at": "2025-09-26T07:36:39Z",
      "updated_at": "2025-10-12T22:59:35Z",
      "pushed_at": "2025-10-12T05:05:30Z"
    },
    "stats": {
      "stars": 255,
      "forks": 42,
      "watchers": 255,
      "open_issues": 0,
      "size": 5985
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 363455,
        "CMake": 4920,
        "Shell": 3014
      },
      "license": null,
      "topics": [
        "lidar",
        "odometry",
        "slam"
      ]
    },
    "content": {
      "readme": "# LiDAR Odometry with Probabilistic Kernel Optimization (PKO)\n\nThis is a real-time LiDAR odometry system designed for SLAM applications. It utilizes feature extraction from point clouds, iterative closest point (ICP) registration, sliding window optimization with Ceres Solver, and Pangolin for 3D visualization.\n\nThe system incorporates **Probabilistic Kernel Optimization (PKO)** for robust state estimation, as described in:\n\n> S. Choi and T.-W. Kim, \"Probabilistic Kernel Optimization for Robust State Estimation,\" *IEEE Robotics and Automation Letters*, vol. 10, no. 3, pp. 2998-3005, 2025, doi: 10.1109/LRA.2025.3536294.\n> \n> **Paper**: [https://ieeexplore.ieee.org/document/10857458](https://ieeexplore.ieee.org/document/10857458)\n\nROS Wrapper: https://github.com/93won/lidar_odometry_ros_wrapper\n\n\n## Features\n\n- ⚡ Real-time LiDAR odometry processing\n- 🎯 Feature-based point cloud registration  \n- 🔧 Ceres Solver-based optimization\n- 📈 Adaptive M-estimator for robust estimation (PKO)\n- 🚗 Support for KITTI dataset (outdoor/vehicle scenarios)\n- 🏠 Support for MID360 LiDAR (indoor/handheld scenarios)\n\n## Demo\n\n[![LiDAR Odometry Demo](https://img.youtube.com/vi/FANz9mhIAQQ/0.jpg)](https://www.youtube.com/watch?v=FANz9mhIAQQ)\n\n*Click to watch the demo video showing real-time LiDAR odometry on KITTI dataset*\n\n## Quick Start\n\n### 1. Build Options\n\n#### Native Build (Ubuntu 22.04)\n```bash\ngit clone https://github.com/93won/lidar_odometry\ncd lidar_odometry\nchmod +x build.sh\n./build.sh\n```\n\n### 2. Download Sample Data\n\nChoose one of the sample datasets:\n\n#### Option A: KITTI Dataset (Outdoor/Vehicle)\nDownload the sample KITTI sequence 07 from [Google Drive](https://drive.google.com/drive/folders/13YL4H9EIfL8oq1bVp0Csm0B7cMF3wT_0?usp=sharing) and extract to `data/kitti/`\n\n#### Option B: MID360 Dataset (Indoor/Handheld)\nDownload the sample MID360 dataset from [Google Drive](https://drive.google.com/file/d/1psjoqrX9CtMvNCUskczUlsmaysh823CO/view?usp=sharing) and extract to `data/MID360/`\n\n*MID360 dataset source: https://www.youtube.com/watch?v=u8siB0KLFLc*\n\n### 3. Update Configuration\n\nChoose the appropriate configuration file for your dataset:\n\n#### For KITTI Dataset\nEdit `config/kitti.yaml` to set your dataset paths:\n```yaml\n# Data paths - Update these paths to your dataset location\ndata_directory: \"/path/to/your/kitti_dataset/sequences\"\nground_truth_directory: \"/path/to/your/kitti_dataset/poses\"  \noutput_directory: \"/path/to/your/output/directory\"\nseq: \"07\"  # Change this to your sequence number\n```\n\n#### For MID360 Dataset  \nEdit `config/mid360.yaml` to set your dataset paths:\n```yaml\n# Data paths - Update these paths to your dataset location\ndata_directory: \"/path/to/your/MID360_dataset\"\noutput_directory: \"/path/to/your/output/directory\"\nseq: \"slam\"  # Subdirectory name containing PLY files\n```\n\n### 4. Run LiDAR Odometry\n\nChoose the appropriate executable for your dataset:\n\n#### For KITTI Dataset (Outdoor/Vehicle)\n```bash\ncd build\n./kitti_lidar_odometry ../config/kitti.yaml\n```\n\n#### For MID360 Dataset (Indoor/Handheld)\n```bash\ncd build\n./mid360_lidar_odometry ../config/mid360.yaml\n```\n\n## Full KITTI Dataset\n\nFor complete evaluation, download the full KITTI dataset from:\n- **Official Website**: [http://www.cvlibs.net/datasets/kitti/](http://www.cvlibs.net/datasets/kitti/)\n- **Odometry Dataset**: [http://www.cvlibs.net/datasets/kitti/eval_odometry.php](http://www.cvlibs.net/datasets/kitti/eval_odometry.php)\n\n## Project Structure\n\n- `app/`: Main applications and dataset players\n  - `kitti_lidar_odometry.cpp`: KITTI dataset application  \n  - `mid360_lidar_odometry.cpp`: MID360 dataset application\n  - `player/`: Dataset-specific player implementations\n- `src/`: Core modules (database, processing, optimization, viewer, util)\n- `thirdparty/`: External libraries (Ceres, Pangolin, Sophus, spdlog)\n- `config/`: Configuration files for different datasets\n- `build.sh`: Build script for native compilation\n\n## System Requirements\n\n- **Ubuntu 20.04/22.04** (recommended)\n- **C++17 Compiler** (g++ or clang++)\n- **CMake** (>= 3.16)\n\n## License\n\nThis project is released under the MIT License.\n\n## References\n\n```bibtex\n@ARTICLE{10857458,\n  author={Choi, Seungwon and Kim, Tae-Wan},\n  journal={IEEE Robotics and Automation Letters}, \n  title={Probabilistic Kernel Optimization for Robust State Estimation}, \n  year={2025},\n  volume={10},\n  number={3},\n  pages={2998-3005},\n  keywords={Kernel;Optimization;State estimation;Probabilistic logic;Tuning;Robustness;Cost function;Point cloud compression;Oceans;Histograms;Robust state estimation;SLAM},\n  doi={10.1109/LRA.2025.3536294}\n}\n```\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-13T02:26:42.142329"
  },
  {
    "basic_info": {
      "name": "WSL-For-FreeBSD",
      "full_name": "BalajeS/WSL-For-FreeBSD",
      "owner": "BalajeS",
      "description": "Experimental project to adapt the WSL2 open-source components to run on FreeBSD",
      "url": "https://github.com/BalajeS/WSL-For-FreeBSD",
      "clone_url": "https://github.com/BalajeS/WSL-For-FreeBSD.git",
      "ssh_url": "git@github.com:BalajeS/WSL-For-FreeBSD.git",
      "homepage": null,
      "created_at": "2025-09-20T18:58:21Z",
      "updated_at": "2025-10-13T02:08:47Z",
      "pushed_at": "2025-09-24T15:12:02Z"
    },
    "stats": {
      "stars": 252,
      "forks": 2,
      "watchers": 252,
      "open_issues": 1,
      "size": 27349
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 3797153,
        "C": 2420655,
        "C#": 125464,
        "CMake": 66173,
        "Python": 49585,
        "PowerShell": 45272,
        "Perl": 6143,
        "Shell": 4453,
        "Makefile": 1476,
        "Batchfile": 794
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# Welcome to the Windows Subsystem for FreeBSD (WSFB)\n\n⚡ **Experimental Project – Running FreeBSD on WSL2** ⚡  \n\nThis repository hosts work-in-progress efforts to run **FreeBSD** inside **Windows Subsystem for Linux (WSL2)** with minimal to no changes to the FreeBSD base system. The project builds on the open-source components of WSL2 to enable FreeBSD to boot and run seamlessly in a Windows environment.\n\n---\n\n## Project Goals\n\n- Enable FreeBSD to run natively on WSL2’s architecture  \n- Make minimal or no modifications to the FreeBSD base system  \n- Contribute improvements back to open-source components where possible  \n\n---\n\n## Current Status\n\n🚧 **Work in Progress** – This is an experimental personal project.  \n\n- FreeBSD boots successfully inside WSL2  \n- Basic functionality is up and running  \n- Ongoing work focuses on networking, I/O, and process management  \n\n---\n\n## Roadmap (High-Level)\n\n- [x] Initial boot support (done experimentally) \n- [x] Full Console Support executing Commands\n- [ ] Networking support (in progress)  \n- [ ] User-mode utilities and integration  \n- [ ] Documentation and examples  \n\n---\n\n## Contributing\n\nAt this stage, contributions are welcome in the form of:\n\n- Feedback or testing results  \n- Bug reports  \n- Discussions and ideas  \n\nPlease open an issue or start a discussion to get involved.  \n\n---\n\n## License\n\nThis project is released under an open-source license (TBD).  \n\n---\n\n### Disclaimer  \n\nThis is a **personal, experimental project** and is **not affiliated** with Microsoft, the FreeBSD Foundation, or the FreeBSD Project. Use at your own risk.\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-13T02:26:43.257412"
  },
  {
    "basic_info": {
      "name": "SetupHijack",
      "full_name": "hackerhouse-opensource/SetupHijack",
      "owner": "hackerhouse-opensource",
      "description": "SetupHijack is a security research tool that exploits race conditions and insecure file handling in Windows applications installer and update processes.",
      "url": "https://github.com/hackerhouse-opensource/SetupHijack",
      "clone_url": "https://github.com/hackerhouse-opensource/SetupHijack.git",
      "ssh_url": "git@github.com:hackerhouse-opensource/SetupHijack.git",
      "homepage": null,
      "created_at": "2025-09-24T20:45:10Z",
      "updated_at": "2025-10-12T22:59:47Z",
      "pushed_at": "2025-09-29T21:47:31Z"
    },
    "stats": {
      "stars": 241,
      "forks": 26,
      "watchers": 241,
      "open_issues": 0,
      "size": 1428
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 16195,
        "Makefile": 2374,
        "Batchfile": 1635
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# SetupHijack\n\n---\n\n## Overview\n\n**SetupHijack** is a security research tool that exploits race conditions and insecure file handling in Windows installer and update processes. It targets scenarios where privileged installers or updaters drop files in `%TEMP%` or other world-writable locations, allowing an attacker to replace these files before they are executed with elevated privileges.\n\n- Does **not** require elevated permissions to run.\n- Does **not** use file system notifications (polls for changes instead).\n- Exploits weaknesses in Authenticode code signing and installer trust models.\n- Can infect `.exe`, `.msi`, and batch files (e.g., `sysinfo`, `netstat`, `ipconfig`).\n- Designed for red team, penetration testing, and security research use only.\n\nThe intended use of this tool is to run in the background on a compromised user account with privileges, in order to elevate another process by hijacking installer/updater file drops. \n\nThe chart below shows real-world example use cases of this exploit in multiple scenarios that can be used for UAC bypass. UAC bypasses are considered a security boundary when running under Adminless and are a common \"attacker requirement\" for disabling security controls. Exploitation of privileged Administrator operations provides generic exploit accessibility for malicious code to side-load or escalate process privileges. This tool can be used to identify additional applications which are exposed to the same types of risk, an attacker can wait for execution of these processes as a means to gain elevated rights without disrupting user behaviors. \n\n![SetupHijack Vulnerability Discovery Chart](Chart.png)\n\n## How It Works\n\n1. **SetupHijack** continuously scans `%TEMP%` (and subdirectories) for new or modified installer files.\n2. When a target file is detected, it is replaced with a user-supplied payload (EXE, MSI, or BAT), optionally preserving the original as a `.bak` file.\n3. If the privileged process executes the replaced file before integrity checks, the payload runs with elevated rights (e.g., SYSTEM or Administrator).\n4. The tool logs all actions and maintains a skiplist to avoid re-infecting the same files.\n\n## Code Signing Note\n\nThis project uses a hacked code-signing process with [SignToolEx.exe and SignToolExHook.dll](https://github.com/hackerhouse-opensource/SignToolEx) to sign payloads and installers. Using valid code-signing certificates and an Authenticode timestamp will increase your success rate when bypassing installer and OS trust checks.\n\n---\n\n## Usage\n\n### Build\n\n```sh\nnmake PAYLOAD=c:\\Path\\to\\your\\payload.exe\n```\n\n### Run (Options)\n\n```sh\nSetupHijack.exe                  # Scan %TEMP%, %APPDATA%, and %USERPROFILE%\\Downloads (default)\nSetupHijack.exe -notemp          # Disable scanning %TEMP%\nSetupHijack.exe -noappdata       # Disable scanning %APPDATA%\nSetupHijack.exe -nodownloads     # Disable scanning %USERPROFILE%\\Downloads\nSetupHijack.exe clean            # Clean mode (restores .bak backups in all enabled locations)\nSetupHijack.exe verbose          # Verbose mode (log all actions)\nSetupHijack.exe <payload.exe>    # Use specified payload for .exe (unless argument is a recognized option)\n```\n\n- Run **SetupHijack.exe** before or during a privileged install/update process.\n- By default, the tool scans all common drop locations: %TEMP%, %APPDATA%, and %USERPROFILE%\\Downloads.\n- You can disable any location with the `-notemp`, `-noappdata`, or `-nodownloads` flags.\n- The `clean` flag restores backups in all enabled locations. The `verbose` flag logs all actions.\n- For remote escalation, use with `shadow.exe` or similar tools on Terminal Services.\n\n## Example Attack Flow\n\n1. Build your payload and SetupHijack:\n   ```sh\n   nmake PAYLOAD=c:\\Users\\YourUser\\Desktop\\payload.exe\n   ```\n2. Start SetupHijack:\n   ```sh\n   SetupHijack.exe\n   ```\n3. Launch the target installer or update process as Administrator.\n4. If the installer drops files in `%TEMP%` and executes them with elevated rights, your payload will be substituted and run.\n\n## Example Output\n\nBelow is a real example of building and running SetupHijack, including code signing and infection output:\n\n```\nC:\\Users\\Fantastic\\Desktop\\Sayuri\\InfectElevatedSetups>nmake PAYLOAD=\"C:\\USers\\Fantastic\\Desktop\\DEMO\\Renge_x64.exe\"\n\nMicrosoft (R) Program Maintenance Utility Version 14.29.30159.0\nCopyright (C) Microsoft Corporation.  All rights reserved.\n\n        powershell -Command \"(Get-Content SetupHijack.cpp) -replace '#define PAYLOAD_PATH L\\\".*\\\"', '#define PAYLOAD_PATH L\\\"%ESCAPED_PAYLOAD%\\\"' | Set-Content SetupHijack.cpp\"\n        cl /nologo /W4 /EHsc /DUNICODE /D_UNICODE /MT /O2 /c SetupHijack.cpp\nSetupHijack.cpp\nSetupHijack.cpp(318): warning C4189: 'hr2': local variable is initialized but not referenced\n        taskkill /f /im SetupHijack.exe 2>nul\n        powershell -Command \"Start-Sleep -Milliseconds 500\"\n        link /nologo /SUBSYSTEM:CONSOLE /ENTRY:wmainCRTStartup /NODEFAULTLIB:MSVCRT /NODEFAULTLIB:MSVCPRT /OUT:Se",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-13T02:26:44.403854"
  },
  {
    "basic_info": {
      "name": "sonshell",
      "full_name": "goudvuur/sonshell",
      "owner": "goudvuur",
      "description": "An effort to \"ssh into my Sony camera\"",
      "url": "https://github.com/goudvuur/sonshell",
      "clone_url": "https://github.com/goudvuur/sonshell.git",
      "ssh_url": "git@github.com:goudvuur/sonshell.git",
      "homepage": "http://www.goudvuur.be",
      "created_at": "2025-09-24T13:13:40Z",
      "updated_at": "2025-10-09T09:15:33Z",
      "pushed_at": "2025-10-03T09:04:11Z"
    },
    "stats": {
      "stars": 213,
      "forks": 5,
      "watchers": 213,
      "open_issues": 0,
      "size": 166
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 145891,
        "Shell": 11452,
        "Python": 7981,
        "CMake": 3616
      },
      "license": "Apache License 2.0",
      "topics": []
    },
    "content": {
      "readme": "# SonShell - an effort to \"ssh into my Sony camera\"\n\nA Linux-only helper built on Sony’s official **Camera Remote SDK**. It connects to a Sony A6700 (and other supported bodies) over Wi-Fi or Ethernet, mirrors new captures straight to your workstation, and drops you into an interactive shell for remote control.\n\nThe shell can download files automatically, trigger the shutter, tweak exposure settings, start live view, run post-download hooks, and keep retrying if the camera drops offline. Everything runs from a single terminal window.\n\n---\n\n## Demo\n\nhttps://github.com/user-attachments/assets/6146ff3b-d51c-412b-8684-bdde5c418d4d\n\n---\n\n## Quick Start\n\n### Requirements\n- Linux (developed on Ubuntu 24.04) with a C++17 toolchain (`gcc`, `g++`, `cmake`, `make`).\n- Sony Camera Remote SDK v2.00.00 (download it from Sony and extract it somewhere convenient).\n- Python 3 for the small header-generation scripts.\n- Runtime deps: libedit, ncurses, libudev, libxml2, OpenCV 4.8 (bundled inside Sony’s SDK).\n\nOn Ubuntu/Debian you can grab the basics with:\n```bash\nsudo apt install autoconf libtool libudev-dev gcc g++ make cmake unzip libxml2-dev libedit-dev python3\n```\n\n### Build in a hurry\n1. Download and extract the Sony Camera Remote SDK v2.00.00, then point `SONY_SDK_DIR` at the folder that contains `app/` (example path shown below):\n   ```bash\n   export SONY_SDK_DIR=\"$HOME/SonySDK/CrSDK_v2.00.00_20250805a_Linux64PC\"\n   ```\n2. Configure CMake and prepare the generated-header folder:\n   ```bash\n   cmake -S . -B build -DSONY_SDK_DIR=\"$SONY_SDK_DIR\"\n   cmake -E make_directory build/gen\n   ```\n3. Generate the lookup tables that pretty-print SDK enums:\n   ```bash\n   python3 tools/gen_prop_names.py --header \"${SONY_SDK_DIR}/app/CRSDK/CrDeviceProperty.h\" -o build/gen/prop_names_generated.h\n   python3 tools/gen_error_names.py --header \"${SONY_SDK_DIR}/app/CRSDK/CrError.h\" -o build/gen/error_names_generated.h\n   ```\n4. Compile and copy the required Sony/OpenCV shared libraries next to the binary:\n   ```bash\n   cmake --build build --config Release\n   ```\n5. Run it (start with enumeration and let SonShell pick the download folder):\n   ```bash\n   ./build/sonshell --dir \"$PWD/photos\" --keepalive 3000\n   ```\n\nThe build copies `libCr_*`, the adapter modules, and Sony’s OpenCV libs into `build/`. Run the binary from inside `build/` (or keep the copied `.so` files alongside it) so live view keeps working.\n\n---\n\n## Command-Line Options\n\n| Option | Description |\n| --- | --- |\n| `--dir <path>` | Directory where downloads are stored. If omitted, files land in the working directory; providing an explicit folder is strongly recommended for sync features. |\n| `--ip <addr>` | Connect directly to a camera at the given IPv4 address (e.g. `192.168.1.1`). Skipped when enumerating automatically. |\n| `--mac <hex:mac>` | Optional MAC address for direct-IP connects (`aa:bb:cc:dd:ee:ff`). Used to seed the SDK’s Ethernet object. |\n| `--user <name>` | Username for cameras with Access Auth enabled. |\n| `--pass <password>` | Password for Access Auth. Combine with `--user`. |\n| `--cmd <path>` | Executable/script that SonShell calls for every file event (new downloads, syncs, rating changes, …). Arguments: `<path> <mode> <operation> [old] [new]`. Runs asynchronously; SonShell does not wait for completion. |\n| `--keepalive <ms>` | Reconnection delay after failure or disconnect. `0` disables retry (SonShell exits on error). |\n| `--verbose`, `-v` | Print detailed property-change logs and transfer progress from the SDK callbacks. |\n\nIf no `--ip` is provided SonShell enumerates available cameras and uses the first match. A fingerprint of the successful connection is cached under `~/.cache/sonshell/fp_enumerated.bin` so subsequent launches pair faster.\n\n---\n\n## Hook Events\n\nWhen `--cmd` is provided SonShell calls the hook for every file-affecting event. The hook always receives:\n\n```\n<path> <mode> <operation> [old] [new]\n```\n\n- `path` – absolute path to the newest local copy of the file.\n- `mode` – current camera operating mode resolved via the SDK. Examples:\n  - `record/still/m` → still capture in manual mode.\n  - `record/still/auto_plus` → still capture in Auto+ mode.\n  - `record/movie/cine_ei/sq` → movie clip shot in Cine EI with S&Q enabled.\n  - `playback` → events raised while browsing files on-body.\n- `operation` – high-level action SonShell observed.\n  - `new` – a freshly captured file copied to disk.\n  - `sync` – a file mirrored during a manual/auto sync.\n  - `rating` – the camera changed the star rating of a file (works wherever the SDK reports the update).\n- `old` / `new` – optional values tied to the operation (for `rating` they are the previous and current star counts, for `new`/`sync` only the `new` value is populated with the original camera path).\n\nThe hook is executed asynchronously, so long-running work should be handled internally or by delegating to background jobs.\n\n---\n\n## Shell Command Reference\n\n| Command | Variants / Subcommands | What it does ",
      "default_branch": "master"
    },
    "fetched_at": "2025-10-13T02:26:45.530331"
  },
  {
    "basic_info": {
      "name": "llmq",
      "full_name": "IST-DASLab/llmq",
      "owner": "IST-DASLab",
      "description": "Quantized LLM training in pure CUDA/C++.",
      "url": "https://github.com/IST-DASLab/llmq",
      "clone_url": "https://github.com/IST-DASLab/llmq.git",
      "ssh_url": "git@github.com:IST-DASLab/llmq.git",
      "homepage": "",
      "created_at": "2025-09-26T17:37:47Z",
      "updated_at": "2025-10-12T08:21:28Z",
      "pushed_at": "2025-10-11T12:03:54Z"
    },
    "stats": {
      "stars": 193,
      "forks": 9,
      "watchers": 193,
      "open_issues": 0,
      "size": 471
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 359875,
        "Cuda": 140446,
        "Python": 13004,
        "CMake": 5844
      },
      "license": null,
      "topics": [
        "cuda",
        "llm-training",
        "quantization-aware-training"
      ]
    },
    "content": {
      "readme": "# LLM.Q\nQuantized LLM training in pure CUDA/C++.\n\n## Overview\n`llm.q` is an implementation of (quantized) large language model training in CUDA, inspired by [llm.c](https://github.com/karpathy/llm.c). It is particularly aimed at medium-sized training setups, i.e., a single node with multiple GPUs.\n\n## Build instructions\nThe code is written in C++20 and requires CUDA 12 or later.  It depends on [nccl](https://developer.nvidia.com/nccl) for communication, and [cudnn](https://developer.nvidia.com/cudnn) for fast attention. Multi-GPU training can either be run in multi-process mode (requires OpenMPI) or in multi-thread mode. On a recent ubuntu system, this should provide\nthe required dependencies (adapt cuda version as needed):\n```´shell\n# build tools\napt install cmake ninja-build git gcc-13 g++-13\n# libs\napt install cuda-12-8 cudnn9-cuda-12-8 libnccl2 libnccl-dev libopenmpi-dev\n```\n\nAdditional header-only dependencies are automatically downloaded by cmake during the build process.\nThese are:\n* [json](https://github.com/nlohmann/json)\n* [cudnn-frontend](https://github.com/NVIDIA/cudnn-frontend)\n* [CLI11](https://github.com/CLIUtils/CLI11)\n* [fmt](https://github.com/fmtlib/fmt)\n\nTo build the training executable, run\n```shell\nmkdir build\ncmake -S . -B build\ncmake --build build --parallel --target train\n```\n\n## How to train your (quantized) llm\n### Data preparation\nIn order to train/fine-tune a model, you first need some data. The [tokenize_data](tokenize_data.py) script provides a utility to prepare token files for training.\nIt only supports a limited number of datasets, but hacking it for your own dataset should be straightforward.\n```shell\nuv run tokenize_data.py --dataset tiny-shakespeare --model qwen\n```\nThis will create `tiny-shakespeare-qwen-train.bin` and `tiny-shakespeare-qwen-eval.bin`.\n\n### Training run\nLet's fine-tune the smallest Qwen model on this data:\n```shell\n./build/train --model=Qwen/Qwen2.5-0.5B \\\n  --train-file=data/tiny-shakespeare-qwen/train.bin \\\n  --eval-file=data/tiny-shakespeare-qwen/eval.bin \\\n  --model-dtype=bf16 --opt-m-dtype=bf16 --opt-v-dtype=bf16 \\\n  --matmul-dtype=e4m3 \\\n  --recompute-block \\\n  --grad-accumulation=8 --steps=30 \\\n  --learning-rate=1e-5 --gpus=1 --batch-size=8\n```\nThe program will print some logging information, such as the following:\n```text\n[Options]\n  recompute-swiglu  : true\n  recompute-norm    : true\n  [...]\n\n[System 0]\n  Device 0: NVIDIA GeForce RTX 4090\n  CUDA version: driver 13000, runtime 13000\n  Memory: 906 MiB / 24080 MiB\n  \nLoading model from `/huggingface/hub/models--Qwen--Qwen2.5-0.5B/snapshots/060db6499f32faf8b98477b0a26969ef7d8b9987/model.safetensors`\n done\n \n[Dataset]\n train:  329k tokens\n   data/tiny-shakespeare-qwen/train.bin :     329663\n eval:   33k tokens\n   data/tiny-shakespeare-qwen/eval.bin :      33698\n\n[Allocator State]\n        Adam V:   942 MiB\n        Adam M:   942 MiB\n     Gradients:   942 MiB\n   Activations:  4505 MiB\n        Master:   682 MiB\n       Weights:   601 MiB\n          Free: 14078 MiB\n      Reserved:   483 MiB\n         Other:   903 MiB\n```\n\nIf `[Allocator State]` shows a lot of `Free` memory (as it does here), you can try increasing the batch size (and adjust `--grad-accumulation` accordingly), or reduce the amount of activation checkpointing.\nFor example, on a 16GiB 4060Ti, `--recompute-block` can be replaced by `--recompute-swiglu`, which increases the activation memory from `4.5 GiB` to `9 GiB`, and\nthe speed from ~11k tps to ~13k tps.\n\nThen, the actual training will begin:\n````text\n[T] step     0 [ 19.9%] | time:  1869 ms | norm   4.315545 | loss   3.282568 | tps 35064 | sol 42.9%\n[T] step     1 [ 39.8%] | time:  1709 ms | norm   8.423664 | loss   3.310652 | tps 38347 | sol 46.9%\n[T] step     2 [ 59.6%] | time:  1708 ms | norm   4.818971 | loss   3.330125 | tps 38370 | sol 47.0%\n[T] step     3 [ 79.5%] | time:  1715 ms | norm   5.247286 | loss   3.259991 | tps 38213 | sol 46.8%\n[V] step     4 [  0.0%] | time:   165 ms | eval   2.945187 | train  3.295834 | tps  148k\n````\nEach `[T]` line is a training step (in contrast to `[V]` validation). It shows the step number, the progress within the epoch,\nthe elapsed time, as well as the current loss and gradient norm. It also calculates the current throuput in tokens per second,\nand sets this in relation to the GPU's speed of light (SOL), i.e., the fastest possible speed if the GPU was only running strictly necessary matmuls at peak flop/s.\n\n### Inspecting the logs\nAfter 50 steps, the training will finish, and save the final model to `model.safetensors`. In addition, a log file will be created,\nwhich contains the training log in JSON format. We can visualize the log using the `plot-training-run.py` utility script:`\n```shell\nuv run python/plot-training-run.py log.json\n```\nThis shows the training and evaluation losses over time, for quick inspection.\nFor a more detailed and interactive workflow, you can export the log to weights&biases:\n```shell\nuv run python/export-wandb.py --log-fi",
      "default_branch": "dev"
    },
    "fetched_at": "2025-10-13T02:26:46.647100"
  },
  {
    "basic_info": {
      "name": "gemini_icpc2025",
      "full_name": "google-deepmind/gemini_icpc2025",
      "owner": "google-deepmind",
      "description": "Gemini 2025 ICPC World Finals Code Submissions",
      "url": "https://github.com/google-deepmind/gemini_icpc2025",
      "clone_url": "https://github.com/google-deepmind/gemini_icpc2025.git",
      "ssh_url": "git@github.com:google-deepmind/gemini_icpc2025.git",
      "homepage": "",
      "created_at": "2025-09-17T10:57:24Z",
      "updated_at": "2025-10-12T05:36:52Z",
      "pushed_at": "2025-09-17T11:09:46Z"
    },
    "stats": {
      "stars": 163,
      "forks": 12,
      "watchers": 163,
      "open_issues": 0,
      "size": 27
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 54237
      },
      "license": "Apache License 2.0",
      "topics": []
    },
    "content": {
      "readme": "# Gemini ICPC 2025 Submissions\n\nThis repository contains the code submissions from an advanced version of\n[Gemini 2.5 Deep Think](https://blog.google/products/gemini/gemini-2-5-deep-think/)\nfor the 2025 International Collegiate Programming Contest World Finals.\n\n## License and disclaimer\n\nCopyright 2025 Google LLC\n\nAll software is licensed under the Apache License, Version 2.0 (Apache 2.0);\nyou may not use this file except in compliance with the Apache 2.0 license.\nYou may obtain a copy of the Apache 2.0 license at:\nhttps://www.apache.org/licenses/LICENSE-2.0\n\nAll other materials are licensed under the Creative Commons Attribution 4.0\nInternational License (CC-BY). You may obtain a copy of the CC-BY license at:\nhttps://creativecommons.org/licenses/by/4.0/legalcode\n\nUnless required by applicable law or agreed to in writing, all software and\nmaterials distributed here under the Apache 2.0 or CC-BY licenses are\ndistributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,\neither express or implied. See the licenses for the specific language governing\npermissions and limitations under those licenses.\n\nThis is not an official Google product.\n",
      "default_branch": "release"
    },
    "fetched_at": "2025-10-13T02:26:47.781026"
  },
  {
    "basic_info": {
      "name": "Architecture",
      "full_name": "TheCherno/Architecture",
      "owner": "TheCherno",
      "description": "An example of how I like to architect applications in C++",
      "url": "https://github.com/TheCherno/Architecture",
      "clone_url": "https://github.com/TheCherno/Architecture.git",
      "ssh_url": "git@github.com:TheCherno/Architecture.git",
      "homepage": null,
      "created_at": "2025-09-21T09:17:03Z",
      "updated_at": "2025-10-12T02:55:49Z",
      "pushed_at": "2025-09-21T09:19:14Z"
    },
    "stats": {
      "stars": 145,
      "forks": 13,
      "watchers": 145,
      "open_issues": 4,
      "size": 80
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 18976,
        "CMake": 3091,
        "GLSL": 1966
      },
      "license": "The Unlicense",
      "topics": []
    },
    "content": {
      "readme": "# Architecture\n\nAn example of how I like to architect applications in C++, as part of a [YouTube mini-series](https://youtube.com/playlist?list=PLlrATfBNZ98cpX2LuxLnLyLEmfD2FPpRA).\n\n## Build\n\nGenerate project files/build using CMake. I like to make a directory called `build` at the root and then run\n```\ncmake ..\n```\nfrom that directory. This will generate relevant project files (eg. Visual Studio for me) which you can then use to build and run.\n\n## Notes\nI chose to use OpenGL (and GLFW) for this due to popular demand [after running a poll](https://www.youtube.com/post/UgkxP9IU8D8UjH8szUipCS3QkJJQOc_cdb0k), however these concepts mostly translate to any other libraries/rendering APIs you may be using. OpenGL and GLFW is simply used as an example, substitute what you like.\n\n## License\nThis repository uses [The Unlicense](https://unlicense.org/), so feel free to use this however you like.",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-13T02:26:48.913168"
  },
  {
    "basic_info": {
      "name": "MarkerPatch",
      "full_name": "Wemino/MarkerPatch",
      "owner": "Wemino",
      "description": " A patch that fixes various issues and limitations in the PC port of Dead Space 2",
      "url": "https://github.com/Wemino/MarkerPatch",
      "clone_url": "https://github.com/Wemino/MarkerPatch.git",
      "ssh_url": "git@github.com:Wemino/MarkerPatch.git",
      "homepage": "",
      "created_at": "2025-09-20T07:42:56Z",
      "updated_at": "2025-10-12T21:26:50Z",
      "pushed_at": "2025-10-09T11:39:42Z"
    },
    "stats": {
      "stars": 134,
      "forks": 1,
      "watchers": 134,
      "open_issues": 2,
      "size": 18773
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 90059
      },
      "license": "GNU General Public License v2.0",
      "topics": []
    },
    "content": {
      "readme": "<p align=\"center\">\n  <img src=\"assets/MarkerPatch_Logo.png\" style=\"max-width:70%\">\n</p>\n\n<p align=\"center\">\nA patch that fixes various issues and limitations in the PC port of Dead Space 2.\n</p>\n\n## How to Install\n\n> [!NOTE]  \n> Compatible with all versions of Dead Space 2 (Steam, EA App).\n>\n> **Download**: [MarkerPatch.zip](https://github.com/Wemino/MarkerPatch/releases/latest/download/MarkerPatch.zip)  \n> Extract the contents of the zip file into the game's folder, in the same directory as the `deadspace2.exe` file.\n\n### Steam Deck/Linux Specific Instructions (Windows users can skip this)\n\n> [!WARNING]\n> To launch the game on Steam Deck or Linux, open the game's properties in Steam and include `WINEDLLOVERRIDES=\"dinput8=n,b\" %command%` in the launch options.\n>\n> **Note**: DXVK limits the framerate to 60 FPS by default. To increase this limit, add the following to your launch options (example for 120 FPS):  \n> `DXVK_FRAME_RATE=120 WINEDLLOVERRIDES=\"dinput8=n,b\" %command%`\n\n# Features\n\n## Havok Physics Fix\n\nStabilizes physics behavior at high framerates to eliminate the annoying flying corpses and limbs. While physics issues begin above 30 FPS, they become noticeably problematic after 100 FPS, causing dead bodies and severed limbs to launch erratically across rooms.\n\n## High-Core CPU Fix\n\nPrevents the game from crashing on systems with more than 10 CPU cores. The game's CPU detection code collects information about each core into fixed-size arrays, but these arrays weren't sized to handle more than 10 cores. When more cores are detected, the code overflows these arrays, corrupting memory and causing crashes later during execution. The patch stops the CPU detection loop early to prevent this overflow.\n\n## VSync Refresh Rate Fix\n\nCorrects the VSync implementation to use the refresh rate selected in the game's settings instead of locking to 30 FPS. The original implementation ignores your chosen refresh rate and forces 30 FPS when VSync is enabled.\n\n<div align=\"center\">\n  <table>\n    <tr>\n      <td width=\"50%\"><img style=\"width:100%\" src=\"assets/vsyncfix_off.png\"></td>\n      <td width=\"50%\"><img style=\"width:100%\" src=\"assets/vsyncfix_on.png\"></td>\n    </tr>\n    <tr>\n      <td align=\"center\">Vanilla (Locked to 30 FPS)</td>\n      <td align=\"center\">MarkerPatch (Uses Selected Rate)</td>\n    </tr>\n  </table>\n</div>\n\n## Automatic Weapon Fire Rate Fix\n\nStabilizes the fire rate of automatic weapons across all framerates. The game's weapon cooldown system checks more frequently at higher framerates, causing automatic weapons like the Pulse Rifle and Flamethrower to fire progressively faster as FPS increases.\n\n## Save System Fixes\n\n### Difficulty Reward Tracking\nFixes the tracking of Zealot and Hardcore difficulty completions to properly unlock rewards. \n\n> **Important**: This fix requires starting a new save with the patch installed. You must keep the patch installed for the entire playthrough for the fix to remain effective.\n\n### Suit ID Conflicts\nResolves item database conflicts where certain DLC suits incorrectly share IDs with other suits:\n- **Zealot Suit** was conflicting with the Security Suit.\n- **Hacker Suit** was conflicting with the Elite Advanced Suit.\n\nThese conflicts would cause one suit to overwrite the other in your inventory, making purchased items disappear.\n\n### String Buffer Overflow Prevention\nPrevents crashes that can rarely occur when the game enumerates save files. This happens in two scenarios: when checking for Dead Space 1 saves to grant the DLC bonus for owning the first game, and when listing your Dead Space 2 save files in the load menu. Though these crashes are uncommon, they can be frustrating when they do occur.\n\n## Subtitle Font Scaling\n\nScales subtitle text appropriately for high resolutions. The game was designed with console limitations in mind and intentionally prevents subtitles from scaling beyond 720p resolution, making them tinier at 1080p and above. This fix removes that limitation and allows proper scaling.\n\nFor those who prefer different subtitle sizes, `FontScalingFactor` in `MarkerPatch.ini` allows fine-tuning the subtitle text size to personal preference.\n\n<div align=\"center\">\n  <table>\n    <tr>\n      <td width=\"50%\"><img style=\"width:100%\" src=\"assets/scaling_off.png\"></td>\n      <td width=\"50%\"><img style=\"width:100%\" src=\"assets/scaling_on.png\"></td>\n    </tr>\n    <tr>\n      <td align=\"center\">4K Vanilla</td>\n      <td align=\"center\">4K MarkerPatch</td>\n    </tr>\n  </table>\n</div>\n\n## Raw Mouse Input\n\nImplements proper raw mouse input to fix sensitivity issues. This works similarly to the existing \"Dead Space 2 Mouse Fix\" mod with several improvements:\n- Added support for zero-gravity areas. (the original mouse fix didn't work properly in zero-G)\n- Sensitivity scaling now matches the in-game sensitivity settings more accurately.\n- Does not interfere with controller inputs when switching between mouse and gamepad.\n\nThe fix decouples mouse sensitivity from the game's fr",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-13T02:26:50.034591"
  },
  {
    "basic_info": {
      "name": "ClutteredEnvironment",
      "full_name": "IntelligentControlSystems/ClutteredEnvironment",
      "owner": "IntelligentControlSystems",
      "description": "This is the accompaning code of the paper titled \"A novel MPC framework for efficient navigation of mobile robots in cluttered environments\"",
      "url": "https://github.com/IntelligentControlSystems/ClutteredEnvironment",
      "clone_url": "https://github.com/IntelligentControlSystems/ClutteredEnvironment.git",
      "ssh_url": "git@github.com:IntelligentControlSystems/ClutteredEnvironment.git",
      "homepage": null,
      "created_at": "2025-09-16T13:49:36Z",
      "updated_at": "2025-10-09T16:51:02Z",
      "pushed_at": "2025-09-22T09:07:57Z"
    },
    "stats": {
      "stars": 121,
      "forks": 9,
      "watchers": 121,
      "open_issues": 0,
      "size": 7741
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 360618,
        "Python": 76060,
        "CMake": 20867,
        "Shell": 13529,
        "Dockerfile": 3821
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "<div align=\"center\">\n  <h1> A novel MPC framework for efficient navigation of mobile robots in cluttered environments </h1>\n\n\n  <a href=\"https://opensource.org/licenses/MIT\">\n    <img src=\"https://img.shields.io/badge/License-MIT-yellow.svg\" alt=\"License: MIT\">\n  </a>\n\n</div>\n\n---\nThis is the accompaning code of the paper titled \"A novel MPC framework for efficient navigation of mobile robots in cluttered environments\". \n[Read preprint on arXiv](https://arxiv.org/abs/2509.15917)\n\n\n## Demo\n\n![](./media/cluttered_mpc_sim.gif)\n\n## Experiments\n\n🎥 [Click to watch the experiment video](https://youtu.be/Hn_hpAmGgq0)\n\n[![](./media/arc_screenshot_anoted.png)](https://youtu.be/Hn_hpAmGgq0)\n\n\n## Prerequisites\n\nThis software is based on the Control and Robotics Software ([CRS](https://gitlab.ethz.ch/ics/crs)), an advanced control software framework to support simulations and experiments in the fields of control and robotics. CRS is built on top of the Robot Operating System (ROS) and primarily written in C++ and Python.\nThe CRS environment uses [Docker](https://www.docker.com) to allow cross-platform compatibility. The only requirement you have is to run an up-to-date operating system and up to 16 GB of free storage (some of it is only required during the setup). Below you find the install instructions for Ubuntu, macOS and Windows.\n\n## Setting up the Docker Image\n\n### Toolkit Installation\nFirst, install the `crs-docker` tool based on your operating system:\n<details>\n<summary>Ubuntu (recommended)</summary>\n\n These instructions were tested on the following Ubuntu versions:\n\n- 20.04 LTS\n- 22.04 LTS\n- 24.04 LTS\n\nHowever, the instructions should apply to all recent Ubuntu versions.\n\n#### Steps\n\n1. Install Docker using the [offical install instructions](https://docs.docker.com/install/)   _Note: The install instructions list Ubuntu in the server section!_\n2. Allow Docker execution as a non-root user; follow [these instructions](https://docs.docker.com/install/linux/linux-postinstall/#manage-docker-as-a-non-root-user)   _Note: Only do the first section \"Manage Docker as a non-root user\"_\n3. Test your Docker installation with the following command   _Note: You might want to restart your computer at this point._\n\n   ```sh\n   docker run hello-world\n   ```\n4. Clone the git repository\n\n   ```sh\n   git clone https://github.com/IntelligentControlSystems/ClutteredEnvironment.git\n   ```\n5. Navigate to the Ubuntu setup folder\n\n   ```sh\n   cd ClutteredEnvironment/.setup/ubuntu\n   ```\n6. Execute the setup script\n\n   ```sh\n   ./setup.sh\n   ```\n\n</details>\n\n<details>\n<summary>Arch Linux </summary>\n\nThe Installation does not differ too much from the Ubuntu installation. There is however one caveat on Arch Linux: Running Docker containers might fill up your memory and crash your system. To prevent this, add following lines to the file `/etc/docker/daemon.json` :\n\n```sh\n{\n  \"default-ulimits\": {\n    \"nofile\": {\n      \"Name\": \"nofile\",\n      \"Soft\": 1024,\n      \"Hard\": 524288\n    }\n  }\n}\n```\n\nDo not forget to restart the docker service with `sudo systemctl restart docker`.\n\nAlternatively, one can specify these limits in the `docker-compose.yaml` file:\n\n```sh\nversion: '3'\nname: \"crs\"\nservices:\n  crs:\n\n    ...\n\n    # ADD THESE 4 LINES\n    ulimits:\n      nofile:\n        soft: 1024\n        hard: 524288\n\n    ...\n```\n\n</details>\n\n<details>\n<summary>MacOS</summary>\n\nThese instructions were tested on **macOS Sonoma (14.4)**. However, the instructions should apply to all recent macOS versions.\n\n#### Steps\n\n1. Install Docker using the [offical install instructions](https://docs.docker.com/install/)\n2. Test your Docker installation with the following command\n\n   ```sh\n   docker run hello-world\n   ```\n3. Clone the git repository   _Note: Make sure you have a SSH key set up, otherwise this doesn't work._\n\n   ```sh\n   git clone https://github.com/IntelligentControlSystems/ClutteredEnvironment.git\n   ```\n4. Navigate to the MacOS setup folder\n\n   ```sh\n   cd ClutteredEnvironment/.setup/macos\n   ```\n5. Execute the setup script\n\n   ```sh\n   ./setup.sh\n   ```\n\n</details>\n\n<details>\n<summary>Windows</summary>\n\n These instructions were tested on the following Windows versions:\n\n- Windows 11\n\nWindows 10 should work as well, but might need some slight modifications.\n\n#### Steps\n\n1. Install Docker using the [official install instructions](https://docs.docker.com/desktop/install/windows-install/)\n2. Make sure to run Docker on WSL 2 (see [Docker Desktop WSL 2 backend on Windows](https://docs.docker.com/desktop/wsl/))\n   1. Make sure you have WSL 2 installed and set Ubuntu as the default distro.\n   2. Make sure to tick the boxes in the Docker Desktop as in the screenshots below.\n\n      ![image.png](uploads/e1e86bcc006aff072295e4f96584b879/image.png){width=\"840\" height=\"440\"}\n\n      ![Screenshot 2024-08-30 103945.png](uploads/94fe1a22e216189487109c874848ff56/Screenshot_2024-08-30_103945.png){width=\"1440\" height=\"759\"}\n3. Open a PowerShell Terminal and get into your defau",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-13T02:26:51.169991"
  },
  {
    "basic_info": {
      "name": "hyprlauncher",
      "full_name": "hyprwm/hyprlauncher",
      "owner": "hyprwm",
      "description": "A multipurpose and versatile launcher / picker for Hyprland",
      "url": "https://github.com/hyprwm/hyprlauncher",
      "clone_url": "https://github.com/hyprwm/hyprlauncher.git",
      "ssh_url": "git@github.com:hyprwm/hyprlauncher.git",
      "homepage": null,
      "created_at": "2025-10-07T15:41:37Z",
      "updated_at": "2025-10-12T17:11:23Z",
      "pushed_at": "2025-10-12T13:59:39Z"
    },
    "stats": {
      "stars": 110,
      "forks": 2,
      "watchers": 110,
      "open_issues": 1,
      "size": 79
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 47000,
        "CMake": 1382
      },
      "license": "BSD 3-Clause \"New\" or \"Revised\" License",
      "topics": []
    },
    "content": {
      "readme": "## hyprlauncher\nA multipurpose and versatile launcher / picker for Hyprland\n\n![](./assets/preview.png)\n\n## Features\n\n- Various providers: Desktop, Unicode, Emoji, Math ...\n- Speedy: Fast, multi-threaded fuzzy searching\n- Daemon by default: instant opening of the launcher\n- Entry frequency caching: commonly used entries appear above others\n\n## Runtime dependencies\n\n- Desktop: none\n- Unicode: `wl-copy`\n- Math: `wl-copy` for copying the result\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-13T02:26:52.291790"
  },
  {
    "basic_info": {
      "name": "tilelang-ascend",
      "full_name": "tile-ai/tilelang-ascend",
      "owner": "tile-ai",
      "description": "Ascend TileLang adapter ",
      "url": "https://github.com/tile-ai/tilelang-ascend",
      "clone_url": "https://github.com/tile-ai/tilelang-ascend.git",
      "ssh_url": "git@github.com:tile-ai/tilelang-ascend.git",
      "homepage": "",
      "created_at": "2025-09-25T11:53:38Z",
      "updated_at": "2025-10-12T19:04:30Z",
      "pushed_at": "2025-10-11T09:11:35Z"
    },
    "stats": {
      "stars": 103,
      "forks": 14,
      "watchers": 103,
      "open_issues": 6,
      "size": 12405
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 2340955,
        "Python": 987694,
        "Shell": 20282,
        "Cython": 8125,
        "CMake": 7206,
        "Dockerfile": 1051
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "<img src=./images/logo-row.svg />\n\n<div align=\"center\">\n\n# TileLang-Ascend\n\n\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/tile-ai/tilelang-ascend)\n\n</div>\n\nTile Language Ascend (**tilelang-ascend**) is a specialized variant of the tile-lang domain-specific language, specifically optimized for Huawei Ascend NPU (Neural Processing Unit) architecture. Built upon the foundation of tile-lang's Pythonic syntax and [TVM](https://tvm.apache.org/) compiler infrastructure, tilelang-ascend enables developers to efficiently create high-performance AI compute kernels tailored for Ascend processors, including operations like GEMM, vector operations, and attention mechanisms. Tilelang-ascend allows developers to focus on productivity without sacrificing the low-level optimizations necessary for state-of-the-art performance on the NPU. The compiler backend supports two technical routes: [Ascend C & PTO](https://github.com/tile-ai/tilelang-ascend/tree/ascendc_pto) and [AscendNPU IR](https://github.com/tile-ai/tilelang-ascend/tree/npuir).\n\n<p align=\"center\">\n  <img src=\"./images/tl-ascend-gemm.png\" width=\"100%\" alt=\"image\">\n\n</p>\n\n## Latest News\n- 09/29/2025 🚀: We are excited to announce that tilelang-ascend, a dsl for high performance AI workloads on Ascend NPUs, is now open source and available to the public!\n\n## Tested Devices\nAlthough tilelang-ascend aims to be portable across a range of Ascend devices, it has been specifically tested and validated on the following NPUs: A2 and A3.\n\n## OP Implementation Examples\n**tilelang-ascend** provides the building blocks to implement a wide variety of operators on the NPU.\nSome examples include:\n\n- [Matrix Multiplication](./examples/gemm/)\n- [Vector Add](./examples/elementwise/)\n- [Flash Attention](./examples/flash_attention/)\n\n\nWithin the `examples` directory, you will also find additional complex kernels—such as [LightningIndexer](./examples/lightning_indexer/) and [SparseFlashAttention](./examples/sparse_flash_attention/), more operators will continuously be added.\n\n\n## Installation\n\n### Environment Preparation\nWe assume you already have an ascend environment with CANN (at least [8.2.RC1](https://www.hiascend.com/developer/download/community/result?from=firmware&product=1&model=30&cann=8.2.RC1)) and torch-npu (at least 2.6.0.RC1) installed. Firstly, set cann environment variables.\n\n  ```bash\n  source {your-cann-installed-path}/ascend-toolkit/set_env.sh\n  ```\n\n### TileLang-Ascend Installation\n\nHere we use the method of compiling from source code for installation.\n\n#### a) Download\n\n    git clone --recursive https://github.com/tile-ai/tilelang-ascend.git\n    cd tilelang-ascend\n\n#### b) Compile and Install\n    bash install_ascend.sh\n\n#### c) Environment Variable Setup\n\n    source set_env.sh\n\n## Run\n\n\nIn this section, you will learn how to call NPU TileLang operators.\n\nHere we use the **Matrix Multiplication** operator as an example for introduction.\n\n\n```\ncd examples/gemm\npython example_gemm.py\n```\n\nUpon success, it will print:\n\n```\nKernel Output Match!\n```\n\n## Comparison with NVIDIA Backend Implementation\n\nGPUs primarily feature a three-level memory hierarchy that can be analogously mapped to NPU hardware architecture as follows:\n\n**Memory Hierarchy Mapping:**\n- `global memory` ↔ `global memory`\n- `shared memory` ↔ `L1 buffer on cube core and unified buffer on vector core`  \n- `register memory` ↔ `L0A/B/C buffer`\n\n**Memory Management:**\nTileLang-Ascend provides memory allocation primitives similar to the GPU version. For example, `alloc_{L1/ub/...}` functions allow on-chip memory allocation in a manner comparable to GPU programming.\n\n**Execution Model Differences:**\nAt the execution level, NPUs lack thread-level abstractions. Therefore, we currently provide computation primitives operating at the `tile` granularity on vector cores. While the GPU version enables automatic parallelization of internal computations (e.g., addition) across different threads using `T.Parallel`, the NPU version requires manual vectorization through primitives like `T.add`.\n\n**Cross-Core Communication:**\nAdditionally, since cube and vector cores on NPUs can only exchange data through global memory/L2 cache, the current implementation requires explicit specification of execution code for different cores using the `T.Scope` primitive. Synchronization between cores is managed through `T.set_cross_flag` and `T.wait_cross_flag`, and intermediate data transfer global tensors must be explicitly specified during kernel definition.\n\n\n## Quick Start\n\nIn this section, you'll learn how to write and execute a straightforward GEMM (matrix multiplication) kernel using tilelang-ascend, The next chapter will introduce how to write a high-performance gemm kernel.\n\n### GEMM Example with Annotations\n\nBelow is an example that demonstrates how to quickly implement a gemm on the ascend.\n\n```python\n@tilelang.jit(out_idx=[-1])\ndef matmul(M, N, K, block_M, block_N, K_L1, dtype=\"float16\", accum_dtype=\"floa",
      "default_branch": "ascendc_pto"
    },
    "fetched_at": "2025-10-13T02:26:53.477797"
  },
  {
    "basic_info": {
      "name": "hyprtoolkit",
      "full_name": "hyprwm/hyprtoolkit",
      "owner": "hyprwm",
      "description": "A modern C++ Wayland-native GUI toolkit",
      "url": "https://github.com/hyprwm/hyprtoolkit",
      "clone_url": "https://github.com/hyprwm/hyprtoolkit.git",
      "ssh_url": "git@github.com:hyprwm/hyprtoolkit.git",
      "homepage": null,
      "created_at": "2025-09-19T14:59:58Z",
      "updated_at": "2025-10-12T19:05:47Z",
      "pushed_at": "2025-10-12T17:03:23Z"
    },
    "stats": {
      "stars": 95,
      "forks": 1,
      "watchers": 95,
      "open_issues": 2,
      "size": 836
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 423950,
        "GLSL": 23877,
        "CMake": 4844,
        "Nix": 3611,
        "Shell": 825
      },
      "license": "BSD 3-Clause \"New\" or \"Revised\" License",
      "topics": []
    },
    "content": {
      "readme": "## hyprtoolkit\nA modern C++ Wayland-native GUI toolkit\n\n![](./assets/preview.png)\n\n## What Hyprtoolkit is\n\nHyprtoolkit is designed to be a small, simple, and modern C++ toolkit for making wayland GUI apps, with\na few goals:\n\n- Simple C++ API for making a GUI app\n- Smooth animations\n- Easy usage\n- Simple system theming\n\n### What Hyprtoolkit is not\n\nHyprtoolkit is not:\n- cross-platform\n- packed with crazy features\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-13T02:26:54.607114"
  },
  {
    "basic_info": {
      "name": "-CRYENGINE-Community-Edition-",
      "full_name": "Pterosoft/-CRYENGINE-Community-Edition-",
      "owner": "Pterosoft",
      "description": "CRYENGINE Community Edition - Release Version",
      "url": "https://github.com/Pterosoft/-CRYENGINE-Community-Edition-",
      "clone_url": "https://github.com/Pterosoft/-CRYENGINE-Community-Edition-.git",
      "ssh_url": "git@github.com:Pterosoft/-CRYENGINE-Community-Edition-.git",
      "homepage": null,
      "created_at": "2025-10-02T12:24:22Z",
      "updated_at": "2025-10-11T20:02:22Z",
      "pushed_at": "2025-10-10T13:46:13Z"
    },
    "stats": {
      "stars": 94,
      "forks": 9,
      "watchers": 94,
      "open_issues": 0,
      "size": 431556
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 1638282,
        "Rich Text Format": 127244,
        "HLSL": 17268,
        "CMake": 16372,
        "C": 3059,
        "Python": 221
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# CRYENGINE Community Edition\nCRYENGINE Community Edition is a new version of the engine developed and maintained by the community. It builds on the foundation of CRYENGINE while introducing new features, improvements, and customization options contributed by developers in their free time.\n## Installation\n- Download the source code for CRYENGINE 5.7\n- Continue to build the solution as stated in the readme file shipped alongside 5.7\n- After solution is created extract the files from this solutionMake sure that the new files are imported into the solution\n  - Locate the projects:EditorCommonSandbox&nbsp;(found in&nbsp;CRYENGINE/Sandbox)\n  - Right-click →&nbsp;Properties&nbsp;→&nbsp;Configuration Properties&nbsp;→&nbsp;C/C++&nbsp;→&nbsp;Advanced.In&nbsp;\n  - Disable Specific Warnings, add: 4996## Files Required to \n- Import __FlowFlashEnableDynTexNode.cpp__\n\nFile Location: Code\\CryEngine\\CryFlowGraph\\FlowSystem\\Nodes\\FlowFlashEnableDynTexNode.cpp\n\nImport Location:&nbsp;CRYENGINE_Win64\\CRYENGINE\\CryEngine\\CryFlowGraph\\Flow System\\Nodes\n- __D3D_DXC.cpp, D3D_RT.cpp,&nbsp;D3D_Shader.cpp__\n\nFile Location: Code\\CryEngine\\RenderDll\\XRenderD3D9\\D3D_DXC.cpp, D3D_RT.cpp,&nbsp;D3D_Shader.cpp\n\nImport Location: CRYENGINE_Win64\\CRYENGINE\\CryEngine\\CryRenderD3D12,&nbsp;CryRenderD3D11\\Source Files\n - __D3D_DXC.h,&nbsp;D3D_RT.h,&nbsp;D3D_Shader.h__\n\nFile Location: Code\\CryEngine\\RenderDll\\XRenderD3D9\\D3D_DXC.h,&nbsp;D3D_RT.h,&nbsp;D3D_Shader.h\n\nImport Location:&nbsp;CRYENGINE_Win64\\CRYENGINE\\CryEngine\\CryRenderD3D12,&nbsp;CryRenderD3D11\\Header Files\n## License&nbsp;\nAll files provided here are licensed under the MIT License, meaning you are free to use them in your own projects at no cost.The engine itself remains under the CRYENGINE license provided by Crytek. You must comply with the terms of that license when using the engine.Before downloading or using these files, please review the official CRYENGINE license on the CRYENGINE website&nbsp;to ensure you fully understand the requirements.Thank you for respecting both licenses and supporting the community effort.\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-13T02:26:55.712094"
  },
  {
    "basic_info": {
      "name": "lidar_odometry_ros_wrapper",
      "full_name": "93won/lidar_odometry_ros_wrapper",
      "owner": "93won",
      "description": "LiDAR Odometry ROS2 Wrapper",
      "url": "https://github.com/93won/lidar_odometry_ros_wrapper",
      "clone_url": "https://github.com/93won/lidar_odometry_ros_wrapper.git",
      "ssh_url": "git@github.com:93won/lidar_odometry_ros_wrapper.git",
      "homepage": "",
      "created_at": "2025-09-27T14:17:58Z",
      "updated_at": "2025-10-12T19:54:35Z",
      "pushed_at": "2025-10-09T03:18:20Z"
    },
    "stats": {
      "stars": 93,
      "forks": 15,
      "watchers": 93,
      "open_issues": 0,
      "size": 8890
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 18913,
        "Python": 14123,
        "CMake": 4132
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# LiDAR Odometry ROS2 Wrapper\n\nThis package provides a ROS2 wrapper for the LiDAR Odometry system with Probabilistic Kernel Optimization (PKO). It enables real-time LiDAR-based odometry estimation in ROS2 environments.\n\n## Demo Video\n\n[![KITTI LiDAR Odometry Demo](https://img.youtube.com/vi/swrJY2EStrs/0.jpg)](https://www.youtube.com/watch?v=swrJY2EStrs)\n[![Mid360 LiDAR Odometry Demo](https://img.youtube.com/vi/HDPA_ILxCrE/0.jpg)](https://youtu.be/HDPA_ILxCrE)\n\n## Features\n\n- ⚡ Real-time LiDAR odometry processing\n- 🎯 Feature-based point cloud registration  \n- 🔧 Ceres Solver-based optimization with PKO\n- 📈 ROS2 native implementation\n- 🌐 TF2 transform broadcasting\n- 📊 Trajectory visualization\n- 🎮 Optional Pangolin viewer integration\n\n## Dependencies\n\n### ROS2 Dependencies\n- `rclcpp`\n- `sensor_msgs`\n- `nav_msgs` \n- `geometry_msgs`\n- `visualization_msgs`\n- `tf2` and `tf2_ros`\n- `pcl_ros` and `pcl_conversions`\n\n### System Dependencies  \n- Eigen3\n- PCL (Point Cloud Library)\n- Ceres Solver\n- OpenGL and GLEW\n- Pangolin (included as submodule)\n\n## Installation\n\n### 1. Setup Workspace and Clone Repository\n```bash\n# Create a new ROS2 workspace\nmkdir -p lidar_odom_ws/src\ncd lidar_odom_ws/src\n\n# Clone the repository\ngit clone https://github.com/93won/lidar_odometry_ros_wrapper.git\ncd lidar_odometry_ros_wrapper\n\n# Initialize and download submodules\ngit submodule update --init --recursive\n```\n\n### 2. Install System Dependencies\n```bash\n# Ubuntu 22.04\nsudo apt update\nsudo apt install -y \\\n    libeigen3-dev \\\n    libpcl-dev \\\n    libceres-dev \\\n    libgl1-mesa-dev \\\n    libglew-dev \\\n    pkg-config\n```\n\n### 3. Build the Package\n```bash\ncd ../../  # Go back to lidar_odom_ws root\ncolcon build --packages-select lidar_odometry_ros\nsource install/setup.bash\n```\n\n## Usage\n\n### Basic Usage\n```bash\n# Launch with default Velodyne topic\nros2 launch lidar_odometry_ros lidar_odometry.launch.py \\\n    config_file:=/path/to/your/workspace/lidar_odometry_ros_wrapper/lidar_odometry/config/kitti.yaml\n\n# Launch with custom topic (e.g., Livox)\nros2 launch lidar_odometry_ros lidar_odometry.launch.py \\\n    config_file:=/path/to/your/workspace/lidar_odometry_ros_wrapper/lidar_odometry/config/kitti.yaml \\\n    pointcloud_topic:=/livox/pointcloud \\\n    use_sim_time:=true\n```\n\n### Quick Start\n\n#### Option 1: KITTI Sample Data\nDownload and play the KITTI sample ROS bag file:\n```bash\n# Download KITTI sample bag\n# https://drive.google.com/file/d/1U0tRSsc1PbEj_QThOHcD8l3qFkma3zjc/view?usp=sharing\n\n# Terminal 1: Launch odometry system\nros2 launch lidar_odometry_ros lidar_odometry.launch.py \\\n    config_file:=/path/to/your/workspace/lidar_odometry_ros_wrapper/lidar_odometry/config/kitti.yaml \\\n    use_sim_time:=true\n\n# Terminal 2: Play KITTI bag file\nros2 bag play /path/to/kitti_sample.bag --clock\n```\n\n#### Option 2: Livox MID360 Sample Data\nDownload and play the Livox MID360 sample ROS bag file:\n```bash\n# Download Livox MID360 sample bag\n# https://drive.google.com/file/d/1UI6Qc5cdY8R61Odc7A6IU-jRWZgnCx2g/view?usp=sharing\n# Source: https://www.youtube.com/watch?v=u8siB0KLFLc\n\n# Terminal 1: Launch odometry system for Livox\nros2 launch lidar_odometry_ros lidar_odometry.launch.py \\\n    config_file:=/path/to/your/workspace/lidar_odometry_ros_wrapper/lidar_odometry/config/kitti.yaml \\\n    use_sim_time:=true \\\n    pointcloud_topic:=/livox/pointcloud\n\n# Terminal 2: Play Livox bag file\nros2 bag play /path/to/livox_mid360_sample.bag --clock\n```\n\n**Note**: The Livox sample data uses standard `sensor_msgs/PointCloud2` messages, not Livox custom message format.\n\n\n\n\n\n\n\n## KITTI Dataset Usage\n\n### 1. Download KITTI Dataset\n```bash\n# Create data directory\nmkdir -p ~/kitti_data\ncd ~/kitti_data\n\n# Download KITTI Odometry Dataset (example: sequence 00)\n# Visit: https://www.cvlibs.net/datasets/kitti/eval_odometry.php\n# Download velodyne laser data and poses\n\n# Expected structure:\n# ~/kitti_data/\n# ├── sequences/\n# │   └── 00/\n# │       ├── velodyne/\n# │       │   ├── 000000.bin\n# │       │   ├── 000001.bin\n# │       │   └── ...\n# │       └── poses.txt\n```\n\n### 2. Convert KITTI to ROS2 Bag\n```bash\n# Use the provided conversion script\ncd ~/ros2_ws/src/lidar_odometry_ros_wrapper/scripts\n\npython3 kitti_to_rosbag.py \\\n    --kitti_dir ~/kitti_data/sequences/07 \\\n    --output_bag ~/kitti_data/kitti_seq07.db3 \\\n    --topic_name /velodyne_points \\\n    --frame_id velodyne\n```\n\n### 3. Run Examples\n\n#### Option A: KITTI Dataset\n```bash\n# Terminal 1: Launch odometry system for KITTI\nros2 launch lidar_odometry_ros lidar_odometry.launch.py \\\n    config_file:=$(pwd)/lidar_odometry/config/kitti.yaml \\\n    use_sim_time:=true \\\n    pointcloud_topic:=/velodyne_points\n\n# Terminal 2: Play KITTI bag file\nros2 bag play ~/kitti_data/kitti_seq07.db3 --clock\n```\n\n#### Option B: Livox MID360 Dataset\n```bash\n# Terminal 1: Launch odometry system for Livox MID360\nros2 launch lidar_odometry_ros lidar_odometry.launch.py \\\n    config_file:=$(pwd)/lidar_odometry/config/kitti.yaml \\\n    use_sim_time:=true \\\n  ",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-13T02:26:56.825885"
  },
  {
    "basic_info": {
      "name": "hint-break",
      "full_name": "sapdragon/hint-break",
      "owner": "sapdragon",
      "description": "Code proving a 25-year blind spot in all disassemblers. PoC for Intel x64/x86 “ghost instructions.”",
      "url": "https://github.com/sapdragon/hint-break",
      "clone_url": "https://github.com/sapdragon/hint-break.git",
      "ssh_url": "git@github.com:sapdragon/hint-break.git",
      "homepage": null,
      "created_at": "2025-10-02T03:52:04Z",
      "updated_at": "2025-10-12T17:50:36Z",
      "pushed_at": "2025-10-02T05:04:36Z"
    },
    "stats": {
      "stars": 91,
      "forks": 2,
      "watchers": 91,
      "open_issues": 1,
      "size": 745
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 431
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# 👻 Ghost in opcode\n\nThis repository contains the Proof-of-Concept and research for a 25-year-old architectural blind spot affecting modern reverse engineering tools.\n\n[![SAMPLE X86](https://raw.githubusercontent.com/sapdragon/hint-break/refs/heads/main/images/sample.png)](https://raw.githubusercontent.com/sapdragon/hint-break/refs/heads/main/images/sample.png)\n\n## The Blind Spot\n\nIn 1997, Intel patented (US5,701,442) a series of \"Hintable NOPs\". While most of these have been assigned functions or are correctly parsed, two opcodes — **`0F 1A`** and **`0F 1B`** — remain ghosts in the machine.\n\nCPUs execute these instructions as valid, multi-byte NOPs. However, leading disassemblers like **IDA Pro, Ghidra, and Binary Ninja** fail to recognize them. They interpret valid, executable code as unknown data, breaking static analysis and creating a simple but highly effective method for anti-disassembly.\n\nThis fundamental issue has remained largely unnoticed for decades.\n\n## How to Test\n\nYou can see the blind spot in action yourself in under a minute.\n\n1.  Grab the pre-compiled binary: `/samples/patched.exe`.\n2.  Open it in your favorite disassembler (IDA, Ghidra, etc.).\n3.  Navigate to the function.\n4.  Observe how the tool fails on the `0F 1A` and `0F 1B` opcodes, showing them as `db 0Fh, 1Ah...`, `undefined`, or `???`, effectively halting the analysis of the function.\n5.  Run `patched.exe`. It will execute flawlessly and print a success message, proving the instructions are valid.\n\n## Repository Structure\n\n-   `/src/`: The C++ source code used to generate the test binary.\n-   `/samples/`\n    -   `patched.exe`: The pre-compiled 64-bit PoC binary.\n-   `/papers/`:\n    -   `ru.pdf`: The full research paper (Russian).\n    -   `en.pdf`: The full research paper (English).\n\n## LICENSE\nMIT\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-13T02:26:57.948103"
  },
  {
    "basic_info": {
      "name": "Bypass_AV",
      "full_name": "hkl1x/Bypass_AV",
      "owner": "hkl1x",
      "description": "免杀木马样本",
      "url": "https://github.com/hkl1x/Bypass_AV",
      "clone_url": "https://github.com/hkl1x/Bypass_AV.git",
      "ssh_url": "git@github.com:hkl1x/Bypass_AV.git",
      "homepage": "",
      "created_at": "2025-10-02T08:21:29Z",
      "updated_at": "2025-10-11T16:05:34Z",
      "pushed_at": "2025-10-11T10:05:48Z"
    },
    "stats": {
      "stars": 89,
      "forks": 13,
      "watchers": 89,
      "open_issues": 1,
      "size": 367
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 40064
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# 这是一个能绕过绝大部分杀软、沙箱的木马样本\n下面我会对木马所涉及的技术进行阐述我会针对shellcode和加载器两方面解释\n## 加载器部分\n### 1.反沙箱 \n#### 众说周知反沙箱的检测常规就是针对主机的cpu、内存、硬盘等操作，但是我个人认为这样不妥因为一些杀软或云沙箱会检测反沙箱功能，会对一些敏感api进行监控从而被抓包，所以我的思路是对桌面的快捷方式检测比如qq、微信、钉钉这些常规使用的软件进行检测逃避云沙箱。\n<img width=\"1918\" height=\"990\" alt=\"vt\" src=\"https://github.com/user-attachments/assets/f6c4d58e-374d-428f-bf0b-73c3ef8233e8\" />\n\n###  2.ntdll的重载和api的动态调用\n\n####  一般杀软的检测机制就是会对一些敏感的api上钩子那么我们通过ntdll的重载和api的动态调用技术就可以绕过钩子实现功能，ntdll重载这一块是从系统目录加载原始 ntdll.dll，将当前进程中被挂钩的 ntdll 代码段（.text 段）替换为原始代码，api动态调用是遍历目标dll的导出表使用hash匹配函数名获取目标函数的地址使用指针执行。\n\n### 3.shellcode和加载器分离\n#### shellcode除了编码绕过杀软还可以和加载器分离，就是shellcode都不在exe里杀软就挺难检测出问题。\n\n## shellcode部分\n### shellcode部分主要多层混淆处理 使用的是XOR+RC4+base64+mac多层处理，最后是mac地址格式存在是windows对mac格式字符串有一定的宽容性。 \n\n## 使用方法\n### 先使用encode.cpp对shellcode进行加密，如果把shellcode写道exe里请在Unseparation_shellcode.cpp的mac_shellcode数组里。如果想实现参数分离可以使用我编译好的exe+shellcode运行即可\n\n#### 感谢阅读\n\n\n\n### English version\n\n\n\nThis is a Trojan sample that can bypass the vast majority of antivirus software and sandboxes. Below, I will explain the technologies involved in the Trojan, focusing on both the shellcode and the loader.\n\n## Loader Section\n### 1. Anti-sandbox\nIt is well-known that the conventional detection of anti-sandbox functions is based on operations on the host's CPU, memory, hard disk, etc. However, I personally think this approach is not ideal because some antivirus software or cloud sandboxes will monitor anti-sandbox functions and keep an eye on sensitive APIs, which may lead to detection. Therefore, my idea is to detect desktop shortcuts, such as those for commonly used software like QQ, WeChat, and DingTalk, to evade cloud sandboxes. <img width=\"1918\" height=\"990\" alt=\"vt\" src=\"https://github.com/user-attachments/assets/f6c4d58e-374d-428f-bf0b-73c3ef8233e8\" />\n\n\n### 2. Overloading of ntdll and Dynamic Invocation of APIs \n\nThe detection mechanism of general anti-virus software is to hook some sensitive APIs. Therefore, we can bypass the hooks and achieve the function by using the ntdll overloading and dynamic API calling techniques. The ntdll overloading part involves loading the original ntdll.dll from the system directory and replacing the hooked ntdll code segment (.text segment) in the current process with the original code. The dynamic API calling is to traverse the export table of the target dll, match the function name using hash, obtain the address of the target function, and execute it using a pointer. \n\n### 3. Separation of Shellcode and Loader\n#### Besides encoding to bypass antivirus software, shellcode can also be separated from the loader. If the shellcode is not included in the exe file, it becomes quite difficult for antivirus software to detect any issues. \n\nThe shellcode section mainly undergoes multi-layer obfuscation processing, which involves XOR, RC4, base64, and MAC. The final output is in MAC address format, taking advantage of Windows' tolerance for MAC format strings. \n\n## Usage Method\n### First, use encode.cpp to encrypt the shellcode. If you write the shellcode into an exe file, please place it in the mac_shellcode array in Unseparation_shellcode.cpp. If you want to achieve parameter separation, you can run the compiled exe + shellcode directly. \n\nThank you for reading.\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-13T02:26:59.063866"
  },
  {
    "basic_info": {
      "name": "orderbook-simulator-cpp",
      "full_name": "SLMolenaar/orderbook-simulator-cpp",
      "owner": "SLMolenaar",
      "description": "A high-performance C++ orderbook engine with microsecond-level latency, supporting multiple ordertypes, price-time priority matching and real time data integration from Binance",
      "url": "https://github.com/SLMolenaar/orderbook-simulator-cpp",
      "clone_url": "https://github.com/SLMolenaar/orderbook-simulator-cpp.git",
      "ssh_url": "git@github.com:SLMolenaar/orderbook-simulator-cpp.git",
      "homepage": "",
      "created_at": "2025-09-30T23:54:28Z",
      "updated_at": "2025-10-13T01:46:53Z",
      "pushed_at": "2025-10-12T22:37:43Z"
    },
    "stats": {
      "stars": 86,
      "forks": 23,
      "watchers": 86,
      "open_issues": 2,
      "size": 112
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 63405,
        "C": 2925,
        "CMake": 2204
      },
      "license": null,
      "topics": [
        "cpp",
        "high-performance",
        "orderbook",
        "quantitative-finance"
      ]
    },
    "content": {
      "readme": "# High-Performance Order Book Engine\n\nA low-latency limit order book implementation in C++20 with real-time market data integration. Built to handle\nhigh-frequency trading workloads with microsecond-level latency.\n\n## Overview\n\nThis project implements a matching engine and order book that supports multiple order types, priority-based matching,\nand real-time market data processing. The architecture is designed for performance-critical applications where latency\nmatters.\n\n**Key metrics:**\n\n- Order insertion: ~400,000 orders/sec\n- Order matching: ~350,000 matches/sec\n- Order cancellation: ~2,000,000 cancels/sec\n- Average operation latency: 2-4 μs\n\n## Features\n\n### Core Order Book\n\n- **Order Types**: GoodTillCancel, Market, ImmediateOrCancel, FillOrKill, GoodForDay\n- **Matching Algorithm**: Price-time priority (FIFO within price levels)\n- **Data Structures**: O(1) order lookup, O(log n) price level access\n- **Trade Execution**: Automatic matching with partial fill support\n\n### Market Data Feed\n\n- Real-time orderbook snapshots via Binance REST API\n- Incremental update processing (new orders, cancellations, modifications)\n- Batch message processing for improved throughput\n- Sequence number tracking for gap detection\n- Latency monitoring and statistics\n\n### Live Market Display\n\n- Real-time visualization of cryptocurrency orderbooks\n- Configurable refresh rates and depth levels\n- Bid-ask spread analysis and mid-price calculation\n- Market microstructure metrics\n\n<img width=\"511\" height=\"930\" alt=\"image\" src=\"https://github.com/user-attachments/assets/12dabc82-3a85-4cf9-8198-379178578fc4\" />\n\n## Build Instructions\n\n### Requirements\n\n- CMake 3.10+\n- C++20 compatible compiler (GCC 10+, Clang 10+, MSVC 2019+)\n- Dependencies (automatically fetched via CMake):\n- libcurl 8.4.0\n- nlohmann/json 3.11.3\n\n### Build\n\n```bash\nmkdir build && cd build\ncmake ..\ncmake --build . --config Release\n```\n\n### Run\n\n```bash\n# Run functionality and performance tests\n./OrderBookTests\n\n# Live cryptocurrency orderbook\n./LiveMarketData SOLUSDT 1 20\n# Args: [SYMBOL] [REFRESH_SECONDS] [DEPTH_LEVELS]\n```\n\n## Architecture\n\n### Class Diagram\n\n```mermaid\nclassDiagram\n    %% Core Type Aliases\n    class Types {\n        <<typedef>>\n        +Price: int32_t\n        +Quantity: uint32_t\n        +OrderId: uint64_t\n    }\n\n    %% Enumerations\n    class OrderType {\n        <<enumeration>>\n        GoodTillCancel\n        ImmediateOrCancel\n        Market\n        GoodForDay\n        FillOrKill\n    }\n\n    class Side {\n        <<enumeration>>\n        Buy\n        Sell\n    }\n\n    class MessageType {\n        <<enumeration>>\n        NewOrder\n        CancelOrder\n        ModifyOrder\n        Trade\n        BookSnapshot\n    }\n\n    %% Constants\n    class Constants {\n        <<static>>\n        +InvalidPrice: Price\n    }\n\n    %% Order Classes\n    class Order {\n        -orderType_: OrderType\n        -orderId_: OrderId\n        -side_: Side\n        -price_: Price\n        -initialQuantity_: Quantity\n        -remainingQuantity_: Quantity\n        +Order(OrderType, OrderId, Side, Price, Quantity)\n        +Order(OrderId, Side, Quantity)\n        +GetOrderId(): OrderId\n        +GetSide(): Side\n        +GetPrice(): Price\n        +GetOrderType(): OrderType\n        +GetInitialQuantity(): Quantity\n        +GetRemainingQuantity(): Quantity\n        +GetFilledQuantity(): Quantity\n        +IsFilled(): bool\n        +Fill(Quantity): void\n        +ToGoodTillCancel(Price): void\n    }\n\n    class OrderModify {\n        -orderId_: OrderId\n        -price_: Price\n        -side_: Side\n        -quantity_: Quantity\n        +OrderModify(OrderId, Side, Price, Quantity)\n        +GetOrderId(): OrderId\n        +GetPrice(): Price\n        +GetSide(): Side\n        +GetQuantity(): Quantity\n        +ToOrderPointer(OrderType): OrderPointer\n    }\n\n    %% Trade Classes\n    class TradeInfo {\n        +orderId_: OrderId\n        +price_: Price\n        +quantity_: Quantity\n    }\n\n    class Trade {\n        -bidTrade_: TradeInfo\n        -askTrade_: TradeInfo\n        +Trade(TradeInfo, TradeInfo)\n        +GetBidTrade(): TradeInfo\n        +GetAskTrade(): TradeInfo\n    }\n\n    %% Level Info Classes\n    class LevelInfo {\n        +price_: Price\n        +quantity_: Quantity\n    }\n\n    class OrderbookLevelInfos {\n        -bids_: LevelInfos\n        -asks_: LevelInfos\n        +OrderbookLevelInfos(LevelInfos, LevelInfos)\n        +GetBids(): LevelInfos\n        +GetAsks(): LevelInfos\n    }\n\n    %% Market Data Messages\n    class NewOrderMessage {\n        +type: MessageType\n        +orderId: OrderId\n        +side: Side\n        +price: Price\n        +quantity: Quantity\n        +orderType: OrderType\n        +timestamp: time_point\n    }\n\n    class CancelOrderMessage {\n        +type: MessageType\n        +orderId: OrderId\n        +timestamp: time_point\n    }\n\n    class ModifyOrderMessage {\n        +type: MessageType\n        +orderId: OrderId\n        +side: Side\n        +newPrice: Price\n        +newQuantity: Quantity\n        +timestamp: time_point\n    }",
      "default_branch": "master"
    },
    "fetched_at": "2025-10-13T02:27:00.185905"
  }
]