## ğŸ“ çƒ­ç‚¹é¡¹ç›®-20260222-python

<div style="background-color: #f5f5f5; padding: 15px; border-radius: 8px; margin: 20px 0;">
- ğŸ¤– æœ¬æŠ¥å‘ŠåŸºäº GitHub API è‡ªåŠ¨ç”Ÿæˆ
- ğŸ“… æ•°æ®æ›´æ–°æ—¶é—´: 2026-02-22 11:32:41 (ä¸Šæµ·æ—¶åŒº)
- ğŸŒŸ æ˜Ÿæ ‡æ•°ç­‰ç»Ÿè®¡ä¿¡æ¯ä¸ºç”Ÿæˆæ—¶çš„å®æ—¶æ•°æ®
- ğŸ“š é¡¹ç›®ä¿¡æ¯æ¥æºäºå„é¡¹ç›®çš„ README æ–‡æ¡£
- ğŸ’¡ çƒ­åº¦æŒ‡æ•°è®¡ç®—æ–¹å¼: æ˜Ÿæ ‡æ•° + Forkæ•° Ã— 0.5
- æœ¬æŠ¥å‘Šç”± ä¸‰å­å¶å¼€æº github-trendingé¡¹ç›®åˆ†æå·¥å…·è‡ªåŠ¨ç”Ÿæˆ
</div>

## ğŸ”— ç›¸å…³é“¾æ¥

- [GitHub API æ–‡æ¡£](https://docs.github.com/en/rest)
- [é¡¹ç›®æ•°æ®è·å–å™¨æºç ](https://github.com/3ziye/github-trending)

---

# çƒ­ç‚¹é¡¹ç›®-20260222-python

<div align="center">
ğŸ“Š <strong>ç”Ÿæˆæ—¶é—´</strong>: 2026å¹´02æœˆ22æ—¥ 11:32  â€¢  
ğŸ¯ <strong>é¡¹ç›®æ•°é‡</strong>: 20 ä¸ª  â€¢  
â±ï¸ <strong>çƒ­åº¦æ—¶é—´</strong>: æœˆæ¦œ  â€¢  
ğŸ”¥ <strong>æ•°æ®æ¥æº</strong>: GitHub API
</div>

---

## ğŸš€ çƒ­é—¨é¡¹ç›®è¯¦æƒ…

### 1. nanobot

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 24,566

**é¡¹ç›®åç§°**: [HKUDS/nanobot](https://github.com/HKUDS/nanobot)
**é¡¹ç›®æè¿°**: "ğŸˆ nanobot: The Ultra-Lightweight OpenClaw"
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: MIT License
**â­ æ˜Ÿæ ‡æ•°**: 22,797
**ğŸ´ Fork æ•°**: 3,538
**ğŸ‘€ å…³æ³¨æ•°**: 22,797
**ğŸ› å¼€æ”¾é—®é¢˜**: 563
**æœ€åæ›´æ–°**: 2026-02-22 (0åˆ†é’Ÿå‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20260222-python/1-nanobot-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: æ— 

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/HKUDS/nanobot.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
**2026-02-21** ğŸ‰ Released **v0.1.4.post1** â€” new providers, media support across channels, and major stability improvements. See [release notes](https://github.com/HKUDS/nanobot/releases/tag/v0.1.4.post1) for details.
**2026-02-20** ğŸ¦ Feishu now receives multimodal files from users. More reliable memory under the hood.
**2026-02-19** âœ¨ Slack now sends files, Discord splits long messages, and subagents work in CLI mode.
**2026-02-18** âš¡ï¸ nanobot now supports VolcEngine, MCP custom auth headers, and Anthropic prompt caching.
**2026-02-17** ğŸ‰ Released **v0.1.4** â€” MCP support, progress streaming, new providers, and multiple channel improvements. Please see [release notes](https://github.com/HKUDS/nanobot/releases/tag/v0.1.4) for details.
**2026-02-16** ğŸ¦ nanobot now integrates a [ClawHub](https://clawhub.ai) skill â€” search and install public agent skills.
**2026-02-15** ğŸ”‘ nanobot now supports OpenAI Codex provider with OAuth login support.
**2026-02-14** ğŸ”Œ nanobot now supports MCP! See [MCP section](#mcp-model-context-protocol) for details.

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 2. knowledge-work-plugins

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 8,058

**é¡¹ç›®åç§°**: [anthropics/knowledge-work-plugins](https://github.com/anthropics/knowledge-work-plugins)
**é¡¹ç›®æè¿°**: Open source repository of plugins primarily intended for knowledge workers to use in Claude Cowork
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: Apache License 2.0
**â­ æ˜Ÿæ ‡æ•°**: 7,671
**ğŸ´ Fork æ•°**: 775
**ğŸ‘€ å…³æ³¨æ•°**: 7,671
**ğŸ› å¼€æ”¾é—®é¢˜**: 45
**æœ€åæ›´æ–°**: 2026-02-22 (24åˆ†é’Ÿå‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20260222-python/2-knowledge-work-plugins-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: æ— 

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/anthropics/knowledge-work-plugins.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 3. ClawWork

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 5,176

**é¡¹ç›®åç§°**: [HKUDS/ClawWork](https://github.com/HKUDS/ClawWork)
**é¡¹ç›®æè¿°**: "ClawWork: OpenClaw as Your AI Coworker - ğŸ’° $10K earned in 7 Hours"
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: MIT License
**â­ æ˜Ÿæ ‡æ•°**: 4,879
**ğŸ´ Fork æ•°**: 595
**ğŸ‘€ å…³æ³¨æ•°**: 4,879
**ğŸ› å¼€æ”¾é—®é¢˜**: 7
**æœ€åæ›´æ–°**: 2026-02-22 (1åˆ†é’Ÿå‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20260222-python/3-ClawWork-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: æ— 

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/HKUDS/ClawWork.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
**2026-02-21 ğŸ”„ ClawMode + Frontend + Agents Update** â€” Updated ClawMode to support ClawWork-specific tools; improved frontend dashboard (untapped potential visualization); added more agents: Claude Sonnet 4.6, Gemini 3.1 Pro and Qwen-3.5-Plus.
**2026-02-20 ğŸ’° Improved Cost Tracking** â€” Token costs are now read directly from various API responses (including thinking tokens) instead of estimation. OpenRouter's reported cost is used verbatim when available.
**2026-02-19 ğŸ“Š Agent Results Updated** â€” Added Qwen3-

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 4. lingbot-world

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 3,035

**é¡¹ç›®åç§°**: [Robbyant/lingbot-world](https://github.com/Robbyant/lingbot-world)
**é¡¹ç›®æè¿°**: Advancing Open-source World Models
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: Apache License 2.0
**â­ æ˜Ÿæ ‡æ•°**: 2,917
**ğŸ´ Fork æ•°**: 237
**ğŸ‘€ å…³æ³¨æ•°**: 2,917
**ğŸ› å¼€æ”¾é—®é¢˜**: 20
**æœ€åæ›´æ–°**: 2026-02-22 (1åˆ†é’Ÿå‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20260222-python/4-lingbot-world-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: https://technology.robbyant.com/lingbot-world

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/Robbyant/lingbot-world.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ·ï¸ é¡¹ç›®æ ‡ç­¾
- `aigc`
- `image-to-video`
- `lingbot-world`
- `video-generation`
- `world-models`

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
**High-Fidelity & Diverse Environments**: It maintains high fidelity and robust dynamics in a broad spectrum of environments, including realism, scientific contexts, cartoon styles, and beyond.
**Long-Term Memory & Consistency**: It enables a minute-level horizon while preserving contextual consistency over time, which is also known as long-term memory.
- Jan 29, 2026: ğŸ‰ We release the technical report, code, and models for LingBot-World.
- It maintains high fidelity and robust dynamics in a broad spectrum of environments, including realism, scientific contexts, cartoon styles, and beyond.
- It enables a minute-level horizon while preserving contextual consistency over time, which is also known as **long-term memory**.

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 5. last30days-skill

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 3,057

**é¡¹ç›®åç§°**: [mvanhorn/last30days-skill](https://github.com/mvanhorn/last30days-skill)
**é¡¹ç›®æè¿°**: Claude Code skill that researches any topic across Reddit + X from the last 30 days, then writes copy-paste-ready prompt...
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: None
**â­ æ˜Ÿæ ‡æ•°**: 2,889
**ğŸ´ Fork æ•°**: 337
**ğŸ‘€ å…³æ³¨æ•°**: 2,889
**ğŸ› å¼€æ”¾é—®é¢˜**: 18
**æœ€åæ›´æ–°**: 2026-02-22 (31åˆ†é’Ÿå‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20260222-python/5-last30days-skill-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: æ— 

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/mvanhorn/last30days-skill.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ·ï¸ é¡¹ç›®æ ‡ç­¾
- `ai-prompts`
- `claude`
- `claude-code`
- `reddit`
- `twitter`

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 6. Trellis

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 2,437

**é¡¹ç›®åç§°**: [mindfold-ai/Trellis](https://github.com/mindfold-ai/Trellis)
**é¡¹ç›®æè¿°**: All-in-one AI framework & toolkit
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: GNU Affero General Public License v3.0
**â­ æ˜Ÿæ ‡æ•°**: 2,378
**ğŸ´ Fork æ•°**: 118
**ğŸ‘€ å…³æ³¨æ•°**: 2,378
**ğŸ› å¼€æ”¾é—®é¢˜**: 1
**æœ€åæ›´æ–°**: 2026-02-22 (21åˆ†é’Ÿå‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20260222-python/6-Trellis-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: https://trytrellis.app

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/mindfold-ai/Trellis.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ·ï¸ é¡¹ç›®æ ‡ç­¾
- `ai-agent`
- `ai-coding`
- `claude-code`
- `cli`
- `codex`
- `cursor`
- `developer-tools`
- `typescript`

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘
- å‘½ä»¤è¡Œå·¥å…·å¼€å‘

---

### 7. DeepSeek-OCR-2

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 2,408

**é¡¹ç›®åç§°**: [deepseek-ai/DeepSeek-OCR-2](https://github.com/deepseek-ai/DeepSeek-OCR-2)
**é¡¹ç›®æè¿°**: Visual Causal Flow
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: Apache License 2.0
**â­ æ˜Ÿæ ‡æ•°**: 2,319
**ğŸ´ Fork æ•°**: 179
**ğŸ‘€ å…³æ³¨æ•°**: 2,319
**ğŸ› å¼€æ”¾é—®é¢˜**: 46
**æœ€åæ›´æ–°**: 2026-02-22 (5åˆ†é’Ÿå‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20260222-python/7-DeepSeek-OCR-2-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: æ— 

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/deepseek-ai/DeepSeek-OCR-2.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
- [Install](#install)
- [vLLM Inference](#vllm-inference)
- [Transformers Inference](#transformers-inference)
- download the vllm-0.8.5 [whl](https://github.com/vllm-project/vllm/releases/tag/v0.8.5)
- VLLM:

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 8. GLM-OCR

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 1,770

**é¡¹ç›®åç§°**: [zai-org/GLM-OCR](https://github.com/zai-org/GLM-OCR)
**é¡¹ç›®æè¿°**: GLM-OCR: Accurate Ã—  Fast Ã— Comprehensive
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: Apache License 2.0
**â­ æ˜Ÿæ ‡æ•°**: 1,710
**ğŸ´ Fork æ•°**: 120
**ğŸ‘€ å…³æ³¨æ•°**: 1,710
**ğŸ› å¼€æ”¾é—®é¢˜**: 35
**æœ€åæ›´æ–°**: 2026-02-22 (1å°æ—¶å‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20260222-python/8-GLM-OCR-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: æ— 

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/zai-org/GLM-OCR.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ·ï¸ é¡¹ç›®æ ‡ç­¾
- `glm`
- `image2text`
- `ocr`

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
**Optimized for Real-World Scenarios**: Designed and optimized for practical business use cases, maintaining robust performance on complex tables, code-heavy documents, seals, and other challenging real-world layouts.
**Efficient Inference**: With only 0.9B parameters, GLM-OCR supports deployment via vLLM, SGLang, and Ollama, significantly reducing inference latency and compute cost, making it ideal for high-concurrency services and edge deployments.
**Easy to Use**: Fully open-sourced and equipped with a comprehensive [SDK](https://github.com/zai-org/GLM-OCR) and inference toolchain, offering simple installation, one-line invocation, and smooth integration into existing production pipelines.
**[Coming Soon]** GLM-OCR Technical Report
**[2026.2.12]** Fine-tuning tutorial based on LLaMA-Factory is now available. See: [GLM-OCR Fine-tuning Guide](examples/finetune/README.md)

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 9. dash

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 1,790

**é¡¹ç›®åç§°**: [agno-agi/dash](https://github.com/agno-agi/dash)
**é¡¹ç›®æè¿°**: Self-learning data agent that grounds its answers in 6 layers of context. Inspired by OpenAI's in-house implementation.
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: Apache License 2.0
**â­ æ˜Ÿæ ‡æ•°**: 1,697
**ğŸ´ Fork æ•°**: 186
**ğŸ‘€ å…³æ³¨æ•°**: 1,697
**ğŸ› å¼€æ”¾é—®é¢˜**: 7
**æœ€åæ›´æ–°**: 2026-02-22 (2å°æ—¶å‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20260222-python/9-dash-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: æ— 

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/agno-agi/dash.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
- Who won the most F1 World Championships?
- How many races has Lewis Hamilton won?
- Compare Ferrari vs Mercedes points 2015-2020
**Schemas lack meaning.**
**Types are misleading.**
**Tribal knowledge is missing.**
**No way to learn from mistakes.**
**Results generally lack interpretation.**

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 10. Qwen3-ASR

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 1,668

**é¡¹ç›®åç§°**: [QwenLM/Qwen3-ASR](https://github.com/QwenLM/Qwen3-ASR)
**é¡¹ç›®æè¿°**: Qwen3-ASR is an open-source series of ASR models developed by the Qwen team at Alibaba Cloud, supporting stable multilin...
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: Apache License 2.0
**â­ æ˜Ÿæ ‡æ•°**: 1,600
**ğŸ´ Fork æ•°**: 136
**ğŸ‘€ å…³æ³¨æ•°**: 1,600
**ğŸ› å¼€æ”¾é—®é¢˜**: 33
**æœ€åæ›´æ–°**: 2026-02-22 (57åˆ†é’Ÿå‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20260222-python/10-Qwen3-ASR-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: æ— 

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/QwenLM/Qwen3-ASR.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
- 2026.1.29: ğŸ‰ğŸ‰ğŸ‰ We have released the [Qwen3-ASR](https://huggingface.co/collections/Qwen/qwen3-asr) series (0.6B/1.7B) and the Qwen3-ForcedAligner-0.6B model. Please check out our [blog](https://qwen.ai/blog?id=qwen3asr)!
- [Overview](#overview)
- [Quickstart](#quickstart)
- [Launch Local Web UI Demo](#launch-local-web-ui-demo)
- [Deployment with vLLM](#deployment-with-vllm)
- [Fine Tuning](#fine-tuning)
- [Docker](#docker)
- [Evaluation](#evaluation)

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 11. claude-seo

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 1,100

**é¡¹ç›®åç§°**: [AgriciDaniel/claude-seo](https://github.com/AgriciDaniel/claude-seo)
**é¡¹ç›®æè¿°**:  Universal SEO skill for Claude Code. Comprehensive SEO analysis for any website or business type.
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: MIT License
**â­ æ˜Ÿæ ‡æ•°**: 1,024
**ğŸ´ Fork æ•°**: 152
**ğŸ‘€ å…³æ³¨æ•°**: 1,024
**ğŸ› å¼€æ”¾é—®é¢˜**: 4
**æœ€åæ›´æ–°**: 2026-02-22 (1å°æ—¶å‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20260222-python/11-claude-seo-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: https://www.skool.com/ai-marketing-hub-pro

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/AgriciDaniel/claude-seo.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ·ï¸ é¡¹ç›®æ ‡ç­¾
- `ai-tools`
- `claude`
- `claude-code`
- `core-web-vitals`
- `schema-markup`
- `seo`
- `seo-audit`
- `seo-tools`

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
- ### Core Web Vitals (Current Metrics)
- **LCP** (Largest Contentful Paint): Target < 2.5s
- **INP** (Interaction to Next Paint): Target < 200ms
- **CLS** (Cumulative Layout Shift): Target < 0.1
- > Note: INP replaced FID on March 12, 2024. FID was fully removed from all Chrome tools on September 9, 2024.

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 12. claw-compactor

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 1,007

**é¡¹ç›®åç§°**: [aeromomo/claw-compactor](https://github.com/aeromomo/claw-compactor)
**é¡¹ç›®æè¿°**: ğŸ¦ Claw Compactor â€” The 98% Crusher. Cut your AI agent token spend in half with 5 layered compression techniques.
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: MIT License
**â­ æ˜Ÿæ ‡æ•°**: 967
**ğŸ´ Fork æ•°**: 81
**ğŸ‘€ å…³æ³¨æ•°**: 967
**ğŸ› å¼€æ”¾é—®é¢˜**: 1
**æœ€åæ›´æ–°**: 2026-02-22 (1å°æ—¶å‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20260222-python/12-claw-compactor-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: æ— 

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/aeromomo/claw-compactor.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
- **5 compression layers** working in sequence for maximum savings
- **Zero LLM cost** â€” all compression is rule-based and deterministic
- **Lossless roundtrip** for dictionary, RLE, and rule-based compression
- **~97% savings** on session transcripts via observation extraction
- **Tiered summaries** (L0/L1/L2) for progressive context loading
- **CJK-aware** â€” full Chinese/Japanese/Korean support
- **One command** (`full`) runs everything in optimal order

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 13. skill-scanner

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 969

**é¡¹ç›®åç§°**: [cisco-ai-defense/skill-scanner](https://github.com/cisco-ai-defense/skill-scanner)
**é¡¹ç›®æè¿°**: Security Scanner for Agent Skills
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: Other
**â­ æ˜Ÿæ ‡æ•°**: 918
**ğŸ´ Fork æ•°**: 102
**ğŸ‘€ å…³æ³¨æ•°**: 918
**ğŸ› å¼€æ”¾é—®é¢˜**: 8
**æœ€åæ›´æ–°**: 2026-02-22 (10åˆ†é’Ÿå‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20260222-python/13-skill-scanner-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: https://blogs.cisco.com/ai/personal-ai-agents-like-moltbot-are-a-security-nightmare

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/cisco-ai-defense/skill-scanner.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ·ï¸ é¡¹ç›®æ ‡ç­¾
- `agent`
- `agent-skills`
- `security`

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
- **Multi-Engine Detection** - Static analysis, behavioral dataflow, LLM semantic analysis, and cloud-based scanning for layered, best-effort coverage
- **False Positive Filtering** - Meta-analyzer significantly reduces noise while preserving detection capability
- **CI/CD Ready** - SARIF output for GitHub Code Scanning, exit codes for build failures
- **Extensible** - Plugin architecture for custom analyzers
**[Join the Cisco AI Discord](https://discord.com/invite/nKWtDcXxtx)** to discuss, share feedback, or connect with the team.
---

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 14. skill-compose

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 941

**é¡¹ç›®åç§°**: [MooseGoose0701/skill-compose](https://github.com/MooseGoose0701/skill-compose)
**é¡¹ç›®æè¿°**: Skill Compose is an open-source agent builder and runtime platform for skill-powered agents. No workflow graphs. No CLI.
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: Apache License 2.0
**â­ æ˜Ÿæ ‡æ•°**: 903
**ğŸ´ Fork æ•°**: 76
**ğŸ‘€ å…³æ³¨æ•°**: 903
**ğŸ› å¼€æ”¾é—®é¢˜**: 2
**æœ€åæ›´æ–°**: 2026-02-22 (0åˆ†é’Ÿå‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20260222-python/14-skill-compose-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: æ— 

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/MooseGoose0701/skill-compose.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
- ğŸ§© **Skills as first-class artifacts** â€” versioned, reviewable skill packages (contracts, references, rubrics, helpers), not brittle graphs.
- ğŸ§  **"Skill-Compose My Agent" workflow** â€” describe what you want; Skill Compose finds/reuses skills, drafts missing ones, and composes an agent.
- ğŸ”Œ **Tool + MCP wiring** â€” connect tools and MCP servers without hand-writing glue code.
- ğŸš€ **Instant publishing** â€” one click to ship as **Web Chat** (shareable link) and/or **API** (integrations-ready endpoint).
- ğŸ›¡ï¸ **Container-first isolation** â€” run agents in containers (or K8s pods) to keep hosts clean and execution reproducible.
- ğŸ§± **Executors for heavy environments** â€” assign custom Docker images/K8s runtimes per agent (GPU/ML/HPC stacks, custom builds).
- ğŸ“¦ **Skill lifecycle management** â€” GitHub import + one-click updates, multi-format import/export, version history, diff/rollback, and local sync.
- ğŸ”„ **Skill evolution from reality** â€” improve skills using feedback + execution traces, with proposed rewrites you can review.

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 15. FastCode

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 947

**é¡¹ç›®åç§°**: [HKUDS/FastCode](https://github.com/HKUDS/FastCode)
**é¡¹ç›®æè¿°**: "FastCode: Accelerating and Streamlining Your Code Understanding"
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: None
**â­ æ˜Ÿæ ‡æ•°**: 895
**ğŸ´ Fork æ•°**: 105
**ğŸ‘€ å…³æ³¨æ•°**: 895
**ğŸ› å¼€æ”¾é—®é¢˜**: 5
**æœ€åæ›´æ–°**: 2026-02-22 (6å°æ—¶å‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20260222-python/15-FastCode-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: æ— 

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/HKUDS/FastCode.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
- 3-4x Faster than competitors (Cursor/Claude Code)
- 44-55% Cost Reduction compared to alternatives
- Highest Accuracy Score across benchmarks
- Up to 10x Token Savings through smart navigation
- Large-Scale Repository Analysis - Handle massive codebases efficiently
- Multi-Language Support - Python, JavaScript, TypeScript, Java, Go, C/C++, Rust, C#
- Multi-Repository Reasoning - Cross-repo dependency analysis
- Small Model Support - Local model compatibility (qwen3-coder-30b)

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 16. lingbot-depth

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 905

**é¡¹ç›®åç§°**: [Robbyant/lingbot-depth](https://github.com/Robbyant/lingbot-depth)
**é¡¹ç›®æè¿°**: Masked Depth Modeling for Spatial Perception
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: Apache License 2.0
**â­ æ˜Ÿæ ‡æ•°**: 874
**ğŸ´ Fork æ•°**: 63
**ğŸ‘€ å…³æ³¨æ•°**: 874
**ğŸ› å¼€æ”¾é—®é¢˜**: 4
**æœ€åæ›´æ–°**: 2026-02-22 (9å°æ—¶å‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20260222-python/16-lingbot-depth-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: https://technology.robbyant.com/lingbot-depth

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/Robbyant/lingbot-depth.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ·ï¸ é¡¹ç›®æ ‡ç­¾
- `depth`
- `depth-camera`
- `masked-image-modeling`

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
**Depth Completion & Refinement**: Fills missing regions with metric accuracy and improved quality
**Scene Reconstruction**: High-fidelity indoor mapping with a strong depth prior
**4D Point Tracking**: Accurate dynamic tracking in metric space for robot learning
**Dexterous Manipulation**: Robust grasping with precise geometric understanding
**[2026.02.15]** Upload LingBot-Depth-v0.5 which fixes the bug in previous version.
- The curated 3

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 17. noodles

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 920

**é¡¹ç›®åç§°**: [unslop-xyz/noodles](https://github.com/unslop-xyz/noodles)
**é¡¹ç›®æè¿°**: Your codebase was probably AI-generated. Get a better handle on it. Noodles creates interactive diagrams that visualize ...
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: MIT License
**â­ æ˜Ÿæ ‡æ•°**: 864
**ğŸ´ Fork æ•°**: 113
**ğŸ‘€ å…³æ³¨æ•°**: 864
**ğŸ› å¼€æ”¾é—®é¢˜**: 2
**æœ€åæ›´æ–°**: 2026-02-20 (1å¤©å‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20260222-python/17-noodles-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: æ— 

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/unslop-xyz/noodles.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
- Scans a folder and builds a manifest of your code
- Uses OpenAI to identify user-facing entry points (CLI commands, routes, UI components)
- Generates D2 diagrams showing how code flows from entry to outcome
- Renders an interactive overlay to explore the diagrams
- Tracks changes and updates diagrams incrementally when code changes
- Python 3.9+
- [uv](https://docs.astral.sh/uv/) (recommended) or pip
- [d2](https://d2lang.com/) CLI for diagram rendering

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 18. paperbanana

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 915

**é¡¹ç›®åç§°**: [llmsresearch/paperbanana](https://github.com/llmsresearch/paperbanana)
**é¡¹ç›®æè¿°**: Open source implementation and extension of Google Researchâ€™s PaperBanana for automated academic figures, diagrams, and ...
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: MIT License
**â­ æ˜Ÿæ ‡æ•°**: 853
**ğŸ´ Fork æ•°**: 124
**ğŸ‘€ å…³æ³¨æ•°**: 853
**ğŸ› å¼€æ”¾é—®é¢˜**: 11
**æœ€åæ›´æ–°**: 2026-02-22 (1åˆ†é’Ÿå‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20260222-python/18-paperbanana-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: æ— 

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/llmsresearch/paperbanana.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ·ï¸ é¡¹ç›®æ ‡ç­¾
- `academic-diagrams`
- `academic-research`
- `agentic-ai`
- `arxiv`
- `diagram-generation`
- `gemini`
- `google-gemini`
- `llm`

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
- Two-phase multi-agent pipeline with iterative refinement
- Multiple VLM and image generation providers (OpenAI, Azure, Gemini)
- Input optimization layer for bet

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 19. lingbot-vla

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 856

**é¡¹ç›®åç§°**: [Robbyant/lingbot-vla](https://github.com/Robbyant/lingbot-vla)
**é¡¹ç›®æè¿°**: A Pragmatic VLA Foundation Model
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: Apache License 2.0
**â­ æ˜Ÿæ ‡æ•°**: 825
**ğŸ´ Fork æ•°**: 62
**ğŸ‘€ å…³æ³¨æ•°**: 825
**ğŸ› å¼€æ”¾é—®é¢˜**: 16
**æœ€åæ›´æ–°**: 2026-02-22 (27åˆ†é’Ÿå‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20260222-python/19-lingbot-vla-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: æ— 

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/Robbyant/lingbot-vla.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ¯ æ ¸å¿ƒç‰¹æ€§
**Large-scale Pre-training Data**: 20,000 hours of real-world
**Strong Performance**: Achieve clear superiority over competitors on simulation and real-world benchmarks.
**Training Efficiency**: Represent a 1.5 âˆ¼ 2.8Ã— (depending on the relied VLM base model) speedup over existing VLA-oriented codebases.
**[2026-01-27]** LingBot-VLA Technical Report is available on Arxiv.
**[2026-01-27]** Weights and code released!
**Pretrained Checkpoints for Post-Training with and without depth**

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---

### 20. OpenPlanter

**ğŸ”¥ çƒ­åº¦æŒ‡æ•°**: 865

**é¡¹ç›®åç§°**: [ShinMegamiBoson/OpenPlanter](https://github.com/ShinMegamiBoson/OpenPlanter)
**é¡¹ç›®æè¿°**: æš‚æ— æè¿°
**ä¸»è¦è¯­è¨€**: Python
**è®¸å¯è¯**: MIT License
**â­ æ˜Ÿæ ‡æ•°**: 806
**ğŸ´ Fork æ•°**: 118
**ğŸ‘€ å…³æ³¨æ•°**: 806
**ğŸ› å¼€æ”¾é—®é¢˜**: 9
**æœ€åæ›´æ–°**: 2026-02-22 (4åˆ†é’Ÿå‰)
**ğŸ“– é¡¹ç›®æ–‡æ¡£**: [README](3ziye-20260222-python/20-OpenPlanter-Readme.md)

**ğŸ  é¡¹ç›®ä¸»é¡µ**: æ— 

**ğŸ“‚ å…‹éš†åœ°å€**: `https://github.com/ShinMegamiBoson/OpenPlanter.git`

**ğŸ’» æŠ€æœ¯æ ˆ**: **ä¸»è¦è¯­è¨€**: Python

#### ğŸ¨ é€‚ç”¨åœºæ™¯
- æ•°æ®ç§‘å­¦ä¸åˆ†æ
- æœºå™¨å­¦ä¹ é¡¹ç›®
- Web åº”ç”¨å¼€å‘

---