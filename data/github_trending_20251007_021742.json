[
  {
    "basic_info": {
      "name": "oq",
      "full_name": "plutov/oq",
      "owner": "plutov",
      "description": "Terminal OpenAPI Spec viewer",
      "url": "https://github.com/plutov/oq",
      "clone_url": "https://github.com/plutov/oq.git",
      "ssh_url": "git@github.com:plutov/oq.git",
      "homepage": "",
      "created_at": "2025-09-12T14:04:46Z",
      "updated_at": "2025-10-06T21:17:09Z",
      "pushed_at": "2025-10-04T19:15:44Z"
    },
    "stats": {
      "stars": 853,
      "forks": 14,
      "watchers": 853,
      "open_issues": 5,
      "size": 1943
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 45041
      },
      "license": "MIT License",
      "topics": [
        "hacktoberfest"
      ]
    },
    "content": {
      "readme": "# oq - a terminal-based OpenAPI Spec (OAS) viewer\n\n<p align=\"center\"><img src=\"preview.gif\" width=\"500\" alt=\"oq preview\"></p>\n\n## Usage\n\n```bash\noq openapi.yaml\n# or\ncat openapi.yaml | oq\n# or\ncurl https://api.example.com/openapi.json | oq\n```\n\n### Keyboard Shortcuts\n\nPress `?` to see the help screen with all available keyboard shortcuts.\n\n## OpenAPI Support\n\n`oq` supports all 3.* OpenAPI specification versions:\n\n- 3.0\n- 3.1\n- 3.2\n\nBoth JSON and YAML formats are supported.\n\nNote: `oq` uses the [libopenapi](https://github.com/pb33f/libopenapi) library as it supports all OpenAPI versions and is actively maintained.\n\n## Installation\n\nUsing go install:\n\n```bash\ngo install github.com/plutov/oq@latest\n```\n\n<details>\n<summary>Package managers</summary>\n\nUsing Homebrew (macOS/Linux):\n\n```bash\nbrew install plutov/tap/oq\n```\n\nArch Linux (AUR):\n\n```bash\nyay -S oq-openapi-viewer-git\n```\n\n</details>\n\nYou can also download the compiled binaries from the Releases page.\n\n### From source\n\n```bash\ngit clone git@github.com:plutov/oq.git\ncd oq\ngo build -o oq .\n```\n\n## License\n\nMIT License - see [LICENSE](LICENSE) file for details.\n\n## Contributing\n\nContributions are welcome! Please feel free to submit issues and pull requests.\n\nWhen contributing:\n\n1. Ensure tests pass: `go test -v`\n2. Test all supported OpenAPI versions (3.0, 3.1, 3.2)\n3. If the UI changes, make sure to run `vhs preview.tape` to generate a new preview GIF\n4. Try to extend test coverage by introducing new example OpenAPI specs in the `examples` folder\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-07T02:17:43.912450"
  },
  {
    "basic_info": {
      "name": "blades",
      "full_name": "go-kratos/blades",
      "owner": "go-kratos",
      "description": "Blades is a Go-based multimodal AI Agent framework.",
      "url": "https://github.com/go-kratos/blades",
      "clone_url": "https://github.com/go-kratos/blades.git",
      "ssh_url": "git@github.com:go-kratos/blades.git",
      "homepage": "",
      "created_at": "2025-09-15T16:43:22Z",
      "updated_at": "2025-10-06T04:41:21Z",
      "pushed_at": "2025-10-06T04:41:17Z"
    },
    "stats": {
      "stars": 489,
      "forks": 49,
      "watchers": 489,
      "open_issues": 27,
      "size": 555
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 70757
      },
      "license": "MIT License",
      "topics": [
        "agent",
        "agentic-framework",
        "agentic-workflow",
        "ai",
        "golang",
        "workflow"
      ]
    },
    "content": {
      "readme": "## Blades\nBlades is a multimodal AI Agent framework in Go, supporting custom models, tools, memory, middleware, and more. It is well-suited for multi-turn conversations, chain reasoning, and structured output.\n> The name comes from the game God of War, set in Greek mythology, which tells the story of Kratos, who becomes a god of war and embarks on a divine slaughter. Blades are Kratos's iconic weapons.\n\n## Architecture Design\nBlades leverages the characteristics of Go to provide a flexible and efficient AI Agent solution. Its core lies in achieving high decoupling and extensibility through a unified interface and pluggable components. The overall architecture is as follows:\n![architecture](./docs/images/architecture.png)\n\n- **Go Idiomatic**: Built entirely in the Go way, the code style and user experience make Go developers feel at home.\n- **Easy to Use**: Through concise code, define an AI Agent and quickly deliver requirements, making complex logic clear, easy to manage, and maintain.\n- **Middleware Ecosystem**: Drawing inspiration from Kratos’s middleware design philosophy, features like Observability, Guardrails, and others can be easily integrated into the AI Agent.\n- **Highly Extensible**: Through a unified interface and pluggable components, achieve high decoupling and extensibility, making it easy to integrate different LLM models and external tools.\n\n## Core Concepts\nThe Blades framework achieves its powerful functionality and flexibility through a series of well-designed core components. These components work together to build the intelligent behavior of the Agent:\n\n* **Agent (Intelligent Entity)**: The core unit that executes tasks, capable of invoking models and tools.\n* **Prompt (Prompt Text)**: A templated text used to interact with LLMs, supporting dynamic variable substitution and complex context construction.\n* **Chain (Chain)**: Links multiple Agents or other Chains to form complex workflows.\n* **ModelProvider (Model)**: A pluggable LLM interface, allowing you to easily switch and integrate different language model services (such as OpenAI).\n* **Tool (Tool)**: External capabilities that the Agent can use, such as calling APIs, querying databases, accessing file systems, etc.\n* **Memory (Memory)**: Provides short-term or long-term memory capabilities for the Agent, enabling context-aware continuous conversations.\n* **Middleware (Middleware)**: Similar to middleware in web frameworks, it can implement cross-cutting control over the Agent.\n\n### Runner\n`Runner` is the most core interface in the Blades framework, defining the basic behavior of all executable components. Its design aims to provide a unified execution paradigm, achieving **decoupling, standardization, and high composability** of various functional modules within the framework through the `Run` and `RunStream` methods. Components such as `Agent`, `Chain`, and `ModelProvider` all implement this interface, unifying their execution logic and allowing different components to be flexibly combined like LEGO bricks to build complex AI Agents.\n\n```go\n// Runner represents an entity that can process prompts and generate responses.\ntype Runner interface {\n    // Run performs a synchronous, non-streaming operation, returning a complete Generation result.\n    Run(context.Context, *Prompt, ...ModelOption) (*Generation, error)\n    // RunStream performs an asynchronous, streaming operation, returning a Streamer for receiving Generation results step by step.\n    RunStream(context.Context, *Prompt, ...ModelOption) (Streamer[*Generation], error)\n}\n```\n![runner](docs/images/runner.png)\n\n### ModelProvider\n`ModelProvider` is the core abstraction layer in the `Blades` framework for interacting with underlying large language models (LLMs). Its design goal is to achieve **decoupling and extensibility** through a unified interface, separating the framework's core logic from the implementation details of specific models (such as OpenAI, DeepSeek, Gemini, etc.). It acts as an adapter, responsible for converting standardized requests within the framework into the format required by the native API of the model and converting the model's response back into the framework's standard format, thus allowing developers to easily switch and integrate different LLMs.\n\n```go\ntype ModelProvider interface {\n    // Generate performs a complete generation request and returns the result at once. Suitable for scenarios where real-time feedback is not needed.\n    Generate(context.Context, *ModelRequest, ...ModelOption) (*ModelResponse, error)\n    // NewStream initiates a streaming request. This method immediately returns a Streamer object, through which the caller can receive the generated content from the model step by step, suitable for building real-time, typewriter-effect conversation applications.\n    NewStream(context.Context, *ModelRequest, ...ModelOption) (Streamer[*ModelResponse], error)\n}\n```\n![ModelProvider](./docs/images/model.png)\n\n### Agent\n`Agent` is the core or",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-07T02:17:45.196792"
  },
  {
    "basic_info": {
      "name": "pgmcp",
      "full_name": "subnetmarco/pgmcp",
      "owner": "subnetmarco",
      "description": "An MCP server to query any Postgres database in natural language.",
      "url": "https://github.com/subnetmarco/pgmcp",
      "clone_url": "https://github.com/subnetmarco/pgmcp.git",
      "ssh_url": "git@github.com:subnetmarco/pgmcp.git",
      "homepage": "",
      "created_at": "2025-09-16T19:45:03Z",
      "updated_at": "2025-10-06T19:47:22Z",
      "pushed_at": "2025-09-25T18:19:25Z"
    },
    "stats": {
      "stars": 477,
      "forks": 48,
      "watchers": 477,
      "open_issues": 1,
      "size": 90
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 146324,
        "Shell": 4707,
        "Dockerfile": 259
      },
      "license": "Other",
      "topics": [
        "agent",
        "agentic-ai",
        "ai",
        "analytics",
        "artificial-intelligence",
        "data-analysis",
        "database",
        "kong",
        "mcp",
        "mcp-server",
        "postgres",
        "postgresql"
      ]
    },
    "content": {
      "readme": "[![ci](https://github.com/subnetmarco/pgmcp/actions/workflows/ci.yml/badge.svg)](https://github.com/subnetmarco/pgmcp/actions/workflows/ci.yml)\n[![Go Report Card](https://goreportcard.com/badge/github.com/subnetmarco/pgmcp)](https://goreportcard.com/report/github.com/subnetmarco/pgmcp)\n[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n\n# PGMCP - PostgreSQL Model Context Protocol Server\n\nPGMCP connects AI assistants to **any PostgreSQL database** through natural language queries. Ask questions in plain English and get structured SQL results with automatic streaming and robust error handling.\n\n**Works with**: Cursor, Claude Desktop, VS Code extensions, and any [MCP-compatible client](https://modelcontextprotocol.io/)\n\n## Quick Start\n\nPGMCP connects to **your existing PostgreSQL database** and makes it accessible to AI assistants through natural language queries.\n\n### Prerequisites\n- PostgreSQL database (existing database with your schema)\n- OpenAI API key (optional, for AI-powered SQL generation)\n\n### Basic Usage\n\n```bash\n# Set up environment variables\nexport DATABASE_URL=\"postgres://user:password@localhost:5432/your-existing-db\"\nexport OPENAI_API_KEY=\"your-api-key\"  # Optional\n\n# Run server (using pre-compiled binary)\n./pgmcp-server\n\n# Test with client in another terminal\n./pgmcp-client -ask \"What tables do I have?\" -format table\n./pgmcp-client -ask \"Who is the customer that has placed the most orders?\" -format table\n./pgmcp-client -search \"john\" -format table\n```\n\nHere is how it works:\n\n```\n👤 User / AI Assistant\n         │\n         │ \"Who are the top customers?\"\n         ▼\n┌─────────────────────────────────────────────────────────────┐\n│                    Any MCP Client                           │\n│                                                             │\n│  PGMCP CLI  │  Cursor  │  Claude Desktop  │  VS Code  │ ... │\n│  JSON/CSV   │  Chat    │  AI Assistant    │  Editor   │     │\n└─────────────────────────────────────────────────────────────┘\n         │\n         │ Streamable HTTP / MCP Protocol\n         ▼\n┌─────────────────────────────────────────────────────────────┐\n│                    PGMCP Server                             │\n│                                                             │\n│  🔒 Security    🧠 AI Engine      🌊 Streaming               │\n│  • Input Valid  • Schema Cache    • Auto-Pagination         │\n│  • Audit Log    • OpenAI API      • Memory Management       │\n│  • SQL Guard    • Error Recovery  • Connection Pool         │\n└─────────────────────────────────────────────────────────────┘\n         │\n         │ Read-Only SQL Queries\n         ▼\n┌─────────────────────────────────────────────────────────────┐\n│                Your PostgreSQL Database                     │\n│                                                             │\n│  Any Schema: E-commerce, Analytics, CRM, etc.               │\n│  Tables • Views • Indexes • Functions                       │\n└─────────────────────────────────────────────────────────────┘\n\nExternal AI Services:\nOpenAI API • Anthropic • Local LLMs (Ollama, etc.)\n\nKey Benefits:\n✅ Works with ANY PostgreSQL database (no assumptions about schema)\n✅ No schema modifications required  \n✅ Read-only access (100% safe)\n✅ Automatic streaming for large results\n✅ Intelligent query understanding (singular vs plural)\n✅ Robust error handling (graceful AI failure recovery)\n✅ PostgreSQL case sensitivity support (mixed-case tables)\n✅ Production-ready security and performance\n✅ Universal database compatibility\n✅ Multiple output formats (table, JSON, CSV)\n✅ Free-text search across all columns\n✅ Authentication support\n✅ Comprehensive testing suite\n```\n\n## Features\n\n- **Natural Language to SQL**: Ask questions in plain English\n- **Automatic Streaming**: Handles large result sets automatically  \n- **Safe Read-Only Access**: Prevents any write operations\n- **Text Search**: Search across all text columns\n- **Multiple Output Formats**: Table, JSON, and CSV\n- **PostgreSQL Case Sensitivity**: Handles mixed-case table names correctly\n- **Universal Compatibility**: Works with any PostgreSQL database\n\n### Environment Variables\n\n**Required:**\n- `DATABASE_URL`: PostgreSQL connection string to your existing database\n\n**Optional:**\n- `OPENAI_API_KEY`: OpenAI API key for AI-powered SQL generation\n- `OPENAI_MODEL`: Model to use (default: \"gpt-4o-mini\")\n- `HTTP_ADDR`: Server address (default: \":8080\")\n- `HTTP_PATH`: MCP endpoint path (default: \"/mcp\")\n- `AUTH_BEARER`: Bearer token for authentication\n\n## Installation\n\n### Download Pre-compiled Binaries\n\n1. Go to [GitHub Releases](https://github.com/subnetmarco/pgmcp/releases)\n2. Download the binary for your platform (Linux, macOS, Windows)\n3. Extract and run:\n\n```bash\n# Example for macOS/Linux\ntar xzf pgmcp_*.tar.gz\ncd pgmcp_*\n./pgmcp-server\n```\n\n### Alternative Options\n\n```bash\n# Homebrew (macOS/Linux) - Available after first release\nbrew tap subnetmarco/homebrew-tap\nbrew inst",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-07T02:17:46.453105"
  },
  {
    "basic_info": {
      "name": "better-curl-saul",
      "full_name": "DeprecatedLuar/better-curl-saul",
      "owner": "DeprecatedLuar",
      "description": "Did you know you have rights? The FOSS says you do... Better Curl Saul is my homemade CLI 'http client' to make api reusability simple.",
      "url": "https://github.com/DeprecatedLuar/better-curl-saul",
      "clone_url": "https://github.com/DeprecatedLuar/better-curl-saul.git",
      "ssh_url": "git@github.com:DeprecatedLuar/better-curl-saul.git",
      "homepage": "",
      "created_at": "2025-09-18T09:00:50Z",
      "updated_at": "2025-10-06T09:56:20Z",
      "pushed_at": "2025-10-03T22:07:52Z"
    },
    "stats": {
      "stars": 219,
      "forks": 7,
      "watchers": 219,
      "open_issues": 2,
      "size": 1687
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 130742,
        "Shell": 6284,
        "HTML": 3925,
        "Nix": 1524
      },
      "license": "MIT License",
      "topics": [
        "api",
        "api-client",
        "cli-tool",
        "curl",
        "curl-commands",
        "golang",
        "http",
        "http-client",
        "http-requests",
        "linux",
        "macos",
        "windows"
      ]
    },
    "content": {
      "readme": "<h3 align=\"center\">When HTTP gets complicated...</h3>\n<p align=\"center\">\n  <img src=\"other/assets/saul-logo (1).png\" width=\"600\"/>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://github.com/DeprecatedLuar/better-curl-saul/stargazers\">\n    <img src=\"https://img.shields.io/github/stars/DeprecatedLuar/better-curl-saul?style=for-the-badge&logo=github&color=1f6feb&logoColor=white&labelColor=black\"/>\n  </a>\n  <a href=\"https://github.com/DeprecatedLuar/better-curl-saul/releases\">\n    <img src=\"https://img.shields.io/github/v/release/DeprecatedLuar/better-curl-saul?style=for-the-badge&logo=go&color=00ADD8&logoColor=white&labelColor=black\"/>\n  </a>\n  <a href=\"https://github.com/DeprecatedLuar/better-curl-saul/blob/main/LICENSE\">\n    <img src=\"https://img.shields.io/github/license/DeprecatedLuar/better-curl-saul?style=for-the-badge&color=green&labelColor=black\"/>\n  </a>\n  <a href=\"https://deprecatedluar.github.io/better-curl-saul/\">\n    <img src=\"https://img.shields.io/badge/Leave_a_Comment-💬-orange?style=for-the-badge&logo=github&logoColor=white&labelColor=black\"/>\n  </a>\n</p>\n\n**v0.3.0 Try out the new curl import/exporting**: `saul myapi set --raw` and `saul myapi get --raw` \n\n---\n\n\n<p align=\"center\">\n  <img src=\"other/assets/saul-catboy-final.png\" width=\"700\"/>\n</p>\n\n<p align=\"center\"> Better Curl Saul is a way to simplify and organize api re-callability (if that's a word)</p>\n \n ---\n\n## **In a nutshell,** this is... not my favorite UX:\n```bash\ncurl -X POST \"https://company.atlassian.net/rest/api/3/issue\" \\\n  -H \"Authorization: Basic $(echo -n 'user@company.com:api-token-here' | base64)\" \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Accept: application/json\" \\\n  -H \"X-Atlassian-Token: no-check\" \\\n  -d '{\n    \"fields\": {\n      \"project\": {\"key\": \"PROJ\"},\n      \"summary\": \"API Bug: Users can'\\''t login after deployment\",\n      \"description\": \"Steps:\\n1. Deploy v2.1.0\\n2. Try login\\n3. Gets 500 error\\n\\nExpected: Login works\\nActual: Server error\",\n      \"issuetype\": {\"name\": \"Bug\"},\n      \"priority\": {\"name\": \"High\"},\n      \"assignee\": {\"accountId\": \"123456:abcd-efgh-ijkl\"},\n      \"labels\": [\"api\", \"login\", \"production\"],\n      \"customfield_10001\": \"2024-01-15\",\n      \"customfield_10002\": {\"value\": \"Backend Team\"}\n    }\n  }'\n```\n\n# Try this instead\n<p align=\"center\">\n  <img src=\"other/assets/demo.gif\" alt=\"Better-Curl Demo\" width=\"800\"/>\n</p>\n\n---\n\n## The nice features you've never seen before\n\n- **Workspace-based** - Each API gets its own organized folder (reusable)\n- **Inline editor** - the `edit` command for any given field also supports `$EDITOR`\n- **Smart variables** - `{@token}` persists,`{?name}` prompts every time\n- **Response filtering** - Show only the fields you care about\n- **Git-friendly** - TOML files version control beautifully\n- **Unix composable** - Script it, pipe it, shell it\n- **TOML converter** - JSON gets reorganized into TOML for readability\n- **Saul Goodman** - It has Saul Goodman on it.\n  \n<img src=\"other/assets/saul-hd-wide.png\" width=\"1000\"/>\n\n\n# Installation\n\n**Supports:** Linux, macOS, Windows (I hope)\n\n### One-Liner (if you have bash)\n```bash\ncurl -sSL https://raw.githubusercontent.com/DeprecatedLuar/better-curl-saul/main/install.sh | bash\n```\n\n<details>\n<summary>Other Install Methods</summary>\n\n<br>\n\n**Manual Install**\n1. Download binary for your OS from [releases](https://github.com/DeprecatedLuar/better-curl-saul/releases)\n2. Make executable: `chmod +x saul-*`\n3. Move to PATH: `sudo mv saul-* /usr/local/bin/saul`\n\n**From Source** (for try-harders)\n```bash\ngit clone https://github.com/DeprecatedLuar/better-curl-saul.git\ncd better-curl-saul\n./other/install-local.sh  # Local development build\n```\n\n**In case you already have Saul** (basically gambling at this point)\n```bash\nsaul set url https://raw.githubusercontent.com/DeprecatedLuar/better-curl-saul/main/install.sh && saul call --raw | bash #(maybe works, who knows)\n```\n**Using Nix and Flakes**\n```bash\nnix profile install github:DeprecatedLuar/better-curl-saul?dir=nix-saul\n```\nThe `saul` command will be available in your PATH\n\n>[!NOTE]\n> Quick install auto-detects your system and downloads binaries or builds from source as fallback. \n> Windows users: I don't know powershell I expect you to have bash 👍\n\n</details>\n\n<br>\n\n\n\n## Commands\n\n| Action | Targets                                                            | Description                              | Example                                    |\n|--------|--------------------------------------------------------------------|------------------------------------------|--------------------------------------------|\n| set    | `url`, `method`, `timeout`, `body`, `header`, `query`, `variables` | Configure request settings and data      | `saul api set url https://...`             |\n| edit   | `body`, `header`, `query`                                          | Edit inline or open in $EDITOR           | `saul edit body user.name` / `saul edit body` |\n| rm     | `body`, `header`, `query`     ",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-07T02:17:47.733157"
  },
  {
    "basic_info": {
      "name": "resterm",
      "full_name": "unkn0wn-root/resterm",
      "owner": "unkn0wn-root",
      "description": "Terminal REST client for .http/.rest files with HTTP, GraphQL and gRPC support.",
      "url": "https://github.com/unkn0wn-root/resterm",
      "clone_url": "https://github.com/unkn0wn-root/resterm.git",
      "ssh_url": "git@github.com:unkn0wn-root/resterm.git",
      "homepage": "",
      "created_at": "2025-09-30T11:47:23Z",
      "updated_at": "2025-10-07T00:44:17Z",
      "pushed_at": "2025-10-06T11:34:39Z"
    },
    "stats": {
      "stars": 197,
      "forks": 4,
      "watchers": 197,
      "open_issues": 0,
      "size": 2493
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 472855
      },
      "license": "Apache License 2.0",
      "topics": [
        "go",
        "golang",
        "rest",
        "rest-api",
        "rest-client",
        "tui",
        "tui-app"
      ]
    },
    "content": {
      "readme": "<h1 align=\"center\">Resterm</h1>\n\n<p align=\"center\">\n  <em>a terminal-based REST client.</em>\n</p>\n\n<p align=\"center\">\n  <img src=\"_media/resterm.png\" alt=\"Screenshot of resterm TUI\" width=\"720\" />\n</p>\n\n## Features\n- **Workspace explorer.** Filters `.http`/`.rest` files, respects workspace roots, and keeps the file pane navigable with incremental search.\n- **Editor with modal workflow.** Starts in view mode, supports Vim-style motions, visual selections with inline highlighting, clipboard yank/cut, `Shift+F` search, and an `i` / `Esc` toggle for insert mode.\n- **Inline requests.** Type `https://api.example.com` or `GET https://api.example.com` directly in the editor and press `Ctrl+Enter` - no `.http`/`.rest` file required.\n- **Curl command parsing (limited).** supports basic `curl` invocations (method, headers, data flags) - more in the road-map.\n- **Status-aware response pane.** Pill-style header calls out workspace, environment, active request, and script/test outcomes; response tabs cover Pretty, Raw, Headers, and History, plus request previews.\n- **Split response views with diffing.** Snap responses into vertical or horizontal splits, pin panes, and compare Pretty/Raw/Headers tabs side-by-side with a unified diff view.\n- **Auth & variable helpers.** `@auth` directives cover basic, bearer, API key, and custom headers; variable resolution spans request, file, environment, and OS layers with helpers like `{{$timestamp}}` and `{{$uuid}}`.\n- **Pre-request & test scripting.** JavaScript (goja) hooks mutate outgoing requests, assert on responses, and surface pass/fail summaries inline.\n- **GraphQL tooling.** `@graphql` and `@variables` directives produce proper payloads, attach operation names, and keep previews/history readable.\n- **gRPC client.** `GRPC host:port` requests with `@grpc` metadata build messages from descriptor sets or reflection, stream metadata/trailers, and log history entries beside HTTP calls.\n- **Session persistence.** Cookie jar, history store, and environment-aware entries survive restarts; `@no-log` can redact bodies.\n- **Configurable transport.** Flag-driven timeout, TLS, redirect, and proxy settings alongside environment file discovery (`resterm.env.json` or legacy `rest-client.env.json`).\n\n> [!WARNING]\n> Resterm is still in early stages so bugs and undesired behaviors can be expected.\n\n## Request File Structure\n\nResterm reads plain-text `.http`/`.rest` files. Each request follows the same conventions so the editor, parser, and history can reason about it consistently.\n\n```http\n### get user\n# @name getUser\n# @description Fetch a user profile\nGET https://{{baseUrl}}/users/{{userId}}\nAuthorization: Bearer {{token}}\nX-Debug: {{$timestamp}}\n\n{\n  \"verbose\": true\n}\n\n### create user\nPOST https://{{baseUrl}}/users\nContent-Type: application/json\n\n< ./payloads/create-user.json\n```\n\n- **Request separators.** Start a new request with a line beginning `###` (an optional label after the hashes is ignored by the parser but is handy for readability).\n- **Metadata directives.** Comment lines (`#` or `//`) before the request line can include directives such as `@name`, `@description`, `@tag`, `@auth`, `@graphql`, `@grpc`, `@variables`, and `@script`. See [Request Metadata & Settings](#request-metadata--settings) for the full list.\n- **Request line.** The first non-comment line specifies the verb and target. HTTP calls use `<METHOD> <URL>`, whereas gRPC calls begin with `GRPC host:port` followed by `@grpc package.Service/Method` metadata.\n- **Headers.** Subsequent lines of the form `Header-Name: value` are sent verbatim after variable substitution.\n- **Body.** A blank line separates headers from the body. You can inline JSON/text, use heredoc-style scripts, or include external files with `< ./path/to/file`.\n- **Inline variables.** Placeholders like `{{userId}}` or `{{token}}` are resolved using the variable stack (request variables, file-level variables, selected environment, then OS environment). Helpers such as `{{$uuid}}` and `{{$timestamp}}` are available out of the box.\n\n## Getting Started\n\n### Install prebuilt binaries\n\nDownload from [GitHub Releases](https://github.com/unkn0wn-root/resterm/releases). You can use the snippets below to automatically detect the latest tag and fetch the matching binary for your platform.\n\n> [!NOTE]\n> The examples require `curl` and `jq`. Install `jq` with your package manager (e.g. `brew install jq`, `sudo apt install jq` etc.).\n\n#### Linux / macOS\n\n```bash\n# Detect latest version\nLATEST_TAG=$(curl -fsSL https://api.github.com/repos/unkn0wn-root/resterm/releases/latest | jq -r .tag_name)\n\n# Download the appropriate binary (Darwin/Linux + amd64/arm64)\ncurl -fL -o resterm \"https://github.com/unkn0wn-root/resterm/releases/download/${LATEST_TAG}/resterm_$(uname -s)_$(uname -m)\"\n\n# Make it executable and install into your PATH\nchmod +x resterm\nsudo install -m 0755 resterm /usr/local/bin/resterm\n```\n\nIf your system does not include `install`, replace the final line with `",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-07T02:17:49.024621"
  },
  {
    "basic_info": {
      "name": "ByteCaster",
      "full_name": "Print3M/ByteCaster",
      "owner": "Print3M",
      "description": "Swiss Army Knife for payload encryption, obfuscation, and conversion to byte arrays – all in a single command (14 output formats supported)! ☢️",
      "url": "https://github.com/Print3M/ByteCaster",
      "clone_url": "https://github.com/Print3M/ByteCaster.git",
      "ssh_url": "git@github.com:Print3M/ByteCaster.git",
      "homepage": "",
      "created_at": "2025-09-17T14:45:28Z",
      "updated_at": "2025-10-07T00:42:38Z",
      "pushed_at": "2025-09-20T13:08:55Z"
    },
    "stats": {
      "stars": 161,
      "forks": 24,
      "watchers": 161,
      "open_issues": 0,
      "size": 10756
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 13941
      },
      "license": null,
      "topics": [
        "encryption-tool",
        "golang",
        "maldev",
        "malware-builder",
        "malware-development",
        "obfuscation-script",
        "redteam",
        "security",
        "security-tools",
        "shellcode",
        "shellcode-convert",
        "shellcode-development",
        "shellcode-encoder",
        "shellcode-injection"
      ]
    },
    "content": {
      "readme": "# ByteCaster\n\nSwiss Army Knife for payload encryption, obfuscation, and conversion to byte arrays – all in a single command!\n\nIt supports 3 encryption algorithms, 4 encoding / obfuscation algorithms and 14 output formats.\n\n![ByteCaster order of opretaions](_img/img-1.png)\n\n## Installation\n\n[Download the compiled binary](https://github.com/Print3M/ByteCaster/releases/tag/1.0.0) or compile Go source code.\n\n## Usage\n\nExample:\n\n```bash\n# Convert .bin file into C bytes array with XOR encryption and IPv4Fuscation\n./ByteCaster -i shellcode.bin -f c -x xor -k 'Test123' -e ipv4\n\n# Convert .bin file into base64 string with XOR encryption\n./ByteCaster -i shellcode.bin -x xor -k 'Test123' -e base64\n```\n\n![ByteCaster demo](_img/img-2.png)\n\n> **NOTE**: The sequence of operations is always the same:\n>\n> 1. Encryption\n> 2. Encoding\n> 3. Output formatting\n\n**`-i / --input <path>`** [required]\n\nBinary input file.\n\n**`-f / --format <value>`** [optional, default: `raw`]\n\nOutput format of the processed data. This generates the final data as an array of bytes in the selected programming language. Output is always sent to STDOUT.\n\nTo avoid applying any formatting output, use the `raw` value (default).\n\nAvailable values: `raw`, `hex`, `c`, `go`, `powershell`, `php`, `js`, `rust`, `csharp`, `nim`, `zig`, `ruby`, `python`, `java`\n\n**`-x / --enc-alg <value>` + `-k / --enc-key <string>`** [optional]\n\nData encryption. Both parameters, the encryption algorithm and the key string, must be provided.\n\nAvailabe values: `xor`, `aes256`, `rc4`\n\nAll supported encryption algorithms are described in details below.\n\n**`-e / --encoding <value>`** [optional]\n\nData encoding. Often used as obfuscation to confuse analysis or changes in the entropy level of data.\n\nAvailable values: `base32`, `base64`, `ipv4`, `mac`\n\nAll supported encoding algorithms are described in details below.\n\n## Supported encryption algorithms\n\n#### **`xor`** [0% overhead]\n\nTypical simple XOR encryption (`a^b`). Each byte is XORed with the byte from the key.\n\n#### **`aes256`** [28 bytes overhead]\n\nAES-256-GCM with the 32-bytes long key derived from SHA-256 hash function.\n\nCiphertext format: `nonce || ciphertext`. Nonce is stored in the first 12 bytes, followed by the encrypted data and authentication tag (the tag is appended automatically by GCM inside ciphertext).\n\nStandard Go implementation of AES encryption:`crypto/aes`\nStandard Go implementation of SHA-256 key derivation: `crypto/sha256`\n\n#### **`rc4`** [0% overhead]\n\nStandard Go implementation of RC4 encryption: `crypto/rc4`\n\n## Supported encoding algorithms\n\n#### **`base32`** [60–65% overhead]\n\nStandard Go implementation of Base32 encoding: `encoding/base32`\n\n#### **`base64`** [33%-37% overhead]\n\nStandard Go implementation of Base64 encoding: `encoding/base64`\n\n#### **`ipv4`** [100%-300% overhead]\n\nThis is known as the _IPv4Fuscation_ technique. Each output byte is converted to one octet in the IPv4 address as a decimal number.\n\nExample data:\n\n```text\n{ 0xe9, 0x36, 0x17, 0xbb, 0xbd, 0x7f, 0x22, 0x10 }\n```\n\nThe output (array of bytes) looks exactly like this in memory:\n\n`233.54.23.187\\0189.127.34.16\\0` ...\n\n> NOTE:\n>\n> - Each IP address ends with a null byte!\n> - If the number of bytes is not divisible by 4, the missing bytes added to the last IP address are 255.\n\n#### **`mac`** [200% overhead]\n\nThis is known as the _MACFuscation_ technique. Each output byte is converted to one octet in the MAC address as a hexadecimal number (lowercase).\n\nExample data:\n\n```text\n{ 0xe9, 0x36, 0x17, 0xbb, 0xbd, 0x7f, 0x22, 0x10, 0x84, 0xA7, 0x6f, 0xcc }\n```\n\nThe output (array of bytes) looks exactly like this in memory:\n\n`e9:36:17:bb:bd:7f\\022:10:84:a7:6f:cc\\0`\n\n> NOTE:\n>\n> - Each MAC address ends with a null byte!\n> - Hexadecimal numbers are lowercase.\n> - If the number of bytes is not divisible by 6, the missing bytes added to the last MAC address are 255 (`ff`).\n\n## Credits\n\n- [HellShell](https://github.com/NUL0x4C/HellShell) - inspired me to implement _IPv4Fuscation_ and _MACFuscation_.\n\n## TODO\n\n- Add base32 encoding\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-07T02:17:50.299118"
  },
  {
    "basic_info": {
      "name": "friendly-potato",
      "full_name": "bingcicle/friendly-potato",
      "owner": "bingcicle",
      "description": "jsonl-tool",
      "url": "https://github.com/bingcicle/friendly-potato",
      "clone_url": "https://github.com/bingcicle/friendly-potato.git",
      "ssh_url": "git@github.com:bingcicle/friendly-potato.git",
      "homepage": null,
      "created_at": "2025-09-29T15:09:04Z",
      "updated_at": "2025-10-04T07:33:17Z",
      "pushed_at": "2025-09-29T15:11:09Z"
    },
    "stats": {
      "stars": 153,
      "forks": 0,
      "watchers": 153,
      "open_issues": 2,
      "size": 7
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 2030
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# jsonl-tool\nMerge or filter JSON Lines.\n\n## Build & Run\n```bash\ngo build -o jsonl-tool\n./jsonl-tool --mode merge --in a.jsonl,b.jsonl > merged.jsonl\n./jsonl-tool --mode filter --in merged.jsonl --field exchange --eq bybit\n./jsonl-tool --mode filter --in merged.jsonl --field symbol --rex \"BTC|ETH\"\n```\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-07T02:17:51.602666"
  },
  {
    "basic_info": {
      "name": "dab-downloader",
      "full_name": "PrathxmOp/dab-downloader",
      "owner": "PrathxmOp",
      "description": "A powerful, modular music downloader that delivers high-quality FLAC files with comprehensive metadata support through the DAB API.",
      "url": "https://github.com/PrathxmOp/dab-downloader",
      "clone_url": "https://github.com/PrathxmOp/dab-downloader.git",
      "ssh_url": "git@github.com:PrathxmOp/dab-downloader.git",
      "homepage": "https://discord.gg/q9RnuVza2",
      "created_at": "2025-09-13T23:36:48Z",
      "updated_at": "2025-10-05T22:23:57Z",
      "pushed_at": "2025-09-30T06:34:46Z"
    },
    "stats": {
      "stars": 125,
      "forks": 5,
      "watchers": 125,
      "open_issues": 3,
      "size": 14765
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 141111,
        "Dockerfile": 1249
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# 🎵 DAB Music Downloader\n\n[![Go Version](https://img.shields.io/badge/go-%3E%3D1.19-blue.svg)](https://golang.org/dl/)\n[![License](https://img.shields.io/badge/license-Educational-green.svg)](#license)\n[![Release](https://img.shields.io/github/v/release/PrathxmOp/dab-downloader)](https://github.com/PrathxmOp/dab-downloader/releases/latest)\n[![Discord Support](https://img.shields.io/badge/Support-Discord-blue.svg?logo=discord&logoColor=white)](https://discord.gg/q9RnuVza2)\n![Development Status](https://img.shields.io/badge/status-unstable%20development-orange.svg)\n\n> A powerful, modular music downloader that delivers high-quality FLAC files with comprehensive metadata support through the DAB API.\n\n## Table of Contents\n- [⚠️ IMPORTANT: Development Status](#️-important-development-status)\n- [✨ Key Features](#-key-features)\n- [📸 Screenshots](#-screenshots)\n- [🚀 Quick Start](#-quick-start)\n  - [Option 1: Using `auto-dl.sh` Script (Recommended)](#option-1-using-auto-dlsh-script-recommended)\n  - [Option 2: Pre-built Binary](#option-2-pre-built-binary)\n  - [Option 3: Build from Source](#option-3-build-from-source)\n  - [Option 4: Docker (Containerized)](#option-4-docker-containerized)\n- [🔄 CRITICAL: Staying Updated](#-critical-staying-updated)\n  - [🚨 Daily Update Routine (Recommended)](#-daily-update-routine-recommended)\n  - [Versioning Format](#versioning-format)\n  - [Option 1: Pre-built Binary Updates](#option-1-pre-built-binary-updates)\n  - [Option 2: Source Code Updates](#option-2-source-code-updates)\n  - [Option 3: Docker Updates](#option-3-docker-updates)\n  - [🔔 Get Update Notifications](#-get-update-notifications)\n- [📋 Usage Guide](#-usage-guide)\n  - [🔍 Search and Discover](#-search-and-discover)\n  - [📀 Download Content](#-download-content)\n  - [🎧 Spotify Integration](#-spotify-integration)\n  - [🎵 Navidrome Integration](#-navidrome-integration)\n- [⚙️ Configuration](#️-configuration)\n  - [First-Time Setup](#first-time-setup)\n  - [Configuration File](#configuration-file)\n- [⚙️ Command-Line Flags](#️-command-line-flags)\n  - [Global Flags (Persistent Flags)](#global-flags-persistent-flags)\n  - [Command-Specific Flags](#command-specific-flags)\n    - [`album` command](#album-command)\n    - [`artist` command](#artist-command)\n    - [`search` command](#search-command)\n    - [`spotify` command](#spotify-command)\n    - [`navidrome` command](#navidrome-command)\n- [📁 File Organization](#-file-organization)\n- [🔧 Advanced Features](#-advanced-features)\n  - [Debug Tools](#debug-tools)\n  - [Quality & Metadata](#quality--metadata)\n- [🐛 Troubleshooting](#-troubleshooting)\n- [💬 Support & Community](#-support--community)\n- [🏗️ Project Architecture](#️-project-architecture)\n- [🤝 Contributing](#-contributing)\n  - [Development Areas Needing Help](#development-areas-needing-help)\n- [⚖️ Legal Notice](#️-legal-notice)\n- [📄 License](#-license)\n- [🌟 Support the Project](#-support-the-project)\n- [Changelog](#changelog)\n- [Update Guide](#update-guide)\n\n## ⚠️ **IMPORTANT: Development Status**\n\n🚧 **This project is currently in active, unstable development.** 🚧\n\n- **Frequent Breaking Changes**: Features may work one day and break the next\n- **Regular Updates Required**: You'll need to update frequently to get the latest fixes\n- **Expect Issues**: Something always seems to break when i fix something else\n- **Pre-Stable Release**: We're working toward a stable v1.0, but we're not there yet\n\n**📢 We strongly recommend:**\n- [Discord Support Group](https://discord.gg/q9RnuVza2) for real-time updates\n- ✅ Checking for updates daily if you're actively using the tool\n- ✅ Being prepared to troubleshoot and report issues\n- ✅ Having patience as we work through the bugs\n\n💬 **Need Help?** Join our [Discord Support Group](https://discord.gg/q9RnuVza2) for instant community support and the latest stability updates!\n\n\n\n## ✨ Key Features\n\n🔍 **Smart Search** - Find artists, albums, and tracks with intelligent filtering  \n📦 **Complete Discographies** - Download entire artist catalogs with automatic categorization  \n🏷️ **Rich Metadata** - Full tag support including genre, composer, producer, ISRC, and copyright  \n🎨 **High-Quality Artwork** - Embedded album covers in original resolution  \n- **Concurrent Downloads** - Fast parallel processing with real-time progress tracking  \n- **Intelligent Retry Logic** - Robust error handling for reliable downloads  \n- **Spotify Integration** - Import and download entire Spotify playlists and albums  \n- **Format Conversion** - Convert downloaded FLAC files to MP3, OGG, Opus with configurable bitrates (requires FFmpeg)  \n- **Navidrome Support** - Seamless integration with your music server  \n- **Customizable Naming** - Define your own file and folder structure with configurable naming masks\n\n## 📸 Screenshots\n\n![img1](./screenshots/ScreenShot1.png)\n![img1](./screenshots/ScreenShot2.png)\n\n## 🚀 Quick Start\n\n### Option 1: Using `auto-dl.sh` Script (Recommended)\n\nThis script simplifies the process of downloading and keeping `dab-down",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-07T02:17:52.890177"
  },
  {
    "basic_info": {
      "name": "konbini",
      "full_name": "whyrusleeping/konbini",
      "owner": "whyrusleeping",
      "description": null,
      "url": "https://github.com/whyrusleeping/konbini",
      "clone_url": "https://github.com/whyrusleeping/konbini.git",
      "ssh_url": "git@github.com:whyrusleeping/konbini.git",
      "homepage": null,
      "created_at": "2025-10-03T20:20:00Z",
      "updated_at": "2025-10-07T01:57:46Z",
      "pushed_at": "2025-10-06T22:02:04Z"
    },
    "stats": {
      "stars": 112,
      "forks": 8,
      "watchers": 112,
      "open_issues": 1,
      "size": 371
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 148489,
        "TypeScript": 56069,
        "CSS": 25038,
        "HTML": 1719,
        "Dockerfile": 1010
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# Konbini - A Cozy Bluesky AppView\n\nKonbini is a partially indexed bluesky appview. It's aim is to provide a \"Friends of Friends\" experience to the bluesky network.\n\nIt is currently _very_ jank and I really just hacked this together in a day. More work to come when I get time.\n\n## Prerequisites\n\n- Go 1.25.1 or later\n- PostgreSQL database\n- Node.js and npm (for frontend)\n- Docker (optional, for easy PostgreSQL setup)\n- Bluesky account credentials\n\n## Quick Start with Docker Compose\n\nThe easiest way to run Konbini is with Docker Compose, which will start PostgreSQL, the backend, and frontend all together.\n\n### Prerequisites\n\n- Docker and Docker Compose installed\n- Creating an app password (via: https://bsky.app/settings/app-passwords)\n\n### Setup\n\n1. Create a `.env` file with your credentials:\n\n```bash\ncp .env.example .env\n# Edit .env and add:\n# - BSKY_HANDLE=your-handle.bsky.social\n# - BSKY_PASSWORD=your-app-password\n```\n\n2. Start all services:\n\n```bash\ndocker-compose up -d\n```\n\n3. Wait for the backend to index posts from the firehose (this may take a few minutes for initial indexing)\n\n4. Open your browser to http://localhost:3000\n\n### Stopping the services\n\n```bash\ndocker-compose down\n```\n\nTo also remove the database volume:\n\n```bash\ndocker-compose down -v\n```\n\n## Manual Setup\n\n### 1. PostgreSQL Database Setup\n\n#### Using Docker (Recommended)\n\n```bash\n# Start PostgreSQL container\ndocker run --name konbini-postgres \\\n  -e POSTGRES_DB=konbini \\\n  -e POSTGRES_USER=konbini \\\n  -e POSTGRES_PASSWORD=your_password \\\n  -p 5432:5432 \\\n  -d postgres:15\n\n# The database will be available at: postgresql://konbini:your_password@localhost:5432/konbini\n```\n\n### 2. Environment Configuration\n\nSet the following environment variables:\n\n```bash\n# Database connection\nexport DATABASE_URL=\"postgresql://konbini:your_password@localhost:5432/konbini\"\n\n# Bluesky credentials\nexport BSKY_HANDLE=\"your-handle.bsky.social\"\nexport BSKY_PASSWORD=\"your-app-password\"\n```\n\n### 3. Build and Run the Go Application\n\n```bash\ngo build\n\n# Run with environment variables\n./konbini\n```\n\n### 4. Frontend Setup\n\n```bash\n# Navigate to frontend directory\ncd frontend\n\n# Install dependencies\nnpm install\n\n# Start the development server\nnpm start\n```\n\nThe frontend will be available at http://localhost:3000 and will connect to the API at http://localhost:4444.\n\n## License\n\nMIT (whyrusleeping)\n",
      "default_branch": "master"
    },
    "fetched_at": "2025-10-07T02:17:54.160370"
  },
  {
    "basic_info": {
      "name": "tunn",
      "full_name": "strandnerd/tunn",
      "owner": "strandnerd",
      "description": "SSH tunnels made simple: Launch and monitor SSH tunnels from a single YAML config and your existing OpenSSH setup.",
      "url": "https://github.com/strandnerd/tunn",
      "clone_url": "https://github.com/strandnerd/tunn.git",
      "ssh_url": "git@github.com:strandnerd/tunn.git",
      "homepage": "",
      "created_at": "2025-09-23T03:13:27Z",
      "updated_at": "2025-10-06T11:54:42Z",
      "pushed_at": "2025-09-24T02:21:54Z"
    },
    "stats": {
      "stars": 111,
      "forks": 5,
      "watchers": 111,
      "open_issues": 1,
      "size": 46
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 64829,
        "Shell": 2298
      },
      "license": "MIT License",
      "topics": [
        "golang",
        "ssh",
        "ssh-tunnel",
        "tunneling"
      ]
    },
    "content": {
      "readme": "![GitHub License](https://img.shields.io/github/license/strandnerd/tunn) ![GitHub Actions Workflow Status](https://img.shields.io/github/actions/workflow/status/strandnerd/tunn/ci.yml) ![GitHub Release](https://img.shields.io/github/v/release/strandnerd/tunn) ![GitHub Issues or Pull Requests](https://img.shields.io/github/issues/strandnerd/tunn)\n\n\n\n# tunn - SSH Tunnel Manager\n\n`tunn` is a developer-friendly wrapper around OpenSSH that makes it easy to manage multiple SSH tunnels defined in a simple configuration file\n\n<img width=\"1536\" height=\"649\" alt=\"tunn-gophers\" src=\"https://github.com/user-attachments/assets/9b88aa87-721b-4577-b0c1-2cf61af4d160\" />\n\n## Features\n\n- 🚀 **Simple Configuration**: Define all your tunnels in a single YAML file\n- 🔧 **Selective Tunnels**: Run all tunnels or specific ones by name\n- 🔌 **Multiple Ports**: Support for multiple port mappings per tunnel\n- 🔐 **SSH Integration**: Leverages your existing SSH configuration\n- ⚡ **Parallel Execution**: All tunnels run concurrently\n- 🧩 **Daemon Mode**: Background service with status reporting via IPC\n- 🧼 **Lean Go Module**: Depends only on `gopkg.in/yaml.v3`, keeping builds clean and portable\n- 🔧 **Native SSH Sessions**: Spawns the system `ssh` binary for each mapping, so keys and config behave exactly like your shell\n- 🎚️ **Per-Port Processes**: Launches one PID per port to pave the way for fine-grained lifecycle controls\n\n\n\n![Screencast from 2025-09-23 22-19-13 (online-video-cutter com)](https://github.com/user-attachments/assets/dbce86b1-c40c-47b9-a89c-6e188ad6e4ee)\n\n\n\n\n## Installation\n\n### Quick Install\n\n```bash\ncurl -sSL https://raw.githubusercontent.com/strandnerd/tunn/main/scripts/install.sh | sudo sh\n```\n\n### From Go Install\n\n```bash\ngo install github.com/strandnerd/tunn@latest\n```\n\n### Build Locally\n\n```bash\ngit clone https://github.com/strandnerd/tunn.git\ncd tunn\ngo build -o tunn\nsudo mv tunn /usr/local/bin/\n```\n\n## Configuration\n\nCreate a `~/.tunnrc` file in your home directory:\n\n```yaml\ntunnels:\n  api:\n    host: myserver          # SSH host from ~/.ssh/config\n    ports:\n      - 3000:3000           # local:remote port mapping\n      - 4000:4001\n    user: apiuser           # optional: SSH user\n    identity_file: ~/.ssh/id_rsa  # optional: SSH key\n\n  db:\n    host: database\n    ports:\n      - 3306:3306           # MySQL\n      - 5432:5432           # PostgreSQL\n    user: dbadmin           # optional: overrides SSH config\n\n  cache:\n    host: cacheserver\n    ports:\n      - 6379:6379           # Redis\n```\n\n### Configuration Fields\n\n- `tunnels`: Map of tunnel names\n- `host`: SSH host alias from `~/.ssh/config`\n- `ports`: List of port mappings in `local:remote` format\n- `user` (optional): SSH username (overrides `~/.ssh/config`)\n- `identity_file` (optional): Path to SSH private key\n\n## Usage\n\n### Run All Tunnels\n\n```bash\ntunn\n```\n\n### Run Specific Tunnels\n\n```bash\n# Single tunnel\ntunn api\n\n# Multiple tunnels\ntunn api db\n\n# All database-related tunnels\ntunn db cache\n```\n\n### Run Tunnels in the Background\n\n```bash\ntunn --detach\n\n# Or only specific tunnels\ntunn --detach api db\n```\n\nThe CLI respawns itself as a daemon, stores metadata under `$XDG_RUNTIME_DIR/tunn` (or `~/.cache/tunn` when the runtime dir is unavailable), and immediately returns control to the terminal.\n\n### Check Daemon Status\n\n```bash\ntunn status\n```\n\nThe status command contacts the daemon's Unix socket, reporting the PID, mode, and the latest port states for each managed tunnel. If no daemon is running, a friendly message is printed instead.\n\n### Stop the Daemon\n\n```bash\ntunn stop\n```\n\nThe stop command asks the daemon to shut down cleanly, waits for it to exit, and reports success.\n\n### Output Example\n\n```\nTunnels Ready\n\n[api]\n    3000 ➜ 3000 [active]\n    4000 ➜ 4001 [active]\n[db]\n    3306 ➜ 3306 [connecting]\n    5432 ➜ 5432 [active]\n```\n\n## SSH Configuration\n\n`tunn` uses your system's SSH configuration. Make sure your hosts are defined in `~/.ssh/config`:\n\n```ssh\nHost myserver\n    HostName 192.168.1.100\n    User myuser\n    Port 22\n\nHost database\n    HostName db.example.com\n    User dbuser\n    IdentityFile ~/.ssh/db_key\n```\n\n## Requirements\n\n- Go 1.21 or higher (for building)\n- OpenSSH client (`ssh` command)\n- Valid SSH configuration\n- macOS and Linux are supported today; Windows support is planned but not available yet\n\n## Daemon Runtime Files\n\nWhile running in detached mode, `tunn` stores the following files in its runtime directory:\n\n- `daemon.pid` – PID of the active daemon; used to prevent duplicate launches.\n- `daemon.sock` – Unix domain socket for control commands (e.g., `tunn status`).\n- `daemon.log` – Aggregated stdout/stderr from the daemon process.\n\nThe directory is created with `0700` permissions, and files are cleaned up automatically when the daemon exits or when stale state is detected on the next launch.\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-07T02:17:55.429284"
  },
  {
    "basic_info": {
      "name": "IAMhounddog",
      "full_name": "VirtueSecurity/IAMhounddog",
      "owner": "VirtueSecurity",
      "description": "A tool to help pentesters quickly identify privileged principals and second-order privilege escalation opportunities in unfamiliar AWS accounts.",
      "url": "https://github.com/VirtueSecurity/IAMhounddog",
      "clone_url": "https://github.com/VirtueSecurity/IAMhounddog.git",
      "ssh_url": "git@github.com:VirtueSecurity/IAMhounddog.git",
      "homepage": null,
      "created_at": "2025-09-12T19:37:53Z",
      "updated_at": "2025-10-06T15:48:44Z",
      "pushed_at": "2025-09-16T17:30:09Z"
    },
    "stats": {
      "stars": 90,
      "forks": 8,
      "watchers": 90,
      "open_issues": 0,
      "size": 10519
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 41331
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# IAMhounddog\n\nA tool to help pentesters quickly identify privileged principals and second-order privilege escalation opportunities in unfamiliar AWS environments.\n\n![alt text](img/screenshot.png)\n\n\nhttps://github.com/user-attachments/assets/e60db9c6-75ee-45f9-83fb-0b58f5683ceb\n\n\n## Usage\n\n1. Download and setup [BloodHound Community Edition](https://bloodhound.specterops.io/get-started/quickstart/community-edition-quickstart)\n1. Install via `go install github.com/VirtueSecurity/IAMhounddog@latest`\n1. Run `$ IAMhounddog` with environment variables set (`export AWS_ACCESS_KEY_ID=...`) or an AWS profile (`-profile`)\n1. Import `output.json` into BloodHound using Administration > File Ingest\n1. Run queries against the data\n\nTo include icons in BloodHound and import the bundled queries into the Cypher tab:\n\n1. In BloodHound, go to Profile > API Key Management > Create Token\n1. Run `$ IAMhounddog -setup -url \"http://localhost:8080\" -id \"KEYIDFROMSTEPABOVE\" -token \"KEYTOKENFROMSTEPABOVE\"`\n\nRequires an AWS principal with either SecurityAudit or ReadOnlyAccess.\n\n## Second-Order Privilege Escalation Opportunities\n\nThere are currently multiple tools (such as [Cloudsplaining](https://github.com/salesforce/cloudsplaining)) that effectively identify first-order privilege escalation opportunities. A classic example would be attaching a policy to a role that includes the `iam:PutRolePolicy` permission or attaching the `AdministratorAccess` policy to a principal. Second-order opportunities occur when a principal may not have direct access to these escalation paths, but can abuse other seemingly-benign permissions to get to them. \n\nFor example, in the screenshot at the top of this README, `testfunction-role-nvc6cbn4` has the `AdministratorAccess` policy applied. `Jacob` is a member of the `Developers` group. The `Developers` group only has the `AWSLAMBDA_FULLACCESS` policy attached. Most current tools would correctly identify the `testfunction-role-nvc6cbn4` role as over-permissioned. However, a manual review is required to identify that this role is attached to a Lambda instance which the `Developers` group can modify and, due to group permissions, `Jacob` can modify. This tool eliminates that manual review step and allows pentesters to accurately assess permission relationships in large AWS accounts.\n\n## Coverage\n\nIAMhounddog identifies relationships across:\n\n- IAM roles, users, and groups\n- Attached and inline policies\n- Trust relationships, including foreign principals\n- Roles attached to the following services:\n    - CloudFormation\n    - EC2\n    - ECS\n    - EKS\n    - Lambda\n    - RDS\n    - Step functions    \n    - CodeBuild\n    - CodePipeline\n\n## Data Model\n\nThe data model produced by the tool confirms to the OpenGraph schema. \n\n```mermaid\ngraph LR;\n    Principal-->|assume role|Role;\n    Role-->|attached policy|Policy_1;\n    Role-->|attached policy|Policy_2;\n    Policy_1-->|ec2RunInstances|EC2;\n    Policy_2-->|permission|SSM;\n    EC2-->|instance role|Role_2;\n```\n\nNodes are resources that exist in AWS, including roles, users, and resource categories (like EC2):\n\n- AWSRole\n- AWSUser\n- AWSGroup\n- AWSPrincipal\n- AWSResource\n\nEdges link these resources together:\n\n- Principals are linked to roles usually through awsAssumeRoleAllowed or iamPassRole edges. \n- Roles are linked to policies through awsAttachedPolicy edges. \n- Policies are attached to resources using actions as the edges, like ec2RunInstances. * is remapped to allaccess due to the schema not liking * in edge names. \n- Resources are attached to instance roles through edges unique to the relationship, like awsEcsTaskRole.\n\n## Credits\n\nIAMhounddog was created by Nathan Tucker and is proudly released by [Virtue Security](https://www.virtuesecurity.com/).\n\n### About Virtue Security\n\nVirtue Security is a specialized cybersecurity firm offering in-depth security testing services including:\n- Application Penetration Testing\n- Cloud Penetration Testing\n- Kubernetes Penetration Testing\n- Network Penetration Testing\n\nVisit [Virtue Security](https://www.virtuesecurity.com/) to learn more about their security services.\n\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-07T02:17:56.736468"
  },
  {
    "basic_info": {
      "name": "SLiteIO",
      "full_name": "beankeji-cloud/SLiteIO",
      "owner": "beankeji-cloud",
      "description": "SLiteIO is a cloud-native block storage solution for Kubernetes, using LVM and SPDK to provide both local volumes and high-performance NVMe-oF remote volumes. Its minimal I/O path delivers excellent performance even with standard SSDs, enabling dynamic block device provisioning in hyper-converged clusters.",
      "url": "https://github.com/beankeji-cloud/SLiteIO",
      "clone_url": "https://github.com/beankeji-cloud/SLiteIO.git",
      "ssh_url": "git@github.com:beankeji-cloud/SLiteIO.git",
      "homepage": "",
      "created_at": "2025-09-26T02:18:16Z",
      "updated_at": "2025-10-06T07:02:52Z",
      "pushed_at": "2025-10-01T01:21:13Z"
    },
    "stats": {
      "stars": 89,
      "forks": 10,
      "watchers": 89,
      "open_issues": 0,
      "size": 1488
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 947455,
        "Shell": 9780,
        "Makefile": 6080
      },
      "license": "Apache License 2.0",
      "topics": []
    },
    "content": {
      "readme": "<p align=\"center\"><img src=doc/image/logo.png alt=\"logo.png\" width=\"300\" /></p>\n<p align=\"center\"><b>云原生存储解决方案</b></p>\n<p align=\"center\">\n  [<a href=\"README.md\">中文</a>] | [<a href=\"README-en.md\">English</a>] \n</p>\n\n\n\n# SLiteIO \n本项目基于[eosphoros-ai/liteio]开发，遵循Apache-2.0 license协议。\n**SLiteIO** 是一款云原生有状态容器化的存储解决方案，依赖于LVM存储引擎，可作为本地卷直接使用，也可通过SPDK导出NVME-OF远端卷。由于其极简的存储IO路径，即使是普通SSD也能发挥出不错的性能。该方案专为超融合架构下的 Kubernetes 设计，可实现集群范围的块设备动态供给。\n\n## 特性\n\n1. **低门槛**: 不仅支持NVME和RDMA网络，满足对极致高性能的追求；还支持普通SSD和网络，也能提供不俗的性能，为初创企业或者设备利旧提供便利。                                                                                                                                                                                                      \n2. **云原生**: SLiteIO通过CSI控制器和驱动实现与Kubernetes集成，提供云原生用户接口。用户可以通过PVC动态分配和销毁SLiteIO卷。\n3. **易安装**: 除了一些少量的配置依赖，SLiteIO可以通过一条命令行快速的安装部署。\n4. **极稳定**: 直接利用LVM作为数据引擎，本地卷直接访问，远端卷通过SPDK导出。整个运行时数据链路非常简单，从而带来极致的稳定。\n5. **省成本**: 支持精简模式，可以做到存储空间用多少分配多少，避免过多分配带来的存储空间浪费。\n6. **丰富的调度策略**: 支持跨节点、跨机柜、跨接入等多种高可用调度策略，满足不同等级的生产系统高可用要求。\n\n## 目的\n\n当前有很多系统运行在虚机或者物理机上，在集群到达一定规模后，存在大量的资源利用率失衡：比如有的节点出现CPU或内存不足，却有大量的存储闲置资源。因此在做容器化改造时，有状态的系统比如数据库采用哪种存储方案，充分利用这些闲置存储资源，成为新的难题。为解决这一问题，我们的目标是开发一种系统，能够在保持接近本地磁盘性能的同时，有效整合这些碎片化的存储资源。\n\n## 架构\n\nSLiteIO由六个组件组成：\n\n1. **Disk-Agent**: Disk-Agent安装在每个后端节点上，并且管理该节点上的存储池，该模块与数据引擎交互，实现卷与快照的创建与删除功能。额外的，Disk-Agent还给控制节点上报了存储池状态并给Prometheus提供卷统计信息。\n2. **Disk-Controller**: Disk-Controller掌握了集群种所有的存储池和卷的全局状态信息。它的主要任务时将卷调度到合适的存储池。\n3. **nvme-tcp**: nvme-tcp是一个内核模块，提供了基于TCP的NVME-OF协议。\n4. **nvmf_tgt**: nvmf_tgt提供了将LVM卷导出成nvme target，从而实现远端卷。\n5. **CSI-Driver**: CSI-Driver实现了Kubernetes CSI标准接口，并以Pod形式部署在计算节点上。它通过lvm和nvme-cli工具链实现与后端存储的连接。\n6. **CSI-Controller**: CSI-Controller是个中心化服务，提供PV的创建于删除处理。 \n\n总体而言，SLiteIO架构为云原生块存储提供了一种可扩展且高效的实现方案。通过多组件协同与接口抽象，该架构能够灵活适配不同存储场景的需求。\n\n![](doc/image/architecture.jpg)\n\n## 快速开始\n\n快速开始指南帮助您快速安装一个K8s集群，并在上面部署SLiteio。\n\n- [快速开始](doc/zh/install.md)\n- [使用kubeadm安装K8s](doc/zh/kubeadm-install.md)\n\n## MYSQL数据库场景性能测试\n**测试环境**：40C/256G，7 * 900GB SSD Raid5，2 * 10Gb   3台                    \n**测试工具**：Sysbench               \n**测试方法**：通过Kubernetes容器化场景和KVM虚拟化场景进行对比测试                                                                                               \n**性能测试场景**：K8S + SLiteIO 本地卷 、K8S + SLiteIO 远端卷、KVM 本地卷\n\n创建5对一主一从8C/16G/75GB的MYSQL实例，初始创建300张表，每张表插入100万条测试数据，通过Sysbentch模拟8、16、32、64、128线程并发分别进行只读、只写和混合读写的测试，测试时长180S。 \n\n### 只读（oltp_read_only）     \n\nUnit: TPS\n\n|    Threads  |  K8S + SLiteIO Local | K8S + SLiteIO Remote | KVM Local |\n|-------------|-------------|----------|----------|\n| 8   | 8441.26       | 8452.56   | 2659.97  |\n| 16  | 9533.01       | 9597.72   | 3478.41  |\n| 32  | 9656.76       | 9625.8    | 4082.99  |\n| 64  | 9843          | 9850      | 4577.7   |\n| 128 | 9623.68       | 9623.37   | 5002.31  |\n\n### 只写（oltp_write_only）\n\nUnit: TPS\n\n|    Threads  |  K8S + SLiteIO Local | K8S + SLiteIO Remote | KVM Local |\n|-------------|-------------|----------|----------|\n| 8   | 13409.11     | 7926.2   | 8694.35  |\n| 16  | 17677.05     | 12203.34 | 12237.73 |\n| 32  | 20760.74     | 17277.57 | 15532.35 |\n| 64  | 21864.19     | 20428.38 | 17265.81 |\n| 128 | 25056.6      | 24343.81 | 19032.64 |\n\n### 读写（oltp_read_write）\n\nUnit: TPS\n\n|    Threads  |  K8S + SLiteIO Local | K8S + SLiteIO Remote | KVM Local |\n|-------------|-------------|----------|----------|\n| 8   | 5159.63     | 4355.29  | 2077.54|\n| 16  | 6115.72     | 5908.65  | 2499.74|\n| 32  | 6339.87     | 6365.55  | 2904.73|\n| 64  | 6861.48     | 6851.73  | 3254.35|\n| 128 | 6997.42     | 6989.52  | 3658.97|\n\n总体来说，MYSQL容器化使用SLiteIO存储方案，在并发较高时，本地卷和远程卷的性能几乎持平。并且容器化后的性能远超出虚拟化场景。\n\n\n## 应用场景\n区别于传统分布式存储，Sliteio本身没有做数据冗余，因此适用于业务或上层中间件自身有数据冗余机制的场景下，比如数据库、分布式缓存等。Sliteio特别适合容器化的场景的有状态服务，预算有限需要利旧传统服务器，可以充分的利用和分配存储资源，并获得不错的性能。\n\n\n\n## 高级主题\n\n- [构建指南](doc/zh/build.md)\n- [插件定制指南](doc/zh/plugins.md)\n\n\n## 发展路线\n\n\n## 联系我们\n\n**邮箱**：13515105030@163.com\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-07T02:17:58.001577"
  },
  {
    "basic_info": {
      "name": "devbox",
      "full_name": "itzCozi/devbox",
      "owner": "itzCozi",
      "description": "Create and manage isolated development environments using Docker with ease.",
      "url": "https://github.com/itzCozi/devbox",
      "clone_url": "https://github.com/itzCozi/devbox.git",
      "ssh_url": "git@github.com:itzCozi/devbox.git",
      "homepage": "https://devbox.ar0.eu",
      "created_at": "2025-09-16T21:43:21Z",
      "updated_at": "2025-10-05T19:24:06Z",
      "pushed_at": "2025-10-02T23:32:47Z"
    },
    "stats": {
      "stars": 84,
      "forks": 2,
      "watchers": 84,
      "open_issues": 1,
      "size": 573
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 225727,
        "Python": 13149,
        "Shell": 6481,
        "Makefile": 3403
      },
      "license": "MIT License",
      "topics": [
        "cli",
        "debian",
        "developer-tools",
        "development",
        "devops",
        "docker",
        "golang",
        "tools",
        "ubuntu-server"
      ]
    },
    "content": {
      "readme": "# devbox\n\n**Isolated development environments for anything**\n\n[![CI](https://github.com/itzcozi/devbox/workflows/CI/badge.svg)](https://github.com/itzcozi/devbox/actions)\n[![Go Report Card](https://goreportcard.com/badge/github.com/itzcozi/devbox)](https://goreportcard.com/report/github.com/itzcozi/devbox)\n[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)\n\ndevbox creates isolated development environments, contained in a project's Docker box (container). Each project operates in its own disposable environment, while your code remains neatly organized in a simple, flat folder on the host machine.\n\n## Features\n\n- 🚀 **Instant Setup** - Create isolated development environments in seconds\n- 🐳 **Docker-based** - Leverage the power of boxes (containers) for consistent environments\n- 📁 **Clean Organization** - Keep your code organized in simple, flat folders\n- 🔧 **Configurable** - Define your environment with simple JSON configuration\n- 🗑️ **Disposable** - Easily destroy and recreate environments as needed\n- 🛡️ **Isolated** - Each project runs in its own box, preventing conflicts\n- 🔄 **Docker-in-Docker** - Use Docker within your devbox environments by default\n- 🐧 **Linux-only** - Officially supported on Debian/Ubuntu systems\n- 🧪 **Well Tested** - Comprehensive test suite on Linux\n\n## Why devbox?\n\ndevbox focuses on fast, disposable, Docker-native development environments with simple, commit-friendly config.\n\n- Minimal config: a small JSON file, no heavy frameworks\n- Clean host workspace: flat folders, no complex mounts\n- Reproducible: isolated per-project boxes you can destroy/recreate anytime\n- Docker-in-Docker ready: use Docker inside your environment out of the box\n- Designed for Linux/WSL: optimized for Debian/Ubuntu workflows\n\n## Installation\n\n```bash\n# Using the install script\ncurl -fsSL https://devbox.ar0.eu/install.sh | bash\n# Or manually: https://devbox.ar0.eu/docs/install/#manual-build-from-source\n```\n\nNote: devbox supports Linux environments only (Debian/Ubuntu). On Windows, use WSL2 with an Ubuntu distribution.\n\n## Quick Start\n\n1. **Initialize a new project**\n   ```bash\n   devbox init my-project\n   ```\n\n2. **Enter the development environment**\n   ```bash\n   devbox shell my-project\n   ```\n\n3. **Run commands in the environment**\n   ```bash\n   devbox run my-project \"python --version\"\n   ```\n\n4. **List your environments**\n   ```bash\n   devbox list\n   ```\n\n5. **Clean up when done**\n   ```bash\n   devbox destroy my-project\n   ```\n\n### Shared configs\n\nCommit a `devbox.json` to your repo so teammates can just:\n\n```bash\ndevbox up\n```\n\nOptional: mount your local dotfiles into the box\n\n```bash\ndevbox up --dotfiles ~/.dotfiles\n```\n\n## Documentation\n\nFor detailed documentation, guides, and examples, visit:\n\n**📖 [devbox.ar0.eu](https://devbox.ar0.eu)**\n\n## License\n\nThis project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.\n\n\n**Created by BadDeveloper with 💚**\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-07T02:17:59.269060"
  },
  {
    "basic_info": {
      "name": "auditkit",
      "full_name": "guardian-nexus/auditkit",
      "owner": "guardian-nexus",
      "description": "AuditKit - Multi-Cloud Compliance Scanner & Evidence Collection",
      "url": "https://github.com/guardian-nexus/auditkit",
      "clone_url": "https://github.com/guardian-nexus/auditkit.git",
      "ssh_url": "git@github.com:guardian-nexus/auditkit.git",
      "homepage": "https://auditkit.io/",
      "created_at": "2025-09-19T03:34:03Z",
      "updated_at": "2025-10-07T01:40:58Z",
      "pushed_at": "2025-09-29T03:34:21Z"
    },
    "stats": {
      "stars": 83,
      "forks": 8,
      "watchers": 83,
      "open_issues": 3,
      "size": 257
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 425906
      },
      "license": "Other",
      "topics": [
        "aws",
        "azure",
        "compliance",
        "golang",
        "pci-dss",
        "security",
        "soc2"
      ]
    },
    "content": {
      "readme": "# AuditKit - Multi-Cloud Compliance Scanner & Evidence Collection\n\n**Open-source compliance scanner for AWS and Azure with auditor-ready evidence collection guides.**\n\n[![GitHub stars](https://img.shields.io/github/stars/guardian-nexus/auditkit)](https://github.com/guardian-nexus/auditkit/stargazers)\n[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)\n![Version](https://img.shields.io/badge/version-v0.6.0-green)\n[![Newsletter](https://img.shields.io/badge/Newsletter-Subscribe-orange)](https://auditkit.substack.com)\n\n## What AuditKit Does\n\nAuditKit scans your cloud infrastructure against SOC2, PCI-DSS, and CMMC controls and provides:\n\n1. **Multi-Cloud Support** - AWS (production), Azure (v0.5.0) \n2. **Clear Pass/Fail Status** - 64 SOC2 controls, 30 PCI-DSS controls, 17 CMMC Level 1 controls\n3. **Exact Fix Commands** - Cloud-specific CLI commands for remediation\n4. **Evidence Collection Guides** - Step-by-step screenshots auditors accept\n5. **Priority-Based Fixes** - Critical issues that will fail your audit vs. nice-to-haves\n\n## Quick Start\n\n### AWS\n```bash\n# Configure AWS credentials\naws configure\n\n# Run SOC2 scan\nauditkit scan -provider aws -framework soc2\n\n# Run CMMC Level 1 scan (DoD contractors)\nauditkit scan -provider aws -framework cmmc\n\n# Generate PDF report\nauditkit scan -provider aws -framework soc2 -format pdf -output aws-soc2.pdf\n```\n\n### Azure (v0.5.0)\n```bash\n# Configure Azure credentials\naz login\nexport AZURE_SUBSCRIPTION_ID=\"your-subscription-id\"\n\n# Run SOC2 scan\nauditkit scan -provider azure -framework soc2\n\n# Run CMMC Level 1 scan\nauditkit scan -provider azure -framework cmmc\n\n# Generate PCI-DSS report\nauditkit scan -provider azure -framework pci -format pdf -output azure-pci.pdf\n```\n\n## Recent Updates\n\n**v0.6.0 (Sept 2025)** - CMMC Level 1 support with November 10, 2025 deadline tracking + CMMC Level 2 Pro available  \n**v0.5.0 (Sept 2025)** - Azure provider support with full SOC2/PCI-DSS implementation  \n**v0.4.1 (Sept 2025)** - Complete SOC2 implementation (all 64 Common Criteria)  \n**v0.4.0 (Sept 2025)** - Multi-framework support with PCI-DSS v4.0  \n**v0.3.0 (Sept 2025)** - Evidence collection guides based on Reddit feedback\n\n## Current Implementation Status\n\n### Cloud Providers\n| Provider | Files | Checks | Status | Authentication |\n|----------|-------|--------|--------|----------------|\n| **AWS** | 17 check files | ~150 checks | ✅ Production | AWS CLI, IAM roles |\n| **Azure** | 12 check files | ~110 checks | ✅ Production | CLI, Service Principal, Managed Identity |\n| **GCP** | Not started | 0 | 🚧 Planned v0.7.0 | - |\n\n### Framework Coverage\n| Framework | AWS Controls | Azure Controls | Status |\n|-----------|--------------|----------------|--------|\n| **SOC2** | 64 (CC1-CC9) | 64 (CC1-CC9) | ✅ Production Ready |\n| **PCI-DSS v4.0** | 30 technical | 30 technical | ✅ Production Ready |\n| **CMMC Level 1** | 17 practices | 17 practices | ✅ Production Ready |\n| **CMMC Level 2** | 110 practices (Pro) | 110 practices (Pro) | 🔥 Pro Feature - [AuditKit Pro](https://auditkit.io/pro/) or e-mail hello@auditkit.io |\n| **HIPAA** | ~10 mapped | ~10 mapped | 🧪 Experimental Only |\n| **ISO 27001** | ~5 mapped | ~5 mapped | 🧪 Experimental Only |\n\n### CMMC Compliance (NEW in v0.6.0)\n- **CMMC Level 1**: 17 foundational practices for Federal Contract Information (FCI)\n- **Deadline**: November 10, 2025 - All DoD contracts will require CMMC compliance\n- **Coverage**: Both AWS and Azure providers support complete Level 1 assessment\n- **Evidence**: Screenshot guides for all 17 practices with exact Azure Portal/AWS Console URLs\n\n### Azure Services Covered (v0.5.0+)\n- **Azure AD (Entra ID)**: MFA, privileged roles, guest access, password policies\n- **Full SOC2 Implementation**: All 64 Common Criteria controls (CC1-CC9)\n- **CMMC Implementation**: All 17 Level 1 practices with DoD deadline tracking\n- **Storage Accounts**: Public access, encryption, secure transfer, access keys\n- **Virtual Machines**: Disk encryption, managed disks, security extensions\n- **Network Security Groups**: Open ports, dangerous rules, flow logs\n- **Key Vault**: Soft delete, purge protection, access policies\n- **Activity Logs**: Retention, log profiles, diagnostic settings\n- **Azure SQL**: Transparent encryption, auditing, firewall rules\n- **Managed Identities**: System vs user-assigned configuration\n\n## What Makes AuditKit Different\n\n### 1. Evidence Collection That Auditors Accept\n\n```yaml\nControl Failed: CC6.2 - Public S3 Bucket\nFix Command: aws s3api put-public-access-block --bucket my-bucket --public-access-block-configuration \"BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true\"\n\nEvidence Required:\n1. Navigate to: https://s3.console.aws.amazon.com/s3/buckets/my-bucket\n2. Click \"Permissions\" tab\n3. Screenshot showing all 4 \"Block public access\" settings = ON\n4. Save as: SOC2_CC6.2_S3_Public_Access.png\n```\n\n## What's New in v0.6.0\n\n### C",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-07T02:18:00.545700"
  },
  {
    "basic_info": {
      "name": "go-commons",
      "full_name": "Rodert/go-commons",
      "owner": "Rodert",
      "description": "A small collection of Go language utility packages. ",
      "url": "https://github.com/Rodert/go-commons",
      "clone_url": "https://github.com/Rodert/go-commons.git",
      "ssh_url": "git@github.com:Rodert/go-commons.git",
      "homepage": "",
      "created_at": "2025-09-07T15:47:35Z",
      "updated_at": "2025-09-29T03:48:18Z",
      "pushed_at": "2025-09-13T12:51:59Z"
    },
    "stats": {
      "stars": 82,
      "forks": 9,
      "watchers": 82,
      "open_issues": 0,
      "size": 16691
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 93002,
        "Makefile": 3546,
        "Shell": 1088
      },
      "license": "The Unlicense",
      "topics": []
    },
    "content": {
      "readme": "# go-commons\r\n\r\n<sub><sup>English | [中文 README](README-zh.md)</sup></sub>\r\n\r\n[![Go Reference](https://pkg.go.dev/badge/github.com/Rodert/go-commons.svg)](https://pkg.go.dev/github.com/Rodert/go-commons)\r\n[![License: Unlicense](https://img.shields.io/badge/license-Unlicense-blue.svg)](LICENSE)\r\n[![Go Tests](https://github.com/Rodert/go-commons/actions/workflows/go-test.yml/badge.svg)](https://github.com/Rodert/go-commons/actions/workflows/go-test.yml)\r\n[![Go Lint](https://github.com/Rodert/go-commons/actions/workflows/go-lint.yml/badge.svg)](https://github.com/Rodert/go-commons/actions/workflows/go-lint.yml)\r\n[![codecov](https://codecov.io/gh/Rodert/go-commons/branch/main/graph/badge.svg)](https://codecov.io/gh/Rodert/go-commons)\r\n\r\nA small collection of Go utility packages focused on string helpers and basic system utilities, with minimal third‑party dependencies.\r\n\r\n## Features\r\n\r\n- **No third‑party deps**: Prefer using the Go standard library where possible\r\n- **String utilities (`stringutils`)**:\r\n  - Emptiness and whitespace: `IsEmpty`, `IsNotEmpty`, `IsBlank`, `IsNotBlank`, `Trim`, `TrimToEmpty`\r\n  - Substrings and checks: `ContainsAny`, `ContainsAll`, `SubstringBefore`, `SubstringAfter`, `StartsWith`, `EndsWith`\r\n  - Transformations: `Capitalize`, `Uncapitalize`, `ReverseString`, `ToUpperCase`, `ToLowerCase`\r\n  - Replace and join: `Join`, `Split`, `Replace`, `ReplaceAll`, `Repeat`\r\n  - Padding and centering: `PadLeft`, `PadRight`, `Center`\r\n  - Misc: `Truncate`, `TruncateWithSuffix`, `CountMatches`, `DefaultIfEmpty`, `DefaultIfBlank`\r\n- **System utilities (`systemutils`)**:\r\n  - CPU utilities (`cpuutils`): `GetCPUInfo` - retrieve CPU cores, usage percentage, and load averages\r\n  - Memory utilities (`memutils`): `GetMemInfo` - get total, available, and used memory\r\n  - Disk utilities (`diskutils`): `GetDiskInfo` - get disk space information including total, free, used space and usage ratio\r\n\r\n## Module\r\n\r\n- Module path: `github.com/Rodert/go-commons`\r\n- Go version: `1.24.7`\r\n\r\n## Install\r\n\r\n```bash\r\ngo get github.com/Rodert/go-commons\r\n```\r\n\r\n## Development\r\n\r\n### Auto-formatting\r\n\r\nThis project uses Git hooks to automatically format Go code before each commit.\r\n\r\nTo install the pre-commit hook:\r\n\r\n```bash\r\nmake hooks\r\n```\r\n\r\n### API Documentation\r\n\r\nThis project includes an interactive API documentation interface using Swagger UI. This allows you to explore and test the library's functions through a web interface.\r\n\r\n#### 📌 Online API Documentation\r\n\r\n**Visit our API documentation online at: [https://rodert.github.io/go-commons](https://rodert.github.io/go-commons)**\r\n\r\nThe online documentation is automatically deployed from the main branch and provides the most up-to-date API reference.\r\n\r\n![API Documentation Interface](images/api-img.png)\r\n\r\n#### Local Development\r\n\r\nTo start the API documentation server locally:\r\n\r\n```bash\r\n./run_apidocs.sh\r\n```\r\n\r\nThen open your browser and navigate to [http://localhost:8080](http://localhost:8080) to view the interactive API documentation.\r\n\r\nTo manually format all Go files:\r\n\r\n```bash\r\nmake fmt\r\n```\r\n\r\n## Usage\r\n\r\n### String Utilities\r\n\r\n```go\r\npackage main\r\n\r\nimport (\r\n\t\"fmt\"\r\n\t\"github.com/Rodert/go-commons/stringutils\"\r\n)\r\n\r\nfunc main() {\r\n\t// Basic string operations\r\n\tfmt.Println(stringutils.IsBlank(\"  \\t\\n\"))         // true\r\n\tfmt.Println(stringutils.Trim(\"  hello  \"))        // \"hello\"\r\n\tfmt.Println(stringutils.TruncateWithSuffix(\"abcdef\", 4, \"..\")) // \"ab..\"\r\n\tfmt.Println(stringutils.PadLeft(\"42\", 5, '0'))     // \"00042\"\r\n\tfmt.Println(stringutils.ContainsAny(\"gopher\", \"go\", \"java\")) // true\r\n\t\r\n\t// String transformations\r\n\tfmt.Println(stringutils.Reverse(\"hello\"))         // \"olleh\"\r\n\tfmt.Println(stringutils.SwapCase(\"Hello World\"))  // \"hELLO wORLD\"\r\n\tfmt.Println(stringutils.PadCenter(\"hello\", 9, '*')) // \"**hello**\"\r\n}\r\n```\r\n\r\n### System Utilities\r\n\r\n```go\r\npackage main\r\n\r\nimport (\r\n\t\"fmt\"\r\n\t\"github.com/Rodert/go-commons/systemutils/cpuutils\"\r\n\t\"github.com/Rodert/go-commons/systemutils/memutils\"\r\n\t\"github.com/Rodert/go-commons/systemutils/diskutils\"\r\n)\r\n\r\nfunc main() {\r\n\t// Get CPU information\r\n\tcpuInfo, err := cpuutils.GetCPUInfo()\r\n\tif err == nil {\r\n\t\tfmt.Printf(\"CPU Cores: %d\\n\", cpuInfo.LogicalCores)\r\n\t\tfmt.Printf(\"CPU Usage: %.2f%%\\n\", cpuInfo.UsagePercent)\r\n\t\tfmt.Printf(\"Load Average: %.2f, %.2f, %.2f\\n\", \r\n\t\t\tcpuInfo.LoadAvg[0], cpuInfo.LoadAvg[1], cpuInfo.LoadAvg[2])\r\n\t}\r\n\t\r\n\t// Get memory information\r\n\tmemInfo, err := memutils.GetMemInfo()\r\n\tif err == nil {\r\n\t\tfmt.Printf(\"Total Memory: %d bytes\\n\", memInfo.Total)\r\n\t\tfmt.Printf(\"Available Memory: %d bytes\\n\", memInfo.Available)\r\n\t\tfmt.Printf(\"Used Memory: %d bytes\\n\", memInfo.Used)\r\n\t}\r\n\t\r\n\t// Get disk information\r\n\tdiskInfo, err := diskutils.GetDiskInfo(\"/\")\r\n\tif err == nil {\r\n\t\tfmt.Printf(\"Disk Path: %s\\n\", diskInfo.Path)\r\n\t\tfmt.Printf(\"Total Space: %d bytes\\n\", diskInfo.Total)\r\n\t\tfmt.Printf(\"Free Space: %d bytes\\n\", diskInfo.Free)\r\n\t\tfmt.Printf(\"Used Space: %d bytes\\n\", diskInfo.Used)\r\n\t\tfmt.P",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-07T02:18:01.872840"
  },
  {
    "basic_info": {
      "name": "frankenphp-grpc",
      "full_name": "dunglas/frankenphp-grpc",
      "owner": "dunglas",
      "description": " A PHP extension to write gRPC servers using the official gRPC library written in Go ",
      "url": "https://github.com/dunglas/frankenphp-grpc",
      "clone_url": "https://github.com/dunglas/frankenphp-grpc.git",
      "ssh_url": "git@github.com:dunglas/frankenphp-grpc.git",
      "homepage": null,
      "created_at": "2025-09-15T13:46:34Z",
      "updated_at": "2025-09-24T17:32:40Z",
      "pushed_at": "2025-09-28T15:09:44Z"
    },
    "stats": {
      "stars": 78,
      "forks": 2,
      "watchers": 78,
      "open_issues": 3,
      "size": 83
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 4367
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# FrankenPHP gRPC Server\n\nA [FrankenPHP](https://frankenphp.dev) extension that allows you to run a [gRPC](https://grpc.io/) server triggering code written either in PHP or Go.\nUnder the hood, this extension uses the [gRPC for Go](https://grpc.io/docs/languages/go/) library and FrankenPHP's [Go extension support](https://frankenphp.dev/docs/extensions/).\n\n> [!WARNING]\n>\n> This extension is highly experimental and not recommended for production use.\n> The public API may change at any time without notice.\n\n## Features\n\n* Run a high performance gRPC server with FrankenPHP (the PHP part is executed in a worker loop)\n* Write gRPC service handlers in PHP\n* Write gRPC service handlers in Go\n* Write gRPC service handlers in a mix of PHP and Go 🤯\n* All features supported by the [gRPC for Go](https://grpc.io/docs/languages/go/) library\n* Entirely written in Go, no C code!\n* [API Platform](https://api-platform.com) compatibility!\n\n## Prerequisites\n\n* FrankenPHP extensions prerequisites: https://frankenphp.dev/docs/extensions/#prerequisites\n* gRPC for Go prerequisites: https://grpc.io/docs/languages/go/quickstart/#prerequisites\n\n## Usage\n\n### Create a Go module\n\n```console\ngo mod init example.com/mygrpcserver \n```\n\n### Create a Protobuf Definition:\n\nCreate a `.proto` file describing your gRPC service and messages.\n\nExample (in a `helloworld/helloworld.proto` file):\n\n```protobuf\nsyntax = \"proto3\";\n\noption go_package = \"example.com/mygrpcserver/helloworld\";\n\npackage helloworld;\n\nservice Greeter {\n  rpc SayHello (HelloRequest) returns (HelloReply) {}\n}\n\nmessage HelloRequest {\n  string name = 1;\n}\n\nmessage HelloReply {\n  string message = 1;\n}\n```\n\nGenerate the Go code:\n\n```console\nprotoc --go_out=. --go_opt=paths=source_relative --go-grpc_out=. --go-grpc_opt=paths=source_relative helloworld/helloworld.proto\n```\n\n### Implement the gRPC Server in Go\n\n```go\npackage mygrpcserver\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\n\tpb \"example.com/mygrpcserver/helloworld\"\n\t\"github.com/dunglas/frankenphp\"\n\tphpGrpc \"github.com/dunglas/frankenphp-grpc\"\n\t\"github.com/go-viper/mapstructure/v2\"\n\t\"google.golang.org/grpc\"\n\t\"google.golang.org/grpc/reflection\"\n)\n\nfunc init() {\n\tphpGrpc.RegisterGrpcServerFactory(func() *grpc.Server {\n\t\ts := grpc.NewServer()\n\t\tpb.RegisterGreeterServer(s, &server{})\n\t\treflection.Register(s)\n\n\t\treturn s\n\t})\n}\n\ntype server struct {\n\tpb.UnimplementedGreeterServer\n}\n\n// SayHello implements helloworld.GreeterServer\nfunc (s *server) SayHello(_ context.Context, in *pb.HelloRequest) (*pb.HelloReply, error) {\n\tif in.Name == \"\" {\n\t\treturn nil, fmt.Errorf(\"the Name field is required\")\n\t}\n\n    // Convert the request to a map[string]any\n\tvar phpRequest map[string]any\n\tif err := mapstructure.Decode(in, &phpRequest); err != nil {\n\t\treturn nil, err\n\t}\n\n    // Call the PHP code, pass the map as a PHP associative array\n\tphpResponse := phpGrpc.HandleRequest(phpRequest)\n\n    // Convert the PHP response (a map) back to a HelloReply struct\n\tvar response pb.HelloReply\n\tif err := mapstructure.Decode(phpResponse.(frankenphp.AssociativeArray).Map, &response); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &response, nil\n}\n```\n\nRefer to the [gRPC for Go documentation](https://grpc.io/docs/languages/go/) for more details on how to implement your gRPC service in Go.\nRfer to the [FrankenPHP extensions documentation](https://frankenphp.dev/docs/extensions/) for more details on how to pass data from Go to PHP and vice versa.\n\n### Implement the gRPC Service Handler in PHP\n\nCreate a file named `grpc-worker.php` in the same directory as the FrankenPHP binary we'll build later:\n\n```php\n<?php\n\n// Require the Composer autoloader here if needed (API Platform, Symfony, etc.)\n//require __DIR__ . '/vendor/autoload.php';\n\n// Handler outside the loop for better performance (doing less work)\n$handler = static function (array $request): array  {\n\t// Do something with the gRPC request\n\n    return ['message' => \"Hello, {$request['Name']}\"];\n};\n\n$maxRequests = (int)($_SERVER['MAX_REQUESTS'] ?? 0);\nfor ($nbRequests = 0; !$maxRequests || $nbRequests < $maxRequests; ++$nbRequests) {\n    $keepRunning = \\frankenphp_handle_request($handler);\n\n    // Call the garbage collector to reduce the chances of it being triggered in the middle of the handling of a request\n    gc_collect_cycles();\n\n    if (!$keepRunning) {\n      break;\n    }\n}\n```\n\n### Create the `Caddyfile`\n\nCreate a `Caddyfile` in the same directory as the FrankenPHP binary we'll build later:\n\n```caddyfile\n{\n\tfrankenphp\n\tgrpc {\n\t\taddress :50051 # Optional\n\t\tworker grpc-worker.php # Optional\n\t\tmin_threads 50 # Optional, defaults to runtime.NumCPU()\n\t}\n}\n```\n\n### Build and Run the FrankenPHP Binary with the gRPC Extension\n\nRun the server:\n\n```console\nXCADDY_DEBUG=1\n    CGO_ENABLED=1 \\\n\tXCADDY_GO_BUILD_FLAGS=\"-tags=nobadger,nomysql,nopgx\" \\\n\tCGO_CFLAGS=\"$(php-config --includes) -I/opt/homebrew/include/\" \\\n\tCGO_LDFLAGS=\"$(php-config --ldflags) $(php-config --libs) -L/opt/homebrew/lib/ -L/usr/lib\" \\\n\txcaddy build\n\n./caddy run\n```\n\nYour ",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-07T02:18:03.133843"
  },
  {
    "basic_info": {
      "name": "tuppr",
      "full_name": "home-operations/tuppr",
      "owner": "home-operations",
      "description": "Kubernetes controller to upgrade Talos and Kubernetes",
      "url": "https://github.com/home-operations/tuppr",
      "clone_url": "https://github.com/home-operations/tuppr.git",
      "ssh_url": "git@github.com:home-operations/tuppr.git",
      "homepage": "",
      "created_at": "2025-09-16T22:01:48Z",
      "updated_at": "2025-10-06T20:48:46Z",
      "pushed_at": "2025-10-06T19:44:24Z"
    },
    "stats": {
      "stars": 76,
      "forks": 0,
      "watchers": 76,
      "open_issues": 2,
      "size": 483
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 161578,
        "Makefile": 16229,
        "Smarty": 13610,
        "Dockerfile": 1256,
        "Shell": 603
      },
      "license": "GNU Affero General Public License v3.0",
      "topics": [
        "kubernetes",
        "talos"
      ]
    },
    "content": {
      "readme": "# tuppr - Talos Linux Upgrade Controller\n\nA Kubernetes controller for managing automated upgrades of Talos Linux and Kubernetes.\n\n## ✨ Features\n\n### Core Capabilities\n\n- 🚀 **Automated Talos node upgrades** with intelligent orchestration\n- 🎯 **Kubernetes upgrades** - upgrade Kubernetes to newer versions\n- 🔒 **Safe upgrade execution** - upgrades always run from healthy nodes (never self-upgrade)\n- 📊 **Built-in health checks** - CEL-based expressions for custom cluster validation\n- 🔄 **Configurable reboot modes** - default or powercycle options\n- 📋 **Comprehensive status tracking** with real-time progress reporting\n- ⚡ **Resilient job execution** with automatic retry and pod replacement\n- 📈 **Prometheus metrics** - detailed monitoring of upgrade progress and health\n\n## 🚀 Quick Start\n\n### Prerequisites\n\n1. **Talos cluster** with API access configured\n2. **Namespace** for the controller (e.g., `system-upgrade`)\n\n### Installation\n\nAllow Talos API access to the desired namespace by applying this config to all of you nodes:\n\n```yaml\nmachine:\n  features:\n    kubernetesTalosAPIAccess:\n      allowedKubernetesNamespaces:\n        - system-upgrade # or the namespace the controller will be installed to\n      allowedRoles:\n        - os:admin\n      enabled: true\n```\n\nInstall the Helm chart:\n\n```bash\n# Install via Helm\nhelm install tuppr oci://ghcr.io/home-operations/charts/tuppr \\\n  --version 0.1.0 \\\n  --namespace system-upgrade\n```\n\n### Basic Usage\n\n#### Talos Node Upgrades\n\nCreate a `TalosUpgrade` resource:\n\n```yaml\napiVersion: tuppr.home-operations.com/v1alpha1\nkind: TalosUpgrade\nmetadata:\n  name: cluster\nspec:\n  talos:\n    # renovate: datasource=docker depName=ghcr.io/siderolabs/installer\n    version: v1.11.0  # Required - target Talos version\n\n  policy:\n    debug: true          # Optional, verbose logging\n    force: false         # Optional, skip etcd health checks\n    rebootMode: default  # Optional, default|powercycle\n    placement: soft      # Optional, hard|soft\n\n  # Custom health checks (optional)\n  healthChecks:\n    - apiVersion: v1\n      kind: Node\n      expr: status.conditions.exists(c, c.type == \"Ready\" && c.status == \"True\")\n\n  # Talosctl configuration (optional)\n  talosctl:\n    image:\n      repository: ghcr.io/siderolabs/talosctl  # Optional, default\n      tag: v1.11.0                             # Optional, auto-detected\n      pullPolicy: IfNotPresent                 # Optional, default\n```\n\n#### Kubernetes Upgrades\n\nCreate a `KubernetesUpgrade` resource:\n\n```yaml\napiVersion: tuppr.home-operations.com/v1alpha1\nkind: KubernetesUpgrade\nmetadata:\n  name: kubernetes\nspec:\n  kubernetes:\n    # renovate: datasource=docker depName=ghcr.io/siderolabs/kubelet\n    version: v1.34.0  # Required - target Kubernetes version\n\n  # Custom health checks (optional)\n  healthChecks:\n    - apiVersion: v1\n      kind: Node\n      expr: status.conditions.exists(c, c.type == \"Ready\" && c.status == \"True\")\n      timeout: 10m\n\n  # Talosctl configuration (optional)\n  talosctl:\n    image:\n      repository: ghcr.io/siderolabs/talosctl  # Optional, default\n      tag: v1.11.0                             # Optional, auto-detected\n      pullPolicy: IfNotPresent                 # Optional, default\n```\n\n## 🎯 Advanced Configuration\n\n### Health Checks\n\nDefine custom health checks using [CEL expressions](https://cel.dev/). These health checks are evaluated before each upgrade and run concurrently.\n\n```yaml\nhealthChecks:\n  # Check all nodes are ready\n  - apiVersion: v1\n    kind: Node\n    expr: |\n      status.conditions.filter(c, c.type == \"Ready\").all(c, c.status == \"True\")\n    timeout: 10m\n\n  # Check specific deployment replicas\n  - apiVersion: apps/v1\n    kind: Deployment\n    name: critical-app\n    namespace: production\n    expr: status.readyReplicas == status.replicas\n\n  # Check custom resources\n  - apiVersion: ceph.rook.io/v1\n    kind: CephCluster\n    name: rook-ceph\n    namespace: rook-ceph\n    expr: status.ceph.health in [\"HEALTH_OK\"]\n```\n\n### Upgrade Policies (TalosUpgrade only)\n\nFine-tune upgrade behavior:\n\n```yaml\npolicy:\n  # Enable debug logging for troubleshooting\n  debug: true\n\n  # Force upgrade even if etcd is unhealthy (dangerous!)\n  force: true\n\n  # Controls how strictly upgrade jobs avoid the target node\n  placement: hard  # or \"soft\"\n\n  # Use powercycle reboot for problematic nodes\n  rebootMode: powercycle  # or \"default\"\n```\n\n## 📊 Monitoring & Metrics\n\n### Prometheus Metrics\n\nTuppr exposes comprehensive Prometheus metrics for monitoring upgrade progress, health check performance, and job execution:\n\n#### Talos Upgrade Metrics\n\n```prometheus\n# Current phase of Talos upgrades (0=Pending, 1=InProgress, 2=Completed, 3=Failed)\ntuppr_talos_upgrade_phase{name=\"cluster\", phase=\"InProgress\"} 1\n\n# Node counts for Talos upgrades\ntuppr_talos_upgrade_nodes_total{name=\"cluster\"} 5\ntuppr_talos_upgrade_nodes_completed{name=\"cluster\"} 3\ntuppr_talos_upgrade_nodes_failed{name=\"cluster\"} 0\n\n# Duration of Talos upgrade phases (histogram)\ntuppr_talos_up",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-07T02:18:04.385043"
  },
  {
    "basic_info": {
      "name": "s3tk",
      "full_name": "KingOfBugbounty/s3tk",
      "owner": "KingOfBugbounty",
      "description": null,
      "url": "https://github.com/KingOfBugbounty/s3tk",
      "clone_url": "https://github.com/KingOfBugbounty/s3tk.git",
      "ssh_url": "git@github.com:KingOfBugbounty/s3tk.git",
      "homepage": null,
      "created_at": "2025-09-13T00:05:26Z",
      "updated_at": "2025-10-02T11:36:11Z",
      "pushed_at": "2025-09-13T00:14:31Z"
    },
    "stats": {
      "stars": 75,
      "forks": 20,
      "watchers": 75,
      "open_issues": 2,
      "size": 9
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 13732
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "<div align=\"center\">\n  <img width=\"768\" alt=\"ChatGPT Image 12 de set de 2025, 21_02_01\" src=\"https://github.com/user-attachments/assets/40674e6f-914b-4cd4-a7a9-421657631756\" />\n</div>\n\n\n<h1 align=\"center\">\n  S3Scan - S3 Bucket Security Scanner / <a href=\"https://x.com/OFJAAAH\" target=\"_blank\" rel=\"noopener\">@✖️OFJAAAH</a>\n</h1>\n\n<p align=\"center\">\n  <strong>A powerful S3 bucket security scanner designed for penetration testing and bug bounty hunting</strong>\n</p>\n\n<p align=\"center\">\n  <img src=\"https://img.shields.io/badge/Go-1.21+-blue.svg\" alt=\"Go Version\">\n  <img src=\"https://img.shields.io/badge/License-MIT-green.svg\" alt=\"License\">\n  <img src=\"https://img.shields.io/badge/Platform-Linux%20%7C%20Windows%20%7C%20macOS-lightgrey.svg\" alt=\"Platform\">\n  <img src=\"https://img.shields.io/github/release/user/s3scan.svg\" alt=\"Release\">\n</p>\n\n<p align=\"center\">\n  This tool automatically detects misconfigurations and security vulnerabilities in AWS S3 buckets.\n</p>\n\n## Features\n\n- **Comprehensive Security Testing**: Tests for multiple S3 bucket vulnerabilities\n- **Multiple Input Formats**: Supports various S3 URL formats and bucket names\n- **Permission Testing**: Checks LIST, UPLOAD, DELETE, and TAKEOVER capabilities\n- **Batch Processing**: Scan multiple buckets from stdin input\n- **Colorized Output**: Easy-to-read results with color-coded vulnerability status\n- **Detailed Reporting**: Comprehensive summary of findings\n\n## Security Tests Performed\n\n### 1. Bucket Existence Check\n- Verifies if the S3 bucket exists\n- Identifies non-existent buckets that could be claimed\n\n### 2. List Permissions (READ)\n- Tests if bucket contents can be enumerated\n- Detects publicly readable buckets\n- **Risk**: Information disclosure, data exposure\n\n### 3. Upload Permissions (WRITE)\n- Tests if files can be uploaded to the bucket\n- Identifies writable buckets\n- **Risk**: Malicious file upload, defacement, hosting malware\n\n### 4. Delete Permissions (DELETE)\n- Tests if objects can be deleted from the bucket\n- Detects buckets with delete permissions\n- **Risk**: Data destruction, denial of service\n\n### 5. Bucket Takeover Detection\n- Identifies non-existent buckets that can be claimed\n- Tests multiple AWS regions for takeover opportunities\n- **Risk**: Subdomain takeover, brand impersonation\n\n## Installation\n\n### Prerequisites\n- Go 1.21 or higher\n- Internet connection for S3 API testing\n\n### Building from Source\n\n1. Clone or download the source code\n2. Navigate to the project directory\n3. Build the binary:\n\n```bash\ngo build -o s3scan main.go\n```\n\n### Quick Setup\n\n```bash\n# Make the binary executable\nchmod +x s3scan\n\n# Optional: Move to system PATH\nsudo mv s3scan /usr/local/bin/\n```\n\n## Usage\n\n### Basic Usage\n\nThe tool reads S3 bucket URLs or names from stdin:\n\n```bash\n# Single bucket\necho \"my-test-bucket\" | ./s3scan\n\n# Multiple buckets from file\ncat buckets.txt | ./s3scan\n\n# Multiple buckets inline\necho -e \"bucket1\\nbucket2\\nbucket3\" | ./s3scan\n```\n\n### Supported Input Formats\n\nThe scanner accepts various S3 URL formats:\n\n- Bucket name: `my-bucket-name`\n- Virtual-hosted style: `https://my-bucket.s3.amazonaws.com`\n- Path-style: `https://s3.amazonaws.com/my-bucket`\n- S3 URI: `s3://my-bucket-name`\n\n### Example Commands\n\n```bash\n# Scan from a list of domains/subdomains\nsubfinder -d example.com | grep s3 | ./s3scan\n\n# Scan buckets found during reconnaissance\necho \"company-backups\" | ./s3scan\necho \"app-uploads\" | ./s3scan\necho \"static-assets\" | ./s3scan\n\n# Batch scan from file\ncat << EOF | ./s3scan\ncompany-data\nbackup-bucket\npublic-assets\nuser-uploads\nEOF\n```\n\n### Integration with Other Tools\n\n```bash\n# With subfinder and grep\nsubfinder -d target.com | grep -i s3 | ./s3scan\n\n# With amass\namass enum -d target.com | grep s3 | ./s3scan\n\n# With waybackurls\necho \"target.com\" | waybackurls | grep s3 | ./s3scan\n```\n\n## Output Interpretation\n\n### Vulnerability Status\n\n- **[VULNERABLE]** - Red: Misconfiguration detected\n- **[SECURE]** - Green: No vulnerabilities found\n- **[EXISTS]** - Green: Bucket exists and accessible\n- **[NOT FOUND]** - Yellow: Bucket doesn't exist\n- **[TAKEOVER POSSIBLE]** - Magenta: Bucket can be claimed\n\n### Permission Types\n\n- **[LIST]** - Can enumerate bucket contents\n- **[UPLOAD]** - Can upload files to bucket\n- **[DELETE]** - Can delete objects from bucket\n- **[TAKEOVER]** - Bucket doesn't exist and can be claimed\n\n### Example Output\n\n```\n[MISCONFIGURED] company-backups\n  └─ [LIST] Public read access - can enumerate bucket contents\n  └─ [UPLOAD] Public write access - can upload malicious files\n\n[TAKEOVER POSSIBLE] old-app-assets\n  └─ [TAKEOVER] Bucket doesn't exist - can be claimed for subdomain takeover\n\n[SECURE] private-data\n```\n\n## Legal and Ethical Usage\n\n⚠️ **IMPORTANT**: This tool is designed for:\n- Authorized penetration testing\n- Bug bounty programs\n- Security assessments on systems you own\n- Educational purposes\n\n**DO NOT USE** for:\n- Unauthorized testing of third-party systems\n- Malicious activities\n- Illegal access att",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-07T02:18:05.681389"
  },
  {
    "basic_info": {
      "name": "sshai",
      "full_name": "sshllm/sshai",
      "owner": "sshllm",
      "description": "基于SSH的AI客户端。随时随地，立即连接使用大模型服务！| SSH-Based AI Client: Seamlessly access large language model services anytime, anywhere with instant connectivity!",
      "url": "https://github.com/sshllm/sshai",
      "clone_url": "https://github.com/sshllm/sshai.git",
      "ssh_url": "git@github.com:sshllm/sshai.git",
      "homepage": "https://sshllm.top",
      "created_at": "2025-09-11T15:57:07Z",
      "updated_at": "2025-10-06T05:57:51Z",
      "pushed_at": "2025-09-29T08:19:07Z"
    },
    "stats": {
      "stars": 71,
      "forks": 4,
      "watchers": 71,
      "open_issues": 0,
      "size": 580
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 125747,
        "Shell": 82720,
        "Makefile": 3381
      },
      "license": "Other",
      "topics": [
        "ai",
        "ai-client",
        "sshai"
      ]
    },
    "content": {
      "readme": "# SSHAI - SSH AI Assistant\n\n[English](./README_EN.md) | 简体中文\n\n一个通过SSH连接提供AI模型服务的智能助手程序，让你可以在任何支持SSH的环境中使用AI助手。 \n\n支持[三种调用模式](https://mp.weixin.qq.com/s/_sSEC15WOfeF0t8AaQ6Qbg)：\n- **交互模式** - 通过SSH连接后，直接在终端中输入命令即可调用AI助手（`ssh your-bot@sshllm.top`）    \n- **命令行模式** - 通过SSH连接后，直接在终端中执行命令即可调用AI助手（`ssh bash@sshllm.top 查看进程占用`）    \n- **管道模式** - 通过SSH连接后，通过管道将内容输入到AI助手即可调用AI助手（`cat doc.txt | ssh fanyi@sshllm.top`）\n\n此项目采用`CodeBuddy`进行开发，完全不写一行代码。    \n关于开发的经验心得，请参考：[不写一行代码！我用 AI 打造了一款 AI 客户端！（开源）](https://mp.weixin.qq.com/s/-5GC3TDAP_CXAcAkGO7tMQ)    \n\n\n## 🚀 精选案例\n`SSHLLM`，基于当前开源版深度定制的多用户多配置版，支持用户注册、配置助手，并分享公开或者私有使用。随时随地通过SSH即可调用AI助手完成如自动生成bash脚本、代码、识别图片验证码等功能。\n\n官网：[https://sshllm.top](https://sshllm.top)\n\n\n## 🚀 体验（开源版本）\n打开你的终端，输入如下命令即可立即体验在线AI服务！\n```bash\nssh test.sshai.top -p 9527\n```\n\n![](docs/screenshot.png)\n\n## ✨ 主要特性\n\n- 🔐 **SSH安全连接** - 通过SSH协议提供加密的AI服务访问\n- 🔑 **灵活认证** - 支持密码认证、SSH公钥免密登录和无密码模式\n- 🗝️ **SSH Keys支持** - 支持多个SSH公钥免密登录，兼容RSA、Ed25519等密钥类型\n- 🤖 **多模型支持** - 支持DeepSeek、Hunyuan等多种AI模型\n- 💭 **实时思考显示** - 支持DeepSeek R1等模型的思考过程实时展示\n- 🛠️ **MCP工具支持** - 支持Model Context Protocol，可集成各种外部工具和服务\n- 🎨 **美观界面** - 彩色输出、动画效果和ASCII艺术\n- ⚙️ **灵活配置** - 支持动态指定配置文件（-c参数）和完整的YAML配置\n- 🌐 **多语言支持** - 支持中文和英文界面\n- 📝 **自定义提示词** - 可配置的AI提示词系统\n- 🚀 **启动欢迎页** - 程序启动时显示美观的欢迎banner\n- 🏗️ **模块化设计** - 清晰的代码架构，易于扩展\n\n## 🚀 快速开始\n\n### 1. 下载和编译\n\n```bash\n# 克隆项目\ngit clone https://github.com/sshllm/sshai.git\ncd sshai\n\n# 编译程序\nmake build\n# 或者\ngo build -o sshai cmd/main.go\n```\n\n### 2. 配置设置\n\n编辑 `config.yaml` 文件，设置你的API密钥：\n\n```yaml\n# API配置\napi:\n  base_url: \"https://api.deepseek.com/v1\"\n  api_key: \"your-api-key-here\"\n  default_model: \"deepseek-v3\"\n\n# 服务器配置\nserver:\n  port: 2213\n  welcome_message: \"欢迎使用SSHAI！\"\n\n# 认证配置（可选）\nauth:\n  password: \"\"  # 留空=无密码认证\n  login_prompt: \"请输入访问密码: \"\n  # SSH公钥免密登录配置（仅在设置password时生效）\n  authorized_keys:\n    - \"ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC... user@hostname\"\n    - \"ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAI... user2@hostname\"\n  authorized_keys_file: \"~/.ssh/authorized_keys\"  # 可选：从文件读取公钥\n\n# 自定义提示词配置\nprompt:\n  system_prompt: \"你是一个专业的AI助手，请用中文回答问题。\"\n  stdin_prompt: \"请分析以下内容并提供相关的帮助或建议：\"\n  exec_prompt: \"请回答以下问题或执行以下任务：\"\n\n# MCP工具配置\nmcp:\n  enabled: true  # 启用MCP功能\n  refresh_interval: 300  # 工具列表刷新间隔（秒）\n  servers:\n    # 使用uvx的稳定服务（推荐）\n    - name: \"time\"\n      transport: \"stdio\"\n      command: [\"uvx\", \"mcp-server-time\"]\n      enabled: true\n    - name: \"fetch\"\n      transport: \"stdio\"\n      command: [\"uvx\", \"mcp-server-fetch\"]\n      enabled: true\n    # 使用npx的服务（可能需要更长启动时间）\n    - name: \"bing\"\n      transport: \"stdio\"\n      command: [\"npx\", \"bing-cn-mcp\"]\n      enabled: true\n```\n\n### 3. 运行服务器\n\n```bash\n# 直接运行（使用默认配置文件 config.yaml）\n./sshai\n\n# 指定配置文件运行\n./sshai -c config.yaml\n./sshai -c /path/to/your/config.yaml\n\n# 后台运行\n./sshai > server.log 2>&1 &\n\n# 使用脚本运行\n./scripts/run.sh\n```\n\n#### 命令行参数\n\n- `-c <config_file>` - 指定配置文件路径\n  - 如果不指定，默认使用当前目录下的 `config.yaml`\n  - 如果配置文件不存在，程序会显示错误提示并退出\n\n```bash\n# 使用示例\n./sshai -c config.yaml          # 使用当前目录的配置文件\n./sshai -c /etc/sshai/config.yaml  # 使用绝对路径的配置文件\n./sshai                         # 默认使用 config.yaml\n```\n\n### 4. 连接使用\n\n```bash\n# 交互模式\nssh user@localhost -p 2213\n\n# 直接执行命令\nssh user@localhost -p 2213 \"你好，请介绍一下你自己\"\n\n# 管道输入分析\ncat file.txt | ssh user@localhost -p 2213\necho \"分析这段代码\" | ssh user@localhost -p 2213\n```\n\n## 📁 项目结构\n\n```\nsshai/\n├── README.md              # 中文说明文档\n├── README_EN.md           # 英文说明文档\n├── LICENSE                # 开源协议\n├── config.yaml           # 主配置文件\n├── config-en.yaml        # 英文配置文件\n├── go.mod                # Go模块依赖\n├── Makefile              # 构建脚本\n├── cmd/                  # 程序入口\n│   └── main.go           # 主程序文件\n├── pkg/                  # 核心模块\n│   ├── config/           # 配置管理\n│   ├── models/           # 数据模型\n│   ├── ai/               # AI助手功能\n│   ├── ssh/              # SSH服务器\n│   └── utils/            # 工具函数\n├── docs/                 # 项目文档\n├── scripts/              # 测试和运行脚本\n└── keys/                 # SSH密钥文件\n```\n\n## 🔧 配置指南\n\n### API配置\n\n支持多个API端点配置：\n\n```yaml\napi:\n  base_url: \"https://api.deepseek.com/v1\"\n  api_key: \"your-deepseek-key\"\n  default_model: \"deepseek-v3\"\n  timeout: 600\n\n# 可配置多个API\napi_endpoints:\n  - name: \"deepseek\"\n    base_url: \"https://api.deepseek.com/v1\"\n    api_key: \"your-key\"\n    default_model: \"deepseek-v3\"\n  - name: \"local\"\n    base_url: \"http://localhost:11434/v1\"\n    api_key: \"ollama\"\n    default_model: \"gemma2:27b\"\n```\n\n### 认证配置\n\n#### 密码认证\n```yaml\nauth:\n  password: \"your-secure-password\"  # 设置访问密码\n  login_prompt: \"请输入访问密码: \"\n```\n\n#### SSH公钥免密登录\n```yaml\nauth:\n  password: \"your-secure-password\"  # 必须设置密码才能启用SSH公钥认证\n  login_prompt: \"请输入访问密码: \"\n  # 方式一：直接配置公钥列表\n  authorized_keys:\n    - \"ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABAQC... user@hostname\"\n    - \"ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAI... user2@hostname\"\n  # 方式二：从文件读取公钥\n  authorized_keys_file: \"~/.ssh/authorized_keys\"\n```\n\n**SSH公钥使用方法**：\n```bash\n# 生成SSH密钥对\nssh-keygen -t ed25519 -f ~/.ssh/sshai_key\n\n# 使用私钥连接（免密登录）\nssh -i ~/.ssh/sshai_key -p 2213 user@localhost\n\n# 查看公钥内容（用于配置）\ncat ~/.ssh/sshai_key.pub\n```\n\n**注意**: \n-",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-07T02:18:07.059817"
  },
  {
    "basic_info": {
      "name": "gomindmapper",
      "full_name": "chinmay-sawant/gomindmapper",
      "owner": "chinmay-sawant",
      "description": "Mind Mapper for Go (Might make it language agnostic in future)",
      "url": "https://github.com/chinmay-sawant/gomindmapper",
      "clone_url": "https://github.com/chinmay-sawant/gomindmapper.git",
      "ssh_url": "git@github.com:chinmay-sawant/gomindmapper.git",
      "homepage": "https://chinmay-sawant.github.io/gomindmapper/",
      "created_at": "2025-09-17T18:43:05Z",
      "updated_at": "2025-10-06T11:28:16Z",
      "pushed_at": "2025-09-28T05:54:45Z"
    },
    "stats": {
      "stars": 67,
      "forks": 1,
      "watchers": 67,
      "open_issues": 0,
      "size": 30624
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 89480,
        "Makefile": 473
      },
      "license": "MIT License",
      "topics": [
        "code-visualization",
        "go-code-visualizer",
        "go-visualizer",
        "mindmap",
        "mindmap-visualizer",
        "visualizer"
      ]
    },
    "content": {
      "readme": "<div align=\"center\">\n\n# GoMindMapper\n\n🚀 **Advanced Go Function Relationship Visualizer** 🚀\n\nInteractive function relationship visualization for Go codebases with intelligent type resolution, interface implementation detection, and external module analysis. Scan any Go repository and explore it through an expandable, pannable, zoomable mind map.\n\n`Go (AST Analyzer + HTTP API)` + `React (Interactive Mind Map)` + `Notion‑style UI`\n\n[![GitHub Stars](https://img.shields.io/github/stars/chinmay-sawant/gomindmapper?style=social)](https://github.com/chinmay-sawant/gomindmapper) \n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Go Version](https://img.shields.io/github/go-mod/go-version/chinmay-sawant/gomindmapper)](https://golang.org/)\n\n---\n\n</div>\n\n## 📋 Table of Contents\n1. [🚀 Quick Start](#quick-start)\n2. [✨ Features Overview](#features-overview)\n3. [🏗️ Architecture](#architecture)\n4. [⚙️ Installation & Setup](#installation--setup)\n5. [🔧 Development](#development)\n6. [📖 Usage Guide](#usage-guide)\n7. [🎯 Advanced Features](#advanced-features)\n8. [🔍 API Reference](#api-reference)\n9. [📊 Data Models](#data-models)\n10. [🎨 Customization](#customization)\n11. [🗺️ Roadmap](#roadmap)\n12. [🤝 Contributing](#contributing)\n13. [📄 License](#license)\n\n---\n\n<a id=\"quick-start\"></a>\n## 🚀 Quick Start\n\nGet started with GoMindMapper in under 2 minutes:\n\n### Single Command Deployment\n```bash\n# Clone and run (example analyzing the 'gopdfsuit' subdirectory)\ngit clone https://github.com/chinmay-sawant/gomindmapper.git\ncd gomindmapper\ngo run cmd/server/main.go -path gopdfsuit -addr :8080 --include-external=true --skip-folders=\"golang.org,gin-gonic,bytedance,ugorji,go-playground\"\n```\n\n**Command Flags:**\n- `-path <dir>`: Repository/subfolder to analyze (e.g., `gopdfsuit`)\n- `-addr <addr>`: HTTP server address (default `:8080`)\n- `--include-external`: Include external module functions in analysis\n- `--skip-folders`: Comma-separated dependency prefixes to skip during external scanning\n\n**Access Points:**\n- 🌐 **Overview**: http://localhost:8080/gomindmapper/\n- 🗺️ **Mind Map**: http://localhost:8080/gomindmapper/view/\n\n> **Note**: Production React assets are automatically served by the Go server — no separate frontend setup required!\n\n### Makefile Shortcuts\n```bash\nmake ui-build   # Build React frontend\nmake server     # Start Go server\nmake ui         # Start React dev server\nmake run        # Run CLI analyzer\n```\n\n---\n\n<a id=\"features-overview\"></a>\n## ✨ Features Overview\n\nGoMindMapper goes beyond simple function visualization with advanced Go code analysis capabilities:\n\n### 🎯 Core Analysis Engine\n* **🧠 AST-based Go Analysis** - Uses Go's built-in AST parsing for accurate function extraction\n* **🔍 Smart Root Detection** - Automatically identify top-level entry points (functions not called by any other user function)\n* **🏗️ Interface Implementation Detection** - Discover concrete implementations of interfaces and add them to call graphs\n* **🔗 Type Resolution Engine** - Resolve method calls through comprehensive type analysis\n* **📦 External Module Scanning** - Recursively scan external dependencies with intelligent filtering\n* **🎛️ Advanced Filtering** - Multi-layer filtering: stdlib, external libraries, framework noise, custom patterns\n* **⚡ Performance Optimization** - Parallel processing, in-memory caching, and efficient data structures\n\n### 🎨 Interactive UI & Visualization\n* **🗺️ Google NotebookLLM-inspired Nodes** - Custom-designed function nodes with color-coded types (main, handler, middleware, config, router)\n* **🖱️ Intuitive Controls** - Pan (drag background), zoom (mouse wheel), expand/collapse nodes individually\n* **🌓 Advanced Theming** - Dark/light theme with system preference detection and localStorage persistence\n* **📤 Drag & Drop Upload** - Drop JSON files directly onto interface for offline analysis\n* **🔎 Real-time Search** - Debounced search with instant results and pagination\n* **📋 Function Details Panel** - Comprehensive information display on node selection (file path, line numbers, calls)\n* **📱 Responsive Design** - Works seamlessly across desktop, tablet, and mobile devices\n* **🎞️ Screenshot Slideshow** - Interactive feature showcase with auto-play and navigation\n* **📊 Comparison Table** - Built-in comparison with other Go visualization tools\n\n### 🔧 Data Management & Integration\n* **🔄 Dual Data Modes** - Switch between offline JSON snapshots or live server API\n* **🔥 Hot Reload Capability** - Refresh data from repository without restarting (`POST /api/reload`)\n* **💾 Multi-format Export** - Download as JSON, with planned support for GraphML/DOT/SVG\n* **📊 Multiple Output Formats** - Generate `functions.json`, `functionmap.json`, and `removed_calls.json`\n* **🌐 Live Server Integration** - RESTful API with pagination, search, and real-time updates\n* **🔒 Concurrent Safety** - Thread-safe operations with proper mutex handling\n\n---\n\n<a id=\"architecture\"></a>\n## 🏗️ Archit",
      "default_branch": "master"
    },
    "fetched_at": "2025-10-07T02:18:08.335403"
  }
]