[
  {
    "basic_info": {
      "name": "ccg-workflow",
      "full_name": "fengshao1227/ccg-workflow",
      "owner": "fengshao1227",
      "description": "å¤šæ¨¡å‹åä½œå¼€å‘å·¥å…·é›† - åŸºäº Claude Code CLIï¼Œæ•´åˆ Codex/Gemini åç«¯èƒ½åŠ›ï¼Œæä¾›æ™ºèƒ½è·¯ç”±ã€ä»£ç å®¡æŸ¥ã€Git å·¥å…·ç­‰ 17+ ä¸ªå‘½ä»¤",
      "url": "https://github.com/fengshao1227/ccg-workflow",
      "clone_url": "https://github.com/fengshao1227/ccg-workflow.git",
      "ssh_url": "git@github.com:fengshao1227/ccg-workflow.git",
      "homepage": "",
      "created_at": "2026-01-04T15:56:26Z",
      "updated_at": "2026-01-20T02:55:04Z",
      "pushed_at": "2026-01-18T14:26:47Z"
    },
    "stats": {
      "stars": 1391,
      "forks": 97,
      "watchers": 1391,
      "open_issues": 2,
      "size": 245730
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 396403,
        "TypeScript": 113314,
        "Shell": 880,
        "JavaScript": 268
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# CCG - Claude + Codex + Gemini Multi-Model Collaboration\n\n<div align=\"center\">\n\n[![npm version](https://img.shields.io/npm/v/ccg-workflow.svg)](https://www.npmjs.com/package/ccg-workflow)\n[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)\n[![Claude Code](https://img.shields.io/badge/Claude%20Code-Compatible-green.svg)](https://claude.ai/code)\n\n</div>\n\nClaude Code ç¼–æ’ Codex + Gemini çš„å¤šæ¨¡å‹åä½œå¼€å‘ç³»ç»Ÿã€‚å‰ç«¯ä»»åŠ¡è·¯ç”±è‡³ Geminiï¼Œåç«¯ä»»åŠ¡è·¯ç”±è‡³ Codexï¼ŒClaude è´Ÿè´£ç¼–æ’å†³ç­–å’Œä»£ç å®¡æ ¸ã€‚\n\n## å®‰è£…\n\n```bash\nnpx ccg-workflow\n```\n\n**è¦æ±‚**ï¼šClaude Code CLIã€Node.js 18+\n\n**å¯é€‰**ï¼šCodex CLIï¼ˆåç«¯ï¼‰ã€Gemini CLIï¼ˆå‰ç«¯ï¼‰\n\n## å‘½ä»¤\n\n| å‘½ä»¤ | è¯´æ˜ |\n|------|------|\n| `/ccg:workflow` | 6 é˜¶æ®µå®Œæ•´å·¥ä½œæµ |\n| `/ccg:plan` | å¤šæ¨¡å‹åä½œè§„åˆ’ (Phase 1-2) |\n| `/ccg:execute` | å¤šæ¨¡å‹åä½œæ‰§è¡Œ (Phase 3-5) |\n| `/ccg:feat` | æ–°åŠŸèƒ½å¼€å‘ |\n| `/ccg:frontend` | å‰ç«¯ä»»åŠ¡ (Gemini) |\n| `/ccg:backend` | åç«¯ä»»åŠ¡ (Codex) |\n| `/ccg:analyze` | æŠ€æœ¯åˆ†æ |\n| `/ccg:debug` | é—®é¢˜è¯Šæ–­ |\n| `/ccg:optimize` | æ€§èƒ½ä¼˜åŒ– |\n| `/ccg:test` | æµ‹è¯•ç”Ÿæˆ |\n| `/ccg:review` | ä»£ç å®¡æŸ¥ |\n| `/ccg:commit` | Git æäº¤ |\n| `/ccg:rollback` | Git å›æ»š |\n| `/ccg:clean-branches` | æ¸…ç†åˆ†æ”¯ |\n| `/ccg:worktree` | Worktree ç®¡ç† |\n| `/ccg:init` | åˆå§‹åŒ– CLAUDE.md |\n| `/ccg:enhance` | Prompt å¢å¼º |\n\n### è§„åˆ’ä¸æ‰§è¡Œåˆ†ç¦»\n\nv1.7.39 æ–°å¢ `/ccg:plan` å’Œ `/ccg:execute` å‘½ä»¤ï¼Œå°†è§„åˆ’ä¸æ‰§è¡Œè§£è€¦ï¼š\n\n```bash\n# 1. ç”Ÿæˆå®æ–½è®¡åˆ’\n/ccg:plan å®ç°ç”¨æˆ·è®¤è¯åŠŸèƒ½\n\n# 2. å®¡æŸ¥è®¡åˆ’ï¼ˆå¯ä¿®æ”¹ï¼‰\n# è®¡åˆ’ä¿å­˜è‡³ .claude/plan/user-auth.md\n\n# 3. æ‰§è¡Œè®¡åˆ’ï¼ˆæ–°ä¼šè¯ä¹Ÿå¯æ‰§è¡Œï¼‰\n/ccg:execute .claude/plan/user-auth.md\n```\n\n## é…ç½®\n\n### ç›®å½•ç»“æ„\n\n```\n~/.claude/\nâ”œâ”€â”€ commands/ccg/       # æ–œæ å‘½ä»¤\nâ”œâ”€â”€ agents/ccg/         # å­æ™ºèƒ½ä½“\nâ”œâ”€â”€ bin/codeagent-wrapper\nâ””â”€â”€ .ccg/\n    â”œâ”€â”€ config.toml\n    â””â”€â”€ prompts/{codex,gemini}/\n```\n\n### ç¯å¢ƒå˜é‡\n\n| å˜é‡ | è¯´æ˜ | é»˜è®¤å€¼ |\n|------|------|--------|\n| `CODEAGENT_POST_MESSAGE_DELAY` | Codex å®Œæˆåç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰ | 5 |\n| `CODEX_TIMEOUT` | codeagent-wrapper æ‰§è¡Œè¶…æ—¶ï¼ˆç§’ï¼‰ | 7200 |\n| `BASH_DEFAULT_TIMEOUT_MS` | Claude Code Bash é»˜è®¤è¶…æ—¶ï¼ˆæ¯«ç§’ï¼‰ | 120000 |\n| `BASH_MAX_TIMEOUT_MS` | Claude Code Bash æœ€å¤§è¶…æ—¶ï¼ˆæ¯«ç§’ï¼‰ | 600000 |\n\né…ç½®æ–¹å¼ï¼ˆ`~/.claude/settings.json`ï¼‰ï¼š\n\n```json\n{\n  \"env\": {\n    \"CODEAGENT_POST_MESSAGE_DELAY\": \"1\",\n    \"CODEX_TIMEOUT\": \"7200\",\n    \"BASH_DEFAULT_TIMEOUT_MS\": \"600000\",\n    \"BASH_MAX_TIMEOUT_MS\": \"3600000\"\n  }\n}\n```\n\n### MCP é…ç½®\n\nace-tool ç”¨äºä»£ç æ£€ç´¢å’Œ Prompt å¢å¼ºï¼Œå®‰è£…æ—¶å¯é€‰é…ç½®ã€‚\n\nToken è·å–ï¼šhttps://augmentcode.com/\n\n## æ›´æ–° / å¸è½½\n\n```bash\n# æ›´æ–°\nnpx ccg-workflow@latest          # npx ç”¨æˆ·\nnpm install -g ccg-workflow@latest  # npm å…¨å±€ç”¨æˆ·\n\n# å¸è½½\nnpx ccg-workflow  # é€‰æ‹© \"å¸è½½å·¥ä½œæµ\"\nnpm uninstall -g ccg-workflow  # npm å…¨å±€ç”¨æˆ·éœ€é¢å¤–æ‰§è¡Œ\n```\n\n## å·²çŸ¥é—®é¢˜\n\n**Codex CLI 0.80.0 è¿›ç¨‹ä¸é€€å‡º**\n\n`--json` æ¨¡å¼ä¸‹ Codex å®Œæˆè¾“å‡ºåè¿›ç¨‹ä¸ä¼šè‡ªåŠ¨é€€å‡ºã€‚\n\nè§£å†³ï¼šè®¾ç½® `CODEAGENT_POST_MESSAGE_DELAY=1`\n\n## æ¶æ„\n\n```\nClaude Code (ç¼–æ’)\n       â”‚\n   â”Œâ”€â”€â”€â”´â”€â”€â”€â”\n   â†“       â†“\nCodex   Gemini\n(åç«¯)   (å‰ç«¯)\n   â”‚       â”‚\n   â””â”€â”€â”€â”¬â”€â”€â”€â”˜\n       â†“\n  Unified Patch\n```\n\nå¤–éƒ¨æ¨¡å‹æ— å†™å…¥æƒé™ï¼Œä»…è¿”å› Patchï¼Œç”± Claude å®¡æ ¸ååº”ç”¨ã€‚\n\n## è‡´è°¢\n\n- [cexll/myclaude](https://github.com/cexll/myclaude) - codeagent-wrapper\n- [UfoMiao/zcf](https://github.com/UfoMiao/zcf) - Git å·¥å…·\n- [GudaStudio/skills](https://github.com/GuDaStudio/skills) - è·¯ç”±è®¾è®¡\n- [ace-tool](https://linux.do/t/topic/1344562) - MCP å·¥å…·\n\n## Star History\n\n[![Star History Chart](https://api.star-history.com/svg?repos=fengshao1227/ccg-workflow&type=timeline&legend=top-left)](https://www.star-history.com/#fengshao1227/ccg-workflow&type=timeline&legend=top-left)\n\n## License\n\nMIT\n\n---\n\nv1.7.39 | [Issues](https://github.com/fengshao1227/ccg-workflow/issues)\n",
      "default_branch": "main"
    },
    "fetched_at": "2026-01-20T02:57:00.486554"
  },
  {
    "basic_info": {
      "name": "nginxpulse",
      "full_name": "likaia/nginxpulse",
      "owner": "likaia",
      "description": "è½»é‡çº§ Nginx è®¿é—®æ—¥å¿—åˆ†æä¸å¯è§†åŒ–é¢æ¿ï¼Œæä¾›å®æ—¶ç»Ÿè®¡ã€PV è¿‡æ»¤ã€IP å½’å±åœ°ä¸å®¢æˆ·ç«¯è§£æã€‚",
      "url": "https://github.com/likaia/nginxpulse",
      "clone_url": "https://github.com/likaia/nginxpulse.git",
      "ssh_url": "git@github.com:likaia/nginxpulse.git",
      "homepage": "https://nginx-pulse.kaisir.cn/",
      "created_at": "2026-01-13T04:19:14Z",
      "updated_at": "2026-01-20T02:55:14Z",
      "pushed_at": "2026-01-19T15:23:28Z"
    },
    "stats": {
      "stars": 1053,
      "forks": 82,
      "watchers": 1053,
      "open_issues": 2,
      "size": 17303
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 313992,
        "Vue": 195470,
        "TypeScript": 53848,
        "SCSS": 36503,
        "Shell": 14374,
        "Python": 11444,
        "Dockerfile": 1643,
        "Makefile": 826,
        "HTML": 383
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "<p align=\"center\">\n  <img src=\"docs/brand-mark.svg\" alt=\"NginxPulse Logo\" width=\"120\" height=\"120\">\n</p>\n\n<p align=\"center\">\n  <a href=\"README_EN.md\">English</a> | ç®€ä½“ä¸­æ–‡\n</p>\n\n# NginxPulse\n\nè½»é‡çº§ Nginx è®¿é—®æ—¥å¿—åˆ†æä¸å¯è§†åŒ–é¢æ¿ï¼Œæä¾›å®æ—¶ç»Ÿè®¡ã€PV è¿‡æ»¤ã€IP å½’å±åœ°ä¸å®¢æˆ·ç«¯è§£æã€‚\n\n![demo-img-1.png](docs/demo-img-1.png)\n\n![demo-img-2.png](docs/demo-img-2.png)\n## ç›®å½•\n- [é¡¹ç›®å¼€å‘æŠ€æœ¯æ ˆ](#é¡¹ç›®å¼€å‘æŠ€æœ¯æ ˆ)\n- [IP å½’å±åœ°æŸ¥è¯¢ç­–ç•¥](#ip-å½’å±åœ°æŸ¥è¯¢ç­–ç•¥)\n- [å¦‚ä½•ä½¿ç”¨é¡¹ç›®](#å¦‚ä½•ä½¿ç”¨é¡¹ç›®)\n  - [1) Docker](#1-docker)\n  - [2) Docker Compose](#2-docker-compose)\n  - [3) æ‰‹åŠ¨æ„å»ºï¼ˆå‰ç«¯ã€åç«¯ï¼‰](#3-æ‰‹åŠ¨æ„å»ºå‰ç«¯åç«¯)\n  - [4) å•ä½“éƒ¨ç½²ï¼ˆå•è¿›ç¨‹ï¼‰](#4-å•ä½“éƒ¨ç½²å•è¿›ç¨‹)\n  - [5) Makefile å¸¸ç”¨å‘½ä»¤](#5-makefile-å¸¸ç”¨å‘½ä»¤)\n- [å¤šä¸ªæ—¥å¿—æ–‡ä»¶å¦‚ä½•æŒ‚è½½ï¼Ÿ](#å¤šä¸ªæ—¥å¿—æ–‡ä»¶å¦‚ä½•æŒ‚è½½)\n- [è¿œç«¯æ—¥å¿—æ”¯æŒï¼ˆsourcesï¼‰](#è¿œç«¯æ—¥å¿—æ”¯æŒsources)\n- [Push Agentï¼ˆå®æ—¶æ¨é€ï¼‰](#push-agentå®æ—¶æ¨é€)\n- [è‡ªå®šä¹‰æ—¥å¿—æ ¼å¼](#è‡ªå®šä¹‰æ—¥å¿—æ ¼å¼)\n- [Caddy æ—¥å¿—æ”¯æŒ](#caddy-æ—¥å¿—æ”¯æŒ)\n- [è®¿é—®å¯†é’¥åˆ—è¡¨ï¼ˆACCESS_KEYSï¼‰](#è®¿é—®å¯†é’¥åˆ—è¡¨access_keys)\n- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)\n- [äºŒæ¬¡å¼€å‘æ³¨æ„äº‹é¡¹](#äºŒæ¬¡å¼€å‘æ³¨æ„äº‹é¡¹)\n- [ç›®å½•ç»“æ„ä¸ä¸»è¦æ–‡ä»¶](#ç›®å½•ç»“æ„ä¸ä¸»è¦æ–‡ä»¶)\n\n## é¡¹ç›®å¼€å‘æŠ€æœ¯æ ˆ\n- **åç«¯**ï¼š`Go 1.23.x` Â· `Gin` Â· `Logrus`\n- **æ•°æ®**ï¼š`SQLite (modernc.org/sqlite)`\n- **IP å½’å±åœ°**ï¼š`ip2region`ï¼ˆæœ¬åœ°åº“ï¼‰ + `ip-api.com`ï¼ˆè¿œç¨‹æ‰¹é‡ï¼‰\n- **å‰ç«¯**ï¼š`Vue 3` Â· `Vite` Â· `TypeScript` Â· `PrimeVue` Â· `ECharts/Chart.js` Â· `Scss`\n- **å®¹å™¨**ï¼š`Docker / Docker Compose` Â· `Nginx`ï¼ˆå‰ç«¯é™æ€éƒ¨ç½²ï¼‰\n\n## IP å½’å±åœ°æŸ¥è¯¢ç­–ç•¥\n1. **å¿«é€Ÿè¿‡æ»¤**ï¼šç©ºå€¼/æœ¬åœ°/å›ç¯åœ°å€è¿”å›â€œæœ¬åœ°â€ï¼Œå†…ç½‘åœ°å€è¿”å›â€œå†…ç½‘/æœ¬åœ°ç½‘ç»œâ€ã€‚\n2. **ç¼“å­˜ä¼˜å…ˆ**ï¼šå†…å­˜ç¼“å­˜å‘½ä¸­ç›´æ¥è¿”å›ï¼ˆæœ€å¤šç¼“å­˜ 50,000 æ¡ï¼‰ã€‚\n3. **è¿œç¨‹ä¼˜å…ˆ**ï¼šè°ƒç”¨ `ip-api.com/batch` æ‰¹é‡æŸ¥è¯¢ï¼Œè¶…æ—¶ 1.2sï¼Œå•æ‰¹æœ€å¤š 100 ä¸ªã€‚\n4. **æœ¬åœ°å…œåº•**ï¼šè¿œç¨‹å¤±è´¥æˆ–ç»“æœä¸ºâ€œæœªçŸ¥â€æ—¶ï¼ŒIPv4 ä½¿ç”¨å†…ç½® ip2region æ•°æ®åº“æœ¬åœ°æŸ¥è¯¢ï¼ˆ50ms è¶…æ—¶ï¼‰ã€‚\n5. **IPv6 å¤„ç†**ï¼šä»…èµ°è¿œç¨‹æŸ¥è¯¢ï¼Œè¿œç¨‹å¤±è´¥åˆ™è¿”å›â€œæœªçŸ¥â€ã€‚\n\n> æœ¬åœ°æ•°æ®åº“ `ip2region.xdb` å†…åµŒåœ¨äºŒè¿›åˆ¶ä¸­ï¼Œé¦–æ¬¡å¯åŠ¨ä¼šè‡ªåŠ¨è§£å‹åˆ° `./var/nginxpulse_data/ip2region.xdb`ï¼Œå¹¶å°è¯•åŠ è½½å‘é‡ç´¢å¼•æå‡æŸ¥è¯¢æ€§èƒ½ã€‚\n\n> æœ¬é¡¹ç›®ä¼šè®¿é—®å¤–ç½‘ IP å½’å±åœ° APIï¼ˆ`ip-api.com`ï¼‰ï¼Œéƒ¨ç½²ç¯å¢ƒéœ€æ”¾è¡Œè¯¥åŸŸåçš„å‡ºç«™è®¿é—®ã€‚\n\n## å¦‚ä½•ä½¿ç”¨é¡¹ç›®\n\n### 1) Docker\nå•é•œåƒï¼ˆå‰ç«¯ Nginx + åç«¯æœåŠ¡ï¼‰ï¼š\n\nä½¿ç”¨è¿œç¨‹é•œåƒï¼ˆDocker Hubï¼‰ï¼š\n\n```bash\ndocker run -d --name nginxpulse \\\n  -p 8088:8088 \\\n  -p 8089:8089 \\\n  -e WEBSITES='[{\"name\":\"ä¸»ç«™\",\"logPath\":\"/share/log/nginx/access.log\",\"domains\":[\"kaisir.cn\",\"www.kaisir.cn\"]}]' \\\n  -v ./nginx_data/logs/all/access.log:/share/log/nginx/access.log:ro \\\n  -v \"$(pwd)/var/nginxpulse_data:/app/var/nginxpulse_data\" \\\n  magiccoders/nginxpulse:latest\n```\n\næœ¬åœ°æ„å»ºè¿è¡Œï¼š\n\n```bash\ndocker build -t nginxpulse:local .\ndocker run -d --name nginxpulse \\\n  -p 8088:8088 \\\n  -p 8089:8089 \\\n  -e WEBSITES='[{\"name\":\"ä¸»ç«™\",\"logPath\":\"/share/log/nginx/access.log\",\"domains\":[\"kaisir.cn\",\"www.kaisir.cn\"]}]' \\\n  -v ./nginx_data/logs/all/access.log:/share/log/nginx/access.log:ro \\\n  -v \"$(pwd)/var/nginxpulse_data:/app/var/nginxpulse_data\" \\\n  nginxpulse:local\n```\n\nå¤šæ¶æ„é•œåƒï¼ˆamd64/arm64ï¼‰æ„å»ºä¸å‘å¸ƒï¼š\n\n```bash\n./scripts/publish_docker.sh -r <repo> -p linux/amd64,linux/arm64\n```\n\nä»…æœ¬åœ°æ„å»ºæŒ‡å®šæ¶æ„ç¤ºä¾‹ï¼š\n\n```bash\ndocker buildx build --platform linux/arm64 -t nginxpulse:local --load .\n```\n\nGitHub Actions è‡ªåŠ¨å‘å¸ƒï¼ˆå¤šæ¶æ„é•œåƒï¼‰ï¼š\n- åœ¨ä»“åº“ Secrets ä¸­é…ç½®ï¼š\n  - `DOCKERHUB_USERNAME`\n  - `DOCKERHUB_TOKEN`\n  - `DOCKERHUB_REPO`ï¼ˆä¾‹å¦‚ï¼š`username/nginxpulse`ï¼‰\n- æ¨é€ `v*` tag æˆ–å‘å¸ƒ Release æ—¶è§¦å‘ã€‚\n\n> å¦‚æœæ›´åå¥½é…ç½®æ–‡ä»¶æ–¹å¼ï¼Œå¯å°† `configs/nginxpulse_config.json` æŒ‚è½½åˆ°å®¹å™¨å†…çš„ `/app/configs/nginxpulse_config.json`ã€‚\n\n### 2) Docker Compose\nä½¿ç”¨è¿œç¨‹é•œåƒï¼ˆDocker Hubï¼‰ï¼šå°† `docker-compose.yml` æ”¹ä¸ºä¸‹æ–¹è¿œç¨‹é•œåƒç‰ˆæœ¬ï¼Œç„¶åæ‰§è¡Œï¼š\n\n```bash\ndocker compose up -d\n```\n\næœ¬åœ°æ„å»ºè¿è¡Œï¼ˆåŸºäºæºç æ„å»ºé•œåƒï¼‰ï¼šä¿æŒä»“åº“è‡ªå¸¦çš„ `docker-compose.yml`ï¼Œæ‰§è¡Œï¼š\n\n```bash\ndocker compose up -d --build\n```\n\nç¤ºä¾‹ `docker-compose.yml`ï¼ˆè¿œç¨‹é•œåƒï¼‰ï¼š\n\n```yml\nversion: \"3.8\"\nservices:\n  nginxpulse:\n    image: magiccoders/nginxpulse:latest\n    container_name: nginxpulse\n    ports:\n      - \"8088:8088\"\n      - \"8089:8089\"\n    environment:\n      WEBSITES: '[{\"name\":\"ä¸»ç«™\",\"logPath\":\"/share/log/nginx/access.log\",\"domains\":[\"kaisir.cn\",\"www.kaisir.cn\"]}]'\n    volumes:\n      - ./nginx_data/logs/all/access.log:/share/log/nginx/access.log:ro\n      - ./var/nginxpulse_data:/app/var/nginxpulse_data\n      - /etc/localtime:/etc/localtime:ro\n    restart: unless-stopped\n```\n\nç¤ºä¾‹ `docker-compose.yml`ï¼ˆæœ¬åœ°æ„å»ºï¼‰ï¼š\n\n```yml\nversion: \"3.8\"\nservices:\n  nginxpulse:\n    image: nginxpulse:local\n    build:\n      context: .\n    container_name: nginxpulse\n    ports:\n      - \"8088:8088\"\n      - \"8089:8089\"\n    environment:\n      WEBSITES: '[{\"name\":\"ä¸»ç«™\",\"logPath\":\"/share/log/nginx/access.log\",\"domains\":[\"kaisir.cn\",\"www.kaisir.cn\"]}]'\n    volumes:\n      - ./nginx_data/logs/all/access.log:/share/log/nginx/access.log:ro\n      - ./var/nginxpulse_data:/app/var/nginxpulse_data\n      - /etc/localtime:/etc/localtime:ro\n    restart: unless-stopped\n```\n\nè¯´æ˜ï¼š\n- `logPath` å¿…é¡»æ˜¯å®¹å™¨å†…è·¯å¾„ï¼Œç¡®ä¿ä¸æŒ‚è½½ç›®å½•ä¸€è‡´ã€‚\n- `var/nginxpulse_data` æŒ‚è½½ç”¨äºæŒä¹…åŒ–æ•°æ®åº“å’Œè§£æç¼“å­˜ï¼Œæ¨èä¿ç•™ã€‚\n\nå‚æ•°è¯´æ˜ï¼ˆç¯å¢ƒå˜é‡ï¼‰ï¼š\n- `WEBSITES`ï¼ˆå¿…å¡«ï¼Œæ— é…ç½®æ–‡ä»¶æ—¶ï¼‰\n  - ç½‘ç«™åˆ—è¡¨ JSON æ•°ç»„ï¼Œå­—æ®µï¼š`name`ã€`logPath`ã€`sources`ã€`domains`ï¼ˆå¯é€‰ï¼‰ã€‚\n  - å½“é…ç½® `sources` æ—¶å°†å¿½ç•¥ `logPath`ï¼Œå¹¶ä»¥è¿œç«¯æ¥æºä½œä¸ºæ—¥å¿—è¾“å…¥ã€‚\n  - `domains` ç”¨äºå°† referer å½’ç±»ä¸ºâ€œç«™å†…è®¿é—®â€ï¼Œä¸å½±å“æ—¥å¿—è§£æä¸ PV è¿‡æ»¤ã€‚\n- `CONFIG_JSON`ï¼ˆå¯é€‰ï¼‰\n  - å®Œæ•´é…ç½® JSON å­—ç¬¦ä¸²ï¼ˆç­‰åŒäº `configs/nginxpulse_config.json` å†…å®¹ï¼‰ã€‚\n  - è®¾ç½®åä¼šå¿½ç•¥æœ¬åœ°é…ç½®æ–‡ä»¶ï¼Œå…¶ä»–ç¯å¢ƒå˜é‡ä»å¯è¦†ç›–å…¶ä¸­å­—æ®µã€‚\n- `LOG_DEST`ï¼ˆå¯é€‰ï¼Œé»˜è®¤ï¼š`file`ï¼‰\n  - æ—¥å¿—è¾“å‡ºä½ç½®ï¼š`file` æˆ– `stdout`ã€‚\n- `TASK_INTERVAL`ï¼ˆå¯é€‰ï¼Œé»˜è®¤ï¼š`1m`ï¼‰\n  - æ‰«æé—´éš”ï¼Œæ”¯æŒ `5m`ã€`25s` ç­‰ Go duration æ ¼å¼ã€‚\n- `LOG_RETENTION_DAYS`ï¼ˆå¯é€‰ï¼Œé»˜è®¤ï¼š`30`ï¼‰\n  - æ—¥å¿—ä¿ç•™å¤©æ•°ï¼Œè¶…è¿‡å¤©æ•°ä¼šæ¸…ç†æ•°æ®åº“ä¸­çš„æ—§æ—¥å¿—ã€‚\n- `DEMO_MODE`ï¼ˆå¯é€‰ï¼Œé»˜è®¤ï¼š`false`ï¼‰\n  - å¼€å¯æ¼”ç¤ºæ¨¡å¼ï¼Œå®šæ—¶ç”Ÿæˆæ¨¡æ‹Ÿæ—¥å¿—å¹¶ç›´æ¥å†™å…¥æ•°æ®åº“ï¼ˆä¸å†è§£ææ—¥å¿—æ–‡ä»¶ï¼‰ã€‚\n- `ACCESS_KEYS`ï¼ˆå¯é€‰ï¼Œé»˜è®¤ï¼šç©ºï¼‰\n  - è®¿é—®å¯†é’¥åˆ—è¡¨ï¼ˆJSON æ•°ç»„æˆ–é€—å·åˆ†éš”ï¼‰ï¼Œé…ç½®åå°†å¯ç”¨è®¿é—®é™åˆ¶ã€‚\n- `APP_LANGUAGE`ï¼ˆå¯é€‰ï¼Œé»˜è®¤ï¼š`zh-CN`ï¼‰\n  - ç³»ç»Ÿé»˜è®¤è¯­è¨€ï¼Œæ”¯æŒ `zh-CN` / `en-US`ï¼ˆä¹Ÿæ¥å— `zh`ã€`en`ï¼‰ã€‚\n  - ä¼šåŒæ­¥å½±å“ IP å½’å±åœ°åœ¨çº¿æŸ¥è¯¢è¿”å›è¯­è¨€ã€‚\n- `SERVER_PORT`ï¼ˆå¯é€‰ï¼Œé»˜è®¤ï¼š`:8089`ï¼‰\n  - æœåŠ¡ç›‘å¬åœ°å€ï¼Œå¯ä¼  `:",
      "default_branch": "main"
    },
    "fetched_at": "2026-01-20T02:57:01.714382"
  },
  {
    "basic_info": {
      "name": "tailsnitch",
      "full_name": "Adversis/tailsnitch",
      "owner": "Adversis",
      "description": "A security auditor for Tailscale configurations. Scans your tailnet for misconfigurations, overly permissive access controls, and security best practice violations.",
      "url": "https://github.com/Adversis/tailsnitch",
      "clone_url": "https://github.com/Adversis/tailsnitch.git",
      "ssh_url": "git@github.com:Adversis/tailsnitch.git",
      "homepage": "",
      "created_at": "2025-12-24T21:54:49Z",
      "updated_at": "2026-01-20T02:31:49Z",
      "pushed_at": "2026-01-07T20:03:36Z"
    },
    "stats": {
      "stars": 1002,
      "forks": 23,
      "watchers": 1002,
      "open_issues": 1,
      "size": 208
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 293978,
        "Makefile": 678
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# Tailsnitch\n\nA security auditor for Tailscale configurations. Tailsnitch scans your tailnet for 50+ misconfigurations, overly permissive access controls, and security best practice violations.\n\n## Quick Start\n\n```bash\n# 1. Set your Tailscale API credentials\nexport TSKEY=\"tskey-api-...\"\n\n# 2. Run audit\ntailsnitch\n\n# 3. See only high-severity findings\ntailsnitch --severity high\n\n# 4. Fix some issues  ~interactively~ yolo mode\ntailsnitch --fix\n```\n\n## Installation\n\n### Download Pre-built Binary\n\nDownload the latest release from [GitHub Releases](https://github.com/Adversis/tailsnitch/releases).\n\n**macOS users:** Remove quarantine attribute after download:\n```bash\nsudo xattr -rd com.apple.quarantine tailsnitch\n```\n\n### Install via Go\n\n```bash\ngo install github.com/Adversis/tailsnitch@latest\n```\n\n### Build from Source\n\n```bash\ngit clone https://github.com/Adversis/tailsnitch.git\ncd tailsnitch\ngo build -o tailsnitch .\n```\n\n## Authentication\n\nTailsnitch supports two authentication methods. OAuth is preferred when both are configured.\n\n### Option 1: OAuth Client (Recommended)\n\nOAuth clients provide scoped, auditable access that doesn't expire when employees leave.\n\n```bash\nexport TS_OAUTH_CLIENT_ID=\"...\"\nexport TS_OAUTH_CLIENT_SECRET=\"tskey-client-...\"\n```\n\nCreate an OAuth client at: https://login.tailscale.com/admin/settings/oauth\n\n**Required scopes for read-only audit:**\n- `all:read` (simplest), or individually:\n- `policy_file:read` - ACL policy\n- `devices:core:read` - Device list\n- `dns:read` - DNS configuration\n- `auth_keys:read` - Auth keys (for AUTH checks)\n\n**Additional scopes for fix mode:**\n- `devices:core` - Delete devices, modify tags (requires tag selection)\n- `auth_keys` - Delete auth keys\n\n### Option 2: API Key\n\nAPI keys operate as the user who created them and inherit that user's permissions.\n\n```bash\nexport TSKEY=\"tskey-api-...\"\n```\n\nCreate an API key at: https://login.tailscale.com/admin/settings/keys\n\n## Usage Examples\n\n### Basic Audit\n\n```bash\n# Run full audit\ntailsnitch\n\n# Show passing checks too (verbose)\ntailsnitch --verbose\n\n# Output as JSON for processing\ntailsnitch --json\n\n# Audit a specific tailnet (when OAuth client has access to multiple)\ntailsnitch --tailnet mycompany.com\n```\n\n### Filter Results\n\n```bash\n# Only show critical and high severity issues\ntailsnitch --severity high\n\n# Filter by category\ntailsnitch --category access    # ACL issues\ntailsnitch --category auth      # Authentication & keys\ntailsnitch --category device    # Device security\ntailsnitch --category network   # Network exposure\ntailsnitch --category ssh       # SSH rules\ntailsnitch --category log       # Logging & admin\n\n# Run specific checks only\ntailsnitch --checks ACL-001,AUTH-001,DEV-010\ntailsnitch --checks stale-devices,tailnet-lock-not-enabled\n\n# List all available checks\ntailsnitch --list-checks\n```\n\n### Interactive Fix Mode\n\nFix mode allows you to remediate issues directly via the Tailscale API:\n\n```bash\n# Interactive fix mode\ntailsnitch --fix\n\n# Preview what would be fixed (dry run)\ntailsnitch --fix --dry-run\n\n# Auto-select safe fixes (still requires confirmation)\ntailsnitch --fix --auto\n\n# Disable audit logging of fix actions\ntailsnitch --fix --no-audit-log\n```\n\n**API-fixable items:**\n\n| Check | Action |\n|-------|--------|\n| AUTH-001, AUTH-002, AUTH-003 | Delete auth keys |\n| AUTH-004 | Replace with ephemeral keys |\n| DEV-002 | Remove tags from user devices |\n| DEV-004 | Delete stale devices |\n| DEV-005 | Authorize pending devices |\n\nFix mode also provides direct links to the admin console for issues that require manual intervention.\n\n### SOC 2 Evidence Export\n\nGenerate evidence reports for SOC 2 audits with Common Criteria (CC) control mappings:\n\n```bash\n# Export as JSON\ntailsnitch --soc2 json > soc2-evidence.json\n\n# Export as CSV (for spreadsheets)\ntailsnitch --soc2 csv > soc2-evidence.csv\n```\n\nThe SOC 2 report includes:\n- Per-resource test results (each device, key, ACL rule tested individually)\n- CC code mappings (CC6.1, CC6.2, CC6.3, CC6.6, CC7.1, CC7.2, etc.)\n- Pass/Fail/N/A status for each control test\n- Timestamp for audit trail\n\n**Example CSV output:**\n```csv\nresource_type,resource_id,resource_name,check_id,check_title,cc_codes,status,details,tested_at\ndevice,node123,prod-server,DEV-001,Tagged devices with key expiry disabled,CC6.1;CC6.3,PASS,Tags: [tag:server] key expiry enabled,2025-01-05T10:30:00Z\nkey,tskey-auth-xxx,tskey-auth-xxx,AUTH-001,Reusable auth keys exist,CC6.1;CC6.2;CC6.3,FAIL,Reusable key expires in 45 days,2025-01-05T10:30:00Z\n```\n\n### Ignore Known Risks\n\nCreate a `.tailsnitch-ignore` file to suppress findings for known-accepted risks:\n\n```bash\n# .tailsnitch-ignore\n# Ignore informational checks\nACL-008  # We intentionally don't use groups\nACL-009  # Legacy ACLs are fine for our use case\n\n# Ignore specific medium checks with justification\nDEV-006  # External devices are approved contractors\nLOG-001  # Flow logs require Enterprise plan\n```\n\n**Ignore file locations (checked in order):**\n",
      "default_branch": "main"
    },
    "fetched_at": "2026-01-20T02:57:02.960297"
  },
  {
    "basic_info": {
      "name": "opensqt_market_maker",
      "full_name": "dennisyang1986/opensqt_market_maker",
      "owner": "dennisyang1986",
      "description": "OpenSQT æ˜¯ä¸€ä¸ªé«˜æ€§èƒ½ã€ä½å»¶è¿Ÿçš„åŠ å¯†è´§å¸åšå¸‚å•†ç³»ç»Ÿï¼Œä¸“æ³¨äºæ°¸ç»­åˆçº¦å¸‚åœºçš„åšå¤šç½‘æ ¼äº¤æ˜“ç­–ç•¥ã€‚ç³»ç»Ÿé‡‡ç”¨ Go è¯­è¨€å¼€å‘ï¼ŒåŸºäº WebSocket å®æ—¶æ•°æ®æµé©±åŠ¨ï¼Œæ—¨åœ¨ä¸º Binanceã€Bitgetã€Gate.io ç­‰ä¸»æµäº¤æ˜“æ‰€æä¾›ç¨³å®šçš„æµåŠ¨æ€§æ”¯æŒã€‚",
      "url": "https://github.com/dennisyang1986/opensqt_market_maker",
      "clone_url": "https://github.com/dennisyang1986/opensqt_market_maker.git",
      "ssh_url": "git@github.com:dennisyang1986/opensqt_market_maker.git",
      "homepage": "https://www.OpenSQT.com/",
      "created_at": "2025-12-24T11:22:01Z",
      "updated_at": "2026-01-19T17:17:39Z",
      "pushed_at": "2025-12-24T12:28:26Z"
    },
    "stats": {
      "stars": 747,
      "forks": 317,
      "watchers": 747,
      "open_issues": 2,
      "size": 1265
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 382146,
        "HTML": 24168
      },
      "license": null,
      "topics": [
        "crypto",
        "crypto-bot",
        "marketmaker",
        "marketmakerbot"
      ]
    },
    "content": {
      "readme": "<div align=\"center\">\n  <img src=\"https://r2.opensqt.com/opensqt_logo.png\" alt=\"OpenSQT Logo\" width=\"600\"/>\n  \n  # OpenSQT Market Maker\n  \n  **æ¯«ç§’çº§é«˜é¢‘åŠ å¯†è´§å¸åšå¸‚å•†ç³»ç»Ÿ | High-Frequency Crypto Market Maker**\n\n  [![Go Version](https://img.shields.io/badge/Go-1.21%2B-blue.svg)](https://golang.org/dl/)\n  [![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)\n</div>\n\n---\n\n## ğŸ“– é¡¹ç›®ç®€ä»‹ (Introduction)\n\nOpenSQT Market Maker æ˜¯ä¸€ä¸ªé«˜æ€§èƒ½ã€ä½å»¶è¿Ÿçš„åŠ å¯†è´§å¸åšå¸‚å•†ç³»ç»Ÿï¼Œä¸“æ³¨äºæ°¸ç»­åˆçº¦å¸‚åœºçš„å•å‘åšå¤šæ— é™ç‹¬ç«‹ç½‘æ ¼äº¤æ˜“ç­–ç•¥ã€‚ç³»ç»Ÿé‡‡ç”¨ Go è¯­è¨€å¼€å‘ï¼ŒåŸºäº WebSocket å®æ—¶æ•°æ®æµé©±åŠ¨ï¼Œæ—¨åœ¨ä¸º Binanceã€Bitgetã€Gate.io ç­‰ä¸»æµäº¤æ˜“æ‰€æä¾›ç¨³å®šçš„æµåŠ¨æ€§æ”¯æŒã€‚\n\nç»è¿‡æ•°ä¸ªç‰ˆæœ¬è¿­ä»£ï¼Œæˆ‘ä»¬å·²ç»ä½¿ç”¨æ­¤ç³»ç»Ÿäº¤æ˜“è¶…è¿‡1äº¿ç¾å…ƒçš„è™šæ‹Ÿè´§å¸ï¼Œä¾‹å¦‚ï¼Œäº¤æ˜“å¸å®‰ETHUSDCï¼Œ0æ‰‹ç»­ï¼Œä»·æ ¼é—´éš”1ç¾å…ƒï¼Œæ¯ç¬”è´­ä¹°300ç¾å…ƒï¼Œæ¯å¤©çš„äº¤æ˜“é‡å°†è¾¾åˆ°300ä¸‡ç¾å…ƒä»¥ä¸Šï¼Œä¸€ä¸ªæœˆå¯ä»¥äº¤æ˜“5000ä¸‡ç¾å…ƒä»¥ä¸Šï¼Œåªè¦å¸‚åœºæ˜¯éœ‡è¡æˆ–å‘ä¸Šå°†æŒç»­äº§ç”Ÿç›ˆåˆ©ï¼Œå¦‚æœå¸‚åœºå•è¾¹ä¸‹è·Œï¼Œ3ä¸‡ç¾å…ƒä¿è¯é‡‘å¯ä»¥ä¿è¯ä¸‹è·Œ1000ä¸ªç‚¹ä¸çˆ†ä»“ï¼Œé€šè¿‡ä¸æ–­äº¤æ˜“æ‹‰ä½æˆæœ¬ï¼Œåªè¦å›æ¶¨50%å³å¯ä¿æœ¬ï¼Œæ¶¨å›å¼€ä»“åŸä»·å¯ä»¥èµšåˆ°ä¸°åšåˆ©æ¶¦ï¼Œå¦‚æœå‡ºç°å•è¾¹æé€Ÿä¸‹è·Œï¼Œä¸»åŠ¨é£æ§ç³»ç»Ÿå°†ä¼šè‡ªåŠ¨è¯†åˆ«ç«‹åˆ»åœæ­¢äº¤æ˜“ï¼Œå½“å¸‚åœºæ¢å¤åæ‰å…è®¸ç»§ç»­ä¸‹å•ï¼Œä¸æ‹…å¿ƒæ’é’ˆçˆ†ä»“ã€‚\n\nä¸¾ä¾‹ï¼š eth 3000ç‚¹å¼€å§‹äº¤æ˜“ï¼Œä»·æ ¼ä¸‹è·Œåˆ°2700ç‚¹ï¼ŒäºæŸçº¦3000ç¾å…ƒï¼Œä»·æ ¼æ¶¨å›2850ç‚¹ä»¥ä¸Šå·²ç»ä¿æœ¬ï¼Œæ¶¨å›3000ç‚¹ï¼Œç›ˆåˆ©åœ¨1000-3000ç¾å…ƒã€‚\n\nOpenSQT is a high-performance, low-latency cryptocurrency market maker system focusing on long grid trading strategies for perpetual contract markets. Developed in Go and driven by WebSocket real-time data streams, it aims to provide stable liquidity support for major exchanges like Binance, Bitget, and Gate.io.\n\n## ğŸ“º å®æ—¶æ¼”ç¤º (Live Demo)\n\n<video src=\"https://r2.opensqt.com/product_review.mp4\" controls=\"controls\" width=\"100%\"></video>\n\n[ç‚¹å‡»è§‚çœ‹æ¼”ç¤ºè§†é¢‘ / Watch Demo Video](https://r2.opensqt.com/product_review.mp4)\n\n## âœ¨ æ ¸å¿ƒç‰¹æ€§ (Key Features)\n\n- **å¤šäº¤æ˜“æ‰€æ”¯æŒ**: é€‚é… Binance, Bitget, Gate.io, Bybit, EdgeX ç­‰ä¸»æµå¹³å°ã€‚\n- **æ¯«ç§’çº§å“åº”**: å…¨ WebSocket é©±åŠ¨ï¼ˆè¡Œæƒ…ä¸è®¢å•æµï¼‰ï¼Œæ‹’ç»è½®è¯¢å»¶è¿Ÿã€‚\n- **æ™ºèƒ½ç½‘æ ¼ç­–ç•¥**: \n  - **å›ºå®šé‡‘é¢æ¨¡å¼**: èµ„é‡‘åˆ©ç”¨ç‡æ›´å¯æ§ã€‚\n  - **è¶…çº§æ§½ä½ç³»ç»Ÿ (Super Slot)**: æ™ºèƒ½ç®¡ç†æŒ‚å•ä¸æŒä»“çŠ¶æ€ï¼Œé˜²æ­¢å¹¶å‘å†²çªã€‚\n- **å¼ºå¤§çš„é£æ§ç³»ç»Ÿ**:\n  - **ä¸»åŠ¨é£æ§**: å®æ—¶ç›‘æ§ K çº¿æˆäº¤é‡å¼‚å¸¸ï¼Œè‡ªåŠ¨æš‚åœäº¤æ˜“ã€‚\n  - **èµ„é‡‘å®‰å…¨**: å¯åŠ¨å‰è‡ªåŠ¨æ£€æŸ¥ä½™é¢ã€æ æ†å€æ•°ä¸æœ€å¤§æŒä»“é£é™©ã€‚\n  - **è‡ªåŠ¨å¯¹è´¦**: å®šæœŸåŒæ­¥æœ¬åœ°ä¸äº¤æ˜“æ‰€çŠ¶æ€ï¼Œç¡®ä¿æ•°æ®ä¸€è‡´æ€§ã€‚\n- **é«˜å¹¶å‘æ¶æ„**: åŸºäº Goroutine + Channel + Sync.Map çš„é«˜æ•ˆå¹¶å‘æ¨¡å‹ã€‚\n\n## ğŸ¦ æ”¯æŒçš„äº¤æ˜“æ‰€ (Supported Exchanges)\n\n| äº¤æ˜“æ‰€ (Exchange) | çŠ¶æ€ (Status) \n|-------------------|---------------\n| **Binance**       | âœ… Stable      \n| **Bitget**        | âœ… Stable      \n| **Gate.io**       | âœ… Stable      \n\n\n## æ¨¡å—æ¶æ„\n\n```\nopensqt_platform/\nâ”œâ”€â”€ main.go                    # ä¸»ç¨‹åºå…¥å£ï¼Œç»„ä»¶ç¼–æ’\nâ”‚\nâ”œâ”€â”€ config/                    # é…ç½®ç®¡ç†\nâ”‚   â””â”€â”€ config.go              # YAMLé…ç½®åŠ è½½ä¸éªŒè¯\nâ”‚\nâ”œâ”€â”€ exchange/                  # äº¤æ˜“æ‰€æŠ½è±¡å±‚ï¼ˆæ ¸å¿ƒï¼‰\nâ”‚   â”œâ”€â”€ interface.go           # IExchange ç»Ÿä¸€æ¥å£\nâ”‚   â”œâ”€â”€ factory.go             # å·¥å‚æ¨¡å¼åˆ›å»ºäº¤æ˜“æ‰€å®ä¾‹\nâ”‚   â”œâ”€â”€ types.go               # é€šç”¨æ•°æ®ç»“æ„\nâ”‚   â”œâ”€â”€ wrapper_*.go           # é€‚é…å™¨ï¼ˆåŒ…è£…å„äº¤æ˜“æ‰€ï¼‰\nâ”‚   â”œâ”€â”€ binance/               # å¸å®‰å®ç°\nâ”‚   â”œâ”€â”€ bitget/                # Bitgetå®ç°\nâ”‚   â””â”€â”€ gate/                  # Gate.ioå®ç°\nâ”‚\nâ”œâ”€â”€ logger/                    # æ—¥å¿—ç³»ç»Ÿ\nâ”‚   â””â”€â”€ logger.go              # æ–‡ä»¶æ—¥å¿— + æ§åˆ¶å°æ—¥å¿—\nâ”‚\nâ”œâ”€â”€ monitor/                   # ä»·æ ¼ç›‘æ§\nâ”‚   â””â”€â”€ price_monitor.go       # å…¨å±€å”¯ä¸€ä»·æ ¼æµ\nâ”‚\nâ”œâ”€â”€ order/                     # è®¢å•æ‰§è¡Œå±‚\nâ”‚   â””â”€â”€ executor_adapter.go    # è®¢å•æ‰§è¡Œå™¨ï¼ˆé™æµ+é‡è¯•ï¼‰\nâ”‚\nâ”œâ”€â”€ position/                  # ä»“ä½ç®¡ç†ï¼ˆæ ¸å¿ƒï¼‰\nâ”‚   â””â”€â”€ super_position_manager.go  # è¶…çº§æ§½ä½ç®¡ç†å™¨\nâ”‚\nâ”œâ”€â”€ safety/                    # å®‰å…¨ä¸é£æ§\nâ”‚   â”œâ”€â”€ safety.go              # å¯åŠ¨å‰å®‰å…¨æ£€æŸ¥\nâ”‚   â”œâ”€â”€ risk_monitor.go        # ä¸»åŠ¨é£æ§ï¼ˆKçº¿ç›‘æ§ï¼‰\nâ”‚   â”œâ”€â”€ reconciler.go          # æŒä»“å¯¹è´¦\nâ”‚   â””â”€â”€ order_cleaner.go       # è®¢å•æ¸…ç†\nâ”‚\nâ””â”€â”€ utils/                     # å·¥å…·å‡½æ•°\n    â””â”€â”€ orderid.go             # è‡ªå®šä¹‰è®¢å•IDç”Ÿæˆ\n```\n\n## æœ€ä½³å®è·µ\n1.ç”¨æ¥åˆ·äº¤æ˜“æ‰€vipï¼Œæœ¬ç³»ç»Ÿæ˜¯åˆ·é‡ç¥å™¨ï¼Œå¦‚æœä¸Šæ¶¨ä¸‹è·Œå¹…åº¦ä¸å¤§ï¼Œ3000ç¾å…ƒä¿è¯é‡‘ä¸¤ä¸‰å¤©å³å¯åˆ·å‡º1000ä¸‡ç¾å…ƒäº¤æ˜“é‡ã€‚\n\n2.èµšé’±çš„æœ€ä½³å®è·µï¼Œåœ¨å¸‚åœºç»è¿‡ä¸€è½®ä¸‹è·Œåä»‹å…¥ï¼Œå…ˆä¹°ä¸€ç¬”æŒä»“ï¼Œç„¶åå†å¯åŠ¨è½¯ä»¶ï¼Œä¼šè‡ªåŠ¨å‘ä¸Šä¸€æ ¼æ ¼å–å‡ºï¼Œå½“ä½ çš„æŒä»“å–å…‰ä»¥ååœæ­¢ç³»ç»Ÿï¼Œæˆ–ä¸ç¡®å®šå½“å‰å¸‚åœºæ˜¯å¦æ˜¯ä½ç‚¹ï¼Œå¯ä»¥ä¸ä¹°åº•ä»“å¯åŠ¨ï¼Œå¦‚æœä¸‹è·Œåœ¨ä½ç‚¹å†è¡¥ä¸€ç¬”æŒä»“é‡æ–°å¯åŠ¨æŒç»­ç»™ä½ å–å‡ºï¼Œåˆ©æ¶¦å°†æœ€å¤§åŒ–ï¼Œå¦‚æ­¤å¾ªç¯å¾€å¤æŒç»­èµšé’±ï¼Œä¸‹è·Œä¹Ÿä¸æ€•ï¼Œç¨‹åºæŒç»­æ‹‰ä½æˆæœ¬ï¼Œåªè¦æ¶¨å›ä¸€åŠå³å¯ä¿æœ¬ã€‚\n\n## ğŸš€ å¿«é€Ÿå¼€å§‹ (Getting Started)\n\n### ç¯å¢ƒè¦æ±‚ (Prerequisites)\n- Go 1.21 æˆ–æ›´é«˜ç‰ˆæœ¬\n- ç½‘ç»œç¯å¢ƒéœ€èƒ½è®¿é—®äº¤æ˜“æ‰€ API\n\n### å®‰è£… (Installation)\n\n1. **å…‹éš†ä»“åº“**\n   ```bash\n   git clone https://github.com/dennisyang1986/opensqt_market_maker.git\n   cd opensqt_market_maker\n   ```\n\n2. **å®‰è£…ä¾èµ–**\n   ```bash\n   go mod download\n   ```\n\n### é…ç½® (Configuration)\n\n1. å¤åˆ¶ç¤ºä¾‹é…ç½®æ–‡ä»¶ï¼š\n   ```bash\n   cp config.example.yaml config.yaml\n   ```\n\n2. ç¼–è¾‘ `config.yaml`ï¼Œå¡«å…¥ä½ çš„ API Key å’Œç­–ç•¥å‚æ•°ï¼š\n\n   ```yaml\n   app:\n     current_exchange: \"binance\"  # é€‰æ‹©äº¤æ˜“æ‰€\n\n   exchanges:\n     binance:\n       api_key: \"YOUR_API_KEY\"\n       secret_key: \"YOUR_SECRET_KEY\"\n       fee_rate: 0.0002\n\n   trading:\n     symbol: \"ETHUSDT\"       # äº¤æ˜“å¯¹\n     price_interval: 2       # ç½‘æ ¼é—´è· (ä»·æ ¼)\n     order_quantity: 30      # æ¯æ ¼æŠ•å…¥é‡‘é¢ (USDT)\n     buy_window_size: 10     # ä¹°å•æŒ‚å•æ•°é‡\n     sell_window_size: 10    # å–å•æŒ‚å•æ•°é‡\n   ```\n\n### è¿è¡Œ (Usage)\n\n```bash\ngo run main.go\n```\n\næˆ–è€…ç¼–è¯‘åè¿è¡Œï¼š\n\n```bash\ngo build -o opensqt\n./opensqt\n```\n\n## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„ (Architecture)\n\nç³»ç»Ÿé‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œæ ¸å¿ƒç»„ä»¶åŒ…æ‹¬ï¼š\n\n- **Exchange Layer**: ç»Ÿä¸€çš„äº¤æ˜“æ‰€æ¥å£æŠ½è±¡ï¼Œå±è”½åº•å±‚ API å·®å¼‚ã€‚\n- **Price Monitor**: å…¨å±€å”¯ä¸€çš„ WebSocket ä»·æ ¼æºï¼Œç¡®ä¿å†³ç­–ä¸€è‡´æ€§ã€‚\n- **Super Position Manager**: æ ¸å¿ƒä»“ä½ç®¡ç†å™¨ï¼ŒåŸºäºæ§½ä½ (Slot) æœºåˆ¶ç®¡ç†è®¢å•ç”Ÿå‘½å‘¨æœŸã€‚\n- **Safety & Risk Control**: å¤šå±‚çº§é£æ§ï¼ŒåŒ…å«å¯åŠ¨æ£€æŸ¥ã€è¿è¡Œæ—¶ç›‘æ§å’Œå¼‚å¸¸ç†”æ–­ã€‚\n\næ›´å¤šè¯¦ç»†æ¶æ„è¯´æ˜è¯·å‚é˜… [ARCHITECTURE.md](ARCHITECTURE.md)ã€‚\n\n## âš ï¸ å…è´£å£°æ˜ (Disclaimer)\n\næœ¬è½¯ä»¶ä»…ä¾›å­¦ä¹ å’Œç ”ç©¶ä½¿ç”¨ã€‚åŠ å¯†è´§å¸äº¤æ˜“å…·æœ‰æé«˜é£é™©ï¼Œå¯èƒ½å¯¼è‡´èµ„é‡‘æŸå¤±ã€‚\n- ä½¿ç”¨æœ¬è½¯ä»¶äº§ç”Ÿçš„ä»»ä½•ç›ˆäºç”±ç”¨æˆ·è‡ªè¡Œæ‰¿æ‹…ã€‚\n- è¯·åŠ¡å¿…åœ¨å®ç›˜å‰ä½¿ç”¨æµ‹è¯•ç½‘ (Testnet) è¿›è¡Œå……åˆ†æµ‹è¯•ã€‚\n- å¼€å‘è€…ä¸å¯¹å› è½¯ä»¶é”™è¯¯ã€ç½‘ç»œå»¶è¿Ÿæˆ–äº¤æ˜“æ‰€æ•…éšœå¯¼è‡´çš„æŸå¤±è´Ÿè´£ã€‚\n\nThis software is for educational and research purposes only. Cryptocurrency trading involves high risk.\n- Users are solely responsible for any profits or losses.\n- Always test thoroughly on Testnet before using real funds.\n- The developers are n",
      "default_branch": "main"
    },
    "fetched_at": "2026-01-20T02:57:04.192369"
  },
  {
    "basic_info": {
      "name": "httpcloak",
      "full_name": "sardanioss/httpcloak",
      "owner": "sardanioss",
      "description": "Go HTTP client with browser-identical TLS/HTTP2 fingerprinting. Bypass bot detection by perfectly mimicking Chrome, Firefox, and Safari at the cryptographic level (JA3/JA4, Akamai fingerprint, header order). Supports HTTP/1.1, HTTP/2, HTTP/3, sessions, cookies, and proxies.",
      "url": "https://github.com/sardanioss/httpcloak",
      "clone_url": "https://github.com/sardanioss/httpcloak.git",
      "ssh_url": "git@github.com:sardanioss/httpcloak.git",
      "homepage": "",
      "created_at": "2025-12-28T22:39:27Z",
      "updated_at": "2026-01-20T02:29:46Z",
      "pushed_at": "2026-01-19T20:05:11Z"
    },
    "stats": {
      "stars": 576,
      "forks": 40,
      "watchers": 576,
      "open_issues": 4,
      "size": 40946
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 649544,
        "C#": 139685,
        "Python": 121477,
        "JavaScript": 97694,
        "Shell": 11122,
        "Makefile": 3318
      },
      "license": "MIT License",
      "topics": [
        "anti-bot",
        "bot-detection",
        "browser-fingerprint",
        "browser-fingerprinting",
        "cloudflare",
        "go",
        "golang",
        "http-client",
        "http2",
        "http3",
        "ja3-fingerprint",
        "ja4-fingerprint",
        "js",
        "nodejs",
        "python",
        "python3",
        "quic",
        "tls-fingerprint",
        "tls-fingerprinting",
        "web-scraping"
      ]
    },
    "content": {
      "readme": "<p align=\"center\">\n<img src=\"httpcloak.png\" alt=\"httpcloak\" width=\"600\">\n</p>\n\n<p align=\"center\">\n  <a href=\"https://pkg.go.dev/github.com/sardanioss/httpcloak\"><img src=\"https://pkg.go.dev/badge/github.com/sardanioss/httpcloak.svg\" alt=\"Go Reference\"></a>\n  <a href=\"https://pypi.org/project/httpcloak/\"><img src=\"https://img.shields.io/pypi/v/httpcloak\" alt=\"PyPI\"></a>\n  <a href=\"https://www.npmjs.com/package/httpcloak\"><img src=\"https://img.shields.io/npm/v/httpcloak\" alt=\"npm\"></a>\n  <a href=\"https://www.nuget.org/packages/HttpCloak\"><img src=\"https://img.shields.io/nuget/v/HttpCloak\" alt=\"NuGet\"></a>\n</p>\n\n<p align=\"center\">\n<i>Every Byte of your Request Indistinguishable from Chrome.</i>\n</p>\n\n<br>\n\n---\n\n## The Problem\n\nBot detection doesn't just check your User-Agent anymore.\n\nIt fingerprints your **TLS handshake**. Your **HTTP/2 frames**. Your **QUIC parameters**. The order of your headers. Whether your SNI is encrypted.\n\nOne mismatch = blocked.\n\n## The Solution\n\n```python\nimport httpcloak\n\nr = httpcloak.get(\"https://target.com\", preset=\"chrome-143\")\n```\n\nThat's it. Full browser transport layer fingerprint.\n\n---\n\n## What Gets Emulated\n\n<table>\n<tr>\n<td width=\"33%\" valign=\"top\">\n\n### ğŸ” TLS Layer\n\n- JA3 / JA4 fingerprints\n- GREASE randomization\n- Post-quantum X25519MLKEM768\n- ECH (Encrypted Client Hello)\n\n</td>\n<td width=\"33%\" valign=\"top\">\n\n### ğŸš€ Transport Layer\n\n- HTTP/2 SETTINGS frames\n- WINDOW_UPDATE values\n- Stream priorities (HPACK)\n- QUIC transport parameters\n- HTTP/3 GREASE frames\n\n</td>\n<td width=\"33%\" valign=\"top\">\n\n### ğŸ§  Header Layer\n\n- Sec-Fetch-* coherence\n- Client Hints (Sec-Ch-UA)\n- Accept / Accept-Language\n- Header ordering\n- Cookie persistence\n\n</td>\n</tr>\n</table>\n\n---\n\n## Results\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  ECH (Encrypted Client Hello)   â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  WITHOUT:  sni=plaintext        â”‚\nâ”‚  WITH:     sni=encrypted   +    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  HTTP/3 Fingerprint Match       â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚  Protocol:        h3       +    â”‚\nâ”‚  QUIC Version:    1        +    â”‚\nâ”‚  Transport Params:         +    â”‚\nâ”‚  GREASE Frames:            +    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n---\n\n## vs curl_cffi\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚        BOTH LIBRARIES          â”‚       HTTPCLOAK ONLY           â”‚\nâ”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\nâ”‚                                â”‚                                â”‚\nâ”‚  + TLS fingerprint (JA3/JA4)   â”‚  + HTTP/3 fingerprinting       â”‚\nâ”‚  + HTTP/2 fingerprint          â”‚  + ECH (encrypted SNI)         â”‚\nâ”‚  + Post-quantum TLS            â”‚  + MASQUE proxy                â”‚\nâ”‚  + Bot score: 99               â”‚  + Domain fronting             â”‚\nâ”‚                                â”‚  + Certificate pinning         â”‚\nâ”‚                                â”‚  + Go, Python, Node.js, C#     â”‚\nâ”‚                                â”‚                                â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n---\n\n## Install\n\n```bash\npip install httpcloak        # Python\nnpm install httpcloak        # Node.js\ngo get github.com/sardanioss/httpcloak   # Go\ndotnet add package HttpCloak # C#\n```\n\n---\n\n## Quick Start\n\n### Python\n\n```python\nimport httpcloak\n\n# Simple request\nr = httpcloak.get(\"https://example.com\", preset=\"chrome-143\")\nprint(r.status_code, r.protocol)\n\n# POST with JSON\nr = httpcloak.post(\"https://httpbin.org/post\",\n    json={\"key\": \"value\"},\n    preset=\"chrome-143\"\n)\n\n# Custom headers\nr = httpcloak.get(\"https://httpbin.org/headers\",\n    headers={\"X-Custom\": \"value\"},\n    preset=\"chrome-143\"\n)\n```\n\n### Go\n\n```go\nimport (\n    \"context\"\n    \"github.com/sardanioss/httpcloak/client\"\n)\n\n// Simple request\nc := client.NewClient(\"chrome-143\")\ndefer c.Close()\n\nresp, _ := c.Get(ctx, \"https://example.com\", nil)\nbody, _ := resp.Text()\nfmt.Println(resp.StatusCode, resp.Protocol)\n\n// POST with JSON\njsonBody := []byte(`{\"key\": \"value\"}`)\nresp, _ = c.Post(ctx, \"https://httpbin.org/post\",\n    bytes.NewReader(jsonBody),\n    map[string][]string{\"Content-Type\": {\"application/json\"}},\n)\n\n// Custom headers\nresp, _ = c.Get(ctx, \"https://httpbin.org/headers\", map[string][]string{\n    \"X-Custom\": {\"value\"},\n})\n```\n\n### Node.js\n\n```javascript\nimport httpcloak from \"httpcloak\";\n\n// Simple request\nconst session = new httpcloak.Session({ preset: \"chrome-143\" });\nconst r = await session.get(\"https://example.com\");\nconsole.log(r.statusCode, r.protocol);\n\n// POST with JSON\nconst r = await session.post(\"https://httpbin.org/post\", {\n    json: { key: \"value\" }\n});\n\n// Custom headers\nconst r = await session.get(\"https://httpbin.org/headers\", {\n    headers: { \"X-Custom\": \"value\" }\n});\n\nsession.close();\n```\n\n### C#\n\n```csharp\nusing HttpCloak;\n\n// Simple request\nusing var session = new Session(preset: Presets.Chrome143);\nvar r = session.Get(\"https://example.com\");\nConsole.WriteLine($\"{r.StatusCode} ",
      "default_branch": "main"
    },
    "fetched_at": "2026-01-20T02:57:05.439955"
  },
  {
    "basic_info": {
      "name": "cordum",
      "full_name": "cordum-io/cordum",
      "owner": "cordum-io",
      "description": "Cordum (cordum.io) is a platform-only control plane for autonomous AI Agents and external workers. It uses NATS for the bus, Redis for state and payload pointers, and CAP v2 wire contracts for jobs, results, and heartbeats. Workers and product packs live outside this repo.Core cordum ",
      "url": "https://github.com/cordum-io/cordum",
      "clone_url": "https://github.com/cordum-io/cordum.git",
      "ssh_url": "git@github.com:cordum-io/cordum.git",
      "homepage": "https://cordum.io/",
      "created_at": "2026-01-11T16:56:02Z",
      "updated_at": "2026-01-20T02:55:21Z",
      "pushed_at": "2026-01-18T16:52:45Z"
    },
    "stats": {
      "stars": 393,
      "forks": 11,
      "watchers": 393,
      "open_issues": 1,
      "size": 35508
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 1001255,
        "TypeScript": 521844,
        "CSS": 32211,
        "Shell": 10404,
        "Dockerfile": 2571,
        "Makefile": 2398,
        "Go Template": 2199,
        "JavaScript": 997,
        "HTML": 440
      },
      "license": "Other",
      "topics": [
        "ai-orchestration",
        "ai-safety",
        "autonomous-agents",
        "governance",
        "llm-agents",
        "workflow-engine"
      ]
    },
    "content": {
      "readme": "# Cordum - Deterministic Control Plane for Autonomous Workflows\n\n[![License: BUSL-1.1](https://img.shields.io/badge/license-BUSL--1.1-blue)](LICENSE)\n[![Release](https://img.shields.io/github/v/release/cordum-io/cordum?sort=semver)](https://github.com/cordum-io/cordum/releases)\n[![Go Version](https://img.shields.io/github/go-mod/go-version/cordum-io/cordum)](go.mod)\n[![Docker Compose](https://img.shields.io/badge/compose-ready-0f766e)](docker-compose.yml)\n[![Docs](https://img.shields.io/badge/docs-cordum--docs-0ea5e9)](docs/README.md)\n![Docker Pulls](https://img.shields.io/docker/pulls/cordum/control-plane)\n![CI](https://github.com/cordum-io/cordum/workflows/CI/badge.svg)\n![CodeQL](https://github.com/cordum-io/cordum/workflows/CodeQL/badge.svg)\n![Coverage Target](https://img.shields.io/badge/coverage-target%2080%25-22c55e)\n[![Website](https://img.shields.io/badge/website-cordum.io-blue)](https://cordum.io)\n[![WebsiteDocs](https://img.shields.io/badge/docs-cordum.io%2Fdocs-0ea5e9)](https://cordum.io/docs)\n[![Discord](https://img.shields.io/badge/discord-join-5865F2?logo=discord&logoColor=white)](https://discord.gg/26yw9VQV)\n\nCordum (cordum.io) is a platform-only control plane for autonomous AI Agents and external workers.\nIt uses NATS for the bus, Redis for state and payload pointers, and CAP v2 wire contracts for jobs,\nresults, and heartbeats. Workers and product packs live outside this repo.\n\nSee the full product docs at [Cordum](https://cordum.io) (or the local `docs/README.md`).\n\n## 2-minute guardrails demo\n\nRun the approval + remediation demo (worker + policy gate + approval): `./tools/scripts/demo_guardrails.sh`\n\nWalkthrough + GIF recording steps: `docs/demo-guardrails.md`\n\n## Getting started (1 minute)\n\n![Getting started](docs/assets/getting-started.gif)\n\nInstall (one-liner):\n\n```bash\ncurl -fsSL https://get.cordum.io | sh\n# or run locally from a clone:\n./tools/scripts/install.sh\n```\n\n`get.cordum.io` should serve `tools/scripts/install.sh` from this repo.\n\n1. `go run ./cmd/cordumctl up` (requires Go), or `docker compose build && docker compose up -d`.\n2. Open `http://localhost:8082` (dashboard).\n3. Run `./tools/scripts/platform_smoke.sh`.\n\n## Feature highlights\n\n- Workflow engine with retries/backoff, approvals, timeouts, delays, and crash-safe state.\n- Least-loaded scheduling with capability-aware pool routing.\n- Policy-before-dispatch (ALLOW/DENY/REQUIRE_APPROVAL/CONSTRAINTS).\n- Pack overlays for workflows, schemas, and policy/config fragments.\n- Durable job bus on NATS JetStream with Redis-backed pointers and auditability.\n- API + CLI for workflows, runs, policy bundles, schemas, packs, locks, and artifacts.\n\n## Architecture (current code)\n\nCore services:\n- API gateway: HTTP/WS + gRPC for jobs, workflows/runs, approvals, config, policy, DLQ, schemas, locks, artifacts, traces, packs.\n- Scheduler: safety gate, routing, job state, reconciler timeouts.\n- Safety kernel: policy check/evaluate/explain/simulate; file policy + config-service fragments.\n- Workflow engine: Redis-backed workflows/runs with fan-out, approvals, retries/backoff, delay/notify/condition steps, reruns, timeline.\n- Context engine (optional): gRPC helper for context windows and memory in Redis.\n- Dashboard (optional): React UI served via Nginx; connects to `/api/v1` and `/api/v1/stream`.\n\nControl plane flow (simplified):\n\n```\nClients/UI\n   |\n   v\nAPI Gateway  --->  Redis (runs, jobs, pointers, config, policy, DLQ)\n   |\n   v\nScheduler  --->  Safety Kernel (policy decision)\n   |\n   v\nNATS (JetStream bus)  --->  External workers (your code)\n```\n\nProtocol:\n- Bus and safety types are CAP v2 (`github.com/cordum-io/cap/v2`) via aliases in `core/protocol/pb/v1`.\n- API/Context protos live in `core/protocol/proto/v1`; generated Go types live in `core/protocol/pb/v1` and `sdk/gen/go/cordum/v1`.\n\nSDK:\n- Public Go SDK lives under `sdk/` (module `github.com/cordum/cordum/sdk`), including generated protos,\n  a minimal gateway client, and a CAP worker runtime (`sdk/runtime`).\n\n## Why Cordum?\n\nCordum is built for teams that need deterministic automation and policy control.\n\n| Capability | Cordum | Typical workflow engines |\n| --- | --- | --- |\n| Policy-before-dispatch | Built-in | External/custom |\n| Approval gates | Built-in | Manual |\n| Scheduling | Least-loaded + pool routing | Queue-based |\n| Pack overlays | Built-in | Plugins/scripts |\n\n## Quickstart (Docker)\n\nRequirements: Docker/Compose, curl, jq. Go is required if you want to use `cordumctl`.\n\n```bash\ngo run ./cmd/cordumctl up\n```\n\nOr manually:\n\n```bash\ndocker compose build\ndocker compose up -d\n```\n\nFor prebuilt images:\n\n```bash\nexport CORDUM_VERSION=v0.1.1\ndocker compose -f docker-compose.release.yml pull\ndocker compose -f docker-compose.release.yml up -d\n```\n\n## Kubernetes (Helm)\n\n```bash\nhelm install cordum ./cordum-helm -n cordum --create-namespace\n```\n\nPublished chart (when available):\n\n```bash\nhelm repo add cordum https://charts.cordum.io\nhelm repo update\nhelm install cordum cordum/cordum",
      "default_branch": "main"
    },
    "fetched_at": "2026-01-20T02:57:06.715390"
  },
  {
    "basic_info": {
      "name": "yolobox",
      "full_name": "finbarr/yolobox",
      "owner": "finbarr",
      "description": "Let your AI go full send. Your home directory stays home.",
      "url": "https://github.com/finbarr/yolobox",
      "clone_url": "https://github.com/finbarr/yolobox.git",
      "ssh_url": "git@github.com:finbarr/yolobox.git",
      "homepage": null,
      "created_at": "2026-01-09T05:05:16Z",
      "updated_at": "2026-01-19T16:18:05Z",
      "pushed_at": "2026-01-19T06:09:23Z"
    },
    "stats": {
      "stars": 393,
      "forks": 20,
      "watchers": 393,
      "open_issues": 0,
      "size": 132
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 44199,
        "Dockerfile": 8228,
        "Shell": 4099,
        "Makefile": 1398
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "```\nâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•—\nâ•šâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•\n â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ•”â•\n  â•šâ–ˆâ–ˆâ•”â•  â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘ â–ˆâ–ˆâ•”â–ˆâ–ˆâ•—\n   â–ˆâ–ˆâ•‘   â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•”â• â–ˆâ–ˆâ•—\n   â•šâ•â•    â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•â• â•šâ•â•â•â•â•â• â•šâ•â•â•â•â•â•  â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â•\n```\n\n**Let your AI go full send. Your home directory stays home.**\n\nRun [Claude Code](https://claude.ai/code), [Codex](https://openai.com/codex/), or any AI coding agent in \"yolo mode\" without nuking your home directory.\n\n## The Problem\n\nAI coding agents are incredibly powerful when you let them run commands without asking permission. But one misinterpreted prompt and `rm -rf ~` later, you're restoring from backup (yea right, as if you have backups lol).\n\n## The Solution\n\n`yolobox` runs your AI agent inside a container where:\n- âœ… Your **project directory** is mounted at `/workspace`\n- âœ… The agent has **full permissions** and **sudo** inside the container\n- âœ… Your **home directory is NOT mounted** (unless you explicitly opt in)\n- âœ… Persistent volumes keep tools and configs across sessions\n\nThe AI can go absolutely wild inside the sandbox. Your actual home directory? Untouchable.\n\n## Quick Start\n\n```bash\n# Install (requires Go)\ncurl -fsSL https://raw.githubusercontent.com/finbarr/yolobox/master/install.sh | bash\n\n# Or clone and build\ngit clone https://github.com/finbarr/yolobox.git\ncd yolobox\nmake install\n```\n\nThen from any project:\n\n```bash\ncd /path/to/your/project\nyolobox claude    # Let it rip\n```\n\nOr use any other AI tool: `yolobox codex`, `yolobox gemini`, `yolobox copilot`.\n\n## Runtime Support\n\n- **macOS**: Docker Desktop, OrbStack, or Colima\n- **Linux**: Docker or Podman\n\n> **Memory:** Claude Code needs **4GB+ RAM** allocated to Docker. Colima defaults to 2GB which will cause OOM kills. Increase with: `colima stop && colima start --memory 8`\n\n## Commands\n\n```bash\n# AI tool shortcuts (recommended)\nyolobox claude              # Run Claude Code\nyolobox codex               # Run OpenAI Codex\nyolobox gemini              # Run Gemini CLI\nyolobox opencode            # Run OpenCode\nyolobox copilot             # Run GitHub Copilot\n\n# General commands\nyolobox                     # Drop into interactive shell (for manual use)\nyolobox run <cmd...>        # Run any command in sandbox\nyolobox setup               # Configure yolobox settings\nyolobox upgrade             # Update binary and pull latest image\nyolobox config              # Show resolved configuration\nyolobox reset --force       # Delete volumes (fresh start)\nyolobox version             # Show version\nyolobox help                # Show help\n```\n\n## Flags\n\n| Flag | Description |\n|------|-------------|\n| `--runtime <name>` | Use `docker` or `podman` |\n| `--image <name>` | Custom base image |\n| `--mount <src:dst>` | Extra mount (repeatable) |\n| `--env <KEY=val>` | Set environment variable (repeatable) |\n| `--setup` | Run interactive setup before starting |\n| `--ssh-agent` | Forward SSH agent socket |\n| `--no-network` | Disable network access |\n| `--no-yolo` | Disable auto-confirmations (mindful mode) |\n| `--readonly-project` | Mount project read-only (outputs go to `/output`) |\n| `--claude-config` | Copy host `~/.claude` config into container |\n| `--git-config` | Copy host `~/.gitconfig` into container |\n\n## Configuration\n\nRun `yolobox setup` to configure your preferences with an interactive wizard.\n\nSettings are saved to `~/.config/yolobox/config.toml`:\n\n```toml\ngit_config = true\nssh_agent = true\nno_network = true\nno_yolo = true\n```\n\nYou can also create `.yolobox.toml` in your project for project-specific settings:\n\n```toml\nmounts = [\"../shared-libs:/libs:ro\"]\nenv = [\"DEBUG=1\"]\nno_network = true\n```\n\nPriority: CLI flags > project config > global config > defaults.\n\n> **Note:** Setting `claude_config = true` in your config will copy your host Claude config on **every** container start, overwriting any changes made inside the container (including auth and history). Prefer using `--claude-config` for one-time syncs.\n\n### Auto-Forwarded Environment Variables\n\nThese are automatically passed into the container if set:\n- `ANTHROPIC_API_KEY`\n- `OPENAI_API_KEY`\n- `COPILOT_GITHUB_TOKEN` / `GH_TOKEN` / `GITHUB_TOKEN`\n- `OPENROUTER_API_KEY`\n- `GEMINI_API_KEY`\n\n## What's in the Box?\n\nThe base image comes batteries-included:\n- **AI CLIs**: Claude Code, Gemini CLI, OpenAI Codex, OpenCode, Copilot (all pre-configured for full-auto mode!)\n- **Runtimes**: Node.js 22, Python 3, Go, Bun\n- **Build tools**: make, cmake, gcc\n- **Git** + **GitHub CLI**\n- **Common utilities**: ripgrep, fd, fzf, jq, vim\n\nNeed something else? The AI has sudo.\n\n### AI CLIs Run in YOLO Mode\n\nInside yolobox, the AI CLIs are aliased to skip all permission prompts:\n\n| Command | Expands to |\n|---------|------------|\n| `claude` | `claude --dangerously-skip-permissions` |\n| `codex` | `codex --dangerously-bypass-approvals-and-sandbox` |\n| `gemini` ",
      "default_branch": "master"
    },
    "fetched_at": "2026-01-20T02:57:07.959513"
  },
  {
    "basic_info": {
      "name": "sentinel",
      "full_name": "aqstack/sentinel",
      "owner": "aqstack",
      "description": "Self-healing edge computing agent with predictive failure detection and partition-resilient orchestration for Kubernetes",
      "url": "https://github.com/aqstack/sentinel",
      "clone_url": "https://github.com/aqstack/sentinel.git",
      "ssh_url": "git@github.com:aqstack/sentinel.git",
      "homepage": "",
      "created_at": "2025-12-25T05:22:51Z",
      "updated_at": "2026-01-15T20:52:41Z",
      "pushed_at": "2026-01-04T10:48:18Z"
    },
    "stats": {
      "stars": 380,
      "forks": 329,
      "watchers": 380,
      "open_issues": 0,
      "size": 110
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 187629,
        "Makefile": 2565
      },
      "license": "MIT License",
      "topics": [
        "aiops",
        "distributed-systems",
        "edge-computing",
        "failure-prediction",
        "golang",
        "kubernetes",
        "machine-learning",
        "prometheus",
        "raft",
        "self-healing"
      ]
    },
    "content": {
      "readme": "# Sentinel\n\n[![CI](https://github.com/aqstack/sentinel/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/aqstack/sentinel/actions/workflows/ci.yml)\n[![Go Report Card](https://goreportcard.com/badge/github.com/aqstack/sentinel)](https://goreportcard.com/report/github.com/aqstack/sentinel)\n\nPredictive failure detection and autonomous orchestration for Kubernetes edge nodes.\n\n## What it does\n\nSentinel runs on each edge node and does three things:\n\n1. **Predicts failures** - Monitors CPU thermals, memory pressure, disk I/O, and network health. Uses lightweight statistical models to predict failures before they happen.\n\n2. **Survives partitions** - When nodes lose contact with the control plane, they form a local consensus group and continue operating autonomously.\n\n3. **Takes action** - Triggers preemptive workload migrations, cordons unhealthy nodes, and logs decisions for reconciliation when connectivity returns.\n\n## Why\n\nKubernetes assumes the control plane is always reachable. Edge environments break this assumption constantly - spotty networks, power issues, harsh conditions. When a node goes \"Unknown\", Kubernetes stops making decisions for it.\n\nCloud AIOps tools assume unlimited resources. Edge nodes run K8s + workloads + monitoring in 4GB RAM with no datacenter cooling.\n\nSentinel fills the gap.\n\n## What's different\n\nMost edge/IoT platforms focus on deployment and connectivity. Most AIOps tools assume cloud-scale resources. Sentinel combines ideas from both:\n\n- **Predictive, not reactive** - Catches thermal throttling and memory pressure before they cause failures\n- **Autonomous, not dependent** - Continues operating during control plane partitions instead of going dark\n- **Lightweight, not bloated** - Runs statistical models in <64MB RAM, no GPUs or cloud inference needed\n- **Consensus-aware** - Nodes coordinate decisions locally using Raft-lite when disconnected\n\n## Quick Start\n\n```bash\n# Build\nmake build\n\n# Run locally\n./bin/predictor --node=my-node\n\n# With config file\n./bin/predictor --config=config.yaml\n\n# Deploy to cluster\nhelm install sentinel ./deploy/helm/sentinel\n```\n\n## Configuration\n\nSentinel supports YAML/JSON config files with CLI flag overrides:\n\n```yaml\nnode:\n  name: edge-node-1\n\nserver:\n  listen: \":9101\"\n  metrics: \":9100\"\n\npredictor:\n  interval: 1s\n  warn_threshold: 0.3\n  critical_threshold: 0.7\n  risk_weights:\n    thermal: 0.3\n    memory: 0.3\n    disk: 0.2\n    network: 0.2\n\nconsensus:\n  enabled: true\n  addr: \":9200\"\n  peers:\n    - edge-node-2:9200\n    - edge-node-3:9200\n\nlogging:\n  level: info\n  format: json\n```\n\nCLI flags:\n\n```bash\n--config          Config file path\n--node            Node name\n--listen          API listen address (default :9101)\n--metrics         Prometheus metrics address (default :9100)\n--interval        Collection interval (default 1s)\n--log-level       Log level: debug, info, warn, error\n--log-format      Log format: text, json\n--consensus-addr  Consensus listen address\n--peers           Comma-separated peer addresses\n```\n\n## Architecture\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                        Sentinel                          â”‚\nâ”‚                                                          â”‚\nâ”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚\nâ”‚  â”‚ Collector  â”‚â”€â–¶â”‚ Predictor  â”‚â”€â–¶â”‚ Consensus (Raft)  â”‚   â”‚\nâ”‚  â”‚            â”‚  â”‚            â”‚  â”‚                   â”‚   â”‚\nâ”‚  â”‚ /proc, /sysâ”‚  â”‚ ML model   â”‚  â”‚ Leader election   â”‚   â”‚\nâ”‚  â”‚ thermals   â”‚  â”‚ risk calc  â”‚  â”‚ Decision log      â”‚   â”‚\nâ”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚\nâ”‚        â”‚               â”‚                  â”‚              â”‚\nâ”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚\nâ”‚                        â–¼                                 â”‚\nâ”‚            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚\nâ”‚            â”‚ Prometheus Metrics  â”‚                       â”‚\nâ”‚            â”‚ Health Endpoints    â”‚                       â”‚\nâ”‚            â”‚ K8s Client          â”‚                       â”‚\nâ”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## API\n\n| Endpoint | Description |\n|----------|-------------|\n| `/health` | Detailed health status with component checks |\n| `/healthz` | Liveness probe |\n| `/readyz` | Readiness probe |\n| `/prediction` | Current failure prediction |\n| `/metrics/latest` | Raw metrics snapshot |\n| `/consensus` | Consensus state and peers |\n| `/decisions` | Autonomous decisions log |\n| `/metrics` | Prometheus metrics |\n\n## Metrics\n\nPrediction:\n- `sentinel_prediction_failure_probability` - 0 to 1\n- `sentinel_prediction_confidence` - model confidence\n- `sentinel_prediction_time_to_failure_seconds` - estimated TTF\n- `sentinel_prediction_preemptive_migrations_total` - migration count\n\nPartition:\n- `sentinel_partition_detected` - 0 or 1\n- `sentinel_partition_duration_seconds` - how long partitioned\n- `sentinel_consensus_is_leader` - leader status\n- `",
      "default_branch": "main"
    },
    "fetched_at": "2026-01-20T02:57:09.197866"
  },
  {
    "basic_info": {
      "name": "clopus-watcher",
      "full_name": "kubeden/clopus-watcher",
      "owner": "kubeden",
      "description": "An autonomous 24/7 on-call engineer in the form of a Claude Code living in a cronjob.",
      "url": "https://github.com/kubeden/clopus-watcher",
      "clone_url": "https://github.com/kubeden/clopus-watcher.git",
      "ssh_url": "git@github.com:kubeden/clopus-watcher.git",
      "homepage": "",
      "created_at": "2025-12-25T18:47:32Z",
      "updated_at": "2026-01-19T14:11:22Z",
      "pushed_at": "2026-01-01T10:28:34Z"
    },
    "stats": {
      "stars": 272,
      "forks": 40,
      "watchers": 272,
      "open_issues": 1,
      "size": 34
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 14048,
        "HTML": 13120,
        "Shell": 7250
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# Clopus Watcher\n\nA Kubernetes-native Claude Code watcher that monitors pods, detects errors, and applies hotfixes directly, or just writes a report on its findings.\n\n## Overview\n\nClopus Watcher runs as a CronJob that:\n1. Monitors pods in a target namespace\n2. Detects degraded pods (CrashLoopBackOff, Error, etc.)\n3. Reads logs to understand the error\n4. Execs into the pod, explores and applies a hotfix\n5. Records the fix to SQLite & provides a report\n\nA separate Dashboard deployment provides a web UI to view all detected errors and applied fixes.\n\n## Prerequisites\n\n**Cluster:**\n\n- Kubernetes cluster\n- Sealed Secrets (for API key / Claude Code Credentials file)\n\n**Local (to build the images):**\n\n- podman / docker / etc.\n- kubectl\n- container registry access\n\n## Configuration\n\n| Environment Variable | Description | Default |\n|---------------------|-------------|---------|\n| `TARGET_NAMESPACE` | Namespace to monitor | `default` |\n| `AUTH_MODE` | Auth method: `api-key` or `credentials` | `api-key` |\n| `WATCHER_MODE` | Watcher mode: `autonomous` or `watcher` | `autonomous` |\n| `ANTHROPIC_API_KEY` | Claude API key (if AUTH_MODE=api-key) | - |\n| `SQLITE_PATH` | Path to SQLite database | `/data/watcher.db` |\n\n## Deployment\n\n### Option 1: API Key (Recommended)\n\n```bash\n# 1. Create namespace\nkubectl create namespace clopus-watcher\n\n# 2. Create secret with API key\nkubectl create secret generic claude-auth \\\n  --namespace clopus-watcher \\\n  --from-literal=api-key=sk-ant-xxxxx\n\n# 3. Ensure AUTH_MODE=api-key in k8s/cronjob.yaml (default)\n\n# 4. Deploy\n./scripts/deploy.sh\n```\n\n### Option 2: Credentials File (OAuth)\n\n```bash\n# 1. Create namespace\nkubectl create namespace clopus-watcher\n\n# 2. Create secret from credentials file\nkubectl create secret generic claude-credentials \\\n  --namespace clopus-watcher \\\n  --from-file=credentials.json=$HOME/.claude/.credentials.json\n\n# 3. Edit k8s/cronjob.yaml:\n#    - Set AUTH_MODE=credentials\n#    - Uncomment claude-credentials volume and volumeMount\n\n# 4. Deploy\n./scripts/deploy.sh\n```\n",
      "default_branch": "main"
    },
    "fetched_at": "2026-01-20T02:57:10.409964"
  },
  {
    "basic_info": {
      "name": "distributed-system-algorithms",
      "full_name": "pipethedev/distributed-system-algorithms",
      "owner": "pipethedev",
      "description": null,
      "url": "https://github.com/pipethedev/distributed-system-algorithms",
      "clone_url": "https://github.com/pipethedev/distributed-system-algorithms.git",
      "ssh_url": "git@github.com:pipethedev/distributed-system-algorithms.git",
      "homepage": null,
      "created_at": "2026-01-03T14:25:21Z",
      "updated_at": "2026-01-15T20:52:47Z",
      "pushed_at": "2026-01-03T16:46:54Z"
    },
    "stats": {
      "stars": 260,
      "forks": 35,
      "watchers": 260,
      "open_issues": 1,
      "size": 9
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 2921
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# Distributed System Algorithms\n\nImplementations of fundamental algorithms that help multiple computers work together and stay coordinated, even when they can't trust a single clock or communicate instantly.\n\nThese are practical Go implementations for understanding how distributed system algorithms work in code.\n",
      "default_branch": "main"
    },
    "fetched_at": "2026-01-20T02:57:11.650778"
  },
  {
    "basic_info": {
      "name": "psc",
      "full_name": "loresuso/psc",
      "owner": "loresuso",
      "description": "the ps utility, with an eBPF twist and container context",
      "url": "https://github.com/loresuso/psc",
      "clone_url": "https://github.com/loresuso/psc.git",
      "ssh_url": "git@github.com:loresuso/psc.git",
      "homepage": null,
      "created_at": "2025-12-29T09:42:20Z",
      "updated_at": "2026-01-19T23:03:31Z",
      "pushed_at": "2026-01-16T23:09:44Z"
    },
    "stats": {
      "stars": 253,
      "forks": 6,
      "watchers": 253,
      "open_issues": 3,
      "size": 104
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 122841,
        "C": 10345,
        "Makefile": 1190
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# psc\n\n**psc** (ps container) is a fast process scanner that uses eBPF iterators and Google CEL to query system state with precision and full container context.\n\n## Why psc?\n\n### Fast Kernel-Level Access with eBPF Iterators\n\npsc uses eBPF iterators to read process and file descriptor information directly from kernel data structures. This approach is:\n\n- **Fast**: eBPF iterators are highly efficient compared to the proc filesystem, where traditional tooling spends most of its time executing system calls\n- **Complete**: Access kernel information not traditionally exposed through `/proc`. I plan to add also a way to access certain fields of the `task_struct` on demand for advanced use, but this is just an idea\n- **Tamper-resistant**: Bypasses the `/proc` filesystem entirely, providing visibility that cannot be subverted by userland rootkits or `LD_PRELOAD` tricks\n\n### Readable Queries with CEL\n\nTraditional Linux tools like `ps`, `lsof`, and `ss` are powerful but inflexible. They output fixed formats that require extensive piping through `grep`, `awk`, and `sed`:\n\n```bash\n# Traditional: Find nginx processes owned by root\nps aux | grep nginx | grep root | grep -v grep\n\n# psc: Express exactly what you mean\npsc 'process.name == \"nginx\" && process.user == \"root\"'\n```\n\n```bash\n# Traditional: Find processes with established connections on port 443\nss -tnp | grep ESTAB | grep :443 | awk '{print $6}' | cut -d'\"' -f2\n\n# psc: One clear expression\npsc 'socket.state == established && socket.dstPort == 443'\n```\n\npsc uses the [Common Expression Language (CEL)](https://github.com/google/cel-go) to filter processes. CEL expressions read almost like natural language, making your scripts self-documenting and maintainable. No more deciphering complex pipelines of `grep | awk | sed | xargs`.\n\nThe `-o` flag lets you output exactly the fields you need, eliminating post-processing entirely:\n\n```bash\npsc 'socket.state == listen' -o process.name,socket.srcPort\n```\n\nOutput presets are also available to quickly print common information:\n```bash\npsc 'socket.type == tcp && socket.dstPort == 443' -o sockets \n```\n\n### Native Container Context\n\nTraditional tools have no concept of containers. Getting container information requires parsing cgroup paths, querying container runtimes, and correlating PIDs manually:\n\n```bash\n# Traditional: Find containerized processes (fragile, incomplete)\nps aux | xargs -I{} sh -c 'cat /proc/{}/cgroup 2>/dev/null | grep -q docker && echo {}'\n\n# psc: Native container support\npsc 'container.runtime == docker'\n```\n\npsc extracts container context (ID, name, image, runtime, labels) automatically for Docker, containerd, CRI-O, and Podman. Debug any container's processes, files, and network connections directly from the host:\n\n```bash\n# Show all processes in a specific container\npsc 'container.name == \"my-app\"' --tree\n\n# Find containers running as root\npsc 'container.runtime == docker && process.user == \"root\"'\n\n# List containers with their images\npsc 'container.id != \"\"' -o process.pid,process.name,container.name,container.image\n```\n\n\n## Building\n\n### Requirements\n\n- Linux kernel 5.8 or later (eBPF iterators were introduced in this version)\n- Go 1.25 or later\n- Clang and LLVM\n- libbpf development headers\n- Linux kernel headers\n- bpftool (for generating vmlinux.h)\n\n### Install Dependencies\n\nOn Debian/Ubuntu:\n\n```bash\nsudo apt-get install clang llvm libbpf-dev linux-headers-$(uname -r) linux-tools-$(uname -r)\n```\n\nOn Fedora/RHEL:\n\n```bash\nsudo dnf install clang llvm libbpf-devel kernel-devel bpftool\n```\n\n### Build\n\n```bash\n# Generate vmlinux.h (required once per kernel version)\nmake vmlinux\n\n# Build the binary\nmake build\n```\n\nOr manually:\n\n```bash\nbpftool btf dump file /sys/kernel/btf/vmlinux format c > bpf/vmlinux.h\ngo generate ./...\ngo build -o psc\n```\n\n### Install\n\n```bash\nsudo make install\n```\n\n## Usage\n\npsc requires **root privileges** to load eBPF programs.\n\n### Basic Usage\n\n```bash\n# List all processes\nsudo psc\n\n# List all processes as a tree\nsudo psc --tree\n```\n\n### Filtering with CEL Expressions\n\nPass a CEL expression as the first argument to filter processes:\n\n```bash\n# Filter by process name\npsc 'process.name == \"nginx\"'\n\n# Filter by user\npsc 'process.user == \"root\"'\n\n# Filter by command line content\npsc 'process.cmdline.contains(\"--config\")'\n\n# Filter by PID range\npsc 'process.pid > 1000 && process.pid < 2000'\n\n# Combine conditions\npsc 'process.name == \"bash\" || process.name == \"zsh\"'\n```\n\n### Container Filtering\n\n```bash\n# Show only containerized processes\npsc 'container.id != \"\"'\n\n# Filter by container runtime (constants: docker, containerd, crio, podman)\npsc 'container.runtime == docker'\n\n# Filter by container name\npsc 'container.name == \"nginx\"'\n\n# Filter by container image\npsc 'container.image.contains(\"nginx:latest\")'\n\n# Show as tree to see container process hierarchy\npsc 'container.runtime == docker' --tree\n```\n\n### Socket and File Descriptor Filtering\n\nUnderstanding why a process exists often requires",
      "default_branch": "main"
    },
    "fetched_at": "2026-01-20T02:57:12.916514"
  },
  {
    "basic_info": {
      "name": "git-wt",
      "full_name": "k1LoW/git-wt",
      "owner": "k1LoW",
      "description": "A Git subcommand that makes `git worktree` simple",
      "url": "https://github.com/k1LoW/git-wt",
      "clone_url": "https://github.com/k1LoW/git-wt.git",
      "ssh_url": "git@github.com:k1LoW/git-wt.git",
      "homepage": "",
      "created_at": "2025-12-26T00:16:09Z",
      "updated_at": "2026-01-19T15:09:16Z",
      "pushed_at": "2026-01-16T23:12:56Z"
    },
    "stats": {
      "stars": 235,
      "forks": 9,
      "watchers": 235,
      "open_issues": 1,
      "size": 288
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 178241,
        "Makefile": 760
      },
      "license": "MIT License",
      "topics": [
        "git",
        "git-worktree"
      ]
    },
    "content": {
      "readme": "# git-wt ![Coverage](https://raw.githubusercontent.com/k1LoW/octocovs/main/badges/k1LoW/git-wt/coverage.svg) ![Code to Test Ratio](https://raw.githubusercontent.com/k1LoW/octocovs/main/badges/k1LoW/git-wt/ratio.svg) ![Test Execution Time](https://raw.githubusercontent.com/k1LoW/octocovs/main/badges/k1LoW/git-wt/time.svg)\n\nA Git subcommand that makes `git worktree` simple.\n\n## Usage\n\n``` console\n$ git wt                       # List all worktrees\n$ git wt <branch|worktree>     # Switch to worktree (create worktree/branch if needed)\n$ git wt -d <branch|worktree>  # Delete worktree and branch (safe)\n$ git wt -D <branch|worktree>  # Force delete worktree and branch\n```\n\n## Install\n\n**go install:**\n\n``` console\n$ go install github.com/k1LoW/git-wt@latest\n```\n\n**homebrew tap:**\n\n``` console\n$ brew install k1LoW/tap/git-wt\n```\n\n**manually:**\n\nDownload binary from [releases page](https://github.com/k1LoW/git-wt/releases)\n\n## Shell Integration\n\nAdd the following to your shell config to enable worktree switching and completion:\n\n**zsh (~/.zshrc):**\n\n``` zsh\neval \"$(git wt --init zsh)\"\n```\n\n**bash (~/.bashrc):** (experimental)\n\n``` bash\neval \"$(git wt --init bash)\"\n```\n\n**fish (~/.config/fish/config.fish):** (experimental)\n\n``` fish\ngit wt --init fish | source\n```\n\n**powershell ($PROFILE):** (experimental)\n\n``` powershell\nInvoke-Expression (git wt --init powershell | Out-String)\n```\n\n> [!IMPORTANT]\n> The shell integration creates a `git()` wrapper function to enable automatic directory switching with `git wt <branch>`. This wrapper intercepts only `git wt <branch>` commands and passes all other git commands through unchanged. If you have other tools or customizations that also wrap the `git` command, there may be conflicts.\n\nIf you want only completion without the `git()` wrapper (no automatic directory switching), use the `--nocd` option:\n\n``` zsh\neval \"$(git wt --init zsh --nocd)\"\n```\n\nYou can also use `--nocd` with `git wt <branch>` to create/switch to a worktree without changing the current directory:\n\n``` console\n$ git wt --nocd feature-branch\n/path/to/worktree/feature-branch  # prints path but stays in current directory\n```\n\n## Configuration\n\nConfiguration is done via `git config`. All config options can be overridden with flags for a single invocation.\n\n#### `wt.basedir` / `--basedir`\n\nWorktree base directory.\n\n``` console\n$ git config wt.basedir \"../{gitroot}-worktrees\"\n# or override for a single invocation\n$ git wt --basedir=\"/tmp/worktrees\" feature-branch\n```\n\nSupported template variables:\n- `{gitroot}`: repository root directory name\n\nDefault: `../{gitroot}-wt`\n\n#### `wt.copyignored` / `--copyignored`\n\nCopy files ignored by `.gitignore` (e.g., `.env`) to new worktrees.\n\n``` console\n$ git config wt.copyignored true\n# or override for a single invocation\n$ git wt --copyignored feature-branch\n$ git wt --copyignored=false feature-branch  # explicitly disable\n```\n\nDefault: `false`\n\n#### `wt.copyuntracked` / `--copyuntracked`\n\nCopy untracked files (not yet added to git) to new worktrees.\n\n``` console\n$ git config wt.copyuntracked true\n# or override for a single invocation\n$ git wt --copyuntracked feature-branch\n$ git wt --copyuntracked=false feature-branch  # explicitly disable\n```\n\nDefault: `false`\n\n#### `wt.copymodified` / `--copymodified`\n\nCopy modified files (tracked but with uncommitted changes) to new worktrees.\n\n``` console\n$ git config wt.copymodified true\n# or override for a single invocation\n$ git wt --copymodified feature-branch\n$ git wt --copymodified=false feature-branch  # explicitly disable\n```\n\nDefault: `false`\n\n#### `wt.nocopy` / `--nocopy`\n\nExclude files matching patterns from copying. Uses `.gitignore` syntax.\n\n``` console\n$ git config --add wt.nocopy \"*.log\"\n$ git config --add wt.nocopy \"vendor/\"\n# or override for a single invocation (multiple patterns supported)\n$ git wt --copyignored --nocopy \"*.log\" --nocopy \"vendor/\" feature-branch\n```\n\nSupported patterns (same as `.gitignore`):\n- `*.log`: wildcard matching\n- `vendor/`: directory matching\n- `**/temp`: match in any directory\n- `/config.local`: relative to git root\n\n#### `wt.copy` / `--copy`\n\nAlways copy files matching patterns, even if they are gitignored. Uses `.gitignore` syntax.\n\n``` console\n$ git config --add wt.copy \"*.code-workspace\"\n$ git config --add wt.copy \".vscode/\"\n# or override for a single invocation (multiple patterns supported)\n$ git wt --copy \"*.code-workspace\" --copy \".vscode/\" feature-branch\n```\n\nThis is useful when you want to copy specific IDE files (like VS Code workspace files) without enabling `wt.copyignored` for all gitignored files.\n\n> [!NOTE]\n> If the same file matches both `wt.copy` and `wt.nocopy`, `wt.nocopy` takes precedence.\n\n#### `wt.hook` / `--hook`\n\nCommands to run after creating a new worktree. Hooks run in the new worktree directory.\n\n``` console\n$ git config --add wt.hook \"npm install\"\n$ git config --add wt.hook \"go generate ./...\"\n# or override for a single invocation (multiple hooks supported)\n$ git w",
      "default_branch": "main"
    },
    "fetched_at": "2026-01-20T02:57:14.175787"
  },
  {
    "basic_info": {
      "name": "cek",
      "full_name": "bschaatsbergen/cek",
      "owner": "bschaatsbergen",
      "description": "Explore the (overlay) filesystem and layers of OCI container images, without running them.",
      "url": "https://github.com/bschaatsbergen/cek",
      "clone_url": "https://github.com/bschaatsbergen/cek.git",
      "ssh_url": "git@github.com:bschaatsbergen/cek.git",
      "homepage": "",
      "created_at": "2025-12-27T17:55:02Z",
      "updated_at": "2026-01-19T23:23:08Z",
      "pushed_at": "2026-01-17T12:12:25Z"
    },
    "stats": {
      "stars": 216,
      "forks": 5,
      "watchers": 216,
      "open_issues": 2,
      "size": 538
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 78075,
        "Makefile": 234
      },
      "license": "MIT License",
      "topics": [
        "containers",
        "oci"
      ]
    },
    "content": {
      "readme": "# cek (container exploration kit)\n\n[![Go Report Card](https://goreportcard.com/badge/github.com/bschaatsbergen/cek)](https://goreportcard.com/report/github.com/bschaatsbergen/cek)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\nExplore OCI container images without running them.\n\ncek is a command-line utility for filesystem exploration inside OCI container\nimages. It focuses on browsing files, reading contents, and inspecting layer\nmechanicsâ€”without running containers. cek reads images directly from local\ncontainer daemons (Docker, Podman, containerd, etc.) or pulls them from remote\nregistries.\n\ncek runs without root privileges and works with any OCI-compliant image\nregistry. While it does not require a container daemon, it can leverage one when\navailable to access locally cached images and avoid registry rate limits. Most\nimportantly, cek never runs containers.\n\n## Installation\n\n```bash\nbrew install cek\n```\n\nOr with Go:\n\n```bash\ngo install github.com/bschaatsbergen/cek@latest\n```\n\nOr build from source:\n\n```bash\ngit clone https://github.com/bschaatsbergen/cek.git\ncd cek\ngo build -o cek .\n```\n\n## Usage\n\n### List files in an image\n\nBy default, `cek ls` shows the merged overlay filesystem, which is what you see\ninside a running container. All layers are combined, with upper layers\noverriding lower ones.\n\nYou can optionally specify a path to list only files under a specific directory.\n\n```bash\n# Show all files (merged overlay view)\ncek ls nginx:latest\n\n# List files in a specific directory\ncek ls nginx:latest /etc\ncek ls nginx:latest /etc/nginx\n\n# Combine path with pattern filter\ncek ls nginx:latest /etc/nginx --filter '*.conf'\n\n# Filter by pattern (supports doublestar glob matching)\ncek ls --filter '**/nginx/*.conf' nginx:latest\n\n# Show files from a specific layer only\ncek ls --layer 1 nginx:latest\n```\n\nPatterns without slashes match against basenames. Patterns with slashes match\nagainst full paths. Use `**` for recursive directory matching.\n\n### Read file contents\n\nWrite file contents to standard output from any image without creating a\ncontainer. Output can be piped to other commands or redirected to files for\ninspection, diffing, or processing.\n\n```bash\ncek cat nginx:latest /etc/nginx/nginx.conf\n\n# Read from a specific layer\ncek cat --layer 2 nginx:latest /etc/os-release\n\n# Pipe to other tools\ncek cat alpine:latest /etc/os-release | grep VERSION_ID\n\n# Compare configuration between image versions\ndiff <(cek cat nginx:1.25 /etc/nginx/nginx.conf) \\\n     <(cek cat nginx:1.24 /etc/nginx/nginx.conf)\n```\n\nThe `cat` command searches layers top-down to find the final file state after\nall overlays, just like in a running container.\n\n### List available tags\n\nList all tags in a repository from the remote registry, allowing you to find\navailable tags or a specific tag.\n\n```bash\ncek tags nginx\n\n# Limit output to first N tags\ncek tags alpine --limit 20\n\n# Pipe to less for pagination\ncek tags nginx | less\n\n# Filter tags with grep\ncek tags nginx | grep '^1\\.2'\ncek tags python | grep -E '^3\\.(11|12)'\n```\n\nNote: This queries the remote registry directly, not the local daemon cache.\n\n### Export images to tar files\n\nExport OCI images to tar files, including manifest, config, and all layers.\nThese tarballs make it easy to move images between environments, share images\nwithout a registry, or back them up for disaster recovery.\n\n```bash\n# Export an image to a tar file\ncek export alpine:latest -o alpine.tar\n\n# Export a specific platform\ncek export --platform linux/amd64 ubuntu:22.04 -o ubuntu-amd64.tar\n\n# Load the exported tar into Docker or Podman\ndocker load -i alpine.tar\npodman load -i alpine.tar\n```\n\nUse cases include air-gapped deployments, image backups, sharing images without\npushing to a registry, and transferring images between different container\nruntimes.\n\n### Display directory tree\n\nShow the directory tree structure of an OCI image, making it easy to visualize\nthe filesystem layout.\n\n```bash\n# Show the top-level directories in an image\ncek tree nginx:latest -L 1\n\n# Inspect the /usr/local/bin folder of a specific layer\ncek tree --layer 4 python:3.12-slim /usr/local/bin\n```\n\n### Inspect image metadata\n\nView image details including digest, creation time, architecture, total size,\nand individual layer information.\n\n```bash\ncek inspect nginx\nImage: nginx\nRegistry: index.docker.io\nDigest: sha256:ec0ee8695f2f71addca9b40f27df0fdfbde460485a2b68b834e18ea856542f1e\nCreated: 2025-12-09T22:50:18Z\nOS/Arch: linux/arm64\nSize: 55.6 MB\n\nLayers:\n#  Digest                                                                   Size\n1  sha256:f626fba1463b32b20f78d29b52dcf15be927dbb5372a9ba6a5f97aad47ae220b  28.7 MB\n2  sha256:89d0a1112522e6e01ed53f0b339cb1a121ea7e19cfebdb325763bf5045ba7a47  26.8 MB\n3  sha256:1b7c70849006971147c73371c868b789998c7220ba42e777d2d7e5894ac26e54  627 B\n4  sha256:b8b0307e95c93307d99d02d3bdc61c3ed0b8d26685bb9bafc6c62d4170a2363e  954 B\n5  sha256:fe1d23b41cb3b150a19a6",
      "default_branch": "main"
    },
    "fetched_at": "2026-01-20T02:57:15.430276"
  },
  {
    "basic_info": {
      "name": "md2wechat-skill",
      "full_name": "geekjourneyx/md2wechat-skill",
      "owner": "geekjourneyx",
      "description": "  ç”¨ Markdown å†™å…¬ä¼—å·æ–‡ç« ï¼Œä¸€é”®è½¬æ¢ä¸ºç²¾ç¾æ’ç‰ˆå¹¶è‡ªåŠ¨ä¸Šä¼ åˆ°å¾®ä¿¡è‰ç¨¿ç®±ã€‚æ”¯æŒ AI å¤šä¸»é¢˜æ ·å¼å’Œæ‰¹é‡å‘å¸ƒï¼Œè®©å…¬ä¼—å·å†™ä½œåƒå‘æœ‹å‹åœˆä¸€æ ·ç®€å•ã€‚https://md2wechat.cn",
      "url": "https://github.com/geekjourneyx/md2wechat-skill",
      "clone_url": "https://github.com/geekjourneyx/md2wechat-skill.git",
      "ssh_url": "git@github.com:geekjourneyx/md2wechat-skill.git",
      "homepage": "https://geekjourney.dev",
      "created_at": "2026-01-11T06:36:13Z",
      "updated_at": "2026-01-20T02:02:05Z",
      "pushed_at": "2026-01-19T15:37:21Z"
    },
    "stats": {
      "stars": 216,
      "forks": 30,
      "watchers": 216,
      "open_issues": 1,
      "size": 100214
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 200852,
        "Shell": 26219,
        "Makefile": 3014,
        "PowerShell": 2963
      },
      "license": null,
      "topics": [
        "claude-skills",
        "golang",
        "markdown-converter",
        "skills",
        "wechat"
      ]
    },
    "content": {
      "readme": "# md2wechat\n\n<div align=\"center\">\n\n**ç”¨ Markdown å†™å…¬ä¼—å·æ–‡ç« ï¼Œåƒå‘æœ‹å‹åœˆä¸€æ ·ç®€å•**\n\n[![Go Version](https://img.shields.io/badge/Go-1.24+-00ADD8?logo=go)](https://golang.org)\n[![License](https://img.shields.io/badge/license-MIT-blue)](LICENSE)\n[![GitHub Release](https://img.shields.io/badge/download-latest-green)](https://github.com/geekjourneyx/md2wechat-skill/releases)\n[![Claude Code](https://img.shields.io/badge/Claude%20Code-Skill-purple)](#-claude-code-é›†æˆ)\n\n---\n\n> ### âš ï¸ é‡è¦æç¤ºï¼šAPI æ¨¡å¼éœ€è¦ md2wechat.cn API æœåŠ¡\n> **æœ¬å·¥å…·ä½¿ç”¨ md2wechat.cn API æœåŠ¡ï¼Œä½¿ç”¨ API æ¨¡å¼å‰éœ€è¦å…ˆè·å– API Key**\n>\n> - ğŸ“– **API æ–‡æ¡£**ï¼šhttps://www.md2wechat.cn/api-docs\n> - ğŸ“§ **è”ç³»è·å–**ï¼šé€šè¿‡ [å®˜ç½‘](https://www.md2wechat.cn/api-docs) è”ç³»è·å– API Key\n> - ğŸ’¡ **AI æ¨¡å¼**ï¼šä¸éœ€è¦ API Keyï¼Œç›´æ¥ä½¿ç”¨ Claude å³å¯\n\n---\n\n[å¿«é€Ÿå¼€å§‹](#-5åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹) â€¢ [Claude Code](#-claude-code-é›†æˆ) â€¢ [åŠŸèƒ½ä»‹ç»](#-æ ¸å¿ƒåŠŸèƒ½) â€¢ [ä½¿ç”¨è¯´æ˜](#-ä½¿ç”¨æ–¹æ³•) â€¢ [å¸¸è§é—®é¢˜](#-å¸¸è§é—®é¢˜)\n\n---\n\n## ğŸš€ Claude Code ç”¨æˆ·ï¼ˆæ¨èï¼‰\n\nåœ¨ Claude Code ä¸­è¿è¡Œä»¥ä¸‹å‘½ä»¤å³å¯ä½¿ç”¨ï¼š\n\n```bash\n/plugin marketplace add geekjourneyx/md2wechat-skill\n/plugin install md2wechat@geekjourneyx-md2wechat-skill\n```\n\nç„¶åç›´æ¥å¯¹è¯ï¼š**\"è¯·ç”¨ç§‹æ—¥æš–å…‰ä¸»é¢˜å°† article.md è½¬æ¢ä¸ºå¾®ä¿¡å…¬ä¼—å·æ ¼å¼\"**\n\n</div>\n\n## âœ¨ è¿™æ˜¯ä»€ä¹ˆï¼Ÿ\n\n**md2wechat** æ˜¯ä¸€ä¸ªè®©ä½ çš„å¾®ä¿¡å…¬ä¼—å·å†™ä½œæ›´é«˜æ•ˆçš„ç¥å™¨ã€‚\n\n> ğŸ’¡ **ä¸€å¥è¯ç†è§£**ï¼šç”¨ Markdown å†™æ–‡ç«  â†’ ä¸€é”®è½¬æ¢ â†’ è‡ªåŠ¨å‘åˆ°å¾®ä¿¡è‰ç¨¿ç®±\n\n**é€‚åˆè°ç”¨ï¼Ÿ**\n\n| ä½ æ˜¯ | ç—›ç‚¹ | md2wechat å¸®ä½  |\n|------|------|---------------|\n| ğŸ“ å†…å®¹åˆ›ä½œè€… | å¾®ä¿¡ç¼–è¾‘å™¨å¤ªéš¾ç”¨ï¼Œæ’ç‰ˆèŠ±æ—¶é—´ | Markdown å†™ä½œï¼Œè‡ªåŠ¨æ’ç‰ˆ |\n| ğŸ’¼ äº§å“ç»ç† | è¦å‘å…¬å‘Šï¼Œä½†ä¸ä¼š HTML | ä¸ç”¨å­¦ä»£ç ï¼Œä¸€è¡Œå‘½ä»¤æå®š |\n| ğŸ‘¨â€ğŸ’» ç¨‹åºå‘˜ | ä¹ æƒ¯ Markdownï¼Œè®¨åŒå¾®ä¿¡ç¼–è¾‘å™¨ | ä¿æŒä½ çš„å†™ä½œä¹ æƒ¯ |\n| ğŸ¤– AI ç”¨æˆ· | ç”¨ AI ç”Ÿæˆå†…å®¹ï¼Œä½†è¦æ‰‹åŠ¨å¤åˆ¶ç²˜è´´ | AI ç”Ÿæˆ â†’ å¾®ä¿¡è‰ç¨¿ï¼Œæ— ç¼è¡”æ¥ |\n\n---\n\n## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½\n\n```mermaid\nflowchart LR\n    A[ç”¨ Markdown å†™æ–‡ç« ] --> B{é€‰æ‹©æ¨¡å¼}\n\n    B -->|API æ¨¡å¼| C[è°ƒç”¨ md2wechat.cn API]\n    C --> D[è·å– HTML]\n\n    B -->|AI æ¨¡å¼ â­| E[Claude AI ç”Ÿæˆ HTML]\n    E --> F[ç²¾ç¾æ’ç‰ˆ]\n\n    D --> G[é¢„è§ˆæ•ˆæœ]\n    F --> G\n\n    G --> H{æ»¡æ„å—}\n    H -->|ä¸æ»¡æ„| B\n    H -->|æ»¡æ„| I[ä¸Šä¼ å›¾ç‰‡]\n    I --> J[å‘é€åˆ°å¾®ä¿¡è‰ç¨¿ç®±]\n    J --> K[å®Œæˆ]\n\n    classDef nodeA fill:#e3f2fd,stroke:#2196f3,color:#0d47a1\n    classDef nodeE fill:#fff3e0,stroke:#ff9800,color:#e65100\n    classDef nodeJ fill:#e8f5e9,stroke:#4caf50,color:#1b5e20\n    classDef nodeK fill:#c8e6c9,stroke:#4caf50,color:#1b5e20\n\n    class A nodeA\n    class E nodeE\n    class J nodeJ\n    class K nodeK\n```\n\n### å››å¤§æ ¸å¿ƒåŠŸèƒ½\n\n| åŠŸèƒ½ | å‘½ä»¤ | è¯´æ˜ | é€‚åˆè° |\n|------|------|------|--------|\n| **Markdown è½¬æ¢** | `convert` | å°† Markdown è½¬æ¢ä¸ºå¾®ä¿¡æ ¼å¼ HTML | æ‰€æœ‰ç”¨æˆ· |\n| **é£æ ¼å†™ä½œ** | `write` | ç”¨åˆ›ä½œè€…é£æ ¼è¾…åŠ©å†™ä½œï¼Œè‡ªåŠ¨ç”Ÿæˆæ–‡ç« å’Œå°é¢æç¤ºè¯ | å†™ä½œå°ç™½ã€å†…å®¹åˆ›ä½œè€… |\n| **AI å»ç—•** ğŸ†• | `humanize` | å»é™¤ AI ç”Ÿæˆç—•è¿¹ï¼Œè®©æ–‡ç« å¬èµ·æ¥æ›´è‡ªç„¶ã€åƒäººå†™çš„ | AI å†™ä½œç”¨æˆ· |\n| **è‰ç¨¿æ¨é€** | `convert --draft` | ä¸€é”®å‘é€åˆ°å¾®ä¿¡è‰ç¨¿ç®± | éœ€è¦é¢‘ç¹å‘å¸ƒçš„ç”¨æˆ· |\n\n**`write` ä¸ `convert` çš„åŒºåˆ«ï¼š**\n\n| å¯¹æ¯”é¡¹ | `write` å‘½ä»¤ | `convert` å‘½ä»¤ |\n|--------|-------------|---------------|\n| **è¾“å…¥** | ä¸€ä¸ªæƒ³æ³•/è§‚ç‚¹/ç‰‡æ®µ | å®Œæ•´çš„ Markdown æ–‡ä»¶ |\n| **è¾“å‡º** | ç»“æ„åŒ–æç¤ºè¯ï¼ˆAI å¤„ç†åç”Ÿæˆæ–‡ç« ï¼‰ | å¾®ä¿¡æ ¼å¼ HTML |\n| **ç”¨é€”** | ä»é›¶å¼€å§‹åˆ›ä½œ | æ ¼å¼è½¬æ¢å·²æœ‰å†…å®¹ |\n| **å°é¢** | è‡ªåŠ¨ç”Ÿæˆå°é¢æç¤ºè¯ | éœ€è¦æ‰‹åŠ¨æŒ‡å®šå°é¢å›¾ |\n\n**ç®€å•ç†è§£ï¼š**\n- `write` = å¸®ä½ å†™æ–‡ç« ï¼ˆä»æƒ³æ³•åˆ°å®Œæ•´æ–‡ç« ï¼‰\n- `convert` = å¸®ä½ æ’ç‰ˆï¼ˆä» Markdown åˆ°å¾®ä¿¡æ ¼å¼ï¼‰\n\n### ä¸¤ç§è½¬æ¢æ¨¡å¼\n\n| æ¨¡å¼ | é€‚åˆè° | ç‰¹ç‚¹ | æ ·å¼ |\n|------|--------|------|------|\n| **API æ¨¡å¼** | è¿½æ±‚ç¨³å®šã€å¿«é€Ÿ | è°ƒç”¨ md2wechat.cn APIï¼Œç§’çº§å“åº” | ç®€æ´ä¸“ä¸š |\n| **AI æ¨¡å¼** â­ | è¿½æ±‚ç²¾ç¾æ’ç‰ˆ | Claude AI ç”Ÿæˆï¼Œæ ·å¼æ›´ä¸°å¯Œ | ç§‹æ—¥æš–å…‰ / æ˜¥æ—¥æ¸…æ–° / æ·±æµ·é™è°§ |\n\n### å®Œæ•´å·¥ä½œæµç¨‹\n\n```mermaid\nflowchart LR\n    A1[Markdown å†™ä½œ] --> A2[æ’å…¥å›¾ç‰‡]\n    A2 --> B1{é€‰æ‹©æ¨¡å¼}\n\n    B1 -->|API| B2[md2wechat.cn]\n    B1 -->|AI| B3[Claude AI]\n\n    B2 --> B4[HTML ç”Ÿæˆ]\n    B3 --> B4\n\n    B4 --> C1[é¢„è§ˆæ•ˆæœ]\n    C1 --> C2{æ»¡æ„å—}\n\n    C2 -->|è°ƒæ•´| B1\n    C2 -->|OK| C3[ä¸Šä¼ å›¾ç‰‡]\n    C3 --> C4[å‘é€è‰ç¨¿]\n    C4 --> C5[å®Œæˆ]\n\n    classDef write fill:#e3f2fd,stroke:#2196f3,color:#0d47a1\n    classDef ai fill:#fff3e0,stroke:#ff9800,color:#e65100\n    classDef done fill:#e8f5e9,stroke:#4caf50,color:#1b5e20\n    classDef success fill:#c8e6c9,stroke:#4caf50,color:#1b5e20\n\n    class A1,A2 write\n    class B3 ai\n    class C4,C5 done\n```\n\n---\n\n## ğŸš€ 5åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹\n\n### ç¬¬ä¸€æ­¥ï¼šä¸‹è½½è½¯ä»¶\n\n> ğŸ’¡ **æœ€æ–°ç‰ˆæœ¬**ï¼šè®¿é—® [Releases é¡µé¢](https://github.com/geekjourneyx/md2wechat-skill/releases) ä¸‹è½½\n\n| ä½ çš„ç³»ç»Ÿ | ä¸‹è½½é“¾æ¥ | å®‰è£…ä½ç½® |\n|----------|----------|----------|\n| ğŸªŸ **Windows** | [ä¸‹è½½ .exe](https://github.com/geekjourneyx/md2wechat-skill/releases/latest/download/md2wechat-windows-amd64.exe) | ä»»æ„æ–‡ä»¶å¤¹ï¼ˆæˆ– `C:\\Windows\\System32\\`ï¼‰ |\n| ğŸ **Mac Intel èŠ¯ç‰‡** | [ä¸‹è½½](https://github.com/geekjourneyx/md2wechat-skill/releases/latest/download/md2wechat-darwin-amd64) | `/usr/local/bin/` æˆ– `~/.local/bin/` |\n| ğŸ **Mac Apple Silicon (M1/M2/M3/M4)** | [ä¸‹è½½](https://github.com/geekjourneyx/md2wechat-skill/releases/latest/download/md2wechat-darwin-arm64) | `/usr/local/bin/` æˆ– `~/.local/bin/` |\n| ğŸ§ **Linux (Intel/AMD)** | [ä¸‹è½½](https://github.com/geekjourneyx/md2wechat-skill/releases/latest/download/md2wechat-linux-amd64) | `/usr/local/bin/` æˆ– `~/.local/bin/` |\n| ğŸ§ **Linux (ARM/æ ‘è“æ´¾)** | [ä¸‹è½½](https://github.com/geekjourneyx/md2wechat-skill/releases/latest/download/md2wechat-linux-arm64) | `/usr/local/bin/` æˆ– `~/.local/bin/` |\n\n> ğŸ” **å¦‚ä½•ç¡®è®¤ Mac èŠ¯ç‰‡ç±»å‹ï¼Ÿ**\n> - ç‚¹å‡»å±å¹•å·¦ä¸Šè§’ **è‹¹æœå›¾æ ‡** â†’ **å…³äºæœ¬æœº**\n> - æŸ¥çœ‹ã€ŒèŠ¯ç‰‡ã€æˆ–ã€Œå¤„ç†å™¨ã€ä¿¡æ¯ï¼š\n>   - æ˜¾ç¤º `Apple M1/M2/M3/M4` â†’ ä¸‹è½½ **Apple Silicon** ç‰ˆæœ¬\n>   - æ˜¾ç¤º `Intel` â†’ ä¸‹è½½ **Intel** ç‰ˆæœ¬\n\n**å®‰è£…æ­¥éª¤**ï¼š\n\n<details>\n<summary><b>Windows å®‰è£…æ–¹æ³•</b></summary>\n\n1. ä¸‹è½½ `md2wechat-windows-amd64.exe`\n2. é‡å‘½åä¸º `md2wechat.exe`ï¼ˆå¯é€‰ï¼‰\n3. æ”¾åˆ°ä»»æ„æ–‡ä»¶å¤¹ï¼Œæˆ–å¤åˆ¶åˆ° `C:\\Windows\\System32\\`ï¼ˆå…¨å±€å¯ç”¨ï¼‰\n4. æ‰“å¼€ CMD æˆ– PowerShellï¼Œè¾“å…¥ `md2wechat --help` æµ‹è¯•\n\n</details>\n\n<details>\n<summary><b>Mac å®‰è£…æ–¹æ³•</b>",
      "default_branch": "main"
    },
    "fetched_at": "2026-01-20T02:57:16.710942"
  },
  {
    "basic_info": {
      "name": "leaker",
      "full_name": "vflame6/leaker",
      "owner": "vflame6",
      "description": "Passive leak enumeration tool.",
      "url": "https://github.com/vflame6/leaker",
      "clone_url": "https://github.com/vflame6/leaker.git",
      "ssh_url": "git@github.com:vflame6/leaker.git",
      "homepage": "https://maksimradaev.com/posts/introducing-leaker/",
      "created_at": "2025-12-25T11:43:14Z",
      "updated_at": "2026-01-20T01:41:42Z",
      "pushed_at": "2026-01-16T02:27:43Z"
    },
    "stats": {
      "stars": 212,
      "forks": 25,
      "watchers": 212,
      "open_issues": 0,
      "size": 480
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 31574,
        "Dockerfile": 389
      },
      "license": "MIT License",
      "topics": [
        "bugbounty",
        "hacking",
        "leak-detection",
        "leaks",
        "osint",
        "reconnaissance"
      ]
    },
    "content": {
      "readme": "<h1 align=\"center\">\n  leaker\n</h1>\n\n<h4 align=\"center\">Passive leak enumeration tool.</h4>\n\n<p align=\"center\">\n<a href=\"https://goreportcard.com/report/github.com/vflame6/leaker\" target=\"_blank\"><img src=\"https://goreportcard.com/badge/github.com/vflame6/leaker\"></a>\n<a href=\"https://github.com/vflame6/leaker/issues\"><img src=\"https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat\"></a>\n<a href=\"https://github.com/vflame6/leaker/releases\"><img src=\"https://img.shields.io/github/release/vflame6/leaker\"></a>\n<a href=\"https://t.me/vflame6\"><img src=\"https://img.shields.io/badge/Follow-@vflame6-33a3e1?style=flat&logo=telegram\"></a>\n</p>\n\nCreated by Maksim Radaev/[@vflame6](https://github.com/vflame6)\n\n---\n\n`leaker` is a leak discovery tool that returns valid credential leaks for emails, using passive online sources. \n\n\n## Features\n\n![leaker](static/leaker_demo.png)\n\nAvailable sources: `proxynova`, `leakcheck`\n\n## Usage\n\n```shell\nleaker -h\n```\n\nHere is a help menu for the tool:\n\n```yaml\nUsage: leaker [<targets>] [flags]\n\n  leaker is a leak discovery tool that returns valid credential leaks for emails, using passive online sources.\n\nArguments:\n  [<targets>]    Target email or file with emails\n\nFlags:\n  -h, --help                                     Show context-sensitive help.\n  -s, --sources=all,...                          Specific sources to use for enumeration (default all). Use --list-sources to display all available sources.\n  --timeout=30s                              Seconds to wait before timing out (default 30s)\n  -N, --no-rate-limit                            Disable rate limiting (DANGER)\n  --no-filter                                Disable results filtering, include every result\n  -o, --output=STRING                            File to write output to\n  --overwrite                                Force overwrite of existing output file\n  -p, --provider-config=\"provider-config.yml\"    Provider config file\n  --proxy=STRING                             HTTP proxy to use with leaker\n  -A, --user-agent=STRING                        Custom user agent\n  --version                                  Print version of leaker\n  -q, --quiet                                    Suppress output, print results only\n  -v, --verbose                                  Show sources in results output\n  -D, --debug                                    Enable debug mode\n  -L, --list-sources                             List all available sources\n```\n\n## Installation\n\n`leaker` requires **go1.25** to install successfully.\n\n```shell\ngo install -v github.com/vflame6/leaker@latest\n```\n\nCompiled versions are available on [Release Binaries](https://github.com/vflame6/leaker/releases) page.\n\nTo Build:\n\n```\ngo build -o leaker main.go\n```\n\n### Post-installation\n\n`leaker` can be used right after the installation, however many sources required API keys to work. View an example configuration file here: https://github.com/vflame6/leaker/blob/main/static/provider-config.yml\n\nThe tool will generate a provider configuration file on the first launch, so you can also specify API keys there.\n\n## Contributing\n\nFeel free to open an issue if something does not work, or if you have any issues. New ideas to improve the tool are much appreciated.\n",
      "default_branch": "main"
    },
    "fetched_at": "2026-01-20T02:57:17.943103"
  },
  {
    "basic_info": {
      "name": "grepai",
      "full_name": "yoanbernabeu/grepai",
      "owner": "yoanbernabeu",
      "description": "Semantic Search & Call Graphs for AI Agents (100% Local)",
      "url": "https://github.com/yoanbernabeu/grepai",
      "clone_url": "https://github.com/yoanbernabeu/grepai.git",
      "ssh_url": "git@github.com:yoanbernabeu/grepai.git",
      "homepage": "https://yoanbernabeu.github.io/grepai/",
      "created_at": "2026-01-09T13:01:33Z",
      "updated_at": "2026-01-20T02:36:33Z",
      "pushed_at": "2026-01-18T13:32:30Z"
    },
    "stats": {
      "stars": 197,
      "forks": 21,
      "watchers": 197,
      "open_issues": 4,
      "size": 381
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 358994,
        "Makefile": 1827,
        "Shell": 1459
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# grepai\n\n[![Go](https://github.com/yoanbernabeu/grepai/actions/workflows/ci.yml/badge.svg)](https://github.com/yoanbernabeu/grepai/actions/workflows/ci.yml)\n[![Go Report Card](https://goreportcard.com/badge/github.com/yoanbernabeu/grepai)](https://goreportcard.com/report/github.com/yoanbernabeu/grepai)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)\n\n**A privacy-first, CLI-native way to semantically search your codebase.**\n\nSearch code by *what it does*, not just what it's called. `grepai` indexes the meaning of your code using vector embeddings, enabling natural language queries that find conceptually related codeâ€”even when naming conventions vary.\n\n## Why grepai?\n\n`grep` was built in 1973 for exact text matching. Modern codebases need semantic understanding.\n\n|                      | `grep` / `ripgrep`           | `grepai`                          |\n|----------------------|------------------------------|-----------------------------------|\n| **Search type**      | Exact text / regex           | Semantic understanding            |\n| **Query**            | `\"func.*Login\"`              | `\"user authentication flow\"`      |\n| **Finds**            | Exact pattern matches        | Conceptually related code         |\n| **AI Agent context** | Requires many searches       | Fewer, more relevant results      |\n\n### Built for AI Agents\n\ngrepai is designed to provide **high-quality context** to AI coding assistants. By returning semantically relevant code chunks, your agents spend less time searching and more time coding.\n\n## Getting Started\n\n### Installation\n\n```bash\ncurl -sSL https://raw.githubusercontent.com/yoanbernabeu/grepai/main/install.sh | sh\n```\n\nOr download from [Releases](https://github.com/yoanbernabeu/grepai/releases).\n\n### Quick Start\n\n```bash\ngrepai init                        # Initialize in your project\ngrepai watch                       # Start background indexing daemon\ngrepai search \"error handling\"     # Search semantically\ngrepai trace callers \"Login\"       # Find who calls a function\n```\n\n## Commands\n\n| Command                  | Description                            |\n|--------------------------|----------------------------------------|\n| `grepai init`            | Initialize grepai in current directory |\n| `grepai watch`           | Start real-time file watcher daemon    |\n| `grepai search <query>`  | Search codebase with natural language  |\n| `grepai trace <cmd>`     | Analyze call graph (callers/callees)   |\n| `grepai status`          | Browse index state interactively       |\n| `grepai agent-setup`     | Configure AI agents integration        |\n| `grepai update`          | Update grepai to the latest version    |\n\n```bash\ngrepai search \"authentication\" -n 5       # Limit results (default: 10)\ngrepai search \"authentication\" --json     # JSON output for AI agents\ngrepai search \"authentication\" --json -c  # Compact JSON (~80% fewer tokens)\n```\n\n### Background Daemon\n\nRun the watcher as a background process:\n\n```bash\ngrepai watch --background    # Start in background\ngrepai watch --status        # Check if running\ngrepai watch --stop          # Stop gracefully\n```\n\nLogs are stored in OS-specific directories:\n\n| Platform | Log Directory |\n|----------|---------------|\n| Linux    | `~/.local/state/grepai/logs/` |\n| macOS    | `~/Library/Logs/grepai/` |\n| Windows  | `%LOCALAPPDATA%\\grepai\\logs\\` |\n\nUse `--log-dir /custom/path` to override (must be passed to all commands):\n\n```bash\ngrepai watch --background --log-dir /custom/path    # Start in background\ngrepai watch --status --log-dir /custom/path        # Check if running\ngrepai watch --stop --log-dir /custom/path          # Stop gracefully\n```\n\n### Self-Update\n\nKeep grepai up to date:\n\n```bash\ngrepai update --check    # Check for available updates\ngrepai update            # Download and install latest version\ngrepai update --force    # Force update even if already on latest\n```\n\nThe update command:\n- Fetches the latest release from GitHub\n- Verifies checksum integrity\n- Replaces the binary automatically\n- Works on all supported platforms (Linux, macOS, Windows)\n\n### Call Graph Analysis\n\nFind function relationships in your codebase:\n\n```bash\ngrepai trace callers \"Login\"           # Who calls Login?\ngrepai trace callees \"HandleRequest\"   # What does HandleRequest call?\ngrepai trace graph \"ProcessOrder\" --depth 3  # Full call graph\n```\n\nOutput as JSON for AI agents:\n```bash\ngrepai trace callers \"Login\" --json\n```\n\n## AI Agent Integration\n\ngrepai integrates natively with popular AI coding assistants. Run `grepai agent-setup` to auto-configure.\n\n| Agent        | Configuration File                     |\n|--------------|----------------------------------------|\n| Cursor       | `.cursorrules`                         |\n| Windsurf     | `.windsurfrules`                       |\n| Claude Code  | `CLAUDE.md` / `.claude/settings.md`    |\n| Gemini CLI   | `GEMINI.md`                            |\n| OpenAI Codex | `AGENTS.md` ",
      "default_branch": "main"
    },
    "fetched_at": "2026-01-20T02:57:19.187534"
  },
  {
    "basic_info": {
      "name": "lagident",
      "full_name": "nook24/lagident",
      "owner": "nook24",
      "description": "Lagident pings targets and collects information about response time and packet loss. Helps you identify anomalies across your network",
      "url": "https://github.com/nook24/lagident",
      "clone_url": "https://github.com/nook24/lagident.git",
      "ssh_url": "git@github.com:nook24/lagident.git",
      "homepage": "",
      "created_at": "2025-12-21T17:37:07Z",
      "updated_at": "2026-01-17T12:04:39Z",
      "pushed_at": "2026-01-04T14:51:27Z"
    },
    "stats": {
      "stars": 195,
      "forks": 7,
      "watchers": 195,
      "open_issues": 2,
      "size": 497
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 38105,
        "TypeScript": 31679,
        "HTML": 9210,
        "CSS": 1634,
        "Dockerfile": 733,
        "Shell": 672
      },
      "license": "MIT License",
      "topics": [
        "gaming",
        "gaming-tools",
        "latency",
        "monitoring",
        "network",
        "observability",
        "ping"
      ]
    },
    "content": {
      "readme": "# Lagident\n\n![Lagident Logo](./Lagident_Logo.png)\n\nLagident pings targets and collects information about response time and packet loss. The results are displayed through a scatter chart, which will (hopefully) help you identify anomalies across your network.\n\nLagident pings each target every **15** seconds.\n\nThis project was highly inspired by [Meshping](https://github.com/Svedrin/meshping). However, Meshping has more features.\n\n## Web interface\n\nLagident has a simple web interface, where you can add new targets to ping.\n\n![Lagident Web Interface](./images/Lagident.png)\n\nBy default Lagident will keep 3 days of data (~17280 measurements per target) and will display all points in a scatter chart.\nYou can use the chart to identify latency spikes or packet loss.\n![Lagident History Chart](./images/Lagident_Modal.png)\n\nFor example the chart for a poor quality Wifi connection can look like in the\nfollowing example.\nAs you can see the measured latency is all over the place from 5ms to 100ms most of the time and spikes to 300ms.\nThis connection is also suffering from packet loss. (0.33%)\n\nPoor quality connections like this can be a pain for online gaming.\n![Lagident Bad Wifi Connection](./images/Lagident_bad_wifi_connection.png)\n\n## Motivation\nMeshping does not store any information about packet loss. Unfortunately, I had to deal with strange packet loss issues on my desktop PC. Additionally, I wanted to embed an Angular application into Go for a long time, so I thought this was a cool project to do.\n\n## Features\n - Graphs displaying latencies and packet loss\n - Mobile-friendly\n - Add and remove targets on the fly\n - Simple Docker-based setup\n - IPv6 support\n\n### Cons\nLagident is not a full-fledged monitoring solution. It is more like a stopwatch. All it does is send ping requests to targets and document the response time and packet loss. That's it. You cannot do anything else.\n\nIf you are looking for a comprehensive monitoring solution that can do more, you may want to take a look at [openITCOCKPIT](https://github.com/openITCOCKPIT/openITCOCKPIT).\n\n## Start in Production Mode\n\nTo start Lagident in production mode, run:\n```sh\ndocker compose up\n```\nThis will build Lagident and start it together with\nits database. Access Lagident on http://localhost:9933.\n\n### Standalone with sqlite\n\nFirst you should create a new volume to store the sqlite database file.\n```\ndocker volume create lagident-sqlite-data\n```\n\nNow you can start the Lagident container:\n```\ndocker run --rm \\\n -p 9933:8080 \\\n -e DB_TYPE=sqlite \\\n -e PROFILE=prod \\\n -v lagident-sqlite-data:/data \\\n --name=lagident \\\n nook24/lagident:latest\n```\n\n### Docker Compose with sqlite\n```\ndocker compose -f docker-compose-sqlite.yml up\n```\n\n## Configuration\n\nLagident can be configured using environment variables. The following environment variables are available:\n\n- `DB_TYPE`: The type of database to use (`mysql` or `sqlite`).\n- `DB_HOST`: The database host (for MySQL).\n- `DB_PORT`: The database port (for MySQL).\n- `DB_USER`: The database user (for MySQL).\n- `DB_PASS`: The database password (for MySQL).\n- `DB_NAME`: The database name.\n- `PROFILE`: The application profile (`dev` or `prod`).\n- `HOUSEKEEPING_RETENTION_DAYS`: 3 (override to keep more or fewer days of data).\n\n## Support for x64 and arm64\n\nThe official Docker images of Lagident are available for `amd64` and `arm64` so you can\nsetup Lagident on your Desktop PC, Apple silicon or a SoC like the Raspberry Pi 4 or newer.\n\n\n\n# Start in development mode\n\n## Environment setup\n\nYou need to have [Go](https://go.dev/),\n[Node.js](https://nodejs.org/) and\n[Docker](https://www.docker.com/)\ninstalled on your computer.\n\nVerify the tools by running the following commands:\n\n```sh\ngo version\nnpm --version\ndocker --version\n```\n\n\nIn the project directory run the command (you might\nneed to prepend it with `sudo` depending on your setup):\n```sh\ndocker compose -f docker-compose-dev.yml up\n```\n\nThis starts a local MySQL database on `localhost:3306`.\nThe database will be populated with test records from\nthe [init-mysqldb.sql](init-mysqldb.sql) file for MySQL\nand in the `InitializeSQLiteDB` function for SQLite.\n\nNavigate to the `server` folder and start the back end:\n\n```sh\ncd server\ngo run server.go\n```\nThe back end will serve on http://localhost:8080.\n\nNavigate to the `webapp` folder, install dependencies,\nand start the front end development server by running:\n\n```sh\ncd webapp\nnpm install\nnpm start\n```\nThe application will be available on http://localhost:3000.\n\n\n## Connect to database\n```\nmysql --defaults-file=./mysql.cnf\n```\n\n## Acknowledgements\n\n- This project was kickstarted using the [goxygen](https://github.com/shpota/goxygen) project, thanks a lot.\n- Also thanks to my brother wo created [meshping](https://github.com/Svedrin/meshping), in the first place.\n\n## Naming\nThe name is a combination of [Lag](https://en.wikipedia.org/wiki/Lag_(video_games)) and [identify](https://en.wiktionary.org/wiki/identify) == `Lagident`.\n\n## Release",
      "default_branch": "main"
    },
    "fetched_at": "2026-01-20T02:57:20.448564"
  },
  {
    "basic_info": {
      "name": "roborev",
      "full_name": "wesm/roborev",
      "owner": "wesm",
      "description": "Background agent to review git commits and autonomously refine your branches with CLI agents while you work, with CLI and TUI support",
      "url": "https://github.com/wesm/roborev",
      "clone_url": "https://github.com/wesm/roborev.git",
      "ssh_url": "git@github.com:wesm/roborev.git",
      "homepage": "",
      "created_at": "2026-01-05T19:28:46Z",
      "updated_at": "2026-01-20T01:59:36Z",
      "pushed_at": "2026-01-19T22:20:15Z"
    },
    "stats": {
      "stars": 187,
      "forks": 19,
      "watchers": 187,
      "open_issues": 0,
      "size": 2149
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 1054310,
        "Shell": 13640,
        "Nix": 1580,
        "Makefile": 531
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# roborev\n\nAutomatic code review for git commits using AI agents (Claude Code, Codex, Gemini, Copilot, OpenCode).\n\n![TUI Queue View](docs/screenshots/tui-queue.png)\n\n## Installation\n\n```bash\ncurl -fsSL https://raw.githubusercontent.com/wesm/roborev/main/scripts/install.sh | bash\n```\n\nOr with Go:\n\n```bash\ngo install github.com/wesm/roborev/cmd/roborev@latest\ngo install github.com/wesm/roborev/cmd/roborevd@latest\n```\n\nEnsure `$GOPATH/bin` is in your PATH:\n\n```bash\nexport PATH=\"$PATH:$(go env GOPATH)/bin\"\n```\n\n## Quick Start\n\n```bash\ncd your-repo\nroborev init          # Install post-commit hook\ngit commit -m \"...\"   # Reviews happen automatically\nroborev tui           # View reviews in interactive UI\n```\n\n**Note**: Hook installation automatically detects your git hook manager (Husky, etc.) via `core.hooksPath`.\n\n## Commands\n\n| Command | Description |\n|---------|-------------|\n| `roborev init` | Initialize roborev in current repo |\n| `roborev status` | Show daemon and queue status |\n| `roborev tui` | Interactive terminal UI |\n| `roborev show [sha]` | Display review for commit |\n| `roborev show --job <id>` | Display review by job ID |\n| `roborev review <sha>` | Queue a commit for review |\n| `roborev review <start> <end>` | Queue a commit range (inclusive) |\n| `roborev review --branch` | Review all commits on current branch |\n| `roborev review --since <commit>` | Review commits since a specific commit |\n| `roborev review --dirty` | Review uncommitted changes |\n| `roborev review --reasoning <level>` | Set reasoning depth (thorough/standard/fast) |\n| `roborev prompt \"<text>\"` | Run ad-hoc prompt with AI agent |\n| `roborev respond <id> [msg]` | Add a response/note to a review |\n| `roborev address <id>` | Mark review as addressed |\n| `roborev refine` | Auto-fix failed reviews using AI |\n| `roborev repo list` | List tracked repositories |\n| `roborev repo rename <old> <new>` | Rename a repository's display name |\n| `roborev stream` | Stream review events (JSONL) |\n| `roborev daemon start\\|stop\\|restart` | Manage the daemon |\n| `roborev install-hook` | Install git post-commit hook |\n| `roborev uninstall-hook` | Remove git post-commit hook |\n| `roborev update` | Update roborev to latest version |\n| `roborev skills install` | Install agent skills (Claude Code, Codex) |\n| `roborev version` | Show version information |\n\n## Reviewing Branches\n\nUse `--branch` to review all commits since your branch diverged from main:\n\n```bash\nroborev review --branch              # Review branch vs auto-detected main/master\nroborev review --branch --base dev   # Review branch vs specific base\nroborev review --branch --wait       # Wait for review and show result\n```\n\nThis is useful for pre-merge reviews of entire feature branches.\n\n## Reviewing Specific Commits\n\nUse `--since` to review commits since a specific point:\n\n```bash\nroborev review --since HEAD~5       # Review last 5 commits\nroborev review --since abc123       # Review commits since abc123 (exclusive)\nroborev review --since v1.0.0       # Review commits since a tag\n```\n\nThe range is exclusive of the starting commit (like git's `..` range syntax). Unlike `--branch`, this works on any branch including main.\n\n## Reviewing Uncommitted Changes\n\nUse `--dirty` to review working tree changes before committing:\n\n```bash\nroborev review --dirty           # Queue review of uncommitted changes\nroborev review --dirty --wait    # Wait for review and show result\n```\n\nIncludes staged changes, unstaged changes to tracked files, and untracked files.\n\nThe `--wait` flag exits with code 0 for passing reviews and code 1 for failing reviews, useful for CI:\n\n```bash\nif ! roborev review --dirty --wait --quiet; then\n    echo \"Review failed - please address findings\"\n    exit 1\nfi\n```\n\n## Ad-Hoc Prompts\n\nUse `prompt` to run arbitrary prompts with AI agents for tasks beyond code review:\n\n```bash\nroborev prompt \"Explain the architecture of this codebase\"\nroborev prompt --wait \"What does the main function do?\"\nroborev prompt --agent claude-code \"Refactor error handling in main.go\"\nroborev prompt --reasoning thorough \"Find potential security issues\"\nroborev prompt --agentic \"Add error handling to main.go\"\ncat instructions.txt | roborev prompt --wait\n```\n\n**Flags:**\n\n| Flag | Description |\n|------|-------------|\n| `--wait` | Wait for job to complete and show result |\n| `--agent` | Agent to use (default: from config) |\n| `--reasoning` | Reasoning level: fast, standard, or thorough |\n| `--no-context` | Don't include repository context in prompt |\n| `--agentic` | Enable agentic mode (allow file edits and commands) |\n| `--yolo` | Alias for `--agentic` |\n| `--quiet` | Suppress output (just enqueue) |\n\nBy default, prompts run in **review mode** (read-only). Use `--agentic` (or `--yolo`) to enable write operations (file edits, bash commands) for tasks that need to modify your codebase.\n\nBy default, prompts include context about the repository (name, path, and any project guidelines from `.roborev.toml`). Use `--no-context",
      "default_branch": "main"
    },
    "fetched_at": "2026-01-20T02:57:21.696793"
  },
  {
    "basic_info": {
      "name": "mac-cleanup-go",
      "full_name": "2ykwang/mac-cleanup-go",
      "owner": "2ykwang",
      "description": "TUI macOS cleaner that scans caches/logs, shows sizes/paths, lets you select what to delete before Trash.",
      "url": "https://github.com/2ykwang/mac-cleanup-go",
      "clone_url": "https://github.com/2ykwang/mac-cleanup-go.git",
      "ssh_url": "git@github.com:2ykwang/mac-cleanup-go.git",
      "homepage": "",
      "created_at": "2026-01-01T14:34:49Z",
      "updated_at": "2026-01-20T01:37:55Z",
      "pushed_at": "2026-01-19T23:58:52Z"
    },
    "stats": {
      "stars": 173,
      "forks": 8,
      "watchers": 173,
      "open_issues": 4,
      "size": 17881
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 337606,
        "Makefile": 2685
      },
      "license": "MIT License",
      "topics": [
        "caches",
        "clean",
        "cleanup",
        "cli",
        "disk-cleanup",
        "golang",
        "homebrew",
        "mac-cleanup",
        "macos",
        "optimize",
        "terminal-ui",
        "tui"
      ]
    },
    "content": {
      "readme": "<div align=\"center\">\n  <h1>mac-cleanup-go</h1>\n  <p>Preview-first TUI for cleaning macOS caches, logs, and temporary files.</p>\n</div>\n\n<p align=\"center\">\n  <a href=\"https://github.com/2ykwang/mac-cleanup-go/releases\"><img src=\"https://img.shields.io/github/v/release/2ykwang/mac-cleanup-go\" alt=\"GitHub Release\"></a>\n  <a href=\"https://goreportcard.com/report/github.com/2ykwang/mac-cleanup-go\"><img src=\"https://goreportcard.com/badge/github.com/2ykwang/mac-cleanup-go\" alt=\"Go Report Card\"></a>\n  <a href=\"https://github.com/2ykwang/mac-cleanup-go/actions/workflows/test.yml\"><img src=\"https://github.com/2ykwang/mac-cleanup-go/actions/workflows/test.yml/badge.svg\" alt=\"CI\"></a>\n  <a href=\"https://codecov.io/gh/2ykwang/mac-cleanup-go\"><img src=\"https://codecov.io/gh/2ykwang/mac-cleanup-go/graph/badge.svg?token=ecH3KP0piI\" alt=\"codecov\"/></a>\n  <a href=\"https://golangci-lint.run/\"><img src=\"https://img.shields.io/badge/linted%20by-golangci--lint-brightgreen\" alt=\"golangci-lint\"></a>\n</p>\n\n<p align=\"center\">\n  <a href=\"README.md\">English</a> | <a href=\"README_KO.md\">í•œêµ­ì–´</a>\n</p>\n\n## Overview\n\n- Preview items before delete and exclude what you want.\n- By default, items go to Trash; only the Trash category empties it permanently.\n- Risky items start excluded; manual categories show guides only.\n- Scope: caches/logs/temp and selected app data (no system optimization or uninstaller).\n\n![demo](assets/result_view.png)\n\n\n## Quick Start\n\nInstall via Homebrew:\n\n```bash\nbrew install 2ykwang/2ykwang/mac-cleanup-go\n```\n\nRun:\n\n```bash\nmac-cleanup\nmac-cleanup --update   # update via Homebrew\n```\n\n> Tip: Grant Full Disk Access to your terminal to clean Trash and restricted locations.  \n> System Settings -> Privacy & Security -> Full Disk Access\n\n![demo](assets/demo.gif)\n\n## What it does\n\n- Scans known cache/log/temp paths across apps and tools in parallel.\n- Lets you preview items and exclude what you want to keep.\n- Labels targets by impact level (safe, moderate, risky).\n- Built-in scans for Homebrew, Docker, and old downloads (brew/docker output or last-modified time filtering).\n\n> Note: Risky categories start selected with all items excluded by default. You must\n> explicitly include items in the preview page to delete them.\n\n## Impact levels\n\n- safe: auto-regenerated caches/logs.\n- moderate: may require re-download or re-login.\n- risky: user data possible; items start excluded.\n- manual: no automatic deletion; shows an app guide.\n\n## Targets\n\n- Total targets: 107.\n- Groups: System 7, Browsers 10, Development 35, Applications 52, Storage 3.\n- Cleanup methods: trash 101, permanent 1, builtin 3, manual 2.\n- Builtins: homebrew, docker, old-downloads (built-in scanners using brew/docker output or last-modified time filtering).\n- Manual: telegram, kakaotalk (no automatic deletion; surfaces large data like chat caches).\n\n## Usage notes\n\n- Full Disk Access helps scan/clean restricted locations.\n- Version check: `mac-cleanup --version`.\n\n<details>\n<summary><strong>Key bindings</strong></summary>\n\nList view:\n\n- `Up`/`Down` or `k`/`j`: move\n- `Space`: select category\n- `a`: select all, `d`: deselect all\n- `Enter` or `p`: preview selection\n- `?`: help, `q`: quit\n\nPreview view:\n\n- `Up`/`Down` or `k`/`j`: move\n- `h`/`l`: previous/next category\n- `Space`: toggle exclude\n- `Enter`: drill into directory\n- `/`: search, `s`: sort, `o`: open in Finder\n- `a`: include all, `d`: exclude all\n- `y`: delete (confirm), `esc`: back\n\nConfirm view:\n\n- `y` or `Enter`: confirm\n- `n` or `esc`: cancel\n\n</details>\n\n## Alternatives\n\n- [mac-cleanup-py](https://github.com/mac-cleanup/mac-cleanup-py) - Python cleanup script for macOS\n- [Mole](https://github.com/tw93/Mole) - Deep clean and optimize your Mac\n\n## License\n\nMIT\n",
      "default_branch": "main"
    },
    "fetched_at": "2026-01-20T02:57:22.951269"
  },
  {
    "basic_info": {
      "name": "skillshare",
      "full_name": "runkids/skillshare",
      "owner": "runkids",
      "description": "ğŸ“š Sync skills to all your AI CLI tools with one command for Claude, Codex, Cursor, Antigravity & more",
      "url": "https://github.com/runkids/skillshare",
      "clone_url": "https://github.com/runkids/skillshare.git",
      "ssh_url": "git@github.com:runkids/skillshare.git",
      "homepage": "",
      "created_at": "2026-01-14T10:07:46Z",
      "updated_at": "2026-01-20T00:23:49Z",
      "pushed_at": "2026-01-19T18:39:02Z"
    },
    "stats": {
      "stars": 168,
      "forks": 13,
      "watchers": 168,
      "open_issues": 1,
      "size": 22848
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 315212,
        "Shell": 15507
      },
      "license": "MIT License",
      "topics": [
        "ai",
        "amp",
        "antigravity",
        "claude-code",
        "cli",
        "codex",
        "cross-machine-sync",
        "cursor",
        "dotfiles",
        "opencode",
        "skills",
        "skills-management",
        "skillshare",
        "team-management"
      ]
    },
    "content": {
      "readme": "<p align=\"center\" style=\"margin-bottom: 0;\">\n  <img src=\".github/assets/logo.png\" alt=\"skillshare\" width=\"280\">\n</p>\n\n<h1 align=\"center\" style=\"margin-top: 0.5rem; margin-bottom: 0.5rem;\">skillshare</h1>\n\n<p align=\"center\">\n  <a href=\"LICENSE\"><img src=\"https://img.shields.io/badge/License-MIT-yellow.svg\" alt=\"License: MIT\"></a>\n  <a href=\"go.mod\"><img src=\"https://img.shields.io/github/go-mod/go-version/runkids/skillshare\" alt=\"Go Version\"></a>\n  <a href=\"https://github.com/runkids/skillshare/releases\"><img src=\"https://img.shields.io/github/v/release/runkids/skillshare\" alt=\"Release\"></a>\n</p>\n\n<p align=\"center\">\n  <strong>Sync skills to all your AI CLI tools with one command</strong><br>\n  Supports Amp, Claude Code, Codex CLI, Crush, Cursor, Gemini CLI, GitHub Copilot, Goose, Letta, Antigravity, OpenCode\n</p>\n\n<p align=\"center\">\n  <img src=\".github/assets/demo.gif\" alt=\"skillshare demo\" width=\"600\">\n</p>\n\n<p align=\"center\">\n  <a href=\"#installation\">Install</a> â€¢\n  <a href=\"#quick-start\">Quick Start</a> â€¢\n  <a href=\"#commands\">Commands</a> â€¢\n  <a href=\"#team-edition\">Team Edition</a> â€¢\n  <a href=\"#reference\">Reference</a> â€¢\n  <a href=\"#faq\">FAQ</a> â€¢\n  <a href=\"#common-issues\">Common Issues</a>\n</p>\n\n> [!NOTE]\n> **[What's New in 0.6.0 â€” Team Edition ğŸ‰](https://github.com/runkids/skillshare/releases/tag/v0.6.0)**\n> - **Tracked Repositories**: `install --track` to clone team skill repos, `update` to keep them current\n> - **Nested Skills**: Organize skills in folders (`work/api/` â†’ `work__api/`)\n> - **Auto-Pruning**: Orphaned symlinks are automatically cleaned on sync\n> - **Collision Detection**: Warns when multiple skills share the same name\n> - [Learn more â†’](#team-edition)\n\n## Why skillshare?\n\n**The problem:** You create a skill in Claude, but need it in Cursor, Codex, and Gemini too. Manually copying? Tedious. What if you update it? Copy again.\n\n**The solution:** One source of truth. Create once, sync everywhere.\n\n```bash\nskillshare pull claude && skillshare sync  # Pull from Claude â†’ sync to all\n```\n\n| What makes it different | |\n|-------------------------|---|\n| ğŸ”„ Bidirectional sync | `pull` from any target, `sync` to all |\n| ğŸŒ Cross-machine sync | `push` / `pull --remote` via git |\n| ğŸ’¾ Backup & restore | Automatic before sync, restore anytime |\n| ğŸ” Diagnostics | `doctor` checks git, broken links, duplicates |\n| ğŸ¤– AI-native | Built-in skill lets your AI manage everything |\n\n## AI-Native Execution\n\nThe built-in [`skillshare` skill](https://github.com/runkids/skillshare/tree/main/skills/skillshare) enables your AI CLI to manage skills directly. Just download the skill folder into your AI CLI's skills directory â€” the binary is auto-downloaded on first use.\n\n```text\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  User: \"sync my skills to all targets\"                      â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                              â”‚\n                              â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  AI reads skillshare skill                                  â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                              â”‚\n                              â–¼\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚  skillshare sync                                            â”‚\nâ”‚  âœ“ Synced 5 skills to claude, codex, cursor                 â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\n> [!TIP]\n> Once installed, just say:\n> - *\"Show my skillshare status\"*\n> - *\"Sync my skills to all targets\"*\n> - *\"Pull skills from Claude and sync everywhere\"*\n> - *\"Install the pdf skill from anthropics/skills\"*\n\n## Installation\n\n### Quick Install\n\n```bash\ncurl -fsSL https://raw.githubusercontent.com/runkids/skillshare/main/install.sh | sh\n```\n\nInstalls to `/usr/local/bin/`. Works on macOS and Linux.\n\n### Homebrew (macOS)\n\n```bash\nbrew install runkids/tap/skillshare\n```\n\n### Uninstall\n\n```bash\nbrew uninstall skillshare              # Homebrew\nsudo rm /usr/local/bin/skillshare      # Manual install\nrm -rf ~/.config/skillshare            # Config & data (optional)\n```\n\n## Quick Start\n\n```bash\nskillshare init --dry-run  # Preview setup\nskillshare init            # Auto-detects installed CLIs, sets up git\nskillshare sync            # Syncs skills to all targets\n```\n\nDone! Your skills are now synced across all AI CLI tools.\n\n## How It Works\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚                  ~/.config/skillshare/skills/               â”‚\nâ”‚         my-skill/   another-skill/   shared-util/           â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                              â”‚\n              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n              â”‚               â”‚               â”‚\n              â–¼               â–¼               â–¼\n       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n       â”‚  Claude   â”‚   â”‚   Codex   â”‚   â”‚  OpenCode â”‚\n       â”‚  skill",
      "default_branch": "main"
    },
    "fetched_at": "2026-01-20T02:57:24.172528"
  }
]