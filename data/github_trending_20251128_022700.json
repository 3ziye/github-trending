[
  {
    "basic_info": {
      "name": "gitlogue",
      "full_name": "unhappychoice/gitlogue",
      "owner": "unhappychoice",
      "description": "A cinematic Git commit replay tool for the terminal, turning your Git history into a living, animated story.",
      "url": "https://github.com/unhappychoice/gitlogue",
      "clone_url": "https://github.com/unhappychoice/gitlogue.git",
      "ssh_url": "git@github.com:unhappychoice/gitlogue.git",
      "homepage": "",
      "created_at": "2025-11-08T21:22:33Z",
      "updated_at": "2025-11-28T02:24:47Z",
      "pushed_at": "2025-11-26T16:42:23Z"
    },
    "stats": {
      "stars": 2578,
      "forks": 47,
      "watchers": 2578,
      "open_issues": 10,
      "size": 81058
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 192482,
        "Tree-sitter Query": 21004,
        "JavaScript": 19194,
        "Shell": 8335,
        "Nix": 2428,
        "Ruby": 1231,
        "Handlebars": 464
      },
      "license": "ISC License",
      "topics": [
        "cli",
        "cli-tool",
        "code-animation",
        "commit-history",
        "developer-tools",
        "git",
        "git-history",
        "git-visualization",
        "productivity",
        "ratatui",
        "rust",
        "screensaver",
        "syntax-highlighting",
        "terminal",
        "terminal-app",
        "terminal-based",
        "terminal-screensaver",
        "tree-sitter",
        "tui",
        "visualization"
      ]
    },
    "content": {
      "readme": "# gitlogue\n\n<a title=\"This tool is Tool of The Week on Terminal Trove, The $HOME of all things in the terminal\" href=\"https://terminaltrove.com/gitlogue/\"><img src=\"https://cdn.terminaltrove.com/media/badges/tool_of_the_week/svg/terminal_trove_tool_of_the_week_green_on_black_bg.svg\" alt=\"Terminal Trove Tool of The Week\" height=\"48\" /></a>\n\n<p align=\"center\">\n  <img src=\"docs/assets/demo.gif\" alt=\"gitlogue demo\" style=\"max-width: 100%; width: 800px;\" />\n</p>\n\nA cinematic Git commit replay tool for the terminal, turning your Git history into a living, animated story.\n\nWatch commits unfold with realistic typing animations, syntax highlighting, and file tree transitions, transforming code changes into a visual experience.\n\n## Installation\n\n### Using Install Script (Recommended)\n\n```bash\ncurl -fsSL https://raw.githubusercontent.com/unhappychoice/gitlogue/main/install.sh | bash\n```\n\n### Using Homebrew\n\n```bash\nbrew install unhappychoice/tap/gitlogue\n```\n\n### Using Cargo\n\n```bash\ncargo install gitlogue\n```\n\n### On Arch Linux\n\n```bash\npacman -S gitlogue\n```\n\n### Using Nix\n\n```bash\n# Run directly without installation\nnix run github:unhappychoice/gitlogue\n\n# Or install to your profile\nnix profile install github:unhappychoice/gitlogue\n\n# For flake-based configurations, add to your inputs:\n# inputs.gitlogue.url = \"github:unhappychoice/gitlogue\";\n# Then use: inputs.gitlogue.packages.${system}.default\n```\n\n### From Source\n\n```bash\ngit clone https://github.com/unhappychoice/gitlogue.git\ncd gitlogue\ncargo install --path .\n```\n\nSee the [Installation Guide](docs/installation.md) for more options and troubleshooting.\n\n## Features\n\nðŸŽ¬ **Commit Replay as Animation** â€” Realistic typing, cursor movement, deletions, and file operations  \nðŸŽ¨ **Tree-sitter Syntax Highlighting** â€” 26 languages supported  \nðŸŒ³ **Project File Tree** â€” Directory structure with change statistics  \nðŸ–¥ï¸ **Screensaver Mode** â€” Endless random commit playback  \nðŸŽ­ **Themes** â€” 9 built-in themes + full customization support  \nâš¡ **Fast & Lightweight** â€” Built with Rust for performance  \n\n## Usage\n\n### Popular Use Cases\n\nðŸ–¥ï¸  **Screensaver** â€” Ambient coding display for your workspace  \nðŸŽ“ **Education** â€” Visualize how code evolved over time  \nðŸ“º **Presentations** â€” Replay real commit histories live  \nðŸŽ¬ **Content Creation** â€” Record demos with VHS or asciinema  \nðŸŽ¨ **Desktop Ricing** â€” A living decoration for your terminal  \nðŸ’¼ **Look Busy Mode** â€” Appear productive during meetings\n\n> [!WARNING]\n> **Not a True Screensaver** â€” gitlogue does not include traditional screensaver functions like power management or screen blanking. It's purely a visual display tool.\n>\n> **OLED Burn-in Risk** â€” Static elements (like the editor background and border lines) may cause burn-in on OLED displays over extended periods. LCD displays are generally safe from this issue.\n\n### Quick Start\n\n```bash\n# Start the cinematic screensaver\ngitlogue\n\n# View a specific commit\ngitlogue --commit abc123\n\n# Replay a range of commits\ngitlogue --commit HEAD~5..HEAD\n\n# Replay commits in chronological order (oldest first)\ngitlogue --order asc\n\n# Loop a specific commit continuously\ngitlogue --commit abc123 --loop\n\n# Loop through a commit range\ngitlogue --commit HEAD~10..HEAD --loop\n\n# Filter commits by author or email (case-insensitive partial match)\ngitlogue --author \"john\"\n\n# Filter commits by date\ngitlogue --after \"2024-01-01\"\ngitlogue --before \"1 week ago\"\ngitlogue --after \"2024-06-01\" --before \"2024-07-01\"\n\n# Use a different theme\ngitlogue --theme dracula\n\n# Adjust typing speed (ms per character)\ngitlogue --speed 20\n\n# Ignore specific file patterns (e.g., notebooks, lock files)\ngitlogue --ignore \"*.ipynb\" --ignore \"poetry.lock\"\n\n# Use an ignore file\ngitlogue --ignore-file .gitlogue-ignore\n\n# List available themes\ngitlogue theme list\n\n# Set default theme\ngitlogue theme set dracula\n\n# Combine options\ngitlogue --commit HEAD~5 --author \"john\" --theme nord --speed 15 --ignore \"*.ipynb\"\n```\n\n## Configuration\n\ngitlogue can be configured via `~/.config/gitlogue/config.toml`.  \nYou can set the default theme, typing speed, and background preferences.\n\nSee the [Configuration Guide](docs/configuration.md) for full options and examples.\n\n## Supported Languages\n\nRust, TypeScript, JavaScript, Python, Go, Ruby, Swift, Kotlin, Java, PHP, C#, C, C++, Haskell, Dart, Scala, Clojure, Zig, Elixir, Erlang, HTML, CSS, JSON, Markdown, YAML, XML\n\n## Documentation\n\n[Installation Guide](docs/installation.md)  \n[Usage Guide](docs/usage.md)  \n[Configuration Guide](docs/configuration.md)  \n[Theme Customization](docs/themes.md)  \n[Contributing Guidelines](docs/CONTRIBUTING.md)  \n[Architecture Overview](docs/ARCHITECTURE.md)\n\n## Related Projects\n\n### Git Visualization & Coding\n\n- [**GitType**](https://github.com/unhappychoice/gittype) - A CLI code-typing game that turns your source code into typing challenges\n\n### Terminal Screensavers\n\n- [**tarts**](https://github.com/oiwn/tarts) - Collection of terminal screensavers in Rust (Matrix, Gam",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-28T02:27:01.288363"
  },
  {
    "basic_info": {
      "name": "Gausian_native_editor",
      "full_name": "gausian-AI/Gausian_native_editor",
      "owner": "gausian-AI",
      "description": "Gausian - Rust-based local video editor for AI video production",
      "url": "https://github.com/gausian-AI/Gausian_native_editor",
      "clone_url": "https://github.com/gausian-AI/Gausian_native_editor.git",
      "ssh_url": "git@github.com:gausian-AI/Gausian_native_editor.git",
      "homepage": "https://gausian.xyz",
      "created_at": "2025-11-04T14:18:16Z",
      "updated_at": "2025-11-27T23:30:00Z",
      "pushed_at": "2025-11-19T07:47:20Z"
    },
    "stats": {
      "stars": 1227,
      "forks": 17,
      "watchers": 1227,
      "open_issues": 2,
      "size": 24794
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 1561015,
        "Objective-C": 22506,
        "Python": 14141,
        "WGSL": 9641,
        "C": 3350,
        "Dockerfile": 265
      },
      "license": "Other",
      "topics": []
    },
    "content": {
      "readme": "<div align=\"center\">\n  <img src=\"apps/desktop/resources/logo_whitebg.png\" width=\"96\" alt=\"Gausian logo\">\n  <h1>Gausian Native Editor</h1>\n  <p><b>Fast, native video editor and preview tool</b> built in Rust with GPU rendering, timeline editing, and local ComfyUI integration.</p>\n\n  <p>\n    <a href=\"#-getting-started\"><b>Get Started</b></a> â€¢\n    <a href=\"#-features\"><b>Features</b></a> â€¢\n    <a href=\"#-architecture\"><b>Architecture</b></a> â€¢\n    <a href=\"#-desktop-app\"><b>Desktop</b></a> â€¢\n    <a href=\"#-cli\"><b>CLI</b></a> â€¢\n    <a href=\"#-decoder--gstreamer-notes\"><b>Decoders</b></a>\n  </p>\n\n  <p>\n    <a href=\"https://gausian.xyz\" target=\"_blank\" rel=\"noopener noreferrer\"><b>Visit gausian.xyz â†—</b></a>\n    &nbsp;â€¢&nbsp;\n    <a href=\"https://discord.gg/JfsKWDBXHT\" target=\"_blank\" rel=\"noopener noreferrer\"><b>Join our Discord â†—</b></a>\n  </p>\n\n  <p>\n    <img alt=\"Rust\" src=\"https://img.shields.io/badge/Rust-stable-orange\">\n    <img alt=\"UI\" src=\"https://img.shields.io/badge/UI-egui%20%2B%20wgpu-8A2BE2\">\n    <img alt=\"Decoders\" src=\"https://img.shields.io/badge/Decode-VideoToolbox%2FGStreamer-2CA5E0\">\n    <img alt=\"Platforms\" src=\"https://img.shields.io/badge/Platforms-macOS%20%7C%20Windows%20%7C%20Linux-4CAF50\">\n    <a href=\"https://discord.gg/JfsKWDBXHT\" target=\"_blank\" rel=\"noopener noreferrer\">\n      <img alt=\"Discord\" src=\"https://img.shields.io/badge/Discord-Join-5865F2?logo=discord&logoColor=white\">\n    </a>\n    <a href=\"https://x.com/maeng313\" target=\"_blank\" rel=\"noopener noreferrer\">\n      <img alt=\"Follow on X\" src=\"https://img.shields.io/badge/X-@maeng313-272a2d?logo=x&logoColor=white\">\n    </a>\n  </p>\n</div>\n\n<hr/>\n\nGausian is a native editor focused on snappy preview, practical timeline tools, and smooth ingest/export. It supports hardware decoding (VideoToolbox on macOS, GStreamer pipelines crossâ€‘platform), a WGPU preview pipeline, and integrates with a local ComfyUI for promptâ€‘based generation via an embedded WebView and autoâ€‘import of outputs. A CLI is included for headless operations.\n\n## ðŸ‘¥ Contributors\n\n[![Contributors](https://contrib.rocks/image?repo=gausian-AI/Gausian_native_editor)](https://github.com/mAengo31)\n\n## âœ¨ Features\n\n- GPU-accelerated preview (WGPU) with YUVâ†’RGB shaders and readback\n- Timeline editing, assets panel, project persistence (SQLite)\n- Local ingest: FFmpeg/ffprobe probing, image/video/audio\n- Exporters: FCPXML (1.9/1.10), FCP7 XML, EDL, JSON\n- Proxy generation via GStreamer (ProRes/NVENC/VAAPI/software)\n- Local ComfyUI: optional embedded WebView and autoâ€‘import from a local ComfyUI output folder\n- Screenplay/Storyboard helpers with LLM providers (OpenAI, etc.)\n- Cross-platform desktop (macOS/Windows/Linux)\n\n## ðŸš€ Getting Started\n\nPrerequisites\n- Rust (stable)\n- FFmpeg/ffprobe on PATH\n- GStreamer for proxy/advanced decode paths (recommended on all platforms; required for some proxies)\n  - macOS (Homebrew): `brew install ffmpeg gstreamer gst-plugins-base gst-plugins-good gst-plugins-bad gst-libav`\n  - Ubuntu/Debian: `sudo apt-get install -y ffmpeg gstreamer1.0-libav gstreamer1.0-plugins-{base,good,bad} gstreamer1.0-tools`\n  - Windows: install a recent GStreamer build (system PATH), FFmpeg\n - ComfyUI (local, optional): required if you want to open the embedded WebView or autoâ€‘import its outputs. Install and run ComfyUI locally (default at http://127.0.0.1:8188). See https://github.com/comfyanonymous/ComfyUI\n\nDesktop app\n```bash\ncargo run --bin desktop\n```\n\nCLI (headless)\n```bash\n# Show commands\ncargo run -p cli -- --help\n```\n\n<!-- Relay section removed: cloud connections not available yet. -->\n\n## ðŸ§© Architecture\n\n- apps/desktop (egui + wgpu)\n  - Timeline, assets, GPU preview, audio engine, export\n  - ComfyUI integration (local only): optional embedded WebView and autoâ€‘import\n- apps/comfywebview\n  - Minimal native WebView window for ComfyUI\n- crates/*\n  - timeline â€” graph, tracks, commands\n  - project â€” SQLite DB, migrations, asset/proxy/job tables\n  - media-io â€” probe/export helpers, waveforms, encoders\n  - renderer â€” WGPU renderer and WGSL shaders\n  - exporters â€” FCPXML/FCP7/EDL/JSON\n  - plugin-host â€” WASM/Python stubs\n  - native-decoder â€” VideoToolbox (macOS) + optional GStreamer backend\n  - cli â€” import/export/convert/analyze/new/encoders\n\n<details>\n  <summary>Project Structure (click to expand)</summary>\n\n<pre><code>apps/\n  desktop/          # egui UI, preview, decode, export\n  comfywebview/     # lightweight native WebView for ComfyUI\n\ncrates/\n  timeline/         # timeline data structures and commands\n  project/          # SQLite DB + migrations\n  media-io/         # probe, waveforms, proxy helpers\n  renderer/         # WGPU renderer & shaders (WGSL)\n  exporters/        # FCPXML/FCP7/EDL/JSON exporters\n  plugin-host/      # plugin runtime stubs (WASM/Python)\n  native-decoder/   # VideoToolbox & GStreamer backend\n  cli/              # headless commands\n\nformats/            # JSON specs (screenplay/storyboard)\n</code></pre>\n</details>\n\n## ðŸ–¥ Desktop App\n\nBuild & run",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-28T02:27:02.445842"
  },
  {
    "basic_info": {
      "name": "install-nothing",
      "full_name": "buyukakyuz/install-nothing",
      "owner": "buyukakyuz",
      "description": "A terminal application that simulates installing things but doesn't actually install anything",
      "url": "https://github.com/buyukakyuz/install-nothing",
      "clone_url": "https://github.com/buyukakyuz/install-nothing.git",
      "ssh_url": "git@github.com:buyukakyuz/install-nothing.git",
      "homepage": "",
      "created_at": "2025-11-17T22:03:19Z",
      "updated_at": "2025-11-27T19:13:36Z",
      "pushed_at": "2025-11-26T18:49:04Z"
    },
    "stats": {
      "stars": 949,
      "forks": 22,
      "watchers": 949,
      "open_issues": 6,
      "size": 3059
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 137535,
        "Dockerfile": 461
      },
      "license": "MIT License",
      "topics": [
        "cli",
        "rust",
        "simulation",
        "terminal"
      ]
    },
    "content": {
      "readme": "# install-nothing\n\nA terminal application that simulates installing things. It doesn't actually install anything.\n\n[![asciicast](https://asciinema.org/a/757039.svg)](https://asciinema.org/a/757039)\n\n## Usage\n\n```bash\ncargo build --release\ncargo run --release\n```\n\nPress Ctrl+C to stop.\n\n### Pick what to install\n\n```bash\n# Install specific stages\ncargo run --release -- deno\n\n# Install everything (default)\ncargo run --release -- --all\n```\n\nSee available stages:\n```bash\ncargo run --release -- --help\n```\n\n\n## Docker\n\nBuild and run:\n\n```bash\ndocker build -t install-nothing .\ndocker run -it --rm --init install-nothing\n```\n\n## License\n\nDo whatever you want with it. Well, except for movies. If you use this in a movie, credit me or something.\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-28T02:27:03.923670"
  },
  {
    "basic_info": {
      "name": "moss-kernel",
      "full_name": "hexagonal-sun/moss-kernel",
      "owner": "hexagonal-sun",
      "description": "Rust Linux-compatible kernel",
      "url": "https://github.com/hexagonal-sun/moss-kernel",
      "clone_url": "https://github.com/hexagonal-sun/moss-kernel.git",
      "ssh_url": "git@github.com:hexagonal-sun/moss-kernel.git",
      "homepage": null,
      "created_at": "2025-11-20T14:54:10Z",
      "updated_at": "2025-11-27T23:13:12Z",
      "pushed_at": "2025-11-27T18:24:03Z"
    },
    "stats": {
      "stars": 832,
      "forks": 31,
      "watchers": 832,
      "open_issues": 11,
      "size": 1109
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 813514,
        "Assembly": 7733,
        "Shell": 2991,
        "Linker Script": 1161,
        "RenderScript": 1
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# moss\n\n![Architecture](https://img.shields.io/badge/arch-aarch64-blue)\n![Language](https://img.shields.io/badge/language-Rust-orange)\n![License](https://img.shields.io/badge/license-MIT-yellow)\n\n![Moss Boot Demo](etc/moss_demo.gif)\n\n**moss** is a Unix-like, Linux-compatible kernel written in Rust and Aarch64\nassembly.\n\nIt features a modern, asynchronous core, a modular architecture abstraction\nlayer, and binary compatibility with Linux userspace applications (currently\ncapable of running most BusyBox commands).\n\n## Features\n\n### Architecture & Memory\n* Full support for aarch64.\n* A well-defined HAL allowing for easy porting to other architectures (e.g.,\n  x86_64, RISC-V).\n* Memory Management:\n    * Full MMU enablement and page table management.\n    * Copy-on-Write (CoW) pages.\n    * Safe copy to/from userspace async functions.\n    * Kernel and userspace page fault management.\n    * Buddy allocator for physical addresses and `smalloc` for boot allocations\n      and tracking memory reservations.\n\n### Async Core\nOne of the defining features of `moss` is its usage of Rust's `async/await`\nmodel within the kernel context:\n* All non-trivial system calls are written as `async` functions, sleep-able\n  functions are prefixed with `.await`.\n* The compiler enforces that spinlocks cannot be held over sleep points,\n  eliminating a common class of kernel deadlocks.\n\n###  Process Management\n* Full task management including scheduling and task migration via IPIs.\n* Currently implements [51 Linux syscalls](./etc/syscalls_linux_aarch64.md); sufficient to execute most BusyBox\n  commands.\n* Advanced forking capabilities via `clone()`.\n* Process and thread signal delivery and raising support.\n\n### VFS & Filesystems\n* Virtual File System with full async abstractions.\n* Drivers:\n    * Ramdisk block device implementation.\n    * FAT32 filesystem driver (ro).\n    * `devtmpfs` driver for kernel character device access.\n\n## `libkernel` & Testing\n`moss` is built on top of `libkernel`, a utility library designed to be\narchitecture-agnostic. This allows logic to be tested on a host machine (e.g.,\nx86) before running on bare metal.\n\n* Address Types: Strong typing for `VA` (Virtual), `PA` (Physical), and `UA`\n  (User) addresses.\n* Containers: `VMA` management, generic page-based ring buffer (`kbuf`), and\n  waker sets.\n* Sync Primitives: `spinlock`, `mutex`, `condvar`, `per_cpu`.\n* Test Suite: A comprehensive suite of 230+ tests ensuring functionality across\n  architectures (e.g., validating Aarch64 page table parsing logic on an x86\n  host).\n\n## Building and Running\n\n### Prerequisites\nYou will need QEMU for aarch64 emulation and dosfstools to create the virtual file system.\n\n```bash\nsudo apt install qemu-system-aarch64 dosfstools\n```\n\nAdditionally you will need a version of the [aarch64-none-elf](https://developer.arm.com/Tools%20and%20Software/GNU%20Toolchain) toolchain installed.\n\n#### Any OS\nTo install aarch64-none-elf on any os, download the correct release of `aarch64-none-elf` onto your computer, unpack it, then export the `bin` folder to path.\n\n#### NixOS\n\nRun the following command\n\n```bash\nnix shell nixpkgs#pkgsCross.aarch64-embedded.stdenv.cc nixpkgs#pkgsCross.aarch64-embedded.stdenv.cc.bintools\n```\n\n### Preparing the image\n\nFirst, run the following script to prepare the binaries for the image:\n```bash\n./scripts/build-deps.sh\n```\n\nThis will download and build the necessary dependencies for the kernel and put them\ninto the `build` directory.\n\nOnce that is done, you can create the image using the following command:\n```bash\nsudo ./scripts/create-image.sh\n```\n\nThis will create an image file named `moss.img` in the root directory of the project,\nformat it as VFAT 32 and create the necessary files and directories for the kernel.\n\nThis script needs to run with sudo to mount the image through a loop device,\nwhich is required to properly create the image for the kernel to work.\n\n### Running via QEMU\n\nTo build the kernel and launch it in QEMU:\n\n``` bash\ncargo run --release\n```\n\n\n### Running the Test Suite\nBecause `libkernel` is architecturally decoupled, you can run the logic tests on\nyour host machine:\n\n``` bash\ncargo test -p libkernel --target x86_64-unknown-linux-gnu\n```\n\n\n### Roadmap & Status\n\nmoss is under active development. Current focus areas include:\n\n* Basic Linux Syscall Compatibility (Testing through BusyBox).\n* Networking Stack: TCP/IP implementation.\n* Scheduler Improvements: Task load balancing.\n* A fully read/write capable filesystem driver (e.g., ext2/4).\n* Expanding coverage beyond the current 49 calls.\n\n## Contributing\n\nContributions are welcome! Whether you are interested in writing a driver,\nporting to x86, or adding syscalls.\n\n## License\nDistributed under the MIT License. See LICENSE for more information.\n",
      "default_branch": "master"
    },
    "fetched_at": "2025-11-28T02:27:05.113139"
  },
  {
    "basic_info": {
      "name": "pipedash",
      "full_name": "hcavarsan/pipedash",
      "owner": "hcavarsan",
      "description": "A desktop app for managing CI/CD pipelines from multiple providers",
      "url": "https://github.com/hcavarsan/pipedash",
      "clone_url": "https://github.com/hcavarsan/pipedash.git",
      "ssh_url": "git@github.com:hcavarsan/pipedash.git",
      "homepage": "",
      "created_at": "2025-10-31T00:02:21Z",
      "updated_at": "2025-11-27T16:02:47Z",
      "pushed_at": "2025-11-16T00:49:29Z"
    },
    "stats": {
      "stars": 820,
      "forks": 50,
      "watchers": 820,
      "open_issues": 13,
      "size": 4924
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 564220,
        "TypeScript": 352043,
        "JavaScript": 5450,
        "Python": 3709,
        "CSS": 3117,
        "HTML": 582
      },
      "license": "GNU General Public License v3.0",
      "topics": [
        "buildkite",
        "cicd",
        "devops",
        "devtools",
        "gitlab",
        "jenkins",
        "sre",
        "tekton"
      ]
    },
    "content": {
      "readme": "<div align=\"center\">\n  <br>\n  <img src=\"./app-icon.png\" width=\"102px\" alt=\"Pipedash Logo\" />\n  <h1>Pipedash</h1>\n  <p>A desktop app for managing CI/CD pipelines from multiple providers </p>\n\n</div>\n\n<p align=\"center\">\n<div align=\"center\">\n<img src=\"./public/pipedashbg.png\" alt=\"Pipedash Screenshot\" style=\"box-shadow: 0 10px 30px rgba(0, 0, 0, 0.3); border-radius: 8px;\"/>\n</div>\n</p>\n\n> **[WIP]** This is an work-in-progress project. It works for basic use cases but hasn't been thoroughly tested. Things might break, APIs might change, and there are probably bugs. Tested primarily on macOS â€“ not sure if it works properly on Linux and Windows due to webview differences.\n\n## About\n\nPipedash aggregates CI/CD pipelines from multiple providers into a single desktop interface. Instead of switching between GitHub Actions, GitLab CI, Buildkite, Jenkins, and Tekton dashboards, view everything in one place.\n\nBuilt with Tauri, Rust, React, and TypeScript.\n\n## Why\n\nMost development teams use multiple CI/CD platforms over time. Open source projects often use GitHub Actions, internal services might run on GitLab CI or Buildkite, Kubernetes-native workloads use Tekton, and there's usually some Jenkins instance handling legacy systems. Checking everything means opening multiple tabs and manually refreshing.\n\nThis tool pulls pipeline data from different providers and shows it together.\n\n## Supported Providers\n\n- GitHub Actions\n- GitLab CI\n- Buildkite\n- Jenkins\n- Tekton CD\n- ArgoCD\n\nThe plugin architecture allows adding more providers.\n\n## What It Does\n\nThe app polls configured providers and displays pipelines organized by repository and workflow. Background refresh runs every X seconds (configurable per provider). When pipeline status changes, the UI updates automatically.\n\nMain capabilities:\n- View pipeline status across multiple providers\n- Browse run history with commit info and execution times\n- Trigger workflows with parameters dynamically loaded from each provider\n- Re-run previous executions with the same parameters\n- Cancel running builds\n- Multiple instances of the same provider type\n\nWhen triggering or re-running a workflow, the app fetches available parameters directly from the provider plugin (workflow inputs for GitHub Actions, pipeline variables for GitLab CI, build parameters for Jenkins and Buildkite, etc.) and displays them in a form.\n\n**Privacy First**\n\nEverything runs locally on the machine. The app only connects to configured CI/CD providers â€“ no analytics, telemetry, or third-party services. Pipeline data is stored in a local SQLite database and API tokens are encrypted in the system keyring.\n\n## Installation\n\nDownload the latest release for your platform from the [releases page](https://github.com/hcavarsan/pipedash/releases).\n\nAvailable for macOS, Windows, and Linux.\n\n## Setup\n\nLaunch the app and add a provider via the sidebar. Each provider needs an API token:\n\n**GitHub Actions**: Personal Access Token with `repo` and `workflow` scopes. Optionally set a custom base URL for GitHub Enterprise.\n\n**GitLab CI**: Personal Access Token with `api` scope. Supports both GitLab.com and self-hosted instances.\n\n**Buildkite**: API Access Token with read permissions and the organization slug.\n\n**Jenkins**: API token, username, and server URL.\n\n**Tekton CD**: Kubernetes config file path and context. Automatically detects namespaces with Tekton pipelines.\n\n**ArgoCD**: Server URL and authentication token. Optionally filter by Git organizations. Monitors application sync status, health, and deployment history.\n\nAfter adding a provider, the app validates credentials and fetches available repositories. Select which ones to monitor and save. Pipelines will appear in the main view and refresh automatically.\n\n## How It Works\n\n**Store**\n\nProvider configurations are stored in a local SQLite database. Tokens are kept separate in the system keyring.\n\nEach provider has its own refresh interval (default: 30 seconds), adjustable based on API rate limits.\n\n\n\n**Plugin System**\n\nEach CI/CD provider is implemented as a plugin that exposes a common interface. The core application doesn't know the specifics of how GitHub Actions, GitLab CI, Buildkite, Jenkins, Tekton, or ArgoCD workâ€”it just calls standard methods like `fetch_pipelines()` or `trigger_pipeline()` and the plugin handles the details.\n\nPlugins are compiled into the application at build time, not loaded dynamically at runtime. This keeps things simpler and avoids the security concerns of runtime plugin loading.\n\nWhen the app starts, it loads cached pipeline data from SQLite immediately. In the background, a refresh loop polls each provider's API and updates the cache when changes are detected. The frontend listens for events and re-renders when new data arrives.\n\n## Adding Providers\n\nTo add support for a new CI/CD platform, create a new crate in `crates/pipedash-plugin-{name}/` and implement the `Plugin` trait from `pipedash-plugin-api`. The trait defines methods for fetching pi",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-28T02:27:06.308451"
  },
  {
    "basic_info": {
      "name": "xleak",
      "full_name": "bgreenwell/xleak",
      "owner": "bgreenwell",
      "description": "A fast terminal Excel viewer with an interactive TUI. Features full-text search, formula display, lazy loading for large files, clipboard support, and export to CSV/JSON. Built with Rust and ratatui.",
      "url": "https://github.com/bgreenwell/xleak",
      "clone_url": "https://github.com/bgreenwell/xleak.git",
      "ssh_url": "git@github.com:bgreenwell/xleak.git",
      "homepage": "",
      "created_at": "2025-11-06T12:51:31Z",
      "updated_at": "2025-11-28T01:45:56Z",
      "pushed_at": "2025-11-24T20:32:43Z"
    },
    "stats": {
      "stars": 810,
      "forks": 33,
      "watchers": 810,
      "open_issues": 9,
      "size": 1218
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 123888,
        "Nix": 4379
      },
      "license": "MIT License",
      "topics": [
        "cli",
        "excel",
        "ratatui",
        "rust",
        "rust-lang",
        "spreadsheet",
        "spreadsheets",
        "tui"
      ]
    },
    "content": {
      "readme": "# xleak <img src=\"assets/logo.jpg\" align=\"right\" width=\"120\" />\n\n[![CI](https://img.shields.io/github/actions/workflow/status/bgreenwell/xleak/ci.yml?style=for-the-badge)](https://github.com/bgreenwell/xleak/actions/workflows/ci.yml)\n[![Crates.io](https://img.shields.io/crates/v/xleak.svg?style=for-the-badge&color=%23107C41)](https://crates.io/crates/xleak)\n[![License: MIT](https://img.shields.io/badge/License-MIT-%232196F3.svg?style=for-the-badge)](https://opensource.org/licenses/MIT)\n[![Rust](https://img.shields.io/badge/rust-1.70%2B-%23D34516.svg?style=for-the-badge&logo=rust&logoColor=white)](https://www.rust-lang.org/)\n\n> Expose Excel files in your terminal - no Microsoft Excel required!\n\nInspired by [doxx](https://github.com/bgreenwell/doxx), `xleak` brings Excel spreadsheets to your command line with beautiful rendering, powerful export capabilities, and a feature-rich interactive TUI.\n\n![xleak demo](assets/demo.gif)\n\n## Features\n\n### Core Functionality\n- **Beautiful terminal rendering** with formatted tables\n- **Interactive TUI mode** - full keyboard navigation with ratatui\n- **Smart data type handling** - numbers right-aligned, text left-aligned, booleans centered\n- **Multi-sheet support** - seamlessly navigate between sheets (Tab/Shift+Tab)\n- **Multiple export formats** - CSV, JSON, plain text\n- **Blazing fast** - powered by `calamine`, the fastest Excel parser in Rust\n- **Multiple file formats** - supports `.xlsx`, `.xls`, `.xlsm`, `.xlsb`, `.ods`\n\n### Interactive TUI Features\n- **Full-text search** - search across all cells with `/`, navigate with `n`/`N`\n- **Clipboard support** - copy cells (`c`) or entire rows (`C`) to clipboard\n- **Formula display** - view Excel formulas in cell detail view (Enter key)\n- **Jump to row/column** - press `Ctrl+G` to jump to any cell (e.g., `A100`, `500`, `10,5`)\n- **Large file optimization** - lazy loading for files with 1000+ rows\n- **Progress indicators** - real-time feedback for long operations\n- **Visual cell highlighting** - current row, column, and cell clearly marked\n\n## Installation\n\n### Via Homebrew (macOS/Linux)\n```bash\nbrew tap bgreenwell/xleak\nbrew install xleak\n```\n\n### Via Cargo\n```bash\ncargo install xleak\n```\n\n### Via Nix\n```bash\n# Run directly\nnix run github:bgreenwell/xleak -- file.xlsx\n\n# Install with flakes\nnix profile install github:bgreenwell/xleak\n\n# Or enter dev shell\nnix develop github:bgreenwell/xleak\n```\n\n### Pre-built Binaries\nDownload pre-built binaries for Windows, Linux, and macOS from the [latest release](https://github.com/bgreenwell/xleak/releases/latest).\n\n### Build from Source\n```bash\ngit clone https://github.com/bgreenwell/xleak.git\ncd xleak\ncargo install --path .\n```\n\n## Usage\n\n### Interactive TUI Mode (Recommended)\n```bash\n# Launch interactive viewer\nxleak quarterly-report.xlsx -i\n\n# Start on a specific sheet\nxleak report.xlsx --sheet \"Q3 Results\" -i\n\n# View formulas by default\nxleak data.xlsx -i --formulas\n```\n\n**TUI Keyboard Shortcuts:**\n- `â†‘ â†“ â† â†’` - Navigate cells\n- `Enter` - View cell details (including formulas)\n- `/` - Search across all cells\n- `n` / `N` - Jump to next/previous search result\n- `Ctrl+G` - Jump to specific row/cell (e.g., `100`, `A50`, `10,5`)\n- `c` - Copy current cell to clipboard\n- `C` - Copy entire row to clipboard\n- `Tab` / `Shift+Tab` - Switch between sheets\n- `?` - Show help\n- `q` - Quit\n\n### Non-Interactive Mode\n\n#### View a spreadsheet\n```bash\nxleak quarterly-report.xlsx\n```\n\n#### View a specific sheet\n```bash\n# By name\nxleak report.xlsx --sheet \"Q3 Results\"\n\n# By index (1-based)\nxleak report.xlsx --sheet 2\n```\n\n#### Limit displayed rows\n```bash\n# Show only first 20 rows\nxleak large-file.xlsx -n 20\n\n# Show all rows\nxleak file.xlsx -n 0\n```\n\n#### Export data\n```bash\n# Export to CSV\nxleak data.xlsx --export csv > output.csv\n\n# Export to JSON\nxleak data.xlsx --export json > output.json\n\n# Export as plain text (tab-separated)\nxleak data.xlsx --export text > output.txt\n```\n\n#### Combine options\n```bash\n# Export specific sheet as CSV\nxleak workbook.xlsx --sheet \"Sales\" --export csv > sales.csv\n```\n\n## Examples\n\n```bash\n# Launch interactive viewer\nxleak quarterly-report.xlsx -i\n\n# Quick preview in non-interactive mode\nxleak quarterly-report.xlsx\n\n# See specific sheet with limited rows\nxleak financial-data.xlsx --sheet \"Summary\" -n 10\n\n# Interactive mode with formulas visible\nxleak data.xlsx -i --formulas\n\n# Export all data from a sheet\nxleak survey-results.xlsx --sheet \"Responses\" --export csv -n 0\n```\n\n## Configuration\n\nxleak supports configuration via a TOML file for persistent settings like default theme and keybindings.\n\n### Config File Location\n\n**Default:** `~/.config/xleak/config.toml` (or `$XDG_CONFIG_HOME/xleak/config.toml`)\n\n**Platform-specific fallback locations:**\n- **macOS:** `~/Library/Application Support/xleak/config.toml`\n- **Linux:** `~/.config/xleak/config.toml` (same as XDG)\n- **Windows:** `%APPDATA%\\xleak\\config.toml`\n\n**Custom:** Use `--config` flag to specify a different location:",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-28T02:27:07.494131"
  },
  {
    "basic_info": {
      "name": "FreeMDU",
      "full_name": "medusalix/FreeMDU",
      "owner": "medusalix",
      "description": "Open hardware and software tools for communicating with Miele appliances via their optical diagnostic interface",
      "url": "https://github.com/medusalix/FreeMDU",
      "clone_url": "https://github.com/medusalix/FreeMDU.git",
      "ssh_url": "git@github.com:medusalix/FreeMDU.git",
      "homepage": null,
      "created_at": "2025-11-15T18:09:24Z",
      "updated_at": "2025-11-27T14:33:21Z",
      "pushed_at": "2025-11-20T12:14:20Z"
    },
    "stats": {
      "stars": 454,
      "forks": 14,
      "watchers": 454,
      "open_issues": 0,
      "size": 360
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 201484
      },
      "license": "Apache License 2.0",
      "topics": []
    },
    "content": {
      "readme": "# FreeMDU [![Build Status](https://img.shields.io/github/actions/workflow/status/medusalix/FreeMDU/ci.yml)](https://github.com/medusalix/FreeMDU/actions/workflows/ci.yml)\n\n<p align=\"center\">\n  <img src=\"demo.gif\" alt=\"Demo\">\n</p>\n\nThe FreeMDU project provides open hardware and software tools for communicating with Miele appliances via their optical diagnostic interface. It serves as a free and open alternative to the proprietary **Miele Diagnostic Utility (MDU)** software, which is only available to registered service technicians.\n\nMost Miele devices manufactured after 1996 include an optical infrared-based diagnostic interface, hidden behind one of the indicator lights on the front panel. On older appliances, this interface is marked by a **Program Correction (PC)** label.\n\nUntil now, communication with this interface required an expensive infrared adapter sold exclusively by Miele, along with their closed-source software. The goal of FreeMDU is to make this interface accessible to everyone for diagnostic and home automation purposes.\n\nThe project is split into three main components:\n\n- [**Protocol**](protocol): core protocol library and device implementations\n- [**TUI**](tui): terminal-based device diagnostic and testing tool\n- [**Home**](home): communication adapter firmware with MQTT integration for Home Assistant\n\nMore details about the proprietary diagnostic interface and the reverse-engineering process behind this project can be found in this [**blog post**](https://medusalix.github.io/posts/miele-interface).\n\n> [!CAUTION]\n> This project is highly experimental and can cause permanent damage to your Miele devices if not used responsibly. Proceed at your own risk.\n\n## Supported devices\n\nWhen a connection is established via the diagnostic interface, the appliance responds with its **software ID**, a 16-bit number that uniquely identifies the firmware version running on the device's microcontroller. However, this ID does not directly correspond to a specific model or board type, so it's impossible to provide a comprehensive list of supported models.\n\nThe following table lists the software IDs and device/board combinations that have been confirmed to work with FreeMDU:\n\n| Software ID | Device         | Board      | Microcontroller           | Optical interface location   | Status             |\n|-------------|----------------|------------|---------------------------|------------------------------|--------------------|\n| 360         | Bare board     | EDPW 223-A | Mitsubishi M38078MC-065FP | *Check inlet (PC)* indicator | ðŸŸ¢ Fully supported |\n| 419         | Bare board     | EDPW 206   | Mitsubishi M37451MC-804FP | *Check inlet (PC)* indicator | ðŸŸ¢ Fully supported |\n| 605         | G 651 I PLUS-3 | EGPL 542-C | Mitsubishi M38027M8       | *Salt (PC)* indicator        | ðŸŸ¢ Fully supported |\n| 629         | W 2446         | EDPL 126-B | Mitsubishi M38079MF-308FP | *Check inlet (PC)* indicator | ðŸŸ¢ Fully supported |\n\nIf your appliance is not listed here but has a model number similar to one of the above, it might already be compatible. In all other cases, determining the **software ID** is the first step toward adding support for new devices.\n\nDetails for adding support for new devices will be provided soon.\n\n## Getting started\n\nBefore using any FreeMDU components, make sure you have the [Rust toolchain](https://rust-lang.org/tools/install) installed on your system.\n\nNext, you'll need to build a [communication adapter](home/README.md#getting-started) to interface with your Miele device. Once the adapter is ready, choose the appropriate use case from the options below:\n\n### Device diagnostics and testing\n\nIf you want to repair or test your appliance:\n\n1. Flash the [home](home) firmware in **bridge mode** onto your communication adapter and attach it to your device.\n\n2. Run the [TUI](tui) application on your desktop computer.\n\n### Integration into home automation systems\n\nIf you want to integrate your appliance into **Home Assistant** or another home automation system:\n\n1. Flash the [home](home) firmware in **standalone mode** onto your communication adapter and attach it to your device.\n\n### Building custom tools\n\nIf you want to develop your own software to communicate with Miele devices:\n\n1. Flash the [home](home) firmware in **bridge mode** onto your communication adapter and attach it to your device.\n\n2. Use the [protocol](protocol) crate to implement your custom software.\n\n## Disclaimer\n\nThis is an independent, open-source project and is **not affiliated with, endorsed by, or sponsored by Miele & Cie. KG** or its affiliates. All product names and trademarks are the property of their respective owners. References to Miele appliances are for descriptive purposes only and do not imply any association with Miele.\n\n## License\n\nLicensed under either of\n\n- Apache License, Version 2.0 ([LICENSE-APACHE](LICENSE-APACHE) or <http://www.apache.org/licenses/LICENSE-2.0>)\n- MIT license ([LICENSE-MIT](LICENSE-MIT) or <http://",
      "default_branch": "master"
    },
    "fetched_at": "2025-11-28T02:27:08.671176"
  },
  {
    "basic_info": {
      "name": "claude-code-mux",
      "full_name": "9j/claude-code-mux",
      "owner": "9j",
      "description": "High-performance AI routing proxy built in Rust with automatic failover, priority-based routing, and    support for 15+ providers (Anthropic, OpenAI, Cerebras, Minimax, Kimi, etc.)",
      "url": "https://github.com/9j/claude-code-mux",
      "clone_url": "https://github.com/9j/claude-code-mux.git",
      "ssh_url": "git@github.com:9j/claude-code-mux.git",
      "homepage": "",
      "created_at": "2025-11-16T17:19:45Z",
      "updated_at": "2025-11-27T15:12:32Z",
      "pushed_at": "2025-11-19T19:37:08Z"
    },
    "stats": {
      "stars": 376,
      "forks": 36,
      "watchers": 376,
      "open_issues": 6,
      "size": 801
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 251634,
        "HTML": 211986,
        "Shell": 3401
      },
      "license": "MIT License",
      "topics": [
        "ai",
        "anthropic",
        "claude-code",
        "claude-code-router",
        "openai"
      ]
    },
    "content": {
      "readme": "# Claude Code Mux\n\n[![CI](https://github.com/9j/claude-code-mux/workflows/CI/badge.svg)](https://github.com/9j/claude-code-mux/actions)\n[![Latest Release](https://img.shields.io/github/v/release/9j/claude-code-mux)](https://github.com/9j/claude-code-mux/releases/latest)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Rust](https://img.shields.io/badge/rust-1.70%2B-orange.svg)](https://www.rust-lang.org/)\n[![GitHub Stars](https://img.shields.io/github/stars/9j/claude-code-mux?style=social)](https://github.com/9j/claude-code-mux)\n[![GitHub Forks](https://img.shields.io/github/forks/9j/claude-code-mux?style=social)](https://github.com/9j/claude-code-mux/fork)\n\nOpenRouter met Claude Code Router. They had a baby.\n\n---\n\nNow your coding assistant can use GLM 4.6 for one task, Kimi K2 Thinking for another, and Minimax M2 for a third. All in the same session. When your primary provider goes down, it falls back to your backup automatically.\n\nâš¡ï¸ **Multi-model intelligence with provider resilience**\n\nA lightweight, Rust-powered proxy that provides intelligent model routing, provider failover, streaming support, and full Anthropic API compatibility for Claude Code.\n\n```\nClaude Code â†’ Claude Code Mux â†’ Multiple AI Providers\n              (Anthropic API)    (OpenAI/Anthropic APIs + Streaming)\n```\n\n## Table of Contents\n\n- [Key Features](#key-features)\n- [Installation](#installation)\n- [Quick Start](#quick-start)\n- [Screenshots](#screenshots)\n- [Usage Guide](#usage-guide)\n- [Routing Logic](#routing-logic)\n- [Configuration Examples](#configuration-examples)\n- [Supported Providers](#supported-providers)\n- [Advanced Features](#advanced-features)\n- [CLI Usage](#cli-usage)\n- [Troubleshooting](#troubleshooting)\n- [FAQ](#faq)\n- [Performance](#performance)\n- [Why Choose Claude Code Mux?](#why-choose-claude-code-mux)\n- [Documentation](#documentation)\n- [Changelog](#changelog)\n- [Contributing](#contributing)\n- [License](#license)\n\n## Key Features\n\n### ðŸŽ¯ Core Features\n- âœ¨ **Modern Admin UI** - Beautiful web interface with auto-save and URL-based navigation\n- ðŸ” **OAuth 2.0 Support** - FREE access for Claude Pro/Max, ChatGPT Plus/Pro, and Google AI Pro/Ultra\n- ðŸ§  **Intelligent Routing** - Auto-route by task type (websearch, reasoning, background, default)\n- ðŸ”„ **Provider Failover** - Automatic fallback to backup providers with priority-based routing\n- ðŸŒŠ **Streaming Support** - Full Server-Sent Events (SSE) streaming for real-time responses\n- ðŸŒ **Multi-Provider Support** - 18+ providers including OpenAI, Anthropic, Google Gemini/Vertex AI, Groq, ZenMux, etc.\n- âš¡ï¸ **High Performance** - ~5MB RAM, <1ms routing overhead (Rust powered)\n- ðŸŽ¯ **Unified API** - Full Anthropic Messages API compatibility\n\n### ðŸš€ Advanced Features\n- ðŸ”€ **Auto-mapping** - Regex-based model name transformation before routing (e.g., transform all `claude-*` to default model)\n- ðŸŽ¯ **Background Detection** - Configurable regex patterns for background task detection\n- ðŸ¤– **Multi-Agent Support** - Dynamic model switching via `CCM-SUBAGENT-MODEL` tags\n- ðŸ“Š **Live Testing** - Built-in test interface to verify routing and responses\n- âš™ï¸ **Centralized Settings** - Dedicated Settings tab for regex pattern management\n\n## Screenshots\n\n<details>\n<summary>ðŸ“¸ Click to view screenshots (5 images)</summary>\n\n### Overview Dashboard\n![Dashboard showing router configuration, providers, and models summary](docs/images/dashboard.png)\n*Main dashboard with router configuration and provider management*\n\n### Provider Management\n![Provider management interface with add/edit capabilities](docs/images/providers.png)\n*Add and manage multiple AI providers with automatic format translation*\n\n### Model Mappings with Fallback\n![Model configuration with priority-based fallback routing](docs/images/models.png)\n*Configure models with priority-based fallback routing*\n\n### Router Configuration\n![Router configuration interface for intelligent routing rules](docs/images/routing.png)\n*Set up intelligent routing rules for different task types*\n\n### Live Testing Interface\n![Testing interface for verifying configuration with real API calls](docs/images/testing.png)\n*Test your configuration with live API requests and responses*\n\n</details>\n\n## Supported Providers\n\n**18+ AI providers with automatic format translation, streaming, and failover:**\n\n- **Anthropic-compatible**: Anthropic (API Key/OAuth), ZenMux, z.ai, Minimax, Kimi\n- **OpenAI-compatible**: OpenAI, OpenRouter, Groq, Together, Fireworks, Deepinfra, Cerebras, Moonshot, Nebius, NovitaAI, Baseten\n- **Google AI**: Gemini (OAuth/API Key), Vertex AI (GCP ADC)\n\n<details>\n<summary>ðŸ“‹ View full provider details</summary>\n\n### Anthropic-Compatible (Native Format)\n- **Anthropic** - Official Claude API provider (supports both API Key and OAuth)\n- **Anthropic (OAuth)** - ðŸ†“ **FREE for Claude Pro/Max subscribers** via OAuth 2.0\n- **ZenMux** - Unified API gateway (Sunnyvale, CA)\n- **z.ai** - China-based, GLM models\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-28T02:27:09.831657"
  },
  {
    "basic_info": {
      "name": "pplx-garden",
      "full_name": "perplexityai/pplx-garden",
      "owner": "perplexityai",
      "description": "Perplexity open source garden for inference technology",
      "url": "https://github.com/perplexityai/pplx-garden",
      "clone_url": "https://github.com/perplexityai/pplx-garden.git",
      "ssh_url": "git@github.com:perplexityai/pplx-garden.git",
      "homepage": null,
      "created_at": "2025-11-04T17:35:34Z",
      "updated_at": "2025-11-27T20:17:13Z",
      "pushed_at": "2025-11-20T06:25:43Z"
    },
    "stats": {
      "stars": 274,
      "forks": 20,
      "watchers": 274,
      "open_issues": 1,
      "size": 178
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 431241,
        "Python": 139522,
        "Cuda": 81745,
        "C++": 10733,
        "Dockerfile": 2142,
        "C": 543,
        "Shell": 529
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "pplx-garden\n===========\n\nPerplexity AI open source garden for inference technology\n\n## Research Paper\n\n[RDMA Point-to-Point Communication for LLM Systems](https://arxiv.org/abs/2510.27656)\n\n## P2P MoE dispatch/combine kernel\n\n* Support both NVIDIA ConnectX-7 and AWS EFA (potentially other RDMA NICs as wel)\n* Use NVLink for intra-node data transfer and RDMA for inter-node\n* Optimize for decode, while also support prefill\n* Split send and recv stages for both dispatch and combine, allow micro-batching\n* SM-free while RDMA transfer\n* Support CUDA Graph\n\n## RDMA TransferEngine library\n\n* Support both NVIDIA ConnectX-7 and AWS EFA (potentially other RDMA NICs as well)\n* Support aggregation of multiple NICs per GPU\n* Support reliable unordered transport protocol\n\n# System requirements\n\n* (Recommended) Linux Kernel 5.12 or higher (for DMA-BUF support)\n* CUDA 12.8 or higher\n* libfabric\n* libibverbs\n* GDRCopy\n* `SYS_PTRACE` and `SYS_ADMIN` Linux capabilities for `pidfd_getfd`. You can obtain these by running as root, with sudo, or inside docker with `--cap-add=SYS_PTRACE --cap-add=SYS_ADMIN`.\n* RDMA network with GPUDirect RDMA support. Each GPU should have at least one dedicated RDMA NIC.\n\n# Docker dev image\n\nWe provide a docker image for the convenience of development. You can build it with the following command:\n\n```bash\ndocker build -t pplx-garden-dev - < docker/dev.Dockerfile\n```\n\nRun the container with the following command:\n\n```bash\n./scripts/run-docker.sh\n```\n\n# Run fabric-debug\n\nThis is the benchmark for our network library.\n\nBuild the benchmark binary:\n\n```bash\ncd /app\ncargo build --release --bin fabric-debug\n```\n\nUsage:\n\n* Server: `fabric-debug [GPUs separated by comma] [NICs per GPU]`\n* Client: `fabric-debug [GPUs separated by comma] [NICs per GPU] [server address]` where the server address is the one printed by the server.\n\n\nExample:\n\n```\nserver$ /app/target/release/fabric-debug 0,1,2,3,4,5,6,7 2\nclient$ /app/target/release/fabric-debug 0,1,2,3,4,5,6,7 2 fe80xxxx\n```\n\n# Build and Install Python Wheel\n\n```bash\ncd /app\nexport TORCH_CMAKE_PREFIX_PATH=$(python3 -c \"import torch; print(torch.utils.cmake_prefix_path)\")\npython3 -m build --wheel\npython3 -m pip install /app/dist/*.whl\n```\n\n# Run All-to-All Benchmark\n\n```bash\n# Environment variables\nNUM_NODES=...\nNODE_RANK=...  # [0, NUM_NODES)\nMASTER_IP=...\n\n# Run on all nodes\ncd /app\npython3 -m benchmarks.bench_all_to_all \\\n    --world-size $((NUM_NODES * 8)) --nets-per-gpu 2 --init-method=tcp://$MASTER_IP:29500 \\\n    --node-rank=$NODE_RANK --nvlink=8\n```\n\nNote:\n\n* Remove `--nvlink` flag if you want to use RDMA only.\n* Set `--nets-per-gpu` accordingly based on the VM instance type.\n\n# All-to-All Performance Results\n\nDecode (128 tokens) Dispatch and Combine:\n\n|      | pplx-EFA | pplx-CX7 | DeepEP-CX7 | x | pplx-EFA | pplx-CX7 | DeepEP-CX7 |\n|------|---------:|---------:|-----------:|---|---------:|---------:|-----------:|\n| EP64 | 266.7 Î¼s | 187.5 Î¼s |   177.9 Î¼s | x | 391.2 Î¼s | 309.1 Î¼s |   325.0 Î¼s |\n| EP32 | 229.1 Î¼s | 153.9 Î¼s |   159.1 Î¼s | x | 335.0 Î¼s | 266.3 Î¼s |   285.0 Î¼s |\n| EP16 | 214.8 Î¼s | 110.2 Î¼s |   123.9 Î¼s | x | 241.5 Î¼s | 185.5 Î¼s |   203.0 Î¼s |\n| EP8  |  49.7 Î¼s |  50.5 Î¼s |    42.6 Î¼s | x |  64.2 Î¼s |  65.3 Î¼s |    72.0 Î¼s |\n\n\nPrefill (4096 tokens) Dispatch and Combine:\n\n| x    |  pplx-EFA |  pplx-CX7 | DeepEP-CX7 | x |  pplx-EFA |  pplx-CX7 | DeepEP-CX7 |\n|------|----------:|----------:|-----------:|---|----------:|----------:|-----------:|\n| EP64 | 5334.3 Î¼s | 4665.2 Î¼s |  5071.6 Î¼s | x | 9779.3 Î¼s | 8771.1 Î¼s |  5922.7 Î¼s |\n| EP32 | 4619.0 Î¼s | 4011.8 Î¼s |  3680.2 Î¼s | x | 8271.5 Î¼s | 7526.8 Î¼s |  3565.4 Î¼s |\n| EP16 | 3196.7 Î¼s | 2734.8 Î¼s |  2481.9 Î¼s | x | 5379.1 Î¼s | 1062.2 Î¼s |  1863.9 Î¼s |\n| EP8  | 1052.4 Î¼s | 5071.1 Î¼s |  1810.3 Î¼s | x | 1396.7 Î¼s | 1405.1 Î¼s |   962.9 Î¼s |\n\n\n# Directory Structure\n\n* `fabric-lib/`: RDMA TransferEngine library\n* `p2p-all-to-all/`: P2P MoE All-to-All implementation\n* `python-ext/`: Python extension module from Rust code\n* `python/pplx_garden/`: Python code for the `pplx_garden` package\n* `rust/`: Rust utility libraries\n\n# Acknowledgments\n\nOur RDMA library is inspired by [MoonCake](https://www.usenix.org/conference/fast25/presentation/qin).\nOur MoE kernel is inspired by [DeepEP](https://github.com/deepseek-ai/DeepEP).\n\n# Citation\n\nIf you find this work useful, please cite:\n\n```\n@misc{pplx-rdma-p2p,\n      title={RDMA Point-to-Point Communication for LLM Systems}, \n      author={Nandor Licker and Kevin Hu and Vladimir Zaytsev and Lequn Chen},\n      year={2025},\n      eprint={2510.27656},\n      archivePrefix={arXiv},\n      primaryClass={cs.DC},\n      url={https://arxiv.org/abs/2510.27656}, \n}\n```\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-28T02:27:11.012931"
  },
  {
    "basic_info": {
      "name": "TinyETL",
      "full_name": "alrpal/TinyETL",
      "owner": "alrpal",
      "description": "Fast, zero-config ETL in a single binary",
      "url": "https://github.com/alrpal/TinyETL",
      "clone_url": "https://github.com/alrpal/TinyETL.git",
      "ssh_url": "git@github.com:alrpal/TinyETL.git",
      "homepage": "",
      "created_at": "2025-11-07T22:32:29Z",
      "updated_at": "2025-11-27T21:23:03Z",
      "pushed_at": "2025-11-24T17:10:12Z"
    },
    "stats": {
      "stars": 262,
      "forks": 9,
      "watchers": 262,
      "open_issues": 9,
      "size": 8556
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 561448,
        "Shell": 4713,
        "Python": 3233,
        "JavaScript": 1521,
        "TSQL": 711
      },
      "license": "Other",
      "topics": []
    },
    "content": {
      "readme": "# TinyETL\n**Fast, zero-config ETL in a single binary**\n\n[![Build Status](https://img.shields.io/badge/build-passing-brightgreen)](https://github.com/alrpal/tinyetl/actions)\n[![Coverage](https://img.shields.io/badge/coverage-60%25-brightgreen)](https://github.com/alrpal/tinyetl/actions)\n[![Version](https://img.shields.io/badge/version-0.8.0-blue)](https://github.com/alrpal/tinyetl/releases)\n[![Rust Edition](https://img.shields.io/badge/rust-2021-orange)](https://doc.rust-lang.org/edition-guide/rust-2021/index.html)\n[![Binary Size](https://img.shields.io/badge/binary-15MB-green)](https://github.com/alrpal/tinyetl/releases)\n\n![TinyETL Demo](examples/tinyetl_preview2-normal-framerate.gif)\n\nTransform and move data between any format or database **instantly**. No dependencies, no config files, just one command.\n\n```bash\n# MySQL â†’ Parquet with inline transformation \ntinyetl \"mysql://user:@host/db#orders\" orders.parquet \\\n  --transform \"total_usd=row.amount * row.exchange_rate\"\n\n# Stream 100k+ rows/sec from CSV â†’ SQLite\ntinyetl large_dataset.csv results.db --batch-size 50000\n\n# Download & convert web data\ntinyetl \"https://api.data.gov/export.json\" analysis.parquet\n```\n\n## Why TinyETL?\n\nâœ… **Single 15 MB binary** â€” no dependencies, no installation headaches  \nâœ… **180k+ rows/sec streaming** â€” handles massive datasets efficiently  \nâœ… **Zero configuration** â€” automatic schema detection and table creation (override with schema and config files in yaml)  \n   *Note: Auto-inferred schemas default all columns to nullable for safety*\n\nâœ… **Lua transformations** â€” powerful data transformations  \nâœ… **Universal connectivity** â€” CSV, JSON, Parquet, Avro, MySQL, PostgreSQL, SQLite, DuckDB, MSSQL, ODBC. Coming soon: Snowflake, Databricks, OneLake\n\nâœ… **Cross-platform** â€” Linux, macOS, Windows ready\n\n## Quick Install\n\n**Download the binary** (recommended):\n\nVisit the [releases page](https://github.com/alrpal/tinyetl/releases/latest) and download the appropriate binary for your platform:\n- Linux x64, Linux ARM64\n- macOS Intel, macOS Apple Silicon  \n- Windows x64, Windows ARM64\n\n<!--\n**Linux x64:**\n```bash\ncurl -L https://github.com/alrpal/tinyetl/releases/latest/download/tinyetl-linux-x64.tar.gz | tar xz\nchmod +x tinyetl\nsudo mv tinyetl /usr/local/bin/  # Optional: add to PATH\n```\n\n**Linux ARM64:**\n```bash\ncurl -L https://github.com/alrpal/tinyetl/releases/latest/download/tinyetl-linux-arm64.tar.gz | tar xz\nchmod +x tinyetl\nsudo mv tinyetl /usr/local/bin/  # Optional: add to PATH\n```\n\n**macOS Intel:**\n```bash\ncurl -L https://github.com/alrpal/tinyetl/releases/latest/download/tinyetl-macos-intel.tar.gz | tar xz\nchmod +x tinyetl\nsudo mv tinyetl /usr/local/bin/  # Optional: add to PATH\n```\n\n**macOS Apple Silicon:**\n```bash\ncurl -L https://github.com/alrpal/tinyetl/releases/latest/download/tinyetl-macos-apple-silicon.tar.gz | tar xz\nchmod +x tinyetl\nsudo mv tinyetl /usr/local/bin/  # Optional: add to PATH\n```\n\n**Windows x64:**\n```powershell\n# Download and extract using PowerShell\nInvoke-WebRequest -Uri \"https://github.com/alrpal/tinyetl/releases/latest/download/tinyetl-windows-x64.zip\" -OutFile \"tinyetl.zip\"\nExpand-Archive -Path \"tinyetl.zip\" -DestinationPath \".\"\n# Move tinyetl.exe to a directory in your PATH\n```\n\n**Windows ARM64:**\n```powershell\n# Download and extract using PowerShell  \nInvoke-WebRequest -Uri \"https://github.com/alrpal/tinyetl/releases/latest/download/tinyetl-windows-arm64.zip\" -OutFile \"tinyetl.zip\"\nExpand-Archive -Path \"tinyetl.zip\" -DestinationPath \".\"\n# Move tinyetl.exe to a directory in your PATH\n```\n-->\n\n**Or install with Cargo** (builds from source):\n```bash\ncargo install tinyetl\n```\n\n**Verify installation**:\n```bash\ntinyetl --version\n```\n\n## Get Started in 30 Seconds\n\n```bash\n# File format conversion (auto-detects schemas)\ntinyetl data.csv output.parquet\ntinyetl data.json analysis.db\n\n# Database to database \ntinyetl \"postgresql://user:@host/db#users\" \"mysql://user:@host/db#users\"\n\n# Transform while transferring\ntinyetl sales.csv results.db --transform \"profit=row.revenue - row.costs; margin=profit/revenue\"\n\n# Process large datasets efficiently  \ntinyetl huge_dataset.csv output.parquet --batch-size 100000\n\n# Download and convert web data\ntinyetl \"https://example.com/api/export\" local_data.json --source-type=csv\n\n# Run complex ETL jobs from configuration files\ntinyetl run my_etl_job.yaml\n```\n\n## Usage\n<div style=\"overflow-x: auto;\">\n\n```\nUsage: tinyetl [OPTIONS] <SOURCE> <TARGET>\n\nDirect Transfer:\n  <SOURCE>  Source connection string (file path or connection string)\n  <TARGET>  Target connection string (file path or connection string)\n\nOptions:\n      --infer-schema             Auto-detect columns and types\n      --schema-file <FILE>       Path to schema file (YAML) to override auto-detection\n      --batch-size <BATCH_SIZE>  Number of rows per batch [default: 10000]\n      --preview <N>              Show first N rows and inferred schema without copying\n      --dry-run                  Validate source/target without tr",
      "default_branch": "master"
    },
    "fetched_at": "2025-11-28T02:27:12.188113"
  },
  {
    "basic_info": {
      "name": "work-tuimer",
      "full_name": "Kamyil/work-tuimer",
      "owner": "Kamyil",
      "description": "Simple, keyboard-driven TUI for time-tracking that allows you to quickly add time blocks and automatically group time if same task was done in different sessions",
      "url": "https://github.com/Kamyil/work-tuimer",
      "clone_url": "https://github.com/Kamyil/work-tuimer.git",
      "ssh_url": "git@github.com:Kamyil/work-tuimer.git",
      "homepage": "",
      "created_at": "2025-10-31T13:26:31Z",
      "updated_at": "2025-11-27T17:15:21Z",
      "pushed_at": "2025-11-27T14:49:26Z"
    },
    "stats": {
      "stars": 231,
      "forks": 4,
      "watchers": 231,
      "open_issues": 9,
      "size": 1330
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 273648,
        "Just": 4016,
        "Shell": 1125,
        "Ruby": 693,
        "Nix": 123
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# WorkTUImer\n![work-tuimer](https://github.com/user-attachments/assets/207f9b66-0b08-4e97-a471-a9f413a7369c)\n\nLive demo: https://x.com/KsenKamil/status/1985423210859368716\n\nSimple, keyboard-driven TUI for time-tracking that allows you to quickly add time blocks and automatically group time if same task was done in different sessions\nBuilt with Rust and ratatui for efficient time management.\n\n## Features\n\n- **Fully keyboard-driven**: No mouse required - everything accessible via keybinds\n- **Active timer tracking**: Start/stop/pause timers that automatically update work records with actual time spent\n- **Time as PIN-Inputs**: Easly type time with 4 clicks, since all time inputs are PIN-input alike\n- **Log tasks and breaks, get totals automatically**: Add work entries with start/end times - durations are calculated and summed\n- **Task picker with history**: Quickly select from previously used task names or create new ones\n- **Calendar navigation**: Jump between days, weeks, and months\n- **Arrow keys or Vim motions**: Navigate with arrow keys + Enter, or use h/j/k/l + i for Vim-style workflow\n- **Inline editing with undo/redo**: Fix mistakes in place, up to 50 levels of history\n- **Auto-saves locally per day**: Data stored as JSON files, for each day, on your machine (`~/.local/share/work-tuimer/`)\n- **Optional ticket integration**: Detect and link to JIRA, Linear, GitHub issues from task names - open ticket URLs directly in your browser from the app\n\n## Installation\n\n### Package Managers\n\n#### Cargo (Rust)\nLINK: https://crates.io/crates/work-tuimer\n```sh\ncargo install work-tuimer\n```\n\n#### (!!! NOT READY YET !!!) Homebrew (macOS/Linux)\n\n```sh\nbrew install work-tuimer\n```\n\n#### Arch Linux (AUR)\nLINK: https://aur.archlinux.org/packages/work-tuimer\n```sh\n# Using yay\nyay -S work-tuimer\n\n# Or manually\ngit clone https://aur.archlinux.org/work-tuimer.git\ncd work-tuimer\nmakepkg -si\n```\n\n#### FreeBSD\n\n```sh\npkg install work-tuimer\n```\n\n### Pre-built Binaries\n\nDownload the latest pre-built binary for your platform from [GitHub Releases](https://github.com/Kamyil/work-tuimer/releases):\n\n- **Linux (x86_64)**: `work-tuimer-linux-x86_64`\n- **macOS (Intel)**: `work-tuimer-macos-x86_64`\n- **macOS (Apple Silicon)**: `work-tuimer-macos-aarch64`\n- **Windows**: `work-tuimer-windows-x86_64.exe`\n\nAfter downloading, make the binary executable and run it:\n\n```bash\n# Linux / macOS\nchmod +x work-tuimer-linux-x86_64\n./work-tuimer-linux-x86_64\n\n# Windows\nwork-tuimer-windows-x86_64.exe\n```\n\n### Build from Source\n\nIf you prefer to build from source or don't see a binary for your platform:\n\n```bash\ncargo build --release\n./target/release/work-tuimer\n```\n\n## Usage\n\n### Browse Mode\n\n| Key | Action |\n|-----|--------|\n| `â†‘/k` | Move selection up |\n| `â†“/j` | Move selection down |\n| `â†/h` | Move field left (Name â†’ Start â†’ End) |\n| `â†’/l` | Move field right (Name â†’ Start â†’ End) |\n| `[` | Navigate to previous day (auto-saves) |\n| `]` | Navigate to next day (auto-saves) |\n| `C` | Open calendar view for date navigation |\n| `Enter/i` | Enter edit mode on selected field |\n| `c` | Change task name (opens picker to select/filter/create) |\n| `n` | Add new work record |\n| `b` | Add break (uses selected record's end time as start) |\n| `d` | Delete selected record |\n| `v` | Enter visual mode (multi-select) |\n| `S` | Start/Stop timer for selected record |\n| `P` | Pause/Resume active timer |\n| `t` | Set current time on selected field |\n| `T` | Open ticket in browser (only visible if config exists) |\n| `L` | Open worklog URL in browser (only visible if config exists) |\n| `u` | Undo last change |\n| `r` | Redo undone change |\n| `s` | Save to file |\n| `q` | Quit (auto-saves) |\n\n### Edit Mode\n\n| Key | Action |\n|-----|--------|\n| `Tab` | Next field (Name â†’ Start â†’ End â†’ Description â†’ Name) |\n| `Enter` | Save changes and exit edit mode |\n| `Esc` | Cancel and exit edit mode |\n| `Backspace` | Delete character |\n| Any char | Insert character |\n\n### Task Picker (accessed via `c` in Browse mode)\n\nPress `c` on the Name field to open the task picker:\n- Shows all unique task names from the current day\n- Type to filter the list\n- Press Enter to select a task or create a new one\n\n| Key | Action |\n|-----|--------|\n| Any char | Type to filter tasks or create new name (including h/j/k/l) |\n| `â†‘` | Move selection up in filtered list |\n| `â†“` | Move selection down in filtered list |\n| `Enter` | Select highlighted task or create typed name |\n| `Backspace` | Delete character from filter |\n| `Esc` | Cancel and return to browse mode |\n\n### Visual Mode\n\n| Key | Action |\n|-----|--------|\n| `â†‘/k` | Extend selection up |\n| `â†“/j` | Extend selection down |\n| `d` | Delete selected records |\n| `Esc` | Exit visual mode |\n\n### Calendar View\n\n| Key | Action |\n|-----|--------|\n| `â†‘/k` | Move selection up (1 week) |\n| `â†“/j` | Move selection down (1 week) |\n| `â†/h` | Move selection left (1 day) |\n| `â†’/l` | Move selection right (1 day) |\n| `[/</,` | Previous month |\n| `]/>/.` | Next month |\n| `Enter` |",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-28T02:27:13.354805"
  },
  {
    "basic_info": {
      "name": "never-jscore",
      "full_name": "neverl805/never-jscore",
      "owner": "neverl805",
      "description": "åŸºäºŽrust deno_coreå¼€å‘å°è£…çš„v8å¼•æ“Žåº“,ç”¨äºŽpythoné«˜æ€§èƒ½æ‰§è¡Œjs.(execjsçš„ä¸Šä½æ›¿ä»£å“)",
      "url": "https://github.com/neverl805/never-jscore",
      "clone_url": "https://github.com/neverl805/never-jscore.git",
      "ssh_url": "git@github.com:neverl805/never-jscore.git",
      "homepage": "https://github.com/neverl805/never-jscore",
      "created_at": "2025-11-04T14:42:59Z",
      "updated_at": "2025-11-28T00:26:12Z",
      "pushed_at": "2025-11-20T11:03:11Z"
    },
    "stats": {
      "stars": 184,
      "forks": 47,
      "watchers": 184,
      "open_issues": 4,
      "size": 1020
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 138813,
        "JavaScript": 135220,
        "Python": 124110
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# never_jscore\n\nåŸºäºŽ Deno Core (V8) çš„é«˜æ€§èƒ½ Python JavaScript æ‰§è¡Œå¼•æ“Žï¼Œ**ä¸“ä¸º JS é€†å‘å·¥ç¨‹ä¼˜åŒ–**ã€‚\n\n[![PyPI](https://img.shields.io/pypi/v/never-jscore)](https://pypi.org/project/never-jscore/)\n[![Python](https://img.shields.io/pypi/pyversions/never-jscore)](https://pypi.org/project/never-jscore/)\n[![License](https://img.shields.io/badge/license-MIT-blue)](LICENSE)\n\n**è­¦å‘Š**ï¼šä»…ä¾›æŠ€æœ¯ç ”ç©¶å’Œå­¦ä¹ ï¼Œè¯·å‹¿ç”¨äºŽè¿æ³•ç”¨é€”ï¼ŒåŽæžœè‡ªè´Ÿã€‚\n\n- **æŠ€æœ¯äº¤æµç¾¤**ï¼šåŠ å¾®ä¿¡ xu970821582\n- æé†’: åŸºäºŽpyo3åº“çš„æ›´æ–°è¿­ä»£æƒ…å†µ,ä¸ªäººæŽ¨èä½¿ç”¨python3.14ç‰ˆæœ¬æ¥ä½¿ç”¨æ­¤åº“,å¯èƒ½ä¼šé¿å…å¾ˆå¤šå¥‡æ€ªçš„æŠ¥é”™\n\n---\n\n## ä¸ºä»€ä¹ˆé€‰æ‹© never_jscoreï¼Ÿ\n\n### æ ¸å¿ƒä¼˜åŠ¿\n\n| ç‰¹æ€§ | never_jscore | PyMiniRacer | PyExecJS |\n|------|--------------|-------------|----------|\n| **Promise/async** | âœ… å®Œæ•´æ”¯æŒ | âŒ ä¸æ”¯æŒ | âŒ ä¸æ”¯æŒ |\n| **Hook æ‹¦æˆª** | âœ… åŒæ¨¡å¼ï¼š`$return()` + `$terminate()` | âŒ | âŒ |\n| **ç¡®å®šæ€§éšæœºæ•°** | âœ… ç§å­æŽ§åˆ¶ | âŒ | âŒ |\n| **Web API** | âœ… å®Œæ•´ï¼ˆrequire/fetch/localStorageï¼‰ | âŒ | âŒ |\n| **æ€§èƒ½ï¼ˆ1000æ¬¡è°ƒç”¨ï¼‰** | **11ms** ðŸ† | 38ms | 69473ms |\n| **ä¸Šä¸‹æ–‡éš”ç¦»** | âœ… ç‹¬ç«‹ V8 Isolate | âœ… | âš ï¸ è¿›ç¨‹éš”ç¦» |\n| **ç±»åž‹æç¤º** | âœ… .pyi æ–‡ä»¶ | âš ï¸ éƒ¨åˆ† | âŒ |\n\n### ä¸“ä¸ºé€†å‘å·¥ç¨‹è®¾è®¡\n\n- ðŸŽ£ **åŒæ¨¡å¼ Hook æ‹¦æˆª**ï¼š\n  - `$return()` - å¿«é€Ÿæ‹¦æˆªï¼Œé€‚åˆç®€å•åœºæ™¯\n  - `$terminate()` - **V8 å¼ºåˆ¶ç»ˆæ­¢ï¼Œæ— æ³•è¢« try-catch æ•èŽ·**ï¼ˆv2.4.3+ æ–°å¢žï¼‰\n- ðŸŽ² **ç¡®å®šæ€§è°ƒè¯•**ï¼šå›ºå®šéšæœºæ•°ç§å­ï¼Œè½»æ¾è°ƒè¯•åŠ¨æ€åŠ å¯†ç®—æ³•\n- ðŸŒ **é›¶é…ç½®è¡¥çŽ¯å¢ƒ**ï¼šå†…ç½® 800+ è¡Œ polyfillï¼Œè‡ªåŠ¨æ¨¡æ‹Ÿæµè§ˆå™¨/Node.js çŽ¯å¢ƒ\n- âš¡ **æžè‡´æ€§èƒ½**ï¼šRust + V8 ç›´æŽ¥ç»‘å®šï¼Œæ¯” PyExecJS å¿« 100-300 å€\n- ðŸ”„ **çŽ°ä»£ JS æ”¯æŒ**ï¼šå®Œæ•´çš„ Promiseã€async/awaitã€fetchã€localStorage\n\n### æ€§èƒ½åŸºå‡†æµ‹è¯•\n\n![img.png](img.png)\n\n| æµ‹è¯•é¡¹ç›® | never_jscore | PyMiniRacer | PyExecJS |\n|---------|-------------|-------------|----------|\n| ç®€å•è®¡ç®— | 0.007ms | 0.005ms | 2.3ms |\n| å­—ç¬¦ä¸²æ“ä½œ | **0.004ms** ðŸ† | 0.008ms | 2.3ms |\n| æ•°ç»„æ“ä½œ | **0.004ms** ðŸ† | 0.006ms | 2.3ms |\n| å¤æ‚ç®—æ³•(1000æ¬¡) | **0.0111s** ðŸ† | 0.0383s | 69.4735s |\n| Promise | **âœ… 0.003ms** | âŒ ä¸æ”¯æŒ | âŒ ä¸æ”¯æŒ |\n\n---\n\n## å¿«é€Ÿå¼€å§‹\n\n### å®‰è£…\n\n```bash\npip install never-jscore\n```\n\n**æ”¯æŒå¹³å°**ï¼šWindowsã€Linuxã€macOS | **Python ç‰ˆæœ¬**ï¼š3.8+\n\n### åŸºæœ¬ç”¨æ³•\n\n```python\nimport never_jscore\n\n# åˆ›å»ºç‹¬ç«‹çš„ JavaScript æ‰§è¡ŒçŽ¯å¢ƒ\nctx = never_jscore.Context()\n\n# æ–¹å¼ 1: ç¼–è¯‘ä»£ç åˆ°å…¨å±€ä½œç”¨åŸŸ\nctx.compile(\"\"\"\n    function encrypt(text, key) {\n        // ä½ çš„åŠ å¯†é€»è¾‘\n        return btoa(text + key);\n    }\n\"\"\")\n\n# è°ƒç”¨å·²å®šä¹‰çš„å‡½æ•°\nresult = ctx.call(\"encrypt\", [\"hello\", \"secret\"])\nprint(result)  # 'aGVsbG9zZWNyZXQ='\n\n# æ–¹å¼ 2: ä¸€æ¬¡æ€§æ±‚å€¼ï¼ˆä¸æ±¡æŸ“å…¨å±€ï¼‰\nresult = ctx.evaluate(\"1 + 2 + 3\")\nprint(result)  # 6\n```\n\n### Promise å’Œ async/awaitï¼ˆè‡ªåŠ¨ç­‰å¾…ï¼‰\n\n```python\nctx = never_jscore.Context()\n\n# å®šä¹‰å¼‚æ­¥å‡½æ•°\nctx.compile(\"\"\"\n    async function fetchUserData(userId) {\n        // æ¨¡æ‹Ÿå¼‚æ­¥æ“ä½œ\n        return await Promise.resolve({\n            id: userId,\n            name: \"User\" + userId,\n            token: Math.random().toString(36)\n        });\n    }\n\"\"\")\n\n# è‡ªåŠ¨ç­‰å¾… Promise å®Œæˆ\nuser = ctx.call(\"fetchUserData\", [12345])\nprint(user)  # {'id': 12345, 'name': 'User12345', 'token': '0.xyz...'}\n\n# Promise é“¾å¼è°ƒç”¨\nresult = ctx.evaluate(\"\"\"\n    Promise.resolve(10)\n        .then(x => x * 2)\n        .then(x => x + 5)\n\"\"\")\nprint(result)  # 25\n```\n\n---\n\n## é«˜çº§åŠŸèƒ½\n\n### ðŸŽ£ Hook æ‹¦æˆªï¼šæå–åŠ å¯†æ•°æ®\n\nåœ¨ JS é€†å‘ä¸­ï¼Œç»å¸¸éœ€è¦æ‹¦æˆªæŸä¸ªå‡½æ•°çš„è°ƒç”¨å¹¶æå–å‚æ•°æˆ–è¿”å›žå€¼ã€‚never_jscore æä¾›**ä¸¤ç§ Hook æ¨¡å¼**ï¼š\n\n#### æ¨¡å¼ 1: `$return()` - å¿«é€Ÿæ‹¦æˆªï¼ˆå¯è¢« try-catch æ•èŽ·ï¼‰\n\n```python\nctx = never_jscore.Context()\n\n# é€‚åˆç®€å•åœºæ™¯\nencrypted_data = ctx.evaluate(\"\"\"\n    (async () => {\n        const originalSend = XMLHttpRequest.prototype.send;\n        XMLHttpRequest.prototype.send = function(data) {\n            $return({\n                url: this._url,\n                encrypted: data\n            });\n        };\n\n        const xhr = new XMLHttpRequest();\n        xhr.open('POST', 'https://api.example.com/login');\n        xhr.send(encryptedPayload);\n    })()\n\"\"\")\n\nprint(f\"æ‹¦æˆªåˆ°çš„åŠ å¯†æ•°æ®: {encrypted_data['encrypted']}\")\n```\n\n#### æ¨¡å¼ 2: `$terminate()` - å¼ºåˆ¶ç»ˆæ­¢ï¼ˆ**æ— æ³•è¢« try-catch æ•èŽ·** â­ v2.4.3+ æ–°å¢žï¼‰\n\n**å…³é”®ç‰¹æ€§ï¼š** ä½¿ç”¨ V8 `terminate_execution()`ï¼Œç»•è¿‡æ‰€æœ‰ try-catch é˜²æŠ¤ï¼\n\n```python\nimport json\n\nctx = never_jscore.Context()\nctx.clear_hook_data()  # æ¸…ç©ºä¹‹å‰çš„æ•°æ®ï¼ˆå¯é€‰ï¼Œä¼šè‡ªåŠ¨æ¸…ç©ºï¼‰\n\n# Hook XMLHttpRequest.send\nctx.compile(\"\"\"\n    XMLHttpRequest.prototype.send = function(data) {\n        // âš¡ ä½¿ç”¨ $terminate å¼ºåˆ¶ç»ˆæ­¢ï¼Œæ— æ³•è¢« try-catch æ•èŽ·\n        $terminate({\n            url: this._url,\n            method: this._method,\n            encrypted: data\n        });\n    };\n\"\"\")\n\n# æ‰§è¡Œç›®æ ‡ä»£ç ï¼ˆå³ä½¿æœ‰ try-catch ä¹Ÿä¼šè¢«ç»ˆæ­¢ï¼‰\ntry:\n    ctx.evaluate(\"\"\"\n        try {\n            const xhr = new XMLHttpRequest();\n            xhr.open('POST', 'https://api.example.com/login');\n            xhr.send(encryptedPayload);\n        } catch (e) {\n            // âŒ è¿™é‡Œä¸ä¼šæ‰§è¡Œ - $terminate æ— æ³•è¢«æ•èŽ·ï¼\n            console.log(\"Will not execute\");\n        }\n    \"\"\")\nexcept Exception as e:\n    # âœ… Python ç«¯æ•èŽ·åˆ°ç»ˆæ­¢\n    print(f\"JS è¢«å¼ºåˆ¶ç»ˆæ­¢: {e}\")\n\n# èŽ·å–æ‹¦æˆªçš„æ•°æ®\nhook_data = ctx.get_hook_data()\nif hook_data:\n    data = json.loads(hook_data)\n    print(f\"æ‹¦æˆªåˆ°çš„åŠ å¯†æ•°æ®: {data['encrypted']}\")\n\n# âš ï¸ æ³¨æ„ï¼šæ¯æ¬¡ evaluate()/call() å‰ä¼šè‡ªåŠ¨æ¸…ç©º hook æ•°æ®\n# å¦‚æžœéœ€è¦ä¿ç•™ä¸Šä¸€æ¬¡çš„æ•°æ®ï¼Œå¿…é¡»åœ¨ä¸‹ä¸€æ¬¡æ‰§è¡Œå‰å…ˆè¯»å–\n```\n\n**ä¸¤ç§æ¨¡å¼å¯¹æ¯”ï¼š**\n\n| ç‰¹æ€§ | `$return()` | `$terminate()` â­ |\n|------|-------------|-------------------|\n| é€Ÿåº¦ | âœ… å¿« | âœ… å¿« |\n| try-catch | âš ï¸ å¯è¢«æ•èŽ· | âœ… **æ— æ³•è¢«æ•èŽ·** |\n| é€‚ç”¨åœºæ™¯ | ç®€å• Hook | å¯¹æŠ—åŠ å›ºä»£ç  |\n| æ•°æ®èŽ·å– | ç›´æŽ¥è¿”å›žå€¼ | `ctx.get_hook_data()` |\n| å¤šæ¬¡æ‰§è¡Œ | âœ… å¯å¤ç”¨ Context | âš ï¸ å»ºè®®æ¸…ç†åŽå¤ç”¨ |\n\n**Hook API æ€»è§ˆ**ï¼š\n- **æ¨¡å¼ 1ï¼š** `$return(value)`, `$exit(value)`, `__neverjscore_return__(value)`\n- **æ¨¡å¼ 2ï¼š** `$terminate(value)`, `__saveAndTerminate__(value)` â­ æ–°å¢ž\n\n**å…¸åž‹åº”ç”¨åœº",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-28T02:27:14.531471"
  },
  {
    "basic_info": {
      "name": "filessh",
      "full_name": "JayanAXHF/filessh",
      "owner": "JayanAXHF",
      "description": "A fast and convenient TUI file browser for remote servers",
      "url": "https://github.com/JayanAXHF/filessh",
      "clone_url": "https://github.com/JayanAXHF/filessh.git",
      "ssh_url": "git@github.com:JayanAXHF/filessh.git",
      "homepage": "https://crates.io/crates/filessh",
      "created_at": "2025-11-11T09:22:32Z",
      "updated_at": "2025-11-27T15:29:45Z",
      "pushed_at": "2025-11-24T13:53:56Z"
    },
    "stats": {
      "stars": 165,
      "forks": 3,
      "watchers": 165,
      "open_issues": 0,
      "size": 302
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 126421
      },
      "license": "The Unlicense",
      "topics": [
        "cli",
        "file-manager",
        "sftp",
        "ssh",
        "tui"
      ]
    },
    "content": {
      "readme": "# FileSSH\n\n[![Built With Ratatui](https://ratatui.rs/built-with-ratatui/badge.svg)](https://ratatui.rs/)\n![crates.io](https://img.shields.io/crates/v/filessh)\n![GitHub Tag](https://img.shields.io/github/v/tag/jayanaxhf/filessh)\n\n\nA TUI-based file explorer for SSH servers, which allows you to browse and manage files on a remote server, edit them in-place, and recursively download directories with parallel directory traversal. It also has the ability to quickly spawn SSH sessions to paths on the remote server.\n\nDual-licensed under MIT or the [UNLICENSE](https://unlicense.org/).\n\n![Made with VHS](https://vhs.charm.sh/vhs-3OLXZvjKpqe5qR7hxsftQF.gif)\n\n## Installation\n### Cargo\n```sh\ncargo install --locked filessh\n```\n### Build from source\n\n1.  Ensure you have Rust and Cargo installed. You can find installation instructions at [rust-lang.org](https://www.rust-lang.org/tools/install).\n2.  Clone the repository:\n    ```sh\n    git clone https://github.com/your-username/filessh.git\n    cd filessh\n    ```\n3.  Build the project:\n    ```sh\n    cargo build --release\n    ```\n    The executable will be located at `target/release/filessh`.\n\n## Todo\n\n- [ ] Add support for rsync and scp\n- [ ] Iron out bugs\n\n## Usage\n\n```sh\nfilessh [OPTIONS] <HOST> <PATH>\n```\n### Features\n1. Modify, delete and browse files on a remote server\n2. Recursively download directories with parallel directory traversal\n3. Quickly open SSH sessions to directories.\n\n### Usage\n\n```\nfilessh [OPTIONS] [HOST] [PATH]\nfilessh <COMMAND>\n\nCommands:\n  connect              Connect explicitly (same as default command)\n  install-man-pages    Install man pages into the system\n  install-completions  Generate shell completion scripts\n\nArguments:\n  [HOST]  The remote host to connect to (e.g., 'example.com' or '192.168.1.100')\n  [PATH]  Initial directory path to open on the remote host\n\nOptions:\n  -p, --port <PORT>\n          The port number to use for the SSH connection [default: 22]\n  -u, --username <USERNAME>\n          The username for logging into the remote host\n  -k, --private-key <PRIVATE_KEY>\n          Path to the private key file for public key authentication\n  -o, --openssh-certificate <OPENSSH_CERTIFICATE>\n          Optional path to an OpenSSH certificate\n  -h, --help\n          Print help\n  -V, --version\n          Print version\n```\n\n### Example\n\n```sh\n./target/release/filessh \\\n    --username myuser \\\n    --private-key ~/.ssh/id_rsa \\\n    example.com \\\n    /home/myuser\n```\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-28T02:27:15.938548"
  },
  {
    "basic_info": {
      "name": "rusub",
      "full_name": "adysec/rusub",
      "owner": "adysec",
      "description": "rusub æ˜¯ä¸€æ¬¾é«˜é€Ÿã€æ™ºèƒ½çš„è·¨å¹³å°å­åŸŸæžšä¸¾å·¥å…·ï¼Œæ”¯æŒå¯å‘å¼æ‰«æã€å†…ç½® 10 ä¸‡+ è¯è¡¨ã€å¼‚æ­¥é«˜å¹¶å‘ã€å¤šæ ¼å¼è¾“å‡ºåŠè‡ªåŠ¨æ–­ç‚¹ç»­ä¼ ã€‚",
      "url": "https://github.com/adysec/rusub",
      "clone_url": "https://github.com/adysec/rusub.git",
      "ssh_url": "git@github.com:adysec/rusub.git",
      "homepage": "https://github.com/adysec/rusub",
      "created_at": "2025-11-06T06:59:21Z",
      "updated_at": "2025-11-26T08:17:16Z",
      "pushed_at": "2025-11-10T09:40:57Z"
    },
    "stats": {
      "stars": 156,
      "forks": 143,
      "watchers": 156,
      "open_issues": 0,
      "size": 552
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 106010
      },
      "license": "MIT License",
      "topics": [
        "dns",
        "dns-server",
        "dnsmasq",
        "dnssec",
        "domain",
        "subdomain",
        "subdomain-finder",
        "subdomain-scanner",
        "subdomains",
        "subdomains-scanner"
      ]
    },
    "content": {
      "readme": "<div align=\"center\">\n\n# rusub\n\nðŸš€ é«˜é€Ÿã€æ™ºèƒ½çš„å­åŸŸæžšä¸¾å·¥å…· (Rust)\n\n[![Rust](https://img.shields.io/badge/rust-1.70%2B-orange.svg)](https://www.rust-lang.org/)\n[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)\n\n</div>\n\n## ðŸ“‹ ç›®å½•\n1. [å¿«é€Ÿå¼€å§‹](#1-å¿«é€Ÿå¼€å§‹)\n2. [é…ç½®å‚æ•°](#2-é…ç½®å‚æ•°)\n3. [å®žç”¨ç¤ºä¾‹](#3-å®žç”¨ç¤ºä¾‹)\n4. [è¾“å‡ºæ ¼å¼](#4-è¾“å‡ºæ ¼å¼)\n5. [æŠ€æœ¯åŽŸç†](#5-æŠ€æœ¯åŽŸç†)\n6. [ä½œä¸ºåº“ä½¿ç”¨](#6-ä½œä¸ºåº“ä½¿ç”¨)\n7. [è®¸å¯ä¸Žå…è´£å£°æ˜Ž](#7-è®¸å¯ä¸Žå…è´£å£°æ˜Ž)\n\n## 1. å¿«é€Ÿå¼€å§‹\n\n### æ ¸å¿ƒç‰¹æ€§\n\n- **ðŸ§  å¯å‘å¼æ‰«æ**ï¼šé»˜è®¤æ™ºèƒ½ç”Ÿæˆ 512 ä¸ªå€™é€‰å­åŸŸï¼Œæ— éœ€å­—å…¸\n- **ðŸ“š å­—å…¸æ‰«æ**ï¼š10 ä¸‡+ è¯è¡¨å·²å†…ç½®ï¼Œæ”¯æŒè‡ªå®šä¹‰å­—å…¸\n- **ðŸ’¾ æ–­ç‚¹ç»­ä¼ **ï¼šè‡ªåŠ¨ä¿å­˜è¿›åº¦ï¼Œä¸­æ–­åŽå¯ç»§ç»­\n- **âš¡ é«˜æ€§èƒ½**ï¼šå¼‚æ­¥å¹¶å‘ï¼ˆé»˜è®¤ 500ï¼‰ï¼Œæ”¯æŒé€ŸçŽ‡æŽ§åˆ¶\n- **ðŸ“Š å¤šæ ¼å¼è¾“å‡º**ï¼šJSONL / TXT / JSON / CSVï¼Œå¯é€‰ gzip åŽ‹ç¼©\n- **ðŸ›¡ï¸ æ³›è§£æžè¿‡æ»¤**ï¼šè‡ªåŠ¨æ£€æµ‹å¹¶è¿‡æ»¤æ³›è§£æžè®°å½•\n- **ðŸŒ è·¨å¹³å° DNS**ï¼šè‡ªåŠ¨è¯»å–ç³»ç»Ÿ DNS é…ç½®ï¼ˆWindows/Linux/macOSï¼‰\n\n### å®‰è£…\n\n```bash\ngit clone https://github.com/adysec/rusub.git\ncd rusub\ncargo build --release\n\n# å¯é€‰ï¼šå®‰è£…åˆ°ç³»ç»Ÿ\ncargo install --path .\n```\n\n**ç¼–è¯‘åŽçš„äºŒè¿›åˆ¶æ–‡ä»¶ï¼ˆçº¦ 4.7 MBï¼‰ï¼š**\n- âœ… 10 ä¸‡+ å­åŸŸè¯è¡¨å·²å†…ç½®\n- âœ… æ— å¤–éƒ¨ä¾èµ–\n- âœ… å¯åœ¨ä»»æ„ç›®å½•è¿è¡Œ\n\n### åŸºæœ¬ç”¨æ³•\n\n```bash\n# é»˜è®¤æ‰«æï¼ˆå¯å‘å¼ 512 å€™é€‰ï¼ŒJSONL è¾“å‡ºï¼‰\nrusub enum example.com\n\n# æ·±åº¦æ‰«æï¼ˆ1024 å€™é€‰ï¼‰\nrusub enum example.com --heuristic-max 1024\n\n# ä½¿ç”¨è‡ªå®šä¹‰å­—å…¸\nrusub enum example.com -f wordlist.txt\n\n# å¤šåŸŸåæ‰«æ\nrusub enum -d target.com -d example.com\n```\n\n## 2. é…ç½®å‚æ•°\n\n### ðŸŽ¯ åŸºç¡€å‚æ•°\n\n| å‚æ•° | è¯´æ˜Ž | é»˜è®¤å€¼ | ç¤ºä¾‹ |\n|------|------|--------|------|\n| `-d, --domain` | ç›®æ ‡åŸŸåï¼ˆå¯é‡å¤ï¼‰ | - | `-d example.com -d test.com` |\n| `--stdin` | ä»Žæ ‡å‡†è¾“å…¥è¯»å–åŸŸå | - | `cat domains.txt \\| rusub enum --stdin` |\n| `-f, --filename` | å­—å…¸æ–‡ä»¶è·¯å¾„ | å†…ç½® | `-f wordlist.txt` |\n| `--domain-list` | åŸŸååˆ—è¡¨æ–‡ä»¶ | - | `--domain-list domains.txt` |\n\n### ðŸ“Š è¾“å‡ºå‚æ•°\n\n| å‚æ•° | è¯´æ˜Ž | é»˜è®¤å€¼ | ç¤ºä¾‹ |\n|------|------|--------|------|\n| `-o, --output` | è¾“å‡ºæ–‡ä»¶è·¯å¾„ | stdout | `-o results.jsonl` |\n| `--output-type` | è¾“å‡ºæ ¼å¼ | jsonl | `txt / json / jsonl / csv` |\n| `--gzip` | å¯ç”¨ gzip åŽ‹ç¼© | autoÂ¹ | `--gzip` |\n| `--not-print` | ä¸æ‰“å°åˆ°ç»ˆç«¯ | false | `--not-print` |\n| `--pure-output` | çº¯å‡€è¾“å‡ºï¼ˆä»…ç»“æžœï¼‰| autoÂ² | `--pure-output` |\n| `--only-alive` | ä»…è¾“å‡ºå­˜æ´»åŸŸå | autoÂ² | `--only-alive` |\n\n> Â¹ è¾“å‡ºæ–‡ä»¶ä»¥ `.gz` ç»“å°¾æ—¶è‡ªåŠ¨å¯ç”¨  \n> Â² json/jsonl æ ¼å¼è‡ªåŠ¨å¯ç”¨\n\n### âš¡ æ€§èƒ½å‚æ•°\n\n| å‚æ•° | è¯´æ˜Ž | é»˜è®¤å€¼ | ç¤ºä¾‹ |\n|------|------|--------|------|\n| `-b, --band` | é€ŸçŽ‡é™åˆ¶ | 3m | `-b 10M` æˆ– `-b 5000` |\n| `-c, --concurrency` | å¹¶å‘æ•° | 500 | `-c 1000` |\n| `--timeout` | æŸ¥è¯¢è¶…æ—¶ï¼ˆç§’ï¼‰ | 6 | `--timeout 10` |\n| `--retry` | å¤±è´¥é‡è¯•æ¬¡æ•° | 3 | `--retry 5` |\n| `-r, --resolvers` | DNS è§£æžå™¨ï¼ˆå¯é‡å¤ï¼‰ | ç³»ç»ŸÂ³ | `-r 8.8.8.8 -r 1.1.1.1` |\n\n> Â³ **DNS è‡ªåŠ¨é…ç½®ï¼ˆè·¨å¹³å°ï¼‰ï¼š**\n> - ðŸ”§ è‡ªåŠ¨è¯»å–ç³»ç»Ÿé…ç½®ï¼ˆWindows/Linux/macOSï¼‰\n> - ðŸ›¡ï¸ è¿‡æ»¤æœ¬åœ°å›žçŽ¯ï¼ˆ127.*ï¼‰å’Œ IPv6 åœ°å€\n> - ðŸŒ æ— ç³»ç»Ÿé…ç½®æ—¶å›žé€€åˆ° 1.1.1.1 / 8.8.8.8\n> - âœï¸ ä½¿ç”¨ `-r` å¯è¦†ç›–é»˜è®¤é…ç½®\n\n### ðŸ§  å¯å‘å¼å‚æ•°\n\n| å‚æ•° | è¯´æ˜Ž | é»˜è®¤å€¼ | æŽ¨èå€¼ |\n|------|------|--------|--------|\n| `--heuristic-max` | å€™é€‰å­åŸŸæ•°é‡ | 512 | 256 / 512 / 1024 / 2048 |\n\n**æ‰«ææ–¹æ¡ˆï¼š**\n- ðŸš€ **è½»é‡**ï¼ˆ256ï¼‰ï¼šå¿«é€ŸéªŒè¯\n- âš–ï¸ **æ ‡å‡†**ï¼ˆ512ï¼‰ï¼šæ—¥å¸¸ä½¿ç”¨ï¼Œé»˜è®¤\n- ðŸ” **æ·±åº¦**ï¼ˆ1024ï¼‰ï¼šæ›´å…¨é¢\n- ðŸ’Ž **å…¨é¢**ï¼ˆ2048ï¼‰ï¼šæœ€å¤§è¦†ç›–\n\n### ðŸ”§ å…¶ä»–å‚æ•°\n\n| å‚æ•° | è¯´æ˜Ž | é»˜è®¤å€¼ | å¯é€‰å€¼ |\n|------|------|--------|--------|\n| `--log-level` | æ—¥å¿—çº§åˆ« | info | error / warn / info / debug / silent |\n\n## 3. å®žç”¨ç¤ºä¾‹\n\n### ðŸ“Œ åŸºç¡€æ‰«æ\n\n```bash\n# å¯å‘å¼æ‰«æ - æ ‡å‡†ï¼ˆ512 å€™é€‰ï¼Œé»˜è®¤ï¼‰\nrusub enum target.com\n\n# å¯å‘å¼æ‰«æ - æ·±åº¦ï¼ˆ1024 å€™é€‰ï¼‰\nrusub enum target.com --heuristic-max 1024\n\n# å¯å‘å¼æ‰«æ - å…¨é¢ï¼ˆ2048 å€™é€‰ï¼‰\nrusub enum target.com --heuristic-max 2048\n\n# å¯å‘å¼æ‰«æ - è½»é‡ï¼ˆ256 å€™é€‰ï¼‰\nrusub enum target.com --heuristic-max 256\n\n# ä½¿ç”¨è‡ªå®šä¹‰å­—å…¸\nrusub enum target.com -f custom.txt\n\n# å¤šåŸŸåæ‰«æ\nrusub enum -d target.com -d example.com -d test.com\n\n# ä»Žæ–‡ä»¶è¯»å–åŸŸååˆ—è¡¨\nrusub enum --domain-list domains.txt\n\n# ä»Žæ ‡å‡†è¾“å…¥è¯»å–\ncat domains.txt | rusub enum --stdin\n```\n\n### ðŸ“Š è¾“å‡ºæŽ§åˆ¶\n\n```bash\n# JSONL æ ¼å¼ï¼ˆé»˜è®¤ï¼‰\nrusub enum target.com -o results.jsonl\n\n# JSON æ ¼å¼\nrusub enum target.com --output-type json -o results.json\n\n# CSV æ ¼å¼\nrusub enum target.com --output-type csv -o results.csv\n\n# TXT æ ¼å¼\nrusub enum target.com --output-type txt -o results.txt\n\n# è‡ªåŠ¨åŽ‹ç¼©\nrusub enum target.com -o results.jsonl.gz\n\n# æå–å­åŸŸå\nrusub enum target.com | jq -r '.subdomain'\n\n# æå– IP åœ°å€\nrusub enum target.com | jq -r '.answers[]'\n\n# è¿‡æ»¤ç‰¹å®šå­åŸŸ\nrusub enum target.com | grep -E \"admin|api|dev\"\n```\n\n### ðŸŽ¯ DNS é…ç½®\n\n```bash\n# ä½¿ç”¨ç³»ç»Ÿ DNSï¼ˆé»˜è®¤ï¼‰\nrusub enum target.com\n\n# æŒ‡å®šå•ä¸ª DNS\nrusub enum target.com -r 8.8.8.8\n\n# æŒ‡å®šå¤šä¸ª DNS\nrusub enum target.com -r 8.8.8.8 -r 1.1.1.1 -r 1.0.0.1\n\n# ä½¿ç”¨å›½å†… DNS\nrusub enum target.com -r 114.114.114.114 -r 223.5.5.5\n```\n\n### âš¡ æ€§èƒ½è°ƒä¼˜\n\n```bash\n# å¿«é€Ÿæ‰«æï¼ˆä½Žå¹¶å‘ï¼‰\nrusub enum target.com -c 200 --timeout 3\n\n# æ ‡å‡†æ‰«æï¼ˆé»˜è®¤ï¼‰\nrusub enum target.com -c 500 --timeout 6\n\n# é«˜é€Ÿæ‰«æï¼ˆé«˜å¹¶å‘ï¼‰\nrusub enum target.com -c 2000 -b 50M --timeout 3\n\n# æžé€Ÿæ‰«æï¼ˆé€‚åˆå†…ç½‘ï¼‰\nrusub enum target.com -c 5000 -b 100M --timeout 2 --retry 1\n```\n\n### ðŸ”„ å®žç”¨æŠ€å·§\n\n```bash\n# å®žæ—¶ç›‘æŽ§ + ä¿å­˜ç»“æžœ\nrusub enum target.com | tee results.jsonl\n\n# é™é»˜æ¨¡å¼ï¼ˆæ— æ—¥å¿—ï¼‰\nrusub enum target.com --log-level silent\n\n# æ–­ç‚¹ç»­ä¼ ï¼ˆè‡ªåŠ¨ï¼‰\nrusub enum target.com -f big-wordlist.txt -o results.jsonl\n# ä¸­æ–­åŽé‡æ–°è¿è¡Œç›¸åŒå‘½ä»¤å³å¯ç»§ç»­\n\n# æ‰¹é‡å¤„ç†\nfor domain in $(cat targets.txt); do\n    rusub enum $domain -o ${domain}.jsonl\ndone\n\n# å·¥å…·é“¾ç»“åˆ\nrusub enum target.com | jq -r '.subdomain' | httpx -silent | grep \"200\"\n\n# è¿‡æ»¤å¹¶æå–æ´»è·ƒå­åŸŸ\nrusub enum target.com | jq -r 'select(.answers != null) | .subdomain'\n```\n\n## 4. è¾“å‡ºæ ¼å¼\n\n### ðŸ“Š JSONLï¼ˆé»˜è®¤ï¼‰\n\næµå¼ JSONï¼Œæ¯è¡Œä¸€ä¸ªè®°å½•ï¼š\n\n```json\n{\"subdomain\":\"www.example.com\",\"answers\":[\"93.184.216.34\"],\"records\":[{\"rtype\":\"A\",\"data\":\"93.184.216.34\"}]}\n{\"subdomain\":\"api.example.com\",\"answers\":[\"10.0.0.1\",\"10.0.0.2\"],\"records\":[{\"rtype\":\"A\",\"data\":\"10.0.0.1\"},{\"rtype\":\"A\",\"data\":\"10.0.0.2\"}]}\n```\n\n*",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-28T02:27:17.138623"
  },
  {
    "basic_info": {
      "name": "pctx",
      "full_name": "portofcontext/pctx",
      "owner": "portofcontext",
      "description": "The pctx framework replaces LLM tool calling with a Code Mode that runs in secure sandboxes.",
      "url": "https://github.com/portofcontext/pctx",
      "clone_url": "https://github.com/portofcontext/pctx.git",
      "ssh_url": "git@github.com:portofcontext/pctx.git",
      "homepage": "https://portofcontext.com",
      "created_at": "2025-11-04T16:54:23Z",
      "updated_at": "2025-11-27T18:45:45Z",
      "pushed_at": "2025-11-27T18:52:26Z"
    },
    "stats": {
      "stars": 155,
      "forks": 15,
      "watchers": 155,
      "open_issues": 7,
      "size": 20442
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 343757,
        "JavaScript": 13995,
        "Python": 5489,
        "Shell": 762,
        "Handlebars": 751
      },
      "license": "MIT License",
      "topics": [
        "ai-agents",
        "api",
        "infrastructure",
        "local-development",
        "mcp",
        "mcp-server",
        "open-source"
      ]
    },
    "content": {
      "readme": "<div align=\"center\">\n  <img src=\".github/assets/logo.png\" alt=\"PCTX Logo\" style=\"height: 128px\">\n  <h1>pctx</h1>\n\n[![Made by](https://img.shields.io/badge/MADE%20BY-Port%20of%20Context-1e40af.svg?style=for-the-badge&labelColor=0c4a6e)](https://portofcontext.com)\n\n[![NPM Version](https://img.shields.io/npm/v/%40portofcontext%2Fpctx)](https://www.npmjs.com/package/@portofcontext/pctx)\n[![Rust](https://img.shields.io/badge/rust-1.89%2B-blue.svg)](https://www.rust-lang.org)\n\n</div>\n\n<div align=\"center\">\n\nThe open source framework to connect AI agents to tools and services with [code mode](#what-is-code-mode)\n\n</div>\n\n## Install\n\n```bash\n# Homebrew\nbrew install portofcontext/tap/pctx\n\n# cURL\ncurl --proto '=https' --tlsv1.2 -LsSf https://raw.githubusercontent.com/portofcontext/pctx/main/install.sh | sh\n\n# npm\nnpm i -g @portofcontext/pctx\n```\n\n## Quick Start\n\n```bash\n# Initialize config for upstream mcp connections\npctx init\n\n# Connect to any MCP server\npctx add my-local-server http://localhost:3000/mcp\npctx add stripe https://mcp.stripe.com\n\n# Start the unified MCP server in dev mode\npctx dev\n\n# copy the pctx url and connect to agents with --transport http\n```\n\nFor complete CLI documentation, see [CLI.md](docs/CLI.md).\nFor configuration options, see [Configuration Guide](docs/config.md).\n\n<img width=\"1020\" height=\"757\" alt=\"Screenshot 2025-11-21 at 11 03 20â€¯AM\" src=\"https://github.com/user-attachments/assets/d61be46d-5a4b-40fd-953a-7dc725266e63\" />\n\n\n## What is pctx?\n\n`pctx` sits between AI agents and MCP servers. It aggregates multiple upstream MCP servers, handles authentication, and exposes tools through a unified [Code Mode](#what-is-code-mode) interface. Instead of agents managing connections to individual MCP servers, they connect once to pctx.\n\n## What is Code Mode?\n\nCode mode replaces sequential tool calling with code execution. Rather than an agent calling tools one at a time and passing results through its context window, it writes TypeScript code that executes in a sandbox. Read Anthropic's overview [here](https://www.anthropic.com/engineering/code-execution-with-mcp).\n\n**Traditional MCP flow**:\n\n1. Agent calls `getSheet(id)`\n2. Server returns 1000 rows â†’ agent's context\n3. Agent calls `filterRows(criteria)`\n4. Server returns 50 rows â†’ agent's context\n\n**With Code Mode**:\n\n```typescript\nconst sheet = await gdrive.getSheet({ sheetId: \"abc\" });\nconst orders = sheet.filter((row) => row.status === \"pending\");\nconsole.log(`Found ${orders.length} orders`);\n```\n\n**Result:** 98.7% reduction in tokens (150k â†’ 2k) for this multi-step operation.\n\n## Features\n\n- **Code Mode interface**: Tools exposed as TypeScript functions for efficient agent interaction. See [Code Mode Guide](docs/code-mode.md).\n- **Upstream MCP server aggregation**: Connect to multiple MCP servers through a single interface. See [Upstream MCP Servers Guide](docs/upstream-mcp-servers.md).\n- **Simple config with CLI**: Create the pctx.json config with a simple CLI. pctx.json manages auth, upstream MCPs, logging, and more. See [Config Guide](docs/config.md).\n- **Secure authentication**: Source secrets from environment variables, system keychain, and external commands. See [Authentication Section](docs/config.md#authentication) in the CLI configuration docs for more details.\n\n## Architecture\n\n```\n    Runs locally â€¢ in docker â€¢ any cloud\n\n  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n  â”‚      AI Agents (Bring any LLM)  â”‚\n  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€-â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                â”‚ MCP\n                â”‚ â€¢ list_functions\n                â”‚ â€¢ get_function_details\n                â”‚ â€¢ execute\n  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n  â”‚            pctx                 â”‚\n  â”‚                                 â”‚\n  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚\n  â”‚  â”‚  TypeScript Compiler    â”‚    â”‚\n  â”‚  â”‚  Sandbox (Deno)         â”‚    â”‚\n  â”‚  â”‚                         â”‚    â”‚\n  â”‚  â”‚  â€¢ Type checking        â”‚    â”‚\n  â”‚  â”‚  â€¢ Rich error feedback  â”‚    â”‚\n  â”‚  â”‚  â€¢ No network access    â”‚    â”‚\n  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\n  â”‚             â”‚ Compiled JS       â”‚\n  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚\n  â”‚  â”‚  Execution Sandbox      â”‚    â”‚\n  â”‚  â”‚  (Deno Runtime)         â”‚    â”‚\n  â”‚  â”‚                         â”‚    â”‚\n  â”‚  â”‚  â€¢ Authenticated MCP    â”‚    â”‚\n  â”‚  â”‚    client connections   â”‚    â”‚\n  â”‚  â”‚  â€¢ Restricted network   â”‚    â”‚\n  â”‚  â”‚  â€¢ Tool call execution  â”‚    â”‚\n  â”‚  â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\n  â””â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n        â”‚      â”‚      â”‚\n        â†“      â†“      â†“\n    â”Œâ”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”\n    â”‚Local â”‚Slack â”‚GitHubâ”‚Customâ”‚\n    â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜\n```\n\n## Security\n\n- LLM generated code runs in an isolated [Deno](https://deno.com) sandbox that can only access the network hosts specified in the configuration file.\n- No filesystem, environment, network (beyond allowed hosts), or system access.\n- MCP clients are authenticated in pctx. LLMs can never see your auth.\n\n## Update\n\nDepending on the installation method (Homebrew/npm/cURL) the update method is differe",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-28T02:27:18.328933"
  },
  {
    "basic_info": {
      "name": "docx_compressor",
      "full_name": "adysec/docx_compressor",
      "owner": "adysec",
      "description": "ä¸€ä¸ªè½»é‡çº§çš„è·¨å¹³å°å·¥å…·ï¼Œç”¨äºŽåŽ‹ç¼© Word (.docx) æ–‡ä»¶ä¸­çš„å›¾ç‰‡ï¼Œæ˜¾è‘—å‡å°æ–‡æ¡£ä½“ç§¯ã€‚æ”¯æŒ Windows ä¸Ž Linuxï¼Œæ‹¥æœ‰ç®€æ´çš„å›¾å½¢åŒ–ç•Œé¢ã€‚",
      "url": "https://github.com/adysec/docx_compressor",
      "clone_url": "https://github.com/adysec/docx_compressor.git",
      "ssh_url": "git@github.com:adysec/docx_compressor.git",
      "homepage": "https://github.com/adysec/docx_compressor",
      "created_at": "2025-11-05T03:51:40Z",
      "updated_at": "2025-11-26T09:53:54Z",
      "pushed_at": "2025-11-07T02:02:39Z"
    },
    "stats": {
      "stars": 151,
      "forks": 143,
      "watchers": 151,
      "open_issues": 0,
      "size": 58
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 10071
      },
      "license": "GNU General Public License v3.0",
      "topics": [
        "docs",
        "docx"
      ]
    },
    "content": {
      "readme": "# ðŸ“˜ DOCX å›¾ç‰‡åŽ‹ç¼©å™¨\n\n**DOCX Compressor** æ˜¯ä¸€ä¸ªè½»é‡çº§ã€è·¨å¹³å°çš„å›¾å½¢åŒ–å·¥å…·ï¼Œç”¨äºŽåŽ‹ç¼© Word (`.docx`) æ–‡æ¡£ä¸­çš„å›¾ç‰‡ï¼Œä»¥å‡å°æ–‡ä»¶ä½“ç§¯ã€‚  \né€‚åˆç”¨äºŽç¼–å†™æ ‡ä¹¦ã€æŠ¥å‘Šã€è®ºæ–‡ç­‰éœ€è¦å‡å°ä¸Šä¼ å¤§å°çš„æ–‡æ¡£åœºæ™¯ã€‚\n\n---\n\n## âœ¨ åŠŸèƒ½ç‰¹ç‚¹\n\n- ðŸ–¼ï¸ **æ™ºèƒ½å›¾ç‰‡åŽ‹ç¼©**ï¼šè‡ªåŠ¨æ£€æµ‹ DOCX å†…çš„æ‰€æœ‰å›¾ç‰‡å¹¶æŒ‰æŒ‡å®šè´¨é‡ä¸Žå°ºå¯¸è¿›è¡ŒåŽ‹ç¼©ã€‚  \n- âš™ï¸ **å¯è°ƒå‚æ•°**ï¼šè‡ªå®šä¹‰å›¾ç‰‡åŽ‹ç¼©è´¨é‡ï¼ˆ1-100ï¼‰ä¸Žæœ€å¤§åˆ†è¾¨çŽ‡ï¼ˆå®½åº¦ï¼‰ã€‚  \n- ðŸ’¾ **ä¿æŒæ–‡æ¡£ç»“æž„**ï¼šä»…åŽ‹ç¼©å›¾ç‰‡ï¼Œä¸å½±å“æ–‡å­—ã€æ ¼å¼æˆ–æ ·å¼ã€‚  \n- ðŸ’» **è·¨å¹³å°æ”¯æŒ**ï¼šåŸºäºŽeguiæä¾›å›¾å½¢åŒ–ç•Œé¢\n  - âœ… Windowsï¼ˆè‡ªåŠ¨éšè—æŽ§åˆ¶å°çª—å£ï¼‰\n  - âœ… Linuxï¼ˆåŒæ—¶æ”¯æŒ Wayland ä¸Ž X11 æ¡Œé¢çŽ¯å¢ƒï¼‰\n- ðŸŒ **ä¸­æ–‡ç•Œé¢**ï¼šå†…ç½® Noto Sans CJK å­—ä½“ï¼Œå®Œç¾Žæ˜¾ç¤ºä¸­æ–‡ã€‚\n\n---\n\n<img width=\"1402\" height=\"1068\" alt=\"å›¾ç‰‡\" src=\"https://github.com/user-attachments/assets/fbee7718-5f4d-4cdf-8ff2-c634a49839e7\" />\n\n## ðŸ–¥ï¸ ä½¿ç”¨æ–¹æ³•\n\n1. **è¿è¡Œç¨‹åº**\n   - Windows ç”¨æˆ·ï¼šç›´æŽ¥åŒå‡» `docx_compressor.exe`\n   - Linux ç”¨æˆ·ï¼šæ‰§è¡Œ `./docx_compressor`\n\n2. **é€‰æ‹©è¾“å…¥æ–‡ä»¶**\n   - ç‚¹å‡»ã€ŒðŸ“‚ è¾“å…¥æ–‡ä»¶ã€é€‰æ‹© `.docx` æ–‡æ¡£ã€‚\n\n3. **è®¾ç½®å‚æ•°**\n   - åŽ‹ç¼©è´¨é‡ï¼ˆ1â€“100ï¼Œé»˜è®¤ 70ï¼‰\n   - æœ€å¤§å®½åº¦ï¼ˆé»˜è®¤ 1280pxï¼‰\n\n4. **é€‰æ‹©è¾“å‡ºæ–‡ä»¶è·¯å¾„**\n   - é»˜è®¤è¾“å‡ºåˆ°åŒç›®å½•ä¸‹ï¼Œæ–‡ä»¶åä¸º `åŽŸæ–‡ä»¶å_åŽ‹ç¼©åŽ.docx`\n\n5. **ç‚¹å‡»ã€ŒðŸš€ å¼€å§‹åŽ‹ç¼©ã€**\n   - è¿›åº¦æ¡ä¸Žè€—æ—¶å°†å®žæ—¶æ˜¾ç¤ºã€‚\n\n---\n\n## ðŸ§© æž„å»ºè¯´æ˜Ž\n\n### ä¾èµ–é¡¹\n\nè¯·ç¡®ä¿ç³»ç»Ÿå·²å®‰è£…ä»¥ä¸‹ä¾èµ–ï¼š\n\n- Rust 1.75 æˆ–æ›´é«˜ç‰ˆæœ¬  \n- `libfontconfig`ï¼ˆLinuxï¼‰  \n- C ç¼–è¯‘å·¥å…·é“¾ï¼ˆå¦‚ `mingw`ï¼‰\n\n### æž„å»ºå‘½ä»¤\n\n```bash\n# å…‹éš†ä»“åº“\ngit clone https://github.com/AdySec/docx-compressor.git\ncd docx-compressor\n\n# æž„å»ºå¯æ‰§è¡Œæ–‡ä»¶\ncargo build --release\ncargo build --release --target x86_64-unknown-linux-gnu\ncargo build --release --target x86_64-pc-windows-gnu\n\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-28T02:27:19.497427"
  },
  {
    "basic_info": {
      "name": "magnolia",
      "full_name": "tuist/magnolia",
      "owner": "tuist",
      "description": "Run your CI pipelines locally",
      "url": "https://github.com/tuist/magnolia",
      "clone_url": "https://github.com/tuist/magnolia.git",
      "ssh_url": "git@github.com:tuist/magnolia.git",
      "homepage": null,
      "created_at": "2025-11-13T15:42:56Z",
      "updated_at": "2025-11-27T22:32:53Z",
      "pushed_at": "2025-11-27T09:50:36Z"
    },
    "stats": {
      "stars": 150,
      "forks": 6,
      "watchers": 150,
      "open_issues": 3,
      "size": 203
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 113855
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# ðŸŒ¸ Magnolia\n<!-- ALL-CONTRIBUTORS-BADGE:START - Do not remove or modify this section -->\n[![All Contributors](https://img.shields.io/badge/all_contributors-1-orange.svg?style=flat-square)](#contributors-)\n<!-- ALL-CONTRIBUTORS-BADGE:END -->\n\nRun GitLab CI, GitHub Actions, and Forgejo pipelines locally.\n\n> [!IMPORTANT]\n> This project is in the ideation phase. We may open PRs and address issues, but we're not actively monitoring repository activity.\n\n## ðŸŒ¸ The Magnolia Manifesto\n\n**[Verse 1]**<br>\nThey say that if you were to see<br>\nYour CI running locally<br>\nIn that terminal window, free<br>\nIt brings you good luck<br>\nAll of you have come<br>\nEven the vendors who dismissed us<br>\nToday, they watch\n\n**[Chorus]**<br>\nThrow magnolias at me<br>\nRun your pipelines locally<br>\nThrow magnolias at me<br>\nOwn your CI destiny\n\n**[Verse 2]**<br>\nOver their platforms, open forges burning bright<br>\nTears and FUD melt into the code<br>\nGitLab and GitHub, Forgejo's might<br>\nDancing with freedom on top of vendor lock<br>\nToday it's all sovereignty mocking fate<br>\nAnd what you couldn't test locally, you test before you commit\n\n## ðŸ“¦ Installation\n\n```bash\nmise use -g ubi:tuist/magnolia\n```\n\nOr download from [releases](https://github.com/tuist/magnolia/releases).\n\n## ðŸš€ Usage\n\n### Running Pipelines Locally\n\nTest your CI/CD pipelines before pushing to your Git forge:\n\n```bash\n# Interactive mode - discover and select pipeline\nmagnolia\n\n# Run a specific workflow\nmagnolia .github/workflows/test.yml\n\n# Run a specific job from a workflow\nmagnolia .github/workflows/test.yml\n# Then select the job interactively\n\n# Run non-interactively (useful for scripts)\nmagnolia .github/workflows/test.yml --job test --non-interactive\n```\n\n**Example workflow:**\n```bash\n$ magnolia .github/workflows/ci.yml\nDiscovering pipelines...\nSelect a pipeline: GitHub Actions: ci.yml\n\nSelect a job to run:\n  > build\n    test\n    deploy\n\nRunning job build from .github/workflows/ci.yml\nâœ“ Step: Checkout code\nâœ“ Step: Install dependencies\nâœ“ Step: Build application\n```\n\n### Migrating from External CI Providers\n\nSeamlessly migrate from external CI providers to your Git forge's native CI using AI-powered translation:\n\n```bash\n# Auto-detect source and target CI systems\nmagnolia migrate\n\n# Preview migration without writing files\nmagnolia migrate --dry-run\n\n# Override target CI system\nmagnolia migrate --to github\n\n# Migrate specific source when multiple configs found\nmagnolia migrate bitrise\n\n# Automated migration (non-interactive)\nmagnolia migrate bitrise --non-interactive\n```\n\n**Example migration:**\n```bash\n$ magnolia migrate bitrise --dry-run --to github\nDetecting CI configurations...\nSource: Bitrise (bitrise.yml)\nTarget: GitHub Actions\n\nInitializing AI agent for migration...\n\nðŸ“‹ Step 1/3: Analyzing source configuration...\n  â†’ Reading Bitrise pipeline from bitrise.yml\n\nðŸ” Step 2/3: Researching CI system documentation and generating configuration...\n  â†’ Consulting Bitrise and GitHub Actions documentation\n  â†’ This may take 30-60 seconds...\n\nâœ… Step 3/3: Migration complete!\n\nDry run - migration preview:\n\nGenerated configuration:\n================================================================================\nname: CI/CD Pipeline\n\non:\n  push:\n    branches: ['**']\n\njobs:\n  primary:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Install dependencies\n        run: npm install\n      - name: Run tests\n        run: npm test\n      - name: Build\n        run: npm run build\n================================================================================\n\nWould be written to: .github/workflows/migrated-workflow.yml\n```\n\n**Common migration scenarios:**\n```bash\n# CircleCI â†’ GitHub Actions\nmagnolia migrate circleci --to github\n\n# Buildkite â†’ GitLab CI\nmagnolia migrate buildkite --to gitlab\n\n# Mobile app (AppCircle) â†’ GitHub Actions\nmagnolia migrate appcircle --to github\n```\n\n**Supported Migration Sources:**\n- Bitrise (`bitrise.yml` or `.bitrise/bitrise.yml`)\n- Codemagic (`codemagic.yaml` or `.codemagic/codemagic.yaml`)\n- CircleCI (`.circleci/config.yml`)\n- AppCircle (`appcircle.yaml`, `configuration.yaml`, or `.appcircle/config.yaml`)\n- Buildkite (`.buildkite/pipeline.yml` or `.buildkite/pipeline.yaml`)\n\n**Migration Targets (auto-detected from git remote):**\n- GitHub Actions (`.github/workflows/*.yml`)\n- GitLab CI (`.gitlab-ci.yml`)\n- Forgejo Actions (`.forgejo/workflows/*.yml`)\n\n**Requirements:**\n- Install either `claude` or `codex` CLI for AI-powered migration\n- The migration feature uses the agentic client protocol to delegate complex translation tasks\n\n### âš¡ Execution\n\n- **GitLab CI**: Executes jobs in containers (Podman/Docker) when `image:` is specified, or on host otherwise.\n- **GitHub Actions / Forgejo Actions**:\n  - Executes `run:` steps in containers based on `runs-on:` runner\n  - Executes marketplace actions (`uses:`) - composite, Docker, and Node.js actions supported\n  - Actions are downloaded once and cached locally in `~/.magnolia/actions",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-28T02:27:20.764438"
  },
  {
    "basic_info": {
      "name": "cc-switch-cli",
      "full_name": "SaladDay/cc-switch-cli",
      "owner": "SaladDay",
      "description": "â­ï¸ A cross-platform CLI All-in-One assistant tool for Claude Code, Codex & Gemini CLI.",
      "url": "https://github.com/SaladDay/cc-switch-cli",
      "clone_url": "https://github.com/SaladDay/cc-switch-cli.git",
      "ssh_url": "git@github.com:SaladDay/cc-switch-cli.git",
      "homepage": null,
      "created_at": "2025-11-23T11:15:12Z",
      "updated_at": "2025-11-28T01:33:24Z",
      "pushed_at": "2025-11-25T16:51:11Z"
    },
    "stats": {
      "stars": 145,
      "forks": 8,
      "watchers": 145,
      "open_issues": 3,
      "size": 23150
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 590256,
        "JavaScript": 18565,
        "Shell": 7469
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "<div align=\"center\">\n\n# CC-Switch CLI\n\n[![Version](https://img.shields.io/badge/version-4.1.1-blue.svg)](https://github.com/saladday/cc-switch-cli/releases)\n[![Platform](https://img.shields.io/badge/platform-Windows%20%7C%20macOS%20%7C%20Linux-lightgrey.svg)](https://github.com/saladday/cc-switch-cli/releases)\n[![Built with Rust](https://img.shields.io/badge/built%20with-Rust-orange.svg)](https://www.rust-lang.org/)\n[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)\n\n**Command-Line Management Tool for Claude Code, Codex & Gemini CLI**\n\nUnified management for Claude Code, Codex & Gemini CLI provider configurations, MCP servers, Skills extensions, and system prompts.\n\n[English](README.md) | [ä¸­æ–‡](README_ZH.md)\n\n</div>\n\n---\n\n## ðŸ“– About\n\nThis project is a **CLI fork** of [CC-Switch](https://github.com/farion1231/cc-switch).\n\n\n**Credits:** Original architecture and core functionality from [farion1231/cc-switch](https://github.com/farion1231/cc-switch)\n\n---\n\n## ðŸ“¸ Screenshots\n\n<table>\n  <tr>\n    <th>Interactive Main Menu</th>\n    <th>Provider Management</th>\n  </tr>\n  <tr>\n    <td><img src=\"assets/screenshots/main-en.png\" alt=\"Main Menu\" width=\"100%\"/></td>\n    <td><img src=\"assets/screenshots/add-en.png\" alt=\"Provider Management\" width=\"100%\"/></td>\n  </tr>\n</table>\n\n---\n\n## ðŸš€ Quick Start\n\n**Interactive Mode (Recommended)**\n```bash\ncc-switch\n```\nðŸ¤© Follow on-screen menus to explore features.\n\n**Command-Line Mode**\n```bash\ncc-switch provider list              # List providers\ncc-switch provider switch <id>       # Switch provider\ncc-switch mcp sync                   # Sync MCP servers\n\n# Use the global `--app` flag to target specific applications:\ncc-switch --app claude provider list    # Manage Claude providers\ncc-switch --app codex mcp sync          # Sync Codex MCP servers\ncc-switch --app gemini prompts list     # List Gemini prompts\n\n# Supported apps: `claude` (default), `codex`, `gemini`\n```\n\nSee the \"Features\" section below for full command list.\n\n---\n\n## âœ¨ Features\n\n### ðŸ”Œ Provider Management\n\nManage API configurations for **Claude Code**, **Codex**, and **Gemini**.\n\n**Features:** One-click switching, multi-endpoint support, API key management, speed testing, provider duplication.\n\n```bash\ncc-switch provider list              # List all providers\ncc-switch provider current           # Show current provider\ncc-switch provider switch <id>       # Switch provider\ncc-switch provider add               # Add new provider\ncc-switch provider edit <id>         # Edit existing provider\ncc-switch provider duplicate <id>    # Duplicate a provider\ncc-switch provider delete <id>       # Delete provider\ncc-switch provider speedtest <id>    # Test API latency\n```\n\n### ðŸ› ï¸ MCP Server Management\n\nManage Model Context Protocol servers across Claude/Codex/Gemini.\n\n**Features:** Unified management, multi-app support, three transport types (stdio/http/sse), automatic sync, smart TOML parser.\n\n```bash\ncc-switch mcp list                   # List all MCP servers\ncc-switch mcp add                    # Add new MCP server (interactive)\ncc-switch mcp edit <id>              # Edit MCP server\ncc-switch mcp delete <id>            # Delete MCP server\ncc-switch mcp enable <id> --app claude   # Enable for specific app\ncc-switch mcp disable <id> --app claude  # Disable for specific app\ncc-switch mcp validate <command>     # Validate command in PATH\ncc-switch mcp sync                   # Sync to live files\ncc-switch mcp import --app claude    # Import from live config\n```\n\n### ðŸ’¬ Prompts Management\n\nManage system prompt presets for AI coding assistants.\n\n**Cross-app support:** Claude (`CLAUDE.md`), Codex (`AGENTS.md`), Gemini (`GEMINI.md`).\n\n```bash\ncc-switch prompts list               # List prompt presets\ncc-switch prompts current            # Show current active prompt\ncc-switch prompts activate <id>      # Activate prompt\ncc-switch prompts deactivate         # Deactivate current active prompt\ncc-switch prompts create             # Create new prompt preset\ncc-switch prompts edit <id>          # Edit prompt preset\ncc-switch prompts show <id>          # Display full content\ncc-switch prompts delete <id>        # Delete prompt\n```\n\n### ðŸŽ¯ Skills Management\n\nâš ï¸ **Note: Not yet implemented in v4.1.x** - This feature is planned for future releases.\n\nManage and extend Claude Code/Codex/Gemini capabilities with community skills.\n\n**Features:** Search skill marketplace, install/uninstall, repository management, skill information.\n\n```bash\ncc-switch skills list                # List installed skills\ncc-switch skills search <query>      # Search available skills\ncc-switch skills install <name>      # Install a skill\ncc-switch skills uninstall <name>    # Uninstall a skill\ncc-switch skills info <name>         # Show skill information\ncc-switch skills repos               # Manage skill repositories\n```\n\n### âš™ï¸ Configuration Management\n\nManage configuration backups, imports, and exports.\n\n**Features:** Custom backup naming, interactive b",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-28T02:27:21.929438"
  },
  {
    "basic_info": {
      "name": "dht-spider",
      "full_name": "adysec/dht-spider",
      "owner": "adysec",
      "description": "Rust å®žçŽ°çš„ BitTorrent DHTï¼ˆBEPâ€‘5ï¼‰ä¸Žçˆ¬è™«ï¼Œå¹¶å†…ç½®å…ƒæ•°æ®ä¸‹è½½ï¼ˆBEPâ€‘9/10ï¼‰ä¸Ž PeXï¼ˆBEPâ€‘11/ut_pexï¼‰ã€‚",
      "url": "https://github.com/adysec/dht-spider",
      "clone_url": "https://github.com/adysec/dht-spider.git",
      "ssh_url": "git@github.com:adysec/dht-spider.git",
      "homepage": null,
      "created_at": "2025-11-13T03:25:51Z",
      "updated_at": "2025-11-26T08:02:33Z",
      "pushed_at": "2025-11-13T03:29:12Z"
    },
    "stats": {
      "stars": 141,
      "forks": 142,
      "watchers": 141,
      "open_issues": 0,
      "size": 30
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 78483
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# dht-spider\n\nRust å®žçŽ°çš„ BitTorrent DHTï¼ˆBEPâ€‘5ï¼‰ä¸Žçˆ¬è™«ï¼Œå¹¶å†…ç½®å…ƒæ•°æ®ä¸‹è½½ï¼ˆBEPâ€‘9/10ï¼‰ä¸Ž PeXï¼ˆBEPâ€‘11/ut_pexï¼‰ã€‚\n\nçŽ°åœ¨åªæ”¯æŒä¸€ç§ç”¨æ³•ï¼šcargo runã€‚æ‰€æœ‰èƒ½åŠ›å‡å·²æ•´åˆè¿›ä¸»ç¨‹åºå¹¶ä»¥ JSONL è¾“å‡ºã€‚\n\n## ç‰¹æ€§æ¦‚è§ˆ\n\n- æ¨¡å¼ï¼š\n  - Standardï¼šä¸¥æ ¼éµå¾ª DHT åè®®\n  - Crawlï¼šåå‘å—…æŽ¢ infohashï¼ˆä¿ƒä½¿å¯¹ç«¯ announce_peerï¼‰\n- KRPCï¼šping / find_node / get_peers / announce_peerï¼ˆå…¥ç«™ä¸Žé€’å½’ï¼‰\n- è·¯ç”±ï¼šKâ€‘Bucket åˆ†è£‚/å€™é€‰ã€XOR è·ç¦»é‚»å±…é€‰æ‹©ã€pingâ€‘thenâ€‘replace ç»´æŠ¤\n- äº‹åŠ¡ï¼šè¶…æ—¶æŒ‡æ•°é€€é¿é‡è¯•ã€é»‘åå•ï¼›token æ ¡éªŒ\n- å…ƒæ•°æ®ï¼šé›†æˆ Wireï¼ˆBEPâ€‘9/10ï¼‰ä¸‹è½½ .torrent metadata\n- PeXï¼šå¯¹ç­‰äº¤æ¢ï¼ˆBEPâ€‘11/ut_pexï¼‰å‘çŽ°æ›´å¤š peers\n  - æ‰©å±•æ¡æ‰‹å£°æ˜Ž ut_pex\n  - è§£æž `added`ï¼ˆç´§å‡‘ IPv4ï¼‰ä¸­çš„ peersï¼Œå¹¶ï¼š\n    1) ç»Ÿä¸€è¾“å‡ºä¸º `type=peer` çš„ JSON è¡Œ\n    2) è‡ªåŠ¨åŠ å…¥æŠ“å–é˜Ÿåˆ—å°è¯•ä¸‹è½½å¯¹åº” infohash çš„ metadata\n\n## å¿«é€Ÿå¼€å§‹\n\næž„å»ºä¸Žè¿è¡Œï¼š\n\n```zsh\ncargo build --release\ncargo run\n```\n\nè¿è¡Œæ—¶è¡Œä¸ºï¼š\n\n- é»˜è®¤æ¨¡å¼ï¼šCrawl\n- é»˜è®¤ç›‘å¬ï¼šUDP 0.0.0.0:6881\n- è¾“å‡ºæ ¼å¼ï¼šJSONLï¼ˆæ¯è¡Œä¸€ä¸ªäº‹ä»¶ï¼‰\n\nç¤ºä¾‹è¾“å‡ºï¼ˆéƒ¨åˆ†ï¼‰ï¼š\n\n```json\n{\"type\":\"peer\",\"ip\":\"203.0.113.7\",\"port\":51413,\"info_hash\":\"a1b2...c3d4\"}\n{\"type\":\"metadata\",\"infohash\":\"a1b2...c3d4\",\"name\":\"SomePack\",\"files\":[{\"path\":[\"dir\",\"file1.mkv\"],\"length\":12345}]}\n{\"type\":\"node\",\"id\":\"a1b2c3...\",\"ip\":\"162.83.157.130\",\"port\":6881}\n```\n\næç¤ºï¼šè‹¥ç«¯å£è¢«å ç”¨ï¼Œå¯åŠ¨ä¼šè¾“å‡ºé”™è¯¯å¹¶é€€å‡ºï¼Œä¾‹å¦‚ï¼š\n\n```json\n{\"level\":\"error\",\"event\":\"startup\",\"error\":\"IO error: Address already in use (os error 98)\"}\n```\n\n## é…ç½®ä¸Žé»˜è®¤å€¼\n\næœ¬é¡¹ç›®éµå¾ªâ€œé›¶å‚æ•°å¯è¿è¡Œâ€ï¼Œå¼€ç®±å³ç”¨ã€‚é»˜è®¤å‚æ•°ï¼ˆå¯èƒ½éšç‰ˆæœ¬è°ƒæ•´ï¼‰åŒ…æ‹¬ï¼š\n\n- è·¯ç”±ä¸Žæ¡¶ï¼šk=8ï¼Œkbucket_size=8\n- ç›‘å¬ï¼šUDP 0.0.0.0:6881\n- å¼•å¯¼èŠ‚ç‚¹ï¼ˆprime_nodesï¼‰ï¼šåŒ…å«å¤šç»„å®˜æ–¹/ç¤¾åŒºèŠ‚ç‚¹ï¼ˆç¤ºä¾‹è§ä¸‹ï¼‰ï¼Œä¾‹å¦‚ï¼š\n  - router.bittorrent.com:6881ã€dht.transmissionbt.com:6881ã€router.utorrent.com:6881ã€router.bitcomet.com:6881\n  - dht.aelitis.com:6881ã€dht.libtorrent.org:25401ã€router.bittorrentcloud.com:6881ã€dht.anaconda.com:6881\n  - dht.vuze.com:6881ã€dht.transmissionbt.net:6881ã€router.silotis.us:6881ã€router.ktorrent.com:6881ã€router.tribler.org:6881\n  - router.bittorrent.jp:6881ã€router.cn.utorrent.com:6881ã€router.bittorrent.ru:6881ã€router.bittorrent.kr:6881\n  - å®žé™…åˆ—è¡¨å¯èƒ½éšç‰ˆæœ¬æ›´æ–°è¿›è¡Œè°ƒæ•´\n- å‘¨æœŸä¸Žè¿‡æœŸï¼škbucket_expired_afterâ‰ˆ15 åˆ†é’Ÿã€node_expired_afterâ‰ˆ15 åˆ†é’Ÿã€check_kbucket_periodâ‰ˆ30 ç§’\n- token è¿‡æœŸï¼šâ‰ˆ600 ç§’\n- æœ€å¤§èŠ‚ç‚¹ï¼šâ‰ˆ5000ï¼›é»‘åå•æœ€å¤§ï¼šâ‰ˆ65536\n- è¿è¡Œæ¨¡å¼ï¼šé»˜è®¤ Crawlï¼ˆåå‘è§¦å‘å¯¹ç«¯ announceï¼‰\n- åˆ·æ–°ä¸Žé‡è¯•ï¼šrefresh_node_numâ‰ˆ8ã€try_timesâ‰ˆ2\n\nç»´æŠ¤è¯­ä¹‰ï¼š\n\n- å¯¹è¿‡æœŸ/å¤±æ´»èŠ‚ç‚¹ï¼šå…ˆ pingï¼Œè¶…æ—¶æ‰æ›¿æ¢ï¼›æ— å…¨å±€â€œå®šæœŸè£å‰ªâ€ã€‚\n- Crawl æ¨¡å¼ï¼šå…¥ç«™ get_peers è¿”å›žç©º nodes + tokenï¼Œä¿ƒä½¿å¯¹ç«¯ announce_peerã€‚\n\n## è¡Œä¸ºè¯´æ˜Ž\n\n- KRPC å¤„ç†ã€é€’å½’æŸ¥æ‰¾ä¸Ž announce æµç¨‹éµå¾ª BEP è§„èŒƒï¼›announce_peer ä¼šå¤ç”¨ get_peers èŽ·å–çš„ tokenã€‚\n- è·¯ç”±è¡¨ä¸Žé‚»å±…é€‰æ‹©ï¼ˆXOR è·ç¦»ï¼‰ï¼›èŠ‚ç‚¹æŒ‰ last_active æŽ’åºã€‚\n- é»˜è®¤ prime èŠ‚ç‚¹ã€compact IPv4 åœ°å€ç¼–ç ã€‚\n\n## è¾“å‡ºæ ¼å¼ï¼ˆç»Ÿä¸€ JSON è¡Œï¼‰\n\n- Peerï¼ˆæ¥è‡ª announce_peer / get_peers çš„ values / PeXï¼‰ï¼š\n  {\"type\":\"peer\",\"ip\":\"<ip>\",\"port\":<port>,\"info_hash\":\"<hex>\"}\n- Metadataï¼ˆtorrent ä¿¡æ¯ï¼Œå•/å¤šæ–‡ä»¶ç»Ÿä¸€ï¼‰ï¼š\n  - å§‹ç»ˆè¾“å‡º files æ•°ç»„ï¼›å•æ–‡ä»¶æ—¶ files=[{\"path\":[name],\"length\":...}]\n  - ç¤ºä¾‹ï¼š {\"type\":\"metadata\",\"infohash\":\"<hex>\",\"name\":\"...\",\"files\":[{\"path\":[...],\"length\":...},...]}\n- DHT èŠ‚ç‚¹ï¼ˆè§£æžè‡ª nodesï¼‰ï¼š\n  {\"type\":\"node\",\"id\":\"<20å­—èŠ‚hex>\",\"ip\":\"<ip>\",\"port\":<port>}\n\nè¯´æ˜Žï¼š\n- å½“å‰å®žçŽ°å·²æ”¯æŒ PeX çš„ IPv4 `added` åˆ—è¡¨ï¼›å¦‚éœ€ IPv6ï¼Œå¯åŽç»­æ‰©å±• `added6` çš„è§£æžã€‚\n- ç§æœ‰ç§é€šå¸¸ç¦ç”¨ PeXï¼›ç¨‹åºä¼šè‡ªç„¶å°Šé‡å¯¹ç«¯èƒ½åŠ›ã€‚",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-28T02:27:23.127484"
  },
  {
    "basic_info": {
      "name": "proxychains-rs",
      "full_name": "adysec/proxychains-rs",
      "owner": "adysec",
      "description": "Rust implementation of proxychains â€” injectable library for chaining TCP/UDP connections via multiple proxies.",
      "url": "https://github.com/adysec/proxychains-rs",
      "clone_url": "https://github.com/adysec/proxychains-rs.git",
      "ssh_url": "git@github.com:adysec/proxychains-rs.git",
      "homepage": "",
      "created_at": "2025-11-27T07:26:30Z",
      "updated_at": "2025-11-27T10:03:45Z",
      "pushed_at": "2025-11-27T09:14:04Z"
    },
    "stats": {
      "stars": 139,
      "forks": 139,
      "watchers": 139,
      "open_issues": 0,
      "size": 51
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 345556
      },
      "license": "GNU General Public License v2.0",
      "topics": [
        "proxies",
        "proxychains",
        "proxychains-features",
        "proxychains-ng",
        "proxychains-review",
        "proxychains-rs",
        "rust"
      ]
    },
    "content": {
      "readme": "# proxychains-rs (v5.0.0)\n\nThis document is a concise usage and build guide for the proxychains-rs repository (version 5.0.0). It focuses on building, running and debugging the Rust implementation that provides proxychains-compatible behavior, and also covers common issues.\n\n---\n\n## Overview\n\nproxychains-rs (v5.0.0) is a Rust implementation that aims to be compatible with existing proxychains behavior. Its goal is to produce a shared library that can be injected into target programs using LD_PRELOAD and that behaves (including textual output) consistently with prior implementations. The runtime artifact produced by this project is `libproxychains_rs.so`.\n\nMain runtime artifact (release):\n\n- `target/release/libproxychains_rs.so` â€” the shared object produced by Rust (cdylib).\n\nNote: The supported runtime artifact is `target/release/libproxychains_rs.so`. The project does not rely on producing a compatibility copy named `libproxychains4.so` by default anymore.\n\nTip: this repository contains a `rust-toolchain` pin (nightly). Cargo will automatically use the pinned nightly toolchain when building the project.\n\nImportant: the repository uses some Rust nightly-only features in parts of the codebase (for example `c_variadic` / `extern_types`). Because of this, a nightly toolchain is required to build.\n\n---\n\n## Local build (recommended)\n\n1. Ensure you have rustup installed and enable the nightly toolchain:\n\n```bash\nrustup toolchain install nightly\n```\n\n2. Build the project using cargo from the `proxychains-rs` directory:\n\n```bash\n# Build the Rust portion using the nightly toolchain\nrustup run nightly cargo build -p proxychains_rs --release\n```\n\nThis will produce the shared object under `target/release/libproxychains_rs.so`.\n\n---\n\n## Using with a target program (example)\n\nTo use proxychains-rs with any dynamically linked program that supports LD_PRELOAD, set the configuration file path and LD_PRELOAD the built shared object:\n\n```bash\nPROXYCHAINS_CONF_FILE=/etc/proxychains.conf LD_PRELOAD=target/release/libproxychains_rs.so curl -I https://www.baidu.com\n```\n\nIf you are replacing an existing `proxychains4` script or binary (the C-based tool), the Rust version aims to be consistent in behavior and log text. Using `target/release/libproxychains_rs.so` as LD_PRELOAD should act as a drop-in replacement for the C artifact.\n\nAn example wrapper similar to `/usr/bin/proxychains`:\n\n```sh\n#!/bin/sh\necho \"ProxyChains-5.0\"\nif [ $# = 0 ]; then\n    echo \"\\tusage:\"\n    echo \"\\t\\tproxychains <prog> [args]\"\n    exit\nfi\nexport LD_PRELOAD=libproxychains_rs.so\nexec \"$@\"\n```\n\n---\n\n## Configuration and debugging options\n\n- Configuration file search order (priority):\n  1. `PROXYCHAINS_CONF_FILE` environment variable (or `-f` argument)\n  2. `./proxychains.conf` in the current directory\n  3. `$(HOME)/.proxychains/proxychains.conf`\n  4. System config `/etc/proxychains.conf` (sysconfdir)\n\n- Settings in the configuration file:\n  - `quiet_mode` â€” suppresses the per-connection log lines (same as the C implementation).\n  - `proxy_dns`, `proxy_dns_daemon`, `proxy_dns_old` â€” control remote-DNS (RDNS) behavior/modes.\n\n- Environment variables:\n  - `PROXYCHAINS_VERBOSE_DEBUG=1` â€” enable extra internal debug traces for development and troubleshooting.\n\n---\n\n## Frequently Asked Questions\n\n- Q: Why is a nightly toolchain required to build?\n  - A: The port uses Rust features that are currently only available on the nightly channel (for example `c_variadic` / `extern_types`). That's why the nightly toolchain is required.\n\n---\n\n## Future improvements (suggestions)\n\n- Reduce or remove `unsafe` and `static mut` usage where practical and refactor key paths to be more idiomatic Rust (long-term goal).\n- Improve cross-platform support.\n\n---\n\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-28T02:27:24.315084"
  }
]