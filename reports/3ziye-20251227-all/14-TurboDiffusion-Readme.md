# TurboDiffusion

<div align="center">
<img src=assets/TurboDiffusion_Logo.png width="30%"/>
</div>

This repository provides the official implementation of **TurboDiffusion**, a video generation acceleration framework that can speed up end-to-end diffusion generation by $100 \sim 200\times$ on a single RTX 5090, while maintaining video quality.   
TurboDiffusion primarily uses [SageAttention](https://github.com/thu-ml/SageAttention), [SLA (Sparse-Linear Attention)](https://github.com/thu-ml/SLA) for attention acceleration, and [rCM](https://github.com/NVlabs/rcm) for timestep distillation.

Paper: [TurboDiffusion: Accelerating Video Diffusion Models by 100-200 Times](https://arxiv.org/pdf/2512.16093)

**Note**: the checkpoints and paper are not finalized, and will be updated later to improve quality.

<div align="center">
<img src="assets/TurboDiffusion_speedup.png" width="99%"/>
</div>

<div align="center">
<img src="assets/acceleration_decomposition.png" width="93%"/>
</div>

<div align="center">
<table>
<tr>
<td align="center" style="border: 2px solid #000; padding: 10px;">
<div style="font-size: 1.1em;">Original, E2E Time: 184s</div>
<div><img src="assets/videos/original/1.3B/11.gif" width="387"/></div>
</td>
<td align="center" style="border: 2px solid #000; padding: 10px;">
<div style="font-size: 1.1em;">TurboDiffusion, E2E Time: <b>1.9s</b></div>
<div><img src="assets/videos/turbodiffusion/1.3B/11.gif" width="387"/></div>
</td>
</tr>
</table>
An example of a <b>5-second video</b> generated by Wan-2.1-T2V-1.3B-480P on a single <b>RTX 5090</b>.
</div>

## Available Models

|              Model Name               |                       Checkpoint Link                        | Best Resolution |
| :-----------------------------------: | :----------------------------------------------------------: | :-------------: |
| `TurboWan2.2-I2V-A14B-720P` | [Huggingface Model](https://huggingface.co/TurboDiffusion/TurboWan2.2-I2V-A14B-720P) | 720p            |
| `TurboWan2.1-T2V-1.3B-480P` | [Huggingface Model](https://huggingface.co/TurboDiffusion/TurboWan2.1-T2V-1.3B-480P) | 480p            |
| `TurboWan2.1-T2V-14B-480P`  | [Huggingface Model](https://huggingface.co/TurboDiffusion/TurboWan2.1-T2V-14B-480P) | 480p            |
| `TurboWan2.1-T2V-14B-720P`  | [Huggingface Model](https://huggingface.co/TurboDiffusion/TurboWan2.1-T2V-14B-720P) | 720p            |



Note: All checkpoints support generating videos at 480p or 720p. The "Best Resolution" column indicates the resolution at which the model provides the best video quality.


## Installation

**Base environment**: `python>=3.9`, `torch>=2.7.0`. `torch==2.8.0` is recommended, as higher versions may cause OOM.

Install TurboDiffusion by pip:

```bash
conda create -n turbodiffusion python=3.12
conda activate turbodiffusion

pip install turbodiffusion --no-build-isolation
```

Or compile from source:

```bash
git clone https://github.com/thu-ml/TurboDiffusion.git
cd TurboDiffusion
git submodule update --init --recursive
pip install -e . --no-build-isolation
```

To enable SageSLA, a fast SLA forward pass based on SageAttention, install [SpargeAttn](https://github.com/thu-ml/SpargeAttn) first:

```bash
pip install git+https://github.com/thu-ml/SpargeAttn.git --no-build-isolation
```


## Inference
For GPUs with more than 40GB of GPU memory, **e.g., H100, please use the unquantized checkpoints (without `-quant`) and remove `--quant_linear` from the command. For RTX 5090, RTX 4090, or similar GPUs, please use the quantized checkpoints (with `-quant`) and add `--quant_linear` in the command.)**

1.  Download the VAE (**applicable for both Wan2.1 and Wan2.2**) and umT5 text encoder checkpoints:

    ```bash
    mkdir checkpoints
    cd checkpoints
    wget https://huggingface.co/Wan-AI/Wan2.1-T2V-1.3B/resolve/main/Wan2.1_VAE.pth
    wget https://huggingface.co/Wan-AI/Wan2.1-T2V-1.3B/resolve/main/models_t5_umt5-xxl-enc-bf16.pth
    ```

2. Download our quantized model checkpoints (For RTX 5090 or similar GPUs):

    ```bash
    # For Wan2.1-T2V-1.3B
    wget https://huggingface.co/TurboDiffusion/TurboWan2.1-T2V-1.3B-480P/resolve/main/TurboWan2.1-T2V-1.3B-480P-quant.pth

    # For Wan2.2-I2V-14B
    wget https://huggingface.co/TurboDiffusion/TurboWan2.2-I2V-A14B-720P/resolve/main/TurboWan2.2-I2V-A14B-high-720P-quant.pth
    wget https://huggingface.co/TurboDiffusion/TurboWan2.2-I2V-A14B-720P/resolve/main/TurboWan2.2-I2V-A14B-low-720P-quant.pth
    ```

    **Or** download our unquantized model checkpoints (For H100 or similar GPUs):
    ```bash
    # For Wan2.1-T2V-1.3B
    wget https://huggingface.co/TurboDiffusion/TurboWan2.1-T2V-1.3B-480P/resolve/main/TurboWan2.1-T2V-1.3B-480P.pth

    # For Wan2.2-I2V-14B
    wget https://huggingface.co/TurboDiffusion/TurboWan2.2-I2V-A14B-720P/resolve/main/TurboWan2.2-I2V-A14B-high-720P.pth
    wget https://huggingface.co/TurboDiffusion/TurboWan2.2-I2V-A14B-720P/resolve/main/TurboWan2.2-I2V-A14B-low-720P.pth
    ```
    

3.  Use