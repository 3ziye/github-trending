[
  {
    "basic_info": {
      "name": "UZDoom",
      "full_name": "UZDoom/UZDoom",
      "owner": "UZDoom",
      "description": "UZDoom is a feature centric port for all Doom engine games, based on GZDoom, adding an advanced renderer, powerful scripting capabilities, and forked under a",
      "url": "https://github.com/UZDoom/UZDoom",
      "clone_url": "https://github.com/UZDoom/UZDoom.git",
      "ssh_url": "git@github.com:UZDoom/UZDoom.git",
      "homepage": "http://zdoom.org",
      "created_at": "2025-10-14T15:41:42Z",
      "updated_at": "2025-10-20T00:19:04Z",
      "pushed_at": "2025-10-19T23:19:44Z"
    },
    "stats": {
      "stars": 745,
      "forks": 37,
      "watchers": 745,
      "open_issues": 90,
      "size": 176736
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 24392233,
        "C": 8249720,
        "ZenScript": 2068459,
        "CMake": 188191,
        "Yacc": 184472,
        "M4": 171384,
        "GLSL": 122478,
        "Objective-C++": 108090,
        "HTML": 33449,
        "Go": 27816,
        "Objective-C": 17478,
        "Python": 12295,
        "Shell": 8641,
        "SWIG": 4538,
        "JavaScript": 2888,
        "Batchfile": 1629,
        "Assembly": 1399,
        "Makefile": 257
      },
      "license": "GNU General Public License v3.0",
      "topics": []
    },
    "content": {
      "readme": "# Welcome to UZDoom!\n\n[![Continuous Integration](https://github.com/UZDoom/UZDoom/actions/workflows/continuous_integration.yml/badge.svg)](https://github.com/UZDoom/UZDoom/actions/workflows/continuous_integration.yml)\n\n## UZDoom is a modder-friendly OpenGL and Vulkan source port based on the DOOM engine\n\nCopyright (c) 1998-2025 ZDoom + GZDoom + UZDoom teams, and contributors\n\nDoom Source (c) 1997 id Software, Raven Software, and contributors\n\nPlease see license files for individual contributor licenses\n\nSpecial thanks to Coraline of the EDGE team for allowing us to use her [README.md](https://github.com/3dfxdev/EDGE/blob/master/README.md) as a template for this one.\n\n### Source code licensed under the GPL v3\n##### https://www.gnu.org/licenses/quick-guide-gplv3.en.html\n---\n\n## How to build UZDoom\n\nTo build UZDoom, please see the [wiki](https://zdoom.org/wiki/) and see the \"Programmer's Corner\" on the bottom-right corner of the page to build for your platform.\n\n# Resources\n- https://zdoom.org/ - Home Page\n- https://forum.zdoom.org/ - Forum\n- https://zdoom.org/wiki/ - Wiki\n- https://dsc.gg/zdoom - Discord Server\n- https://docs.google.com/spreadsheets/d/1pvwXEgytkor9SClCiDn4j5AH7FedyXS-ocCbsuQIXDU/edit?usp=sharing - Translation sheet (Google Docs)\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-20T02:30:27.170897"
  },
  {
    "basic_info": {
      "name": "EDR-Freeze",
      "full_name": "TwoSevenOneT/EDR-Freeze",
      "owner": "TwoSevenOneT",
      "description": "EDR-Freeze is a tool that puts a process of EDR, AntiMalware into a coma state.",
      "url": "https://github.com/TwoSevenOneT/EDR-Freeze",
      "clone_url": "https://github.com/TwoSevenOneT/EDR-Freeze.git",
      "ssh_url": "git@github.com:TwoSevenOneT/EDR-Freeze.git",
      "homepage": null,
      "created_at": "2025-09-21T01:21:06Z",
      "updated_at": "2025-10-19T20:37:21Z",
      "pushed_at": "2025-10-11T01:32:51Z"
    },
    "stats": {
      "stars": 672,
      "forks": 128,
      "watchers": 672,
      "open_issues": 2,
      "size": 30
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 19030
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "### EDR-Freeze\n\nThis is a tool that exploits the software vulnerability of WerFaultSecure to suspend the processes of EDRs and antimalware without needing to use the BYOVD (Bring Your Own Vulnerable Driver) attack method.\n\nEDR-Freeze operates in user mode, so you don't need to install any additional drivers. It can run on the latest version of Windows.\n\n*The experiment was conducted with the latest version of Windows at the time of the project creation: __Windows 11 24H2__*\n\n### Command Line Syntax\n\n**EDR-Freeze.exe [TargetPID] [SleepTime]**\n\n*Example: __EDR-Freeze.exe 1234 10000__*\n\n*Freeze the target for 10000 milliseconds*\n\n## Links\n\n[EDR-Freeze: A Tool That Puts EDRs And Antivirus Into A Coma State](https://www.zerosalarium.com/2025/09/EDR-Freeze-Puts-EDRs-Antivirus-Into-Coma.html)\n\n[Tool to run process with PPL without driver](https://github.com/TwoSevenOneT/CreateProcessAsPPL)\n\n## How to Use EDR-Freeze Effectively\n\nInstead of running EDR-Freeze with a long sleep duration, you should incorporate it into a script with the following steps:\n\n1. Temporarily halt all Antimalware/EDR processes for a short period (1-3 seconds).\n2. Execute tasks immediately after a successful suspension.\n\nSince the GUI may become unresponsive in some cases, you should choose the shortest sleep time possible. Just make sure that the script executions are completed before the Antimalware/EDR resumes.\n\nAlternatively, it's best to insert the code you want to execute directly into the source code of EDR-Freeze:\n\n<img width=\"748\" height=\"387\" alt=\"Insert code\" src=\"https://github.com/user-attachments/assets/1c6f8819-5a21-4cc4-b72f-ea00be0fd092\" />\n\n\n## Author:\n\n[Two Seven One Three](https://x.com/TwoSevenOneT)\n",
      "default_branch": "master"
    },
    "fetched_at": "2025-10-20T02:30:28.390134"
  },
  {
    "basic_info": {
      "name": "dsa-code",
      "full_name": "ghostmkg/dsa-code",
      "owner": "ghostmkg",
      "description": null,
      "url": "https://github.com/ghostmkg/dsa-code",
      "clone_url": "https://github.com/ghostmkg/dsa-code.git",
      "ssh_url": "git@github.com:ghostmkg/dsa-code.git",
      "homepage": "",
      "created_at": "2025-09-30T03:02:13Z",
      "updated_at": "2025-10-19T18:17:07Z",
      "pushed_at": "2025-10-19T13:53:39Z"
    },
    "stats": {
      "stars": 328,
      "forks": 806,
      "watchers": 328,
      "open_issues": 29,
      "size": 18671
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 854250,
        "Java": 522673,
        "Python": 305944,
        "HTML": 163540,
        "C": 74830,
        "JavaScript": 53955,
        "Go": 40584,
        "Rust": 32427,
        "Ruby": 23287,
        "Kotlin": 19650,
        "TypeScript": 13638,
        "PHP": 10218,
        "Swift": 1102
      },
      "license": "MIT License",
      "topics": [
        "hacktoberfest",
        "hacktoberfest-accepted",
        "hacktoberfest2025"
      ]
    },
    "content": {
      "readme": "# üìò DSA-Code\n\nWelcome to **DSA-Code** üéâ\nThis repository is a collection of **Data Structures and Algorithms (DSA)** solutions implemented in multiple programming languages.\nThe goal of this repo is to help learners and contributors **explore, practice, and improve** their problem-solving skills in DSA.\n\nWelcome to **DSA-Code** üéâ  \nA community-driven repository of **Data Structures and Algorithms (DSA)** solutions implemented in multiple programming languages.  \nThe goal of this project is to help learners and contributors **explore, practice, and enhance** their problem-solving skills in DSA.  \n\n## üöÄ Features\n\n* üíª Solutions in multiple programming languages (C, C++, Python, Java, JavaScript, etc.)\n* üß© Beginner-friendly problem statements and structured solutions\n* üåç Open-source project ‚Äî everyone is welcome to contribute\n* üí™ Perfect for **Hacktoberfest**, **coding practice**, and **interview preparation**\n* üìÇ Each folder contains DSA problems and solutions in the respective programming language\n\n## üöÄ Features  \n- üí° Solutions in multiple languages ‚Äî *C, C++, Python, Java, JavaScript,* and more.  \n- üßë‚Äçüíª Beginner-friendly problem statements with clear, structured solutions.  \n- üó∫Ô∏è **Comprehensive DSA Roadmap** to guide your journey.  \n- üåç Open-source project ‚Äî perfect for **Hacktoberfest**, coding practice, and interviews.  \n- üß© Each folder contains DSA problems and solutions for the respective programming language.  \n\n---\n\n## ü§ù How to Contribute\n\n---\n\n### 1Ô∏è‚É£ Fork the Repository  \nClick the **Fork** button (top-right) to create your own copy.  \n\n```bash\ngit clone https://github.com/<your-username>/dsa-code.git\ncd dsa-code\n```\n\n### 3Ô∏è‚É£ Create a branch\n\n```bash\ngit checkout -b feature-branch-name\n4Ô∏è‚É£ Add Your Code\n\nNavigate to the correct folder (e.g., Python/, Java/, etc.)\n\nAdd your DSA problem solution file.\n\n### 5Ô∏è‚É£ Commit and push changes\n\n```bash\n\nEnsure proper file naming and comments for clarity.\n5Ô∏è‚É£ Commit and Push Changes\n\ngit add .\ngit commit -m \"Added solution for <problem-name> in <language>\"\ngit push origin feature-branch-name\n6Ô∏è‚É£ Create a Pull Request\n\nGo to the Pull Requests tab on the original repo.\n\nClick on New Pull Request.\n\n### 6Ô∏è‚É£ Raise a Pull Request (PR)\n\nSubmit and wait for review üöÄ\nüìù Contribution Guidelines\n\n‚úÖ Write clean, readable, and well-commented code.\n‚úÖ Add only DSA-related problems and solutions.\n‚úÖ Maintain folder structure and avoid duplicates.\nüö´ Do not copy-paste code without proper reference or attribution.\nüì¢ Join Our Community\n\nBe a part of our growing community üå± ‚Äî learn, code, and grow together!\n\nüí¨ Join on Discord\n\nüì¢ Join on Telegram\n\nüíº Follow on LinkedIn\n\nüí¨ Join our WhatsApp Community\n\nüì∫ Subscribe on YouTube\n\nüê¶ Follow on Twitter\n\nüì∏ Follow on Instagram\n‚òï Support the Project\n\nIf you love this project and want to support future development, consider buying us a coffee:\n\n<a href=\"https://www.buymeacoffee.com/mgoshwami1c\"> <img src=\"https://cdn.buymeacoffee.com/buttons/v2/default-yellow.png\" height=\"50\" width=\"210\" alt=\"Buy Me A Coffee\"> </a>\nüè∑Ô∏è GitHub Badges\n---\n\n## üè∑Ô∏è GitHub Badges  \n\n![GitHub Repo stars](https://img.shields.io/github/stars/ghostmkg/dsa-code?style=for-the-badge)  \n![GitHub forks](https://img.shields.io/github/forks/ghostmkg/dsa-code?style=for-the-badge)  \n![GitHub issues](https://img.shields.io/github/issues/ghostmkg/dsa-code?style=for-the-badge)  \n![GitHub pull requests](https://img.shields.io/github/issues-pr/ghostmkg/dsa-code?style=for-the-badge)  \n![GitHub license](https://img.shields.io/github/license/ghostmkg/dsa-code?style=for-the-badge)  \n![Contributions Welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=for-the-badge)  \n\n---\n\n**Happy Coding! üöÄ**\n\n\n\nHappy Coding! üöÄ\n\n---\n\n### üîö Last Step:\n1. Jab ye content paste kar lo, to niche **\"Mark as resolved\"** button pe click karo.  \n2. Phir ‚Äú**Commit merge**‚Äù pe click karo.  \n\nBas ho gaya üéâ  \nAb tera PR **conflict-free** ho gaya hai aur Hacktoberfest ke liye **valid contribution** count ho jayega ‚úÖ  \n\n---\n\nChahe to tu mujhe ek screenshot bhej de editor ka (jab paste kar lega) ‚Äî main confirm kar dunga ki sab perfect hai aur merge safe hai üëå\n\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-20T02:30:29.589448"
  },
  {
    "basic_info": {
      "name": "WSL-For-FreeBSD",
      "full_name": "BalajeS/WSL-For-FreeBSD",
      "owner": "BalajeS",
      "description": "Experimental project to adapt the WSL2 open-source components to run FreeBSD OS",
      "url": "https://github.com/BalajeS/WSL-For-FreeBSD",
      "clone_url": "https://github.com/BalajeS/WSL-For-FreeBSD.git",
      "ssh_url": "git@github.com:BalajeS/WSL-For-FreeBSD.git",
      "homepage": "",
      "created_at": "2025-09-20T18:58:21Z",
      "updated_at": "2025-10-19T14:04:31Z",
      "pushed_at": "2025-10-15T17:34:59Z"
    },
    "stats": {
      "stars": 325,
      "forks": 6,
      "watchers": 325,
      "open_issues": 3,
      "size": 27351
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 3797153,
        "C": 2420655,
        "C#": 125464,
        "CMake": 66173,
        "Python": 49585,
        "PowerShell": 45272,
        "Perl": 6143,
        "Shell": 4453,
        "Makefile": 1476,
        "Batchfile": 794
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# Welcome to the Windows Subsystem for FreeBSD (WSFB)\n\n‚ö° **Experimental Project ‚Äì Running FreeBSD on WSL2** ‚ö°  \n\nThis repository hosts work-in-progress efforts to run **FreeBSD** inside **Windows Subsystem for Linux (WSL2)** with minimal to no changes to the FreeBSD base system. The project builds on the open-source components of WSL2 to enable FreeBSD to boot and run seamlessly in a Windows environment.\n\nTechnical description and video available here - https://x.com/balajesankar/status/1970585411153207715\n\n---\n\n## Project Goals\n\n- Enable FreeBSD to run natively on WSL2‚Äôs architecture  \n- Make minimal or no modifications to the FreeBSD base system  \n- Contribute improvements back to open-source components where possible  \n\n---\n\n## Current Status\n\nüöß This is an experimental personal project. Here is what works now \n\n- FreeBSD boots successfully inside WSL2  \n- Basic functionality is up and running  \n- Ongoing work focuses on networking, I/O, and process management  \n\n---\n\n## Roadmap (High-Level)\n\n- [x] Initial boot support (done experimentally) \n- [x] Full Console Support executing Commands\n- [ ] Networking support (in progress)  \n- [ ] User-mode utilities and integration  \n- [ ] Documentation and examples  \n\n---\n\n## Contributing\n\nAt this stage, contributions are welcome in the form of:\n\n- Feedback or testing results  \n- Bug reports  \n- Discussions and ideas  \n\nPlease open an issue or start a discussion to get involved.  \n\n---\n\n## License\n\nThis project is released under an open-source license (TBD).  \n\n---\n\n### Disclaimer  \n\nThis is a **personal, experimental project** and is **not affiliated** with Microsoft, the FreeBSD Foundation, or the FreeBSD Project. Use at your own risk.\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-20T02:30:30.807433"
  },
  {
    "basic_info": {
      "name": "lidar_odometry",
      "full_name": "93won/lidar_odometry",
      "owner": "93won",
      "description": "Probabilistic Kernel Optimization for Robust State Estimation",
      "url": "https://github.com/93won/lidar_odometry",
      "clone_url": "https://github.com/93won/lidar_odometry.git",
      "ssh_url": "git@github.com:93won/lidar_odometry.git",
      "homepage": "",
      "created_at": "2025-09-26T07:36:39Z",
      "updated_at": "2025-10-19T14:15:53Z",
      "pushed_at": "2025-10-18T10:29:37Z"
    },
    "stats": {
      "stars": 267,
      "forks": 46,
      "watchers": 267,
      "open_issues": 0,
      "size": 6139
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 469969,
        "CMake": 5262,
        "Shell": 3014
      },
      "license": null,
      "topics": [
        "lidar",
        "odometry",
        "slam"
      ]
    },
    "content": {
      "readme": "# LiDAR Odometry with Probabilistic Kernel Optimization (PKO)\n\nThis is a real-time LiDAR odometry system designed for SLAM applications. It utilizes feature extraction from point clouds, iterative closest point (ICP) registration, sliding window optimization with Ceres Solver, and Pangolin for 3D visualization.\n\nThe system incorporates **Probabilistic Kernel Optimization (PKO)** for robust state estimation, as described in:\n\n> S. Choi and T.-W. Kim, \"Probabilistic Kernel Optimization for Robust State Estimation,\" *IEEE Robotics and Automation Letters*, vol. 10, no. 3, pp. 2998-3005, 2025, doi: 10.1109/LRA.2025.3536294.\n> \n> **Paper**: [https://ieeexplore.ieee.org/document/10857458](https://ieeexplore.ieee.org/document/10857458)\n\nROS Wrapper: https://github.com/93won/lidar_odometry_ros_wrapper\n\n\n## Features\n\n- ‚ö° Real-time LiDAR odometry processing\n- üéØ Feature-based point cloud registration  \n- üîß Ceres Solver-based optimization\n- üìà Adaptive M-estimator for robust estimation (PKO)\n- üîß Asynchronous loop closure detection and pose graph optimization (PGO)\n- üöó Support for KITTI dataset (outdoor/vehicle scenarios)\n- üè† Support for MID360 LiDAR (indoor/handheld scenarios)\n\n## Demo\n\n[![LiDAR Odometry Demo](https://img.youtube.com/vi/FANz9mhIAQQ/0.jpg)](https://www.youtube.com/watch?v=FANz9mhIAQQ)\n\n*Click to watch the demo video showing real-time LiDAR odometry on KITTI dataset*\n\n## Quick Start\n\n### 1. Build Options\n\n#### Native Build (Ubuntu 22.04)\n```bash\ngit clone https://github.com/93won/lidar_odometry\ncd lidar_odometry\nchmod +x build.sh\n./build.sh\n```\n\n### 2. Download Sample Data\n\nChoose one of the sample datasets:\n\n#### Option A: KITTI Dataset (Outdoor/Vehicle)\nDownload the sample KITTI sequence 07 from [Google Drive](https://drive.google.com/drive/folders/13YL4H9EIfL8oq1bVp0Csm0B7cMF3wT_0?usp=sharing) and extract to `data/kitti/`\n\n#### Option B: MID360 Dataset (Indoor/Handheld)\nDownload the sample MID360 dataset from [Google Drive](https://drive.google.com/file/d/1psjoqrX9CtMvNCUskczUlsmaysh823CO/view?usp=sharing) and extract to `data/MID360/`\n\n*MID360 dataset source: https://www.youtube.com/watch?v=u8siB0KLFLc*\n\n### 3. Update Configuration\n\nChoose the appropriate configuration file for your dataset:\n\n#### For KITTI Dataset\nEdit `config/kitti.yaml` to set your dataset paths:\n```yaml\n# Data paths - Update these paths to your dataset location\ndata_directory: \"/path/to/your/kitti_dataset/sequences\"\nground_truth_directory: \"/path/to/your/kitti_dataset/poses\"  \noutput_directory: \"/path/to/your/output/directory\"\nseq: \"07\"  # Change this to your sequence number\n```\n\n#### For MID360 Dataset  \nEdit `config/mid360.yaml` to set your dataset paths:\n```yaml\n# Data paths - Update these paths to your dataset location\ndata_directory: \"/path/to/your/MID360_dataset\"\noutput_directory: \"/path/to/your/output/directory\"\nseq: \"slam\"  # Subdirectory name containing PLY files\n```\n\n### 4. Run LiDAR Odometry\n\nChoose the appropriate executable for your dataset:\n\n#### For KITTI Dataset (Outdoor/Vehicle)\n```bash\ncd build\n./kitti_lidar_odometry ../config/kitti.yaml\n```\n\n#### For MID360 Dataset (Indoor/Handheld)\n```bash\ncd build\n./mid360_lidar_odometry ../config/mid360.yaml\n```\n\n## Full KITTI Dataset\n\nFor complete evaluation, download the full KITTI dataset from:\n- **Official Website**: [http://www.cvlibs.net/datasets/kitti/](http://www.cvlibs.net/datasets/kitti/)\n- **Odometry Dataset**: [http://www.cvlibs.net/datasets/kitti/eval_odometry.php](http://www.cvlibs.net/datasets/kitti/eval_odometry.php)\n\n## Project Structure\n\n- `app/`: Main applications and dataset players\n  - `kitti_lidar_odometry.cpp`: KITTI dataset application  \n  - `mid360_lidar_odometry.cpp`: MID360 dataset application\n  - `player/`: Dataset-specific player implementations\n- `src/`: Core modules (database, processing, optimization, viewer, util)\n- `thirdparty/`: External libraries (Ceres, Pangolin, Sophus, spdlog)\n- `config/`: Configuration files for different datasets\n- `build.sh`: Build script for native compilation\n\n## System Requirements\n\n- **Ubuntu 20.04/22.04** (recommended)\n- **C++17 Compiler** (g++ or clang++)\n- **CMake** (>= 3.16)\n\n## Configuration\n\n### Loop Closure Detection\n\nThe system supports automatic loop closure detection using LiDAR Iris descriptors. Configure these settings in `config/*.yaml`:\n\n```yaml\nloop_detector:\n  enable_loop_detection: true        # Enable/disable loop closure detection\n  similarity_threshold: 0.3          # Descriptor similarity threshold (0.0 = identical, lower is stricter)\n  min_keyframe_gap: 50               # Dual purpose:\n                                     #   1) Minimum keyframe ID gap for candidate search (prevents false positives from nearby frames)\n                                     #   2) Cooldown gap after successful loop closure (prevents repeated detections)\n  max_search_distance: 5.0           # Maximum Euclidean distance (meters) to search for loop candidates\n  enable_debug_output: true          # Enable detailed de",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-20T02:30:32.010810"
  },
  {
    "basic_info": {
      "name": "SetupHijack",
      "full_name": "hackerhouse-opensource/SetupHijack",
      "owner": "hackerhouse-opensource",
      "description": "SetupHijack is a security research tool that exploits race conditions and insecure file handling in Windows applications installer and update processes.",
      "url": "https://github.com/hackerhouse-opensource/SetupHijack",
      "clone_url": "https://github.com/hackerhouse-opensource/SetupHijack.git",
      "ssh_url": "git@github.com:hackerhouse-opensource/SetupHijack.git",
      "homepage": null,
      "created_at": "2025-09-24T20:45:10Z",
      "updated_at": "2025-10-15T14:29:06Z",
      "pushed_at": "2025-09-29T21:47:31Z"
    },
    "stats": {
      "stars": 245,
      "forks": 27,
      "watchers": 245,
      "open_issues": 0,
      "size": 1428
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 16195,
        "Makefile": 2374,
        "Batchfile": 1635
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# SetupHijack\n\n---\n\n## Overview\n\n**SetupHijack** is a security research tool that exploits race conditions and insecure file handling in Windows installer and update processes. It targets scenarios where privileged installers or updaters drop files in `%TEMP%` or other world-writable locations, allowing an attacker to replace these files before they are executed with elevated privileges.\n\n- Does **not** require elevated permissions to run.\n- Does **not** use file system notifications (polls for changes instead).\n- Exploits weaknesses in Authenticode code signing and installer trust models.\n- Can infect `.exe`, `.msi`, and batch files (e.g., `sysinfo`, `netstat`, `ipconfig`).\n- Designed for red team, penetration testing, and security research use only.\n\nThe intended use of this tool is to run in the background on a compromised user account with privileges, in order to elevate another process by hijacking installer/updater file drops. \n\nThe chart below shows real-world example use cases of this exploit in multiple scenarios that can be used for UAC bypass. UAC bypasses are considered a security boundary when running under Adminless and are a common \"attacker requirement\" for disabling security controls. Exploitation of privileged Administrator operations provides generic exploit accessibility for malicious code to side-load or escalate process privileges. This tool can be used to identify additional applications which are exposed to the same types of risk, an attacker can wait for execution of these processes as a means to gain elevated rights without disrupting user behaviors. \n\n![SetupHijack Vulnerability Discovery Chart](Chart.png)\n\n## How It Works\n\n1. **SetupHijack** continuously scans `%TEMP%` (and subdirectories) for new or modified installer files.\n2. When a target file is detected, it is replaced with a user-supplied payload (EXE, MSI, or BAT), optionally preserving the original as a `.bak` file.\n3. If the privileged process executes the replaced file before integrity checks, the payload runs with elevated rights (e.g., SYSTEM or Administrator).\n4. The tool logs all actions and maintains a skiplist to avoid re-infecting the same files.\n\n## Code Signing Note\n\nThis project uses a hacked code-signing process with [SignToolEx.exe and SignToolExHook.dll](https://github.com/hackerhouse-opensource/SignToolEx) to sign payloads and installers. Using valid code-signing certificates and an Authenticode timestamp will increase your success rate when bypassing installer and OS trust checks.\n\n---\n\n## Usage\n\n### Build\n\n```sh\nnmake PAYLOAD=c:\\Path\\to\\your\\payload.exe\n```\n\n### Run (Options)\n\n```sh\nSetupHijack.exe                  # Scan %TEMP%, %APPDATA%, and %USERPROFILE%\\Downloads (default)\nSetupHijack.exe -notemp          # Disable scanning %TEMP%\nSetupHijack.exe -noappdata       # Disable scanning %APPDATA%\nSetupHijack.exe -nodownloads     # Disable scanning %USERPROFILE%\\Downloads\nSetupHijack.exe clean            # Clean mode (restores .bak backups in all enabled locations)\nSetupHijack.exe verbose          # Verbose mode (log all actions)\nSetupHijack.exe <payload.exe>    # Use specified payload for .exe (unless argument is a recognized option)\n```\n\n- Run **SetupHijack.exe** before or during a privileged install/update process.\n- By default, the tool scans all common drop locations: %TEMP%, %APPDATA%, and %USERPROFILE%\\Downloads.\n- You can disable any location with the `-notemp`, `-noappdata`, or `-nodownloads` flags.\n- The `clean` flag restores backups in all enabled locations. The `verbose` flag logs all actions.\n- For remote escalation, use with `shadow.exe` or similar tools on Terminal Services.\n\n## Example Attack Flow\n\n1. Build your payload and SetupHijack:\n   ```sh\n   nmake PAYLOAD=c:\\Users\\YourUser\\Desktop\\payload.exe\n   ```\n2. Start SetupHijack:\n   ```sh\n   SetupHijack.exe\n   ```\n3. Launch the target installer or update process as Administrator.\n4. If the installer drops files in `%TEMP%` and executes them with elevated rights, your payload will be substituted and run.\n\n## Example Output\n\nBelow is a real example of building and running SetupHijack, including code signing and infection output:\n\n```\nC:\\Users\\Fantastic\\Desktop\\Sayuri\\InfectElevatedSetups>nmake PAYLOAD=\"C:\\USers\\Fantastic\\Desktop\\DEMO\\Renge_x64.exe\"\n\nMicrosoft (R) Program Maintenance Utility Version 14.29.30159.0\nCopyright (C) Microsoft Corporation.  All rights reserved.\n\n        powershell -Command \"(Get-Content SetupHijack.cpp) -replace '#define PAYLOAD_PATH L\\\".*\\\"', '#define PAYLOAD_PATH L\\\"%ESCAPED_PAYLOAD%\\\"' | Set-Content SetupHijack.cpp\"\n        cl /nologo /W4 /EHsc /DUNICODE /D_UNICODE /MT /O2 /c SetupHijack.cpp\nSetupHijack.cpp\nSetupHijack.cpp(318): warning C4189: 'hr2': local variable is initialized but not referenced\n        taskkill /f /im SetupHijack.exe 2>nul\n        powershell -Command \"Start-Sleep -Milliseconds 500\"\n        link /nologo /SUBSYSTEM:CONSOLE /ENTRY:wmainCRTStartup /NODEFAULTLIB:MSVCRT /NODEFAULTLIB:MSVCPRT /OUT:Se",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-20T02:30:33.220569"
  },
  {
    "basic_info": {
      "name": "sonshell",
      "full_name": "goudvuur/sonshell",
      "owner": "goudvuur",
      "description": "An effort to \"ssh into my Sony camera\"",
      "url": "https://github.com/goudvuur/sonshell",
      "clone_url": "https://github.com/goudvuur/sonshell.git",
      "ssh_url": "git@github.com:goudvuur/sonshell.git",
      "homepage": "http://www.goudvuur.be",
      "created_at": "2025-09-24T13:13:40Z",
      "updated_at": "2025-10-18T15:57:13Z",
      "pushed_at": "2025-10-18T15:57:10Z"
    },
    "stats": {
      "stars": 216,
      "forks": 5,
      "watchers": 216,
      "open_issues": 1,
      "size": 155
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 155527,
        "Shell": 58599,
        "Python": 7981,
        "CMake": 6315
      },
      "license": "Apache License 2.0",
      "topics": []
    },
    "content": {
      "readme": "# SonShell - an effort to \"ssh into my Sony camera\"\n\nA Linux-only helper built on Sony‚Äôs official **Camera Remote SDK**. It connects to supported Sony bodies (the full SDK model list is recognised) over Wi-Fi or Ethernet, mirrors new captures straight to your workstation, and drops you into an interactive shell for remote control.\n\nThe shell can download files automatically, trigger the shutter, tweak exposure settings, start live view, run post-download hooks, and keep retrying if the camera drops offline. Everything runs from a single terminal window.\n\n---\n\n## Demo\n\nhttps://github.com/user-attachments/assets/6146ff3b-d51c-412b-8684-bdde5c418d4d\n\n---\n\n## Quick Start\n\n### Requirements\n- Linux (developed on Ubuntu 24.04) with a C++17 toolchain (`gcc`, `g++`, `cmake`, `make`).\n- Sony Camera Remote SDK v2.00.00 (download it from Sony and extract it somewhere convenient).\n- Python 3 for the small header-generation scripts.\n- `pkg-config` (or `pkgconf`) so CMake can locate GTK when linking Sony‚Äôs OpenCV bundle (omit when configuring with `-DSONSHELL_HEADLESS=ON`).\n- Runtime deps: libedit, ncurses, libudev, libxml2, OpenCV 4.8 (bundled inside Sony‚Äôs SDK).\n\nOn Ubuntu/Debian you can grab the basics with:\n```bash\nsudo apt install autoconf libtool libudev-dev gcc g++ make cmake unzip libxml2-dev libedit-dev python3 pkg-config\n```\n\n### Build in a hurry\n1. Download and extract the Sony Camera Remote SDK v2.00.00, then configure CMake while pointing `SONY_SDK_DIR` at the folder that contains `app/`:\n   ```bash\n   cmake -S . -B build -DSONY_SDK_DIR=\"$HOME/SonySDK/CrSDK_v2.00.00_20250805a_Linux64PC\"\n   ```\n2. Compile and copy the required Sony/OpenCV shared libraries next to the binary:\n   ```bash\n   cmake --build build --config Release\n   ```\n3. Run it (start with enumeration and let SonShell pick the download folder):\n   ```bash\n   ./build/sonshell --dir \"$PWD/photos\" --keepalive 3000\n   ```\n\n### Headless builds\n\nIf you are compiling on a machine without a GUI stack, pass `-DSONSHELL_HEADLESS=ON` to the CMake configure step. This skips the OpenCV/GTK dependencies and disables the live-view `monitor` command. The binary prints a reminder at startup and any `monitor` invocation warns that the build is headless.\n\nThe build copies `libCr_*`, the adapter modules, and Sony‚Äôs OpenCV libs into `build/`. Run the binary from inside `build/` (or keep the copied `.so` files alongside it) so live view keeps working.\n\n---\n\n## Command-Line Options\n\n| Option | Description |\n| --- | --- |\n| `--dir <path>` | Directory where downloads are stored. If omitted, files land in the working directory; providing an explicit folder is strongly recommended for sync features. |\n| `--ip <addr>` | Connect directly to a camera at the given IPv4 address (e.g. `192.168.1.1`). Skipped when enumerating automatically. |\n| `--mac <hex:mac>` | Optional MAC address for direct-IP connects (`aa:bb:cc:dd:ee:ff`). Used to seed the SDK‚Äôs Ethernet object. |\n| `--model <name>` | Optional camera model hint for direct-IP connects (e.g. `a7r5`, `fx3`, `zve1`). Enumeration ignores this flag and always picks the first discovered device. |\n| `--user <name>` | Username for cameras with Access Auth enabled. |\n| `--pass <password>` | Password for Access Auth. Combine with `--user`. |\n| `--cmd <path>` | Executable/script that SonShell calls for every file event (new downloads, syncs, rating changes, ‚Ä¶). Arguments: `<path> <mode> <operation> [old] [new]`. Runs asynchronously; SonShell does not wait for completion. |\n| `--keepalive <ms>` | Reconnection delay after failure or disconnect. `0` disables retry (SonShell exits on error). |\n| `--verbose`, `-v` | Print detailed property-change logs and transfer progress from the SDK callbacks. |\n\nIf no `--ip` is provided SonShell enumerates available cameras and uses the first match. A fingerprint of the successful connection is cached under `~/.cache/sonshell/fp_enumerated.bin` so subsequent launches pair faster.\n\n---\n\n## Hook Events\n\nWhen `--cmd` is provided SonShell calls the hook for every file-affecting event. The hook always receives:\n\n```\n<path> <mode> <operation> [old] [new]\n```\n\n- `path` ‚Äì absolute path to the newest local copy of the file.\n- `mode` ‚Äì current camera operating mode resolved via the SDK. Examples:\n  - `record/still/m` ‚Üí still capture in manual mode.\n  - `record/still/auto_plus` ‚Üí still capture in Auto+ mode.\n  - `record/movie/cine_ei/sq` ‚Üí movie clip shot in Cine EI with S&Q enabled.\n  - `playback` ‚Üí events raised while browsing files on-body.\n- `operation` ‚Äì high-level action SonShell observed.\n  - `new` ‚Äì a freshly captured file copied to disk.\n  - `sync` ‚Äì a file mirrored during a manual/auto sync.\n  - `rating` ‚Äì the camera changed the star rating of a file (works wherever the SDK reports the update).\n- `old` / `new` ‚Äì optional values tied to the operation (for `rating` they are the previous and current star counts, for `new`/`sync` only the `new` value is populated with the original camera path).\n\nThe hook is",
      "default_branch": "master"
    },
    "fetched_at": "2025-10-20T02:30:34.446567"
  },
  {
    "basic_info": {
      "name": "llmq",
      "full_name": "IST-DASLab/llmq",
      "owner": "IST-DASLab",
      "description": "Quantized LLM training in pure CUDA/C++.",
      "url": "https://github.com/IST-DASLab/llmq",
      "clone_url": "https://github.com/IST-DASLab/llmq.git",
      "ssh_url": "git@github.com:IST-DASLab/llmq.git",
      "homepage": "",
      "created_at": "2025-09-26T17:37:47Z",
      "updated_at": "2025-10-19T20:34:14Z",
      "pushed_at": "2025-10-18T17:25:35Z"
    },
    "stats": {
      "stars": 205,
      "forks": 12,
      "watchers": 205,
      "open_issues": 0,
      "size": 500
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 376142,
        "Cuda": 118531,
        "Python": 13004,
        "CMake": 5873
      },
      "license": null,
      "topics": [
        "cuda",
        "llm-training",
        "quantization-aware-training"
      ]
    },
    "content": {
      "readme": "# LLM.Q\nQuantized LLM training in pure CUDA/C++.\n\n## Overview\n`llm.q` is an implementation of (quantized) large language model training in CUDA, inspired by [llm.c](https://github.com/karpathy/llm.c). It is particularly aimed at medium-sized training setups, i.e., a single node with multiple GPUs.\n\n## Build instructions\nThe code is written in C++20 and requires CUDA 12 or later.  It depends on [nccl](https://developer.nvidia.com/nccl) for communication, and [cudnn](https://developer.nvidia.com/cudnn) for fast attention. Multi-GPU training can either be run in multi-process mode (requires OpenMPI) or in multi-thread mode. On a recent ubuntu system, this should provide\nthe required dependencies (adapt cuda version as needed):\n```¬¥shell\n# build tools\napt install cmake ninja-build git gcc-13 g++-13\n# libs\napt install cuda-12-8 cudnn9-cuda-12-8 libnccl2 libnccl-dev libopenmpi-dev\n```\n\nAdditional header-only dependencies are automatically downloaded by cmake during the build process.\nThese are:\n* [json](https://github.com/nlohmann/json)\n* [cudnn-frontend](https://github.com/NVIDIA/cudnn-frontend)\n* [CLI11](https://github.com/CLIUtils/CLI11)\n* [fmt](https://github.com/fmtlib/fmt)\n\nTo build the training executable, run\n```shell\nmkdir build\ncmake -S . -B build\ncmake --build build --parallel --target train\n```\n\n## How to train your (quantized) llm\n### Data preparation\nIn order to train/fine-tune a model, you first need some data. The [tokenize_data](tokenize_data.py) script provides a utility to prepare token files for training.\nIt only supports a limited number of datasets, but hacking it for your own dataset should be straightforward.\n```shell\nuv run tokenize_data.py --dataset tiny-shakespeare --model qwen\n```\nThis will create `tiny-shakespeare-qwen-train.bin` and `tiny-shakespeare-qwen-eval.bin`.\n\n### Training run\nLet's fine-tune the smallest Qwen model on this data:\n```shell\n./build/train --model=Qwen/Qwen2.5-0.5B \\\n  --train-file=data/tiny-shakespeare-qwen/train.bin \\\n  --eval-file=data/tiny-shakespeare-qwen/eval.bin \\\n  --model-dtype=bf16 --opt-m-dtype=bf16 --opt-v-dtype=bf16 \\\n  --matmul-dtype=e4m3 \\\n  --recompute-block \\\n  --grad-accumulation=8 --steps=30 \\\n  --learning-rate=1e-5 --gpus=1 --batch-size=8\n```\nThe program will print some logging information, such as the following:\n```text\n[Options]\n  recompute-swiglu  : true\n  recompute-norm    : true\n  [...]\n\n[System 0]\n  Device 0: NVIDIA GeForce RTX 4090\n  CUDA version: driver 13000, runtime 13000\n  Memory: 906 MiB / 24080 MiB\n  \nLoading model from `/huggingface/hub/models--Qwen--Qwen2.5-0.5B/snapshots/060db6499f32faf8b98477b0a26969ef7d8b9987/model.safetensors`\n done\n \n[Dataset]\n train:  329k tokens\n   data/tiny-shakespeare-qwen/train.bin :     329663\n eval:   33k tokens\n   data/tiny-shakespeare-qwen/eval.bin :      33698\n\n[Allocator State]\n        Adam V:   942 MiB\n        Adam M:   942 MiB\n     Gradients:   942 MiB\n   Activations:  4505 MiB\n        Master:   682 MiB\n       Weights:   601 MiB\n          Free: 14078 MiB\n      Reserved:   483 MiB\n         Other:   903 MiB\n```\n\nIf `[Allocator State]` shows a lot of `Free` memory (as it does here), you can try increasing the batch size (and adjust `--grad-accumulation` accordingly), or reduce the amount of activation checkpointing.\nFor example, on a 16GiB 4060Ti, `--recompute-block` can be replaced by `--recompute-swiglu`, which increases the activation memory from `4.5 GiB` to `9 GiB`, and\nthe speed from ~11k tps to ~13k tps.\n\nThen, the actual training will begin:\n````text\n[T] step     0 [ 19.9%] | time:  1869 ms | norm   4.315545 | loss   3.282568 | tps 35064 | sol 42.9%\n[T] step     1 [ 39.8%] | time:  1709 ms | norm   8.423664 | loss   3.310652 | tps 38347 | sol 46.9%\n[T] step     2 [ 59.6%] | time:  1708 ms | norm   4.818971 | loss   3.330125 | tps 38370 | sol 47.0%\n[T] step     3 [ 79.5%] | time:  1715 ms | norm   5.247286 | loss   3.259991 | tps 38213 | sol 46.8%\n[V] step     4 [  0.0%] | time:   165 ms | eval   2.945187 | train  3.295834 | tps  148k\n````\nEach `[T]` line is a training step (in contrast to `[V]` validation). It shows the step number, the progress within the epoch,\nthe elapsed time, as well as the current loss and gradient norm. It also calculates the current throuput in tokens per second,\nand sets this in relation to the GPU's speed of light (SOL), i.e., the fastest possible speed if the GPU was only running strictly necessary matmuls at peak flop/s.\n\n### Inspecting the logs\nAfter 50 steps, the training will finish, and save the final model to `model.safetensors`. In addition, a log file will be created,\nwhich contains the training log in JSON format. We can visualize the log using the `plot-training-run.py` utility script:`\n```shell\nuv run python/plot-training-run.py log.json\n```\nThis shows the training and evaluation losses over time, for quick inspection.\nFor a more detailed and interactive workflow, you can export the log to weights&biases:\n```shell\nuv run python/export-wandb.py --log-fi",
      "default_branch": "dev"
    },
    "fetched_at": "2025-10-20T02:30:35.655513"
  },
  {
    "basic_info": {
      "name": "orderbook-simulator-cpp",
      "full_name": "SLMolenaar/orderbook-simulator-cpp",
      "owner": "SLMolenaar",
      "description": "A high-performance C++ orderbook engine with microsecond-level latency, supporting multiple ordertypes, price-time priority matching and real time data integration from Binance",
      "url": "https://github.com/SLMolenaar/orderbook-simulator-cpp",
      "clone_url": "https://github.com/SLMolenaar/orderbook-simulator-cpp.git",
      "ssh_url": "git@github.com:SLMolenaar/orderbook-simulator-cpp.git",
      "homepage": "",
      "created_at": "2025-09-30T23:54:28Z",
      "updated_at": "2025-10-19T21:30:54Z",
      "pushed_at": "2025-10-15T11:59:44Z"
    },
    "stats": {
      "stars": 195,
      "forks": 57,
      "watchers": 195,
      "open_issues": 2,
      "size": 121
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 63386,
        "C": 2925,
        "CMake": 2204
      },
      "license": null,
      "topics": [
        "cpp",
        "high-performance",
        "orderbook",
        "quantitative-finance"
      ]
    },
    "content": {
      "readme": "# High-Performance Order Book Engine\n\nA low-latency limit order book implementation in C++20 with real-time market data integration. Built to handle\nhigh-frequency trading workloads with microsecond-level latency.\n\n## Overview\n\nThis project implements a matching engine and order book that supports multiple order types, priority-based matching,\nand real-time market data processing. The architecture is designed for performance-critical applications where latency\nmatters.\n\n**Key metrics:**\n\n- Order insertion: ~400,000 orders/sec\n- Order matching: ~350,000 matches/sec\n- Order cancellation: ~2,000,000 cancels/sec\n- Average operation latency: 2-4 Œºs\n\n## Features\n\n### Core Order Book\n\n- **Order Types**: GoodTillCancel, Market, ImmediateOrCancel, FillOrKill, GoodForDay\n- **Matching Algorithm**: Price-time priority (FIFO within price levels)\n- **Data Structures**: O(1) order lookup, O(log n) price level access\n- **Trade Execution**: Automatic matching with partial fill support\n\n### Market Data Feed\n\n- Real-time orderbook snapshots via Binance REST API\n- Incremental update processing (new orders, cancellations, modifications)\n- Batch message processing for improved throughput\n- Sequence number tracking for gap detection\n- Latency monitoring and statistics\n\n### Live Market Display\n\n- Real-time visualization of cryptocurrency orderbooks\n- Configurable refresh rates and depth levels\n- Bid-ask spread analysis and mid-price calculation\n- Market microstructure metrics\n\n<img width=\"511\" height=\"930\" alt=\"image\" src=\"https://github.com/user-attachments/assets/12dabc82-3a85-4cf9-8198-379178578fc4\" />\n\n## Build Instructions\n\n### Requirements\n\n- CMake 3.10+\n- C++20 compatible compiler (GCC 10+, Clang 10+, MSVC 2019+)\n- Dependencies (automatically fetched via CMake):\n- libcurl 8.4.0\n- nlohmann/json 3.11.3\n\n### Build\n\n```bash\nmkdir build && cd build\ncmake ..\ncmake --build . --config Release\n```\n\n### Run\n\n```bash\n# Run functionality and performance tests\n./OrderBookTests\n\n# Live cryptocurrency orderbook\n./LiveMarketData SOLUSDT 1 20\n# Args: [SYMBOL] [REFRESH_SECONDS] [DEPTH_LEVELS]\n```\n\n## Architecture\n\n### Class Diagram\n\n```mermaid\nclassDiagram\n    %% Core Type Aliases\n    class Types {\n        <<typedef>>\n        +Price: int32_t\n        +Quantity: uint32_t\n        +OrderId: uint64_t\n    }\n\n    %% Enumerations\n    class OrderType {\n        <<enumeration>>\n        GoodTillCancel\n        ImmediateOrCancel\n        Market\n        GoodForDay\n        FillOrKill\n    }\n\n    class Side {\n        <<enumeration>>\n        Buy\n        Sell\n    }\n\n    class MessageType {\n        <<enumeration>>\n        NewOrder\n        CancelOrder\n        ModifyOrder\n        Trade\n        BookSnapshot\n    }\n\n    %% Constants\n    class Constants {\n        <<static>>\n        +InvalidPrice: Price\n    }\n\n    %% Order Classes\n    class Order {\n        -orderType_: OrderType\n        -orderId_: OrderId\n        -side_: Side\n        -price_: Price\n        -initialQuantity_: Quantity\n        -remainingQuantity_: Quantity\n        +Order(OrderType, OrderId, Side, Price, Quantity)\n        +Order(OrderId, Side, Quantity)\n        +GetOrderId(): OrderId\n        +GetSide(): Side\n        +GetPrice(): Price\n        +GetOrderType(): OrderType\n        +GetInitialQuantity(): Quantity\n        +GetRemainingQuantity(): Quantity\n        +GetFilledQuantity(): Quantity\n        +IsFilled(): bool\n        +Fill(Quantity): void\n        +ToGoodTillCancel(Price): void\n    }\n\n    class OrderModify {\n        -orderId_: OrderId\n        -price_: Price\n        -side_: Side\n        -quantity_: Quantity\n        +OrderModify(OrderId, Side, Price, Quantity)\n        +GetOrderId(): OrderId\n        +GetPrice(): Price\n        +GetSide(): Side\n        +GetQuantity(): Quantity\n        +ToOrderPointer(OrderType): OrderPointer\n    }\n\n    %% Trade Classes\n    class TradeInfo {\n        +orderId_: OrderId\n        +price_: Price\n        +quantity_: Quantity\n    }\n\n    class Trade {\n        -bidTrade_: TradeInfo\n        -askTrade_: TradeInfo\n        +Trade(TradeInfo, TradeInfo)\n        +GetBidTrade(): TradeInfo\n        +GetAskTrade(): TradeInfo\n    }\n\n    %% Level Info Classes\n    class LevelInfo {\n        +price_: Price\n        +quantity_: Quantity\n    }\n\n    class OrderbookLevelInfos {\n        -bids_: LevelInfos\n        -asks_: LevelInfos\n        +OrderbookLevelInfos(LevelInfos, LevelInfos)\n        +GetBids(): LevelInfos\n        +GetAsks(): LevelInfos\n    }\n\n    %% Market Data Messages\n    class NewOrderMessage {\n        +type: MessageType\n        +orderId: OrderId\n        +side: Side\n        +price: Price\n        +quantity: Quantity\n        +orderType: OrderType\n        +timestamp: time_point\n    }\n\n    class CancelOrderMessage {\n        +type: MessageType\n        +orderId: OrderId\n        +timestamp: time_point\n    }\n\n    class ModifyOrderMessage {\n        +type: MessageType\n        +orderId: OrderId\n        +side: Side\n        +newPrice: Price\n        +newQuantity: Quantity\n        +timestamp: time_point\n    }",
      "default_branch": "master"
    },
    "fetched_at": "2025-10-20T02:30:36.884774"
  },
  {
    "basic_info": {
      "name": "Architecture",
      "full_name": "TheCherno/Architecture",
      "owner": "TheCherno",
      "description": "An example of how I like to architect applications in C++",
      "url": "https://github.com/TheCherno/Architecture",
      "clone_url": "https://github.com/TheCherno/Architecture.git",
      "ssh_url": "git@github.com:TheCherno/Architecture.git",
      "homepage": null,
      "created_at": "2025-09-21T09:17:03Z",
      "updated_at": "2025-10-19T07:40:05Z",
      "pushed_at": "2025-09-21T09:19:14Z"
    },
    "stats": {
      "stars": 153,
      "forks": 13,
      "watchers": 153,
      "open_issues": 4,
      "size": 80
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 18976,
        "CMake": 3091,
        "GLSL": 1966
      },
      "license": "The Unlicense",
      "topics": []
    },
    "content": {
      "readme": "# Architecture\n\nAn example of how I like to architect applications in C++, as part of a [YouTube mini-series](https://youtube.com/playlist?list=PLlrATfBNZ98cpX2LuxLnLyLEmfD2FPpRA).\n\n## Build\n\nGenerate project files/build using CMake. I like to make a directory called `build` at the root and then run\n```\ncmake ..\n```\nfrom that directory. This will generate relevant project files (eg. Visual Studio for me) which you can then use to build and run.\n\n## Notes\nI chose to use OpenGL (and GLFW) for this due to popular demand [after running a poll](https://www.youtube.com/post/UgkxP9IU8D8UjH8szUipCS3QkJJQOc_cdb0k), however these concepts mostly translate to any other libraries/rendering APIs you may be using. OpenGL and GLFW is simply used as an example, substitute what you like.\n\n## License\nThis repository uses [The Unlicense](https://unlicense.org/), so feel free to use this however you like.",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-20T02:30:38.096112"
  },
  {
    "basic_info": {
      "name": "hyprlauncher",
      "full_name": "hyprwm/hyprlauncher",
      "owner": "hyprwm",
      "description": "A multipurpose and versatile launcher / picker for Hyprland",
      "url": "https://github.com/hyprwm/hyprlauncher",
      "clone_url": "https://github.com/hyprwm/hyprlauncher.git",
      "ssh_url": "git@github.com:hyprwm/hyprlauncher.git",
      "homepage": "https://wiki.hypr.land/Hypr-Ecosystem/hyprlauncher/",
      "created_at": "2025-10-07T15:41:37Z",
      "updated_at": "2025-10-20T01:18:04Z",
      "pushed_at": "2025-10-19T14:37:36Z"
    },
    "stats": {
      "stars": 150,
      "forks": 5,
      "watchers": 150,
      "open_issues": 4,
      "size": 103
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 53038,
        "CMake": 2810
      },
      "license": "BSD 3-Clause \"New\" or \"Revised\" License",
      "topics": []
    },
    "content": {
      "readme": "## hyprlauncher\nA multipurpose and versatile launcher / picker for Hyprland\n\n![](./assets/preview.png)\n\n## Features\n\n- Various providers: Desktop, Unicode, Emoji, Math ...\n- Speedy: Fast, multi-threaded fuzzy searching\n- Daemon by default: instant opening of the launcher\n- Entry frequency caching: commonly used entries appear above others\n- Manual entry providing: make a simple selector from your own list\n\n## Runtime dependencies\n\n- Desktop: none\n- Unicode: `wl-copy`\n- Math: `wl-copy` for copying the result\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-20T02:30:39.303743"
  },
  {
    "basic_info": {
      "name": "MarkerPatch",
      "full_name": "Wemino/MarkerPatch",
      "owner": "Wemino",
      "description": " A patch that fixes various issues and limitations in the PC port of Dead Space 2",
      "url": "https://github.com/Wemino/MarkerPatch",
      "clone_url": "https://github.com/Wemino/MarkerPatch.git",
      "ssh_url": "git@github.com:Wemino/MarkerPatch.git",
      "homepage": "",
      "created_at": "2025-09-20T07:42:56Z",
      "updated_at": "2025-10-19T23:08:30Z",
      "pushed_at": "2025-10-09T11:39:42Z"
    },
    "stats": {
      "stars": 136,
      "forks": 1,
      "watchers": 136,
      "open_issues": 2,
      "size": 18773
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 90059
      },
      "license": "GNU General Public License v2.0",
      "topics": []
    },
    "content": {
      "readme": "<p align=\"center\">\n  <img src=\"assets/MarkerPatch_Logo.png\" style=\"max-width:70%\">\n</p>\n\n<p align=\"center\">\nA patch that fixes various issues and limitations in the PC port of Dead Space 2.\n</p>\n\n## How to Install\n\n> [!NOTE]  \n> Compatible with all versions of Dead Space 2 (Steam, EA App).\n>\n> **Download**: [MarkerPatch.zip](https://github.com/Wemino/MarkerPatch/releases/latest/download/MarkerPatch.zip)  \n> Extract the contents of the zip file into the game's folder, in the same directory as the `deadspace2.exe` file.\n\n### Steam Deck/Linux Specific Instructions (Windows users can skip this)\n\n> [!WARNING]\n> To launch the game on Steam Deck or Linux, open the game's properties in Steam and include `WINEDLLOVERRIDES=\"dinput8=n,b\" %command%` in the launch options.\n>\n> **Note**: DXVK limits the framerate to 60 FPS by default. To increase this limit, add the following to your launch options (example for 120 FPS):  \n> `DXVK_FRAME_RATE=120 WINEDLLOVERRIDES=\"dinput8=n,b\" %command%`\n\n# Features\n\n## Havok Physics Fix\n\nStabilizes physics behavior at high framerates to eliminate the annoying flying corpses and limbs. While physics issues begin above 30 FPS, they become noticeably problematic after 100 FPS, causing dead bodies and severed limbs to launch erratically across rooms.\n\n## High-Core CPU Fix\n\nPrevents the game from crashing on systems with more than 10 CPU cores. The game's CPU detection code collects information about each core into fixed-size arrays, but these arrays weren't sized to handle more than 10 cores. When more cores are detected, the code overflows these arrays, corrupting memory and causing crashes later during execution. The patch stops the CPU detection loop early to prevent this overflow.\n\n## VSync Refresh Rate Fix\n\nCorrects the VSync implementation to use the refresh rate selected in the game's settings instead of locking to 30 FPS. The original implementation ignores your chosen refresh rate and forces 30 FPS when VSync is enabled.\n\n<div align=\"center\">\n  <table>\n    <tr>\n      <td width=\"50%\"><img style=\"width:100%\" src=\"assets/vsyncfix_off.png\"></td>\n      <td width=\"50%\"><img style=\"width:100%\" src=\"assets/vsyncfix_on.png\"></td>\n    </tr>\n    <tr>\n      <td align=\"center\">Vanilla (Locked to 30 FPS)</td>\n      <td align=\"center\">MarkerPatch (Uses Selected Rate)</td>\n    </tr>\n  </table>\n</div>\n\n## Automatic Weapon Fire Rate Fix\n\nStabilizes the fire rate of automatic weapons across all framerates. The game's weapon cooldown system checks more frequently at higher framerates, causing automatic weapons like the Pulse Rifle and Flamethrower to fire progressively faster as FPS increases.\n\n## Save System Fixes\n\n### Difficulty Reward Tracking\nFixes the tracking of Zealot and Hardcore difficulty completions to properly unlock rewards. \n\n> **Important**: This fix requires starting a new save with the patch installed. You must keep the patch installed for the entire playthrough for the fix to remain effective.\n\n### Suit ID Conflicts\nResolves item database conflicts where certain DLC suits incorrectly share IDs with other suits:\n- **Zealot Suit** was conflicting with the Security Suit.\n- **Hacker Suit** was conflicting with the Elite Advanced Suit.\n\nThese conflicts would cause one suit to overwrite the other in your inventory, making purchased items disappear.\n\n### String Buffer Overflow Prevention\nPrevents crashes that can rarely occur when the game enumerates save files. This happens in two scenarios: when checking for Dead Space 1 saves to grant the DLC bonus for owning the first game, and when listing your Dead Space 2 save files in the load menu. Though these crashes are uncommon, they can be frustrating when they do occur.\n\n## Subtitle Font Scaling\n\nScales subtitle text appropriately for high resolutions. The game was designed with console limitations in mind and intentionally prevents subtitles from scaling beyond 720p resolution, making them tinier at 1080p and above. This fix removes that limitation and allows proper scaling.\n\nFor those who prefer different subtitle sizes, `FontScalingFactor` in `MarkerPatch.ini` allows fine-tuning the subtitle text size to personal preference.\n\n<div align=\"center\">\n  <table>\n    <tr>\n      <td width=\"50%\"><img style=\"width:100%\" src=\"assets/scaling_off.png\"></td>\n      <td width=\"50%\"><img style=\"width:100%\" src=\"assets/scaling_on.png\"></td>\n    </tr>\n    <tr>\n      <td align=\"center\">4K Vanilla</td>\n      <td align=\"center\">4K MarkerPatch</td>\n    </tr>\n  </table>\n</div>\n\n## Raw Mouse Input\n\nImplements proper raw mouse input to fix sensitivity issues. This works similarly to the existing \"Dead Space 2 Mouse Fix\" mod with several improvements:\n- Added support for zero-gravity areas. (the original mouse fix didn't work properly in zero-G)\n- Sensitivity scaling now matches the in-game sensitivity settings more accurately.\n- Does not interfere with controller inputs when switching between mouse and gamepad.\n\nThe fix decouples mouse sensitivity from the game's fr",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-20T02:30:40.525375"
  },
  {
    "basic_info": {
      "name": "tilelang-ascend",
      "full_name": "tile-ai/tilelang-ascend",
      "owner": "tile-ai",
      "description": "Ascend TileLang adapter ",
      "url": "https://github.com/tile-ai/tilelang-ascend",
      "clone_url": "https://github.com/tile-ai/tilelang-ascend.git",
      "ssh_url": "git@github.com:tile-ai/tilelang-ascend.git",
      "homepage": "",
      "created_at": "2025-09-25T11:53:38Z",
      "updated_at": "2025-10-20T02:29:27Z",
      "pushed_at": "2025-10-20T02:29:24Z"
    },
    "stats": {
      "stars": 125,
      "forks": 24,
      "watchers": 125,
      "open_issues": 9,
      "size": 15012
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 2346447,
        "Python": 991286,
        "Shell": 20282,
        "Cython": 8125,
        "CMake": 7206,
        "Dockerfile": 1051
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "<img src=./images/logo-row.svg />\n\n<div align=\"center\">\n\n# TileLang-Ascend\n\n\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/tile-ai/tilelang-ascend)\n\n</div>\n\nTile Language Ascend (**tilelang-ascend**) is a specialized variant of the tile-lang domain-specific language, specifically optimized for Huawei Ascend NPU (Neural Processing Unit) architecture. Built upon the foundation of tile-lang's Pythonic syntax and [TVM](https://tvm.apache.org/) compiler infrastructure, tilelang-ascend enables developers to efficiently create high-performance AI compute kernels tailored for Ascend processors, including operations like GEMM, vector operations, and attention mechanisms. Tilelang-ascend allows developers to focus on productivity without sacrificing the low-level optimizations necessary for state-of-the-art performance on the NPU. The compiler backend supports two technical routes: [Ascend C & PTO](https://github.com/tile-ai/tilelang-ascend/tree/ascendc_pto) and [AscendNPU IR](https://github.com/tile-ai/tilelang-ascend/tree/npuir).\n\n<p align=\"center\">\n  <img src=\"./images/tl-ascend-gemm.png\" width=\"100%\" alt=\"image\">\n\n</p>\n\n## Latest News\n- 09/29/2025 üöÄ: We are excited to announce that tilelang-ascend, a dsl for high performance AI workloads on Ascend NPUs, is now open source and available to the public!\n\n## Tested Devices\nAlthough tilelang-ascend aims to be portable across a range of Ascend devices, it has been specifically tested and validated on the following NPUs: A2 and A3.\n\n## OP Implementation Examples\n**tilelang-ascend** provides the building blocks to implement a wide variety of operators on the NPU.\nSome examples include:\n\n- [Matrix Multiplication](./examples/gemm/)\n- [Vector Add](./examples/elementwise/)\n- [Flash Attention](./examples/flash_attention/)\n\n\nWithin the `examples` directory, you will also find additional complex kernels‚Äîsuch as [LightningIndexer](./examples/lightning_indexer/) and [SparseFlashAttention](./examples/sparse_flash_attention/), more operators will continuously be added.\n\n\n## Installation\n\n### Environment Preparation\nWe assume you already have an ascend environment with CANN (at least [8.2.RC1](https://www.hiascend.com/developer/download/community/result?from=firmware&product=1&model=30&cann=8.2.RC1)) and torch-npu (at least 2.6.0.RC1) installed. Firstly, set cann environment variables.\n\n  ```bash\n  source {your-cann-installed-path}/ascend-toolkit/set_env.sh\n  ```\n\n### TileLang-Ascend Installation\n\nHere we use the method of compiling from source code for installation.\n\n#### a) Download\n\n    git clone --recursive https://github.com/tile-ai/tilelang-ascend.git\n    cd tilelang-ascend\n\n#### b) Compile and Install\n    bash install_ascend.sh\n\n#### c) Environment Variable Setup\n\n    source set_env.sh\n\n## Run\n\n\nIn this section, you will learn how to call NPU TileLang operators.\n\nHere we use the **Matrix Multiplication** operator as an example for introduction.\n\n\n```\ncd examples/gemm\npython example_gemm.py\n```\n\nUpon success, it will print:\n\n```\nKernel Output Match!\n```\n\n## Comparison with NVIDIA Backend Implementation\n\nGPUs primarily feature a three-level memory hierarchy that can be analogously mapped to NPU hardware architecture as follows:\n\n**Memory Hierarchy Mapping:**\n- `global memory` ‚Üî `global memory`\n- `shared memory` ‚Üî `L1 buffer on cube core and unified buffer on vector core`  \n- `register memory` ‚Üî `L0A/B/C buffer`\n\n**Memory Management:**\nTileLang-Ascend provides memory allocation primitives similar to the GPU version. For example, `alloc_{L1/ub/...}` functions allow on-chip memory allocation in a manner comparable to GPU programming.\n\n**Execution Model Differences:**\nAt the execution level, NPUs lack thread-level abstractions. Therefore, we currently provide computation primitives operating at the `tile` granularity on vector cores. While the GPU version enables automatic parallelization of internal computations (e.g., addition) across different threads using `T.Parallel`, the NPU version requires manual vectorization through primitives like `T.add`.\n\n**Cross-Core Communication:**\nAdditionally, since cube and vector cores on NPUs can only exchange data through global memory/L2 cache, the current implementation requires explicit specification of execution code for different cores using the `T.Scope` primitive. Synchronization between cores is managed through `T.set_cross_flag` and `T.wait_cross_flag`, and intermediate data transfer global tensors must be explicitly specified during kernel definition.\n\n\n## Quick Start\n\nIn this section, you'll learn how to write and execute a straightforward GEMM (matrix multiplication) kernel using tilelang-ascend, The next chapter will introduce how to write a high-performance gemm kernel.\n\n### GEMM Example with Annotations\n\nBelow is an example that demonstrates how to quickly implement a gemm on the ascend.\n\n```python\n@tilelang.jit(out_idx=[-1])\ndef matmul(M, N, K, block_M, block_N, K_L1, dtype=\"float16\", accum_dtype=\"floa",
      "default_branch": "ascendc_pto"
    },
    "fetched_at": "2025-10-20T02:30:41.745621"
  },
  {
    "basic_info": {
      "name": "bypass-all",
      "full_name": "Answerr/bypass-all",
      "owner": "Answerr",
      "description": "ÂÖçÊùÄÊâÄÊúâÊùÄËΩØ„ÄÅbypass allÔºåÁªïËøáWB„ÄÅVT Ôºå0Ê£ÄÊµã„ÄÇ",
      "url": "https://github.com/Answerr/bypass-all",
      "clone_url": "https://github.com/Answerr/bypass-all.git",
      "ssh_url": "git@github.com:Answerr/bypass-all.git",
      "homepage": null,
      "created_at": "2025-10-10T06:26:38Z",
      "updated_at": "2025-10-20T02:25:14Z",
      "pushed_at": "2025-10-10T08:45:24Z"
    },
    "stats": {
      "stars": 111,
      "forks": 23,
      "watchers": 111,
      "open_issues": 0,
      "size": 3046
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 57610,
        "C": 52066,
        "Shell": 2287
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# bypass-all\n\nÂÖçË¥£Â£∞ÊòéÔºö\n\nËßÜÈ¢ë‰∏≠ÊâÄÊúâÊìç‰ΩúÂùáÂú®ÂèóÊéßÁöÑÈù∂Êú∫ÁéØÂ¢É‰∏≠ÂÆåÊàêÔºå‰∏çÂ≠òÂú®‰ªª‰ΩïÂÆûÈôÖÊîªÂáªË°å‰∏∫ÔºåËØ∑Â§ßÂÆ∂Âä°ÂøÖÈÅµÂÆàÊ≥ïÂæãÊ≥ïËßÑÔºåÂàáÂãøÂ∞ÜÊ≠§Á±ªÊäÄÊúØÁî®‰∫éÈùûÊ≥ïÁî®ÈÄî\n\n‰ªãÁªçÔºö\n\narsenal-kit ‰∫åÂºÄÔºö\n\nÊ≠§È°πÁõÆ‰∏∫UDRL-VS‰∫åÂºÄ„ÄÅprocess inject kit‰∫åÂºÄ ÔºåÂéªÈô§yaraÁâπÂæÅÁöÑprofileÔºåÁÆÄÂçïÁöÑshellcodeloader‰∏∫ÂçïÊñá‰ª∂ËøúÁ®ãÂàÜÁ¶ªÂä†ËΩΩ\n\n\n\n‰ΩøÁî®ÊñπÊ≥ïÂèÇËÄÉËßÜÈ¢ëÔºö\n\nhttps://www.bilibili.com/video/BV1Mp47z1EMW/?vd_source=23bb70e55009a3bee5844639552aeb7e\n\n\n\nËØÅÊòéÔºö\n\nÊµãËØïÊó∂Èó¥Ôºö2025.10.09\n\n \n\n \n\n![image-20251009170235870](images/image-20251009170235870.png)\n\n![image-20251009170527008](images/image-20251009170527008.png)\n\n![image-20251009170706366](images/image-20251009170706366.png) \n\n![image-20251009170734229](images/image-20251009170734229.png) \n\n![image-20251009170829808](images/image-20251009170829808.png) \n\n\n\n![image-20251009170926500](images/image-20251009170926500.png) \n\n\n\n![image-20251009170633248](images/image-20251009170633248.png)  \n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-20T02:30:42.985629"
  },
  {
    "basic_info": {
      "name": "lidar_odometry_ros_wrapper",
      "full_name": "93won/lidar_odometry_ros_wrapper",
      "owner": "93won",
      "description": "LiDAR Odometry ROS2 Wrapper",
      "url": "https://github.com/93won/lidar_odometry_ros_wrapper",
      "clone_url": "https://github.com/93won/lidar_odometry_ros_wrapper.git",
      "ssh_url": "git@github.com:93won/lidar_odometry_ros_wrapper.git",
      "homepage": "",
      "created_at": "2025-09-27T14:17:58Z",
      "updated_at": "2025-10-20T02:20:21Z",
      "pushed_at": "2025-10-18T10:21:48Z"
    },
    "stats": {
      "stars": 106,
      "forks": 19,
      "watchers": 106,
      "open_issues": 0,
      "size": 8893
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 19344,
        "Python": 14123,
        "CMake": 4503
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# LiDAR Odometry ROS2 Wrapper\n\nThis package provides a ROS2 wrapper for the LiDAR Odometry system with Probabilistic Kernel Optimization (PKO). It enables real-time LiDAR-based odometry estimation in ROS2 environments.\n\n## Demo Video\n\n[![KITTI LiDAR Odometry Demo](https://img.youtube.com/vi/swrJY2EStrs/0.jpg)](https://www.youtube.com/watch?v=swrJY2EStrs)\n[![Mid360 LiDAR Odometry Demo](https://img.youtube.com/vi/HDPA_ILxCrE/0.jpg)](https://youtu.be/HDPA_ILxCrE)\n\n## Features\n\n- ‚ö° Real-time LiDAR odometry processing\n- üéØ Feature-based point cloud registration  \n- üîß Ceres Solver-based optimization with PKO\n- üìà ROS2 native implementation\n- üåê TF2 transform broadcasting\n- üìä Trajectory visualization\n- üéÆ Optional Pangolin viewer integration\n\n## Dependencies\n\n### ROS2 Dependencies\n- `rclcpp`\n- `sensor_msgs`\n- `nav_msgs` \n- `geometry_msgs`\n- `visualization_msgs`\n- `tf2` and `tf2_ros`\n- `pcl_ros` and `pcl_conversions`\n\n### System Dependencies  \n- Eigen3\n- PCL (Point Cloud Library)\n- Ceres Solver\n- OpenGL and GLEW\n- Pangolin (included as submodule)\n\n## Installation\n\n### 1. Setup Workspace and Clone Repository\n```bash\n# Create a new ROS2 workspace\nmkdir -p lidar_odom_ws/src\ncd lidar_odom_ws/src\n\n# Clone the repository\ngit clone https://github.com/93won/lidar_odometry_ros_wrapper.git\ncd lidar_odometry_ros_wrapper\n\n# Initialize and download submodules\ngit submodule update --init --recursive\n```\n\n### 2. Install System Dependencies\n```bash\n# Ubuntu 22.04\nsudo apt update\nsudo apt install -y \\\n    libeigen3-dev \\\n    libpcl-dev \\\n    libceres-dev \\\n    libgl1-mesa-dev \\\n    libglew-dev \\\n    pkg-config\n```\n\n### 3. Build the Package\n```bash\ncd ../../  # Go back to lidar_odom_ws root\ncolcon build --packages-select lidar_odometry_ros\nsource install/setup.bash\n```\n\n## Usage\n\n### Basic Usage\n```bash\n# Launch with default Velodyne topic\nros2 launch lidar_odometry_ros lidar_odometry.launch.py \\\n    config_file:=/path/to/your/workspace/lidar_odometry_ros_wrapper/lidar_odometry/config/kitti.yaml\n\n# Launch with custom topic (e.g., Livox)\nros2 launch lidar_odometry_ros lidar_odometry.launch.py \\\n    config_file:=/path/to/your/workspace/lidar_odometry_ros_wrapper/lidar_odometry/config/kitti.yaml \\\n    pointcloud_topic:=/livox/pointcloud \\\n    use_sim_time:=true\n```\n\n### Quick Start\n\n#### Option 1: KITTI Sample Data\nDownload and play the KITTI sample ROS bag file:\n```bash\n# Download KITTI sample bag\n# https://drive.google.com/file/d/1U0tRSsc1PbEj_QThOHcD8l3qFkma3zjc/view?usp=sharing\n\n# Terminal 1: Launch odometry system\nros2 launch lidar_odometry_ros lidar_odometry.launch.py \\\n    config_file:=/path/to/your/workspace/lidar_odometry_ros_wrapper/lidar_odometry/config/kitti.yaml \\\n    use_sim_time:=true\n\n# Terminal 2: Play KITTI bag file\nros2 bag play /path/to/kitti_sample.bag --clock\n```\n\n#### Option 2: Livox MID360 Sample Data\nDownload and play the Livox MID360 sample ROS bag file:\n```bash\n# Download Livox MID360 sample bag\n# https://drive.google.com/file/d/1UI6Qc5cdY8R61Odc7A6IU-jRWZgnCx2g/view?usp=sharing\n# Source: https://www.youtube.com/watch?v=u8siB0KLFLc\n\n# Terminal 1: Launch odometry system for Livox\nros2 launch lidar_odometry_ros lidar_odometry.launch.py \\\n    config_file:=/path/to/your/workspace/lidar_odometry_ros_wrapper/lidar_odometry/config/kitti.yaml \\\n    use_sim_time:=true \\\n    pointcloud_topic:=/livox/pointcloud\n\n# Terminal 2: Play Livox bag file\nros2 bag play /path/to/livox_mid360_sample.bag --clock\n```\n\n**Note**: The Livox sample data uses standard `sensor_msgs/PointCloud2` messages, not Livox custom message format.\n\n\n\n\n\n\n\n## KITTI Dataset Usage\n\n### 1. Download KITTI Dataset\n```bash\n# Create data directory\nmkdir -p ~/kitti_data\ncd ~/kitti_data\n\n# Download KITTI Odometry Dataset (example: sequence 00)\n# Visit: https://www.cvlibs.net/datasets/kitti/eval_odometry.php\n# Download velodyne laser data and poses\n\n# Expected structure:\n# ~/kitti_data/\n# ‚îú‚îÄ‚îÄ sequences/\n# ‚îÇ   ‚îî‚îÄ‚îÄ 00/\n# ‚îÇ       ‚îú‚îÄ‚îÄ velodyne/\n# ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ 000000.bin\n# ‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ 000001.bin\n# ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ ...\n# ‚îÇ       ‚îî‚îÄ‚îÄ poses.txt\n```\n\n### 2. Convert KITTI to ROS2 Bag\n```bash\n# Use the provided conversion script\ncd ~/ros2_ws/src/lidar_odometry_ros_wrapper/scripts\n\npython3 kitti_to_rosbag.py \\\n    --kitti_dir ~/kitti_data/sequences/07 \\\n    --output_bag ~/kitti_data/kitti_seq07.db3 \\\n    --topic_name /velodyne_points \\\n    --frame_id velodyne\n```\n\n### 3. Run Examples\n\n#### Option A: KITTI Dataset\n```bash\n# Terminal 1: Launch odometry system for KITTI\nros2 launch lidar_odometry_ros lidar_odometry.launch.py \\\n    config_file:=$(pwd)/lidar_odometry/config/kitti.yaml \\\n    use_sim_time:=true \\\n    pointcloud_topic:=/velodyne_points\n\n# Terminal 2: Play KITTI bag file\nros2 bag play ~/kitti_data/kitti_seq07.db3 --clock\n```\n\n#### Option B: Livox MID360 Dataset\n```bash\n# Terminal 1: Launch odometry system for Livox MID360\nros2 launch lidar_odometry_ros lidar_odometry.launch.py \\\n    config_file:=$(pwd)/lidar_odometry/config/kitti.yaml \\\n    use_sim_time:=true \\\n  ",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-20T02:30:44.224837"
  },
  {
    "basic_info": {
      "name": "perf-portfolio",
      "full_name": "ashtonsix/perf-portfolio",
      "owner": "ashtonsix",
      "description": "HPC research and demonstrations",
      "url": "https://github.com/ashtonsix/perf-portfolio",
      "clone_url": "https://github.com/ashtonsix/perf-portfolio.git",
      "ssh_url": "git@github.com:ashtonsix/perf-portfolio.git",
      "homepage": null,
      "created_at": "2025-10-04T13:03:51Z",
      "updated_at": "2025-10-16T23:28:24Z",
      "pushed_at": "2025-10-16T13:16:26Z"
    },
    "stats": {
      "stars": 101,
      "forks": 5,
      "watchers": 101,
      "open_issues": 0,
      "size": 45
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 94286,
        "C": 19716,
        "Makefile": 3352,
        "Awk": 3062
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# Ashton Six: Performance Portfolio\n\n10+ years experience in software engineering, now specialising in HPC.\n\n## Projects\n\n1. **[NEON Bytepack](./bytepack/README.md)** ‚Äî bit pack/unpack routines; ~1.9√ó GB/s vs SOTA plane-transpose baseline.\n1. **[NEON Delta Coding](./delta/README.md)** ‚Äî delta, delta-of-delta and xor-with-previous decoding; ~1.5‚Äì2.2x GB/s vs baseline.\n1. More releasing soon.\n\n## Contact\n\nAvailable for hire: https://ashtonsix.com\n\nFollow me on X [@ashtonsix](https://x.com/ashtonsix) and LinkedIn [in/ashtonsix](https://linkedin.com/in/ashtonsix).\n\n## Development Environment\n\nLaunch a fresh `m8g.large` instance on AWS (Neoverse V2, Graviton4) with Ubuntu LTS, connect via VSCode, and run this setup:\n\n```sh\n# Basics\nsudo apt update\nsudo apt install -y curl gnupg lsb-release make gawk build-essential\n\n# LLVM toolchain (v21 pinned)\ncodename=\"$(lsb_release -cs)\"\nsudo mkdir -p /etc/apt/keyrings\ncurl -fsSL https://apt.llvm.org/llvm-snapshot.gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/llvm.gpg\necho \"deb [signed-by=/etc/apt/keyrings/llvm.gpg] http://apt.llvm.org/$codename/ llvm-toolchain-$codename-21 main\" | \\\n  sudo tee /etc/apt/sources.list.d/llvm-21.list >/dev/null\nsudo apt update\nsudo apt install -y clang-21 lld-21 llvm-21-tools\nsudo ln -sf /usr/bin/ld.lld-21 /usr/bin/ld.lld\n\n# SIMDe (SIMD Everywhere)\ngit clone --depth 1 https://github.com/simd-everywhere/simde /tmp/simde\nsudo rm -rf /usr/local/include/simde\nsudo mkdir -p /usr/local/include\nsudo cp -R /tmp/simde/simde /usr/local/include/\n\n# Source\ngit clone --depth 1 https://github.com/ashtonsix/perf-portfolio.git\n```\n\n## License\n\nApache 2.0\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-20T02:30:45.457997"
  },
  {
    "basic_info": {
      "name": "-CRYENGINE-Community-Edition-",
      "full_name": "Pterosoft/-CRYENGINE-Community-Edition-",
      "owner": "Pterosoft",
      "description": "CRYENGINE Community Edition - Release Version",
      "url": "https://github.com/Pterosoft/-CRYENGINE-Community-Edition-",
      "clone_url": "https://github.com/Pterosoft/-CRYENGINE-Community-Edition-.git",
      "ssh_url": "git@github.com:Pterosoft/-CRYENGINE-Community-Edition-.git",
      "homepage": null,
      "created_at": "2025-10-02T12:24:22Z",
      "updated_at": "2025-10-19T20:19:13Z",
      "pushed_at": "2025-10-19T20:19:09Z"
    },
    "stats": {
      "stars": 98,
      "forks": 10,
      "watchers": 98,
      "open_issues": 0,
      "size": 431643
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 2007468,
        "Rich Text Format": 127244,
        "HLSL": 17268,
        "CMake": 16372,
        "C": 3059,
        "Python": 221
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# CRYENGINE Community Edition\nCRYENGINE Community Edition is a new version of the engine developed and maintained by the community. It builds on the foundation of CRYENGINE while introducing new features, improvements, and customization options contributed by developers in their free time.\n## Installation\n- Download the source code for CRYENGINE 5.7\n- tODO\n## License&nbsp;\nAll files provided here are licensed under the MIT License, meaning you are free to use them in your own projects at no cost.The engine itself remains under the CRYENGINE license provided by Crytek. You must comply with the terms of that license when using the engine.Before downloading or using these files, please review the official CRYENGINE license on the CRYENGINE website&nbsp;to ensure you fully understand the requirements.Thank you for respecting both licenses and supporting the community effort.\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-20T02:30:46.669587"
  },
  {
    "basic_info": {
      "name": "InlineExecuteEx",
      "full_name": "0xTriboulet/InlineExecuteEx",
      "owner": "0xTriboulet",
      "description": "A BOF that's a BOF Loader",
      "url": "https://github.com/0xTriboulet/InlineExecuteEx",
      "clone_url": "https://github.com/0xTriboulet/InlineExecuteEx.git",
      "ssh_url": "git@github.com:0xTriboulet/InlineExecuteEx.git",
      "homepage": "",
      "created_at": "2025-10-12T21:57:23Z",
      "updated_at": "2025-10-19T22:17:46Z",
      "pushed_at": "2025-10-16T08:35:58Z"
    },
    "stats": {
      "stars": 96,
      "forks": 14,
      "watchers": 96,
      "open_issues": 0,
      "size": 8872
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 77517,
        "C": 39607,
        "Python": 30781,
        "Makefile": 1670
      },
      "license": "Apache License 2.0",
      "topics": []
    },
    "content": {
      "readme": "# InlineExcuteEx\nBeacon Object Files (BOFs) in the Cobalt Strike ecosystem are intended to be an abstraction of [Position Independent Code (PIC)](https://aff-wg.org/). To maximize\nthe benefits of this, Cobalt Strike pre-processes BOFs to strip away sections that are not needed to achieve code execution. This design\nconfers some advantages for users of the framework. It reduces the size of the BOF that Beacon receives from the Teamserver, and the BOF \nloader in Beacon is very small compared to other BOF implementations. Unfortunately, this pre-processing has the inadvertent effect of\nreducing the features available from a BOF because the additional information is not available to Beacon at load-time. `InlineExcuteEx`\nimplements [COFFLoader](https://github.com/trustedsec/COFFLoader) as a Cobalt Strike compatible BOF, which can be used to fire other BOFs\nin a more complete way than what is currently possible from Beacon.\n\nThe obvious trade here is that you lose the approximate lightness of PIC offered by Beacon's BOF loader, in favor of a heavier abstraction. This is a nuance that may or may not be relevant to your use case. The intent of this implementation is to offer users of the framework a *choice*.\n\n## Basic Usage\nLoad `inline-execute-ex.cna` from the `Script Manager`. This will make the `inline-execute-ex` command available to you.\n\n```\nBOF+\n====\n[EXPERIMENTAL] BOF Loader.\n\n\t[EXPERIMENTAL] I heard you like BOFs. So I put a BOF in your BOF.\n```\n\nYou can use the `help inline-execute-ex` command to get some usage information from the command line.\n\n```\nbeacon> help inline-execute-ex\n# 1 - a string containing the BOF file\n# 2 - the entry point to call\n# 3 - arguments to pass to the BOF file\n\nUsage: inline-execute-ex 'bof.o' 'go' 'hello world!'\n```\n\n## Drop-In Replacement for `beacon_inline_execute`\nConventional `.cna` scripts register an alias that calls `beacon_inline_execute` to task Beacon to run a BOF. If you want to use `InlineExecuteEx` instead of the default BOF loader for a capability, you can move the `inline-execute-ex.cna` script, the `Release` directory, and the `x64` directory to the same directory as your BOF's `.cna` script.\n\n```sh\n    Directory: C:\\CS-Situational-Awareness-BOF\\SA\n\n\nMode                 LastWriteTime         Length Name\n----                 -------------         ------ ----\n[...snip...]\nd-----        10/15/2025   4:28 PM                Release\nd-----        10/15/2025   4:28 PM                x64\n-a----        10/15/2025   4:42 PM           2153 inline-execute-ex.cna\n-a----        10/15/2025   4:31 PM          45298 SA.cna\n```\n\nThen include the `inline-execute-ex.cna` in your BOF's cna script.\n```perl\n# SA.cna\ninclude(getFileProper(script_resource(\"inline-execute-ex.cna\"))); # This is the line you want to add\n\n%recordmapping = %(\nA => 1,\nNS => 2,\nMD => 3,\nMF => 4,\n[...snip...]\n```\n\nLastly, replace calls to `beacon_inline_execute` with `beacon_inline_execute_ex`.\n```perl\nalias dir {\n\tlocal('$params $keys $args $targetdir $subdirs $ttp $text');\n\n[...snip...]\n\n    # We changed the line below\n\tbeacon_inline_execute_ex($1, readbof($1, \"dir\", $msg, $ttp), \"go\", $args);\n}\n```\nThen reload your `.cna` in the `Script Manager`. If all goes well, you should see this when you run the alias.\n```sh\n[10/15 16:36:25] beacon> dir\n[10/15 16:36:25] [+] Running dir (T1083)\n[10/15 16:36:25] [*] Running dir (T1083)\n[10/15 16:36:25] [*] Running InlineExecuteEx. # <----- It works!\n[10/15 16:36:26] [+] host called home, sent: 23152 bytes\n[10/15 16:36:26] [+] received output:\nContents of .\\*:\n\t10/15/2025 16:25           <dir> .\n\t09/07/2025 15:20           <dir> ..\n\t10/12/2025 12:00          575216 beacon_x64.exe\n[...snip...]\n\t                        66840774 Total File Size for 2 File(s)\n\t                                                      8 Dir(s)\n\n[10/15 16:36:26] [+] received output:\n[+] Success!\n\n```\n\n## Beacon Object File Visual Studio Template\n\nSee the [BOF-VS](https://github.com/Cobalt-Strike/bof-vs) repository for more information about the template behind this BOF.",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-20T02:30:47.868612"
  },
  {
    "basic_info": {
      "name": "hint-break",
      "full_name": "sapdragon/hint-break",
      "owner": "sapdragon",
      "description": "Code proving a 25-year blind spot in all disassemblers. PoC for Intel x64/x86 ‚Äúghost instructions.‚Äù",
      "url": "https://github.com/sapdragon/hint-break",
      "clone_url": "https://github.com/sapdragon/hint-break.git",
      "ssh_url": "git@github.com:sapdragon/hint-break.git",
      "homepage": null,
      "created_at": "2025-10-02T03:52:04Z",
      "updated_at": "2025-10-18T18:47:28Z",
      "pushed_at": "2025-10-02T05:04:36Z"
    },
    "stats": {
      "stars": 94,
      "forks": 4,
      "watchers": 94,
      "open_issues": 1,
      "size": 745
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 431
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# üëª Ghost in opcode\n\nThis repository contains the Proof-of-Concept and research for a 25-year-old architectural blind spot affecting modern reverse engineering tools.\n\n[![SAMPLE X86](https://raw.githubusercontent.com/sapdragon/hint-break/refs/heads/main/images/sample.png)](https://raw.githubusercontent.com/sapdragon/hint-break/refs/heads/main/images/sample.png)\n\n## The Blind Spot\n\nIn 1997, Intel patented (US5,701,442) a series of \"Hintable NOPs\". While most of these have been assigned functions or are correctly parsed, two opcodes ‚Äî **`0F 1A`** and **`0F 1B`** ‚Äî remain ghosts in the machine.\n\nCPUs execute these instructions as valid, multi-byte NOPs. However, leading disassemblers like **IDA Pro, Ghidra, and Binary Ninja** fail to recognize them. They interpret valid, executable code as unknown data, breaking static analysis and creating a simple but highly effective method for anti-disassembly.\n\nThis fundamental issue has remained largely unnoticed for decades.\n\n## How to Test\n\nYou can see the blind spot in action yourself in under a minute.\n\n1.  Grab the pre-compiled binary: `/samples/patched.exe`.\n2.  Open it in your favorite disassembler (IDA, Ghidra, etc.).\n3.  Navigate to the function.\n4.  Observe how the tool fails on the `0F 1A` and `0F 1B` opcodes, showing them as `db 0Fh, 1Ah...`, `undefined`, or `???`, effectively halting the analysis of the function.\n5.  Run `patched.exe`. It will execute flawlessly and print a success message, proving the instructions are valid.\n\n## Repository Structure\n\n-   `/src/`: The C++ source code used to generate the test binary.\n-   `/samples/`\n    -   `patched.exe`: The pre-compiled 64-bit PoC binary.\n-   `/papers/`:\n    -   `ru.pdf`: The full research paper (Russian).\n    -   `en.pdf`: The full research paper (English).\n\n## LICENSE\nMIT\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-20T02:30:49.072345"
  },
  {
    "basic_info": {
      "name": "Bypass_AV",
      "full_name": "hkl1x/Bypass_AV",
      "owner": "hkl1x",
      "description": "ÂÖçÊùÄÊú®È©¨Ê†∑Êú¨",
      "url": "https://github.com/hkl1x/Bypass_AV",
      "clone_url": "https://github.com/hkl1x/Bypass_AV.git",
      "ssh_url": "git@github.com:hkl1x/Bypass_AV.git",
      "homepage": "",
      "created_at": "2025-10-02T08:21:29Z",
      "updated_at": "2025-10-17T08:46:28Z",
      "pushed_at": "2025-10-11T10:05:48Z"
    },
    "stats": {
      "stars": 92,
      "forks": 13,
      "watchers": 92,
      "open_issues": 1,
      "size": 367
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 40064
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# ËøôÊòØ‰∏Ä‰∏™ËÉΩÁªïËøáÁªùÂ§ßÈÉ®ÂàÜÊùÄËΩØ„ÄÅÊ≤ôÁÆ±ÁöÑÊú®È©¨Ê†∑Êú¨\n‰∏ãÈù¢Êàë‰ºöÂØπÊú®È©¨ÊâÄÊ∂âÂèäÁöÑÊäÄÊúØËøõË°åÈòêËø∞Êàë‰ºöÈíàÂØπshellcodeÂíåÂä†ËΩΩÂô®‰∏§ÊñπÈù¢Ëß£Èáä\n## Âä†ËΩΩÂô®ÈÉ®ÂàÜ\n### 1.ÂèçÊ≤ôÁÆ± \n#### ‰ºóËØ¥Âë®Áü•ÂèçÊ≤ôÁÆ±ÁöÑÊ£ÄÊµãÂ∏∏ËßÑÂ∞±ÊòØÈíàÂØπ‰∏ªÊú∫ÁöÑcpu„ÄÅÂÜÖÂ≠ò„ÄÅÁ°¨ÁõòÁ≠âÊìç‰ΩúÔºå‰ΩÜÊòØÊàë‰∏™‰∫∫ËÆ§‰∏∫ËøôÊ†∑‰∏çÂ¶•Âõ†‰∏∫‰∏Ä‰∫õÊùÄËΩØÊàñ‰∫ëÊ≤ôÁÆ±‰ºöÊ£ÄÊµãÂèçÊ≤ôÁÆ±ÂäüËÉΩÔºå‰ºöÂØπ‰∏Ä‰∫õÊïèÊÑüapiËøõË°åÁõëÊéß‰ªéËÄåË¢´ÊäìÂåÖÔºåÊâÄ‰ª•ÊàëÁöÑÊÄùË∑ØÊòØÂØπÊ°åÈù¢ÁöÑÂø´Êç∑ÊñπÂºèÊ£ÄÊµãÊØîÂ¶Çqq„ÄÅÂæÆ‰ø°„ÄÅÈíâÈíâËøô‰∫õÂ∏∏ËßÑ‰ΩøÁî®ÁöÑËΩØ‰ª∂ËøõË°åÊ£ÄÊµãÈÄÉÈÅø‰∫ëÊ≤ôÁÆ±„ÄÇ\n<img width=\"1918\" height=\"990\" alt=\"vt\" src=\"https://github.com/user-attachments/assets/f6c4d58e-374d-428f-bf0b-73c3ef8233e8\" />\n\n###  2.ntdllÁöÑÈáçËΩΩÂíåapiÁöÑÂä®ÊÄÅË∞ÉÁî®\n\n####  ‰∏ÄËà¨ÊùÄËΩØÁöÑÊ£ÄÊµãÊú∫Âà∂Â∞±ÊòØ‰ºöÂØπ‰∏Ä‰∫õÊïèÊÑüÁöÑapi‰∏äÈí©Â≠êÈÇ£‰πàÊàë‰ª¨ÈÄöËøántdllÁöÑÈáçËΩΩÂíåapiÁöÑÂä®ÊÄÅË∞ÉÁî®ÊäÄÊúØÂ∞±ÂèØ‰ª•ÁªïËøáÈí©Â≠êÂÆûÁé∞ÂäüËÉΩÔºåntdllÈáçËΩΩËøô‰∏ÄÂùóÊòØ‰ªéÁ≥ªÁªüÁõÆÂΩïÂä†ËΩΩÂéüÂßã ntdll.dllÔºåÂ∞ÜÂΩìÂâçËøõÁ®ã‰∏≠Ë¢´ÊåÇÈí©ÁöÑ ntdll ‰ª£Á†ÅÊÆµÔºà.text ÊÆµÔºâÊõøÊç¢‰∏∫ÂéüÂßã‰ª£Á†ÅÔºåapiÂä®ÊÄÅË∞ÉÁî®ÊòØÈÅçÂéÜÁõÆÊ†ádllÁöÑÂØºÂá∫Ë°®‰ΩøÁî®hashÂåπÈÖçÂáΩÊï∞ÂêçËé∑ÂèñÁõÆÊ†áÂáΩÊï∞ÁöÑÂú∞ÂùÄ‰ΩøÁî®ÊåáÈíàÊâßË°å„ÄÇ\n\n### 3.shellcodeÂíåÂä†ËΩΩÂô®ÂàÜÁ¶ª\n#### shellcodeÈô§‰∫ÜÁºñÁ†ÅÁªïËøáÊùÄËΩØËøòÂèØ‰ª•ÂíåÂä†ËΩΩÂô®ÂàÜÁ¶ªÔºåÂ∞±ÊòØshellcodeÈÉΩ‰∏çÂú®exeÈáåÊùÄËΩØÂ∞±Êå∫ÈöæÊ£ÄÊµãÂá∫ÈóÆÈ¢ò„ÄÇ\n\n## shellcodeÈÉ®ÂàÜ\n### shellcodeÈÉ®ÂàÜ‰∏ªË¶ÅÂ§öÂ±ÇÊ∑∑Ê∑ÜÂ§ÑÁêÜ ‰ΩøÁî®ÁöÑÊòØXOR+RC4+base64+macÂ§öÂ±ÇÂ§ÑÁêÜÔºåÊúÄÂêéÊòØmacÂú∞ÂùÄÊ†ºÂºèÂ≠òÂú®ÊòØwindowsÂØπmacÊ†ºÂºèÂ≠óÁ¨¶‰∏≤Êúâ‰∏ÄÂÆöÁöÑÂÆΩÂÆπÊÄß„ÄÇ \n\n## ‰ΩøÁî®ÊñπÊ≥ï\n### ÂÖà‰ΩøÁî®encode.cppÂØπshellcodeËøõË°åÂä†ÂØÜÔºåÂ¶ÇÊûúÊääshellcodeÂÜôÈÅìexeÈáåËØ∑Âú®Unseparation_shellcode.cppÁöÑmac_shellcodeÊï∞ÁªÑÈáå„ÄÇÂ¶ÇÊûúÊÉ≥ÂÆûÁé∞ÂèÇÊï∞ÂàÜÁ¶ªÂèØ‰ª•‰ΩøÁî®ÊàëÁºñËØëÂ•ΩÁöÑexe+shellcodeËøêË°åÂç≥ÂèØ\n\n#### ÊÑüË∞¢ÈòÖËØª\n\n\n\n### English version\n\n\n\nThis is a Trojan sample that can bypass the vast majority of antivirus software and sandboxes. Below, I will explain the technologies involved in the Trojan, focusing on both the shellcode and the loader.\n\n## Loader Section\n### 1. Anti-sandbox\nIt is well-known that the conventional detection of anti-sandbox functions is based on operations on the host's CPU, memory, hard disk, etc. However, I personally think this approach is not ideal because some antivirus software or cloud sandboxes will monitor anti-sandbox functions and keep an eye on sensitive APIs, which may lead to detection. Therefore, my idea is to detect desktop shortcuts, such as those for commonly used software like QQ, WeChat, and DingTalk, to evade cloud sandboxes. <img width=\"1918\" height=\"990\" alt=\"vt\" src=\"https://github.com/user-attachments/assets/f6c4d58e-374d-428f-bf0b-73c3ef8233e8\" />\n\n\n### 2. Overloading of ntdll and Dynamic Invocation of APIs \n\nThe detection mechanism of general anti-virus software is to hook some sensitive APIs. Therefore, we can bypass the hooks and achieve the function by using the ntdll overloading and dynamic API calling techniques. The ntdll overloading part involves loading the original ntdll.dll from the system directory and replacing the hooked ntdll code segment (.text segment) in the current process with the original code. The dynamic API calling is to traverse the export table of the target dll, match the function name using hash, obtain the address of the target function, and execute it using a pointer. \n\n### 3. Separation of Shellcode and Loader\n#### Besides encoding to bypass antivirus software, shellcode can also be separated from the loader. If the shellcode is not included in the exe file, it becomes quite difficult for antivirus software to detect any issues. \n\nThe shellcode section mainly undergoes multi-layer obfuscation processing, which involves XOR, RC4, base64, and MAC. The final output is in MAC address format, taking advantage of Windows' tolerance for MAC format strings. \n\n## Usage Method\n### First, use encode.cpp to encrypt the shellcode. If you write the shellcode into an exe file, please place it in the mac_shellcode array in Unseparation_shellcode.cpp. If you want to achieve parameter separation, you can run the compiled exe + shellcode directly. \n\nThank you for reading.\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-20T02:30:50.279157"
  }
]