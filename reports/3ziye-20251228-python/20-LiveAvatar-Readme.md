<div align="center">

<p align="center">
  <img src="./assets/logo.png" width="200px" alt="Live Avatar Teaser">
</p>

<h1>ğŸ¬ Live Avatar: Streaming Real-time Audio-Driven Avatar Generation with Infinite Length</h1>
<!-- <h3>The code will be open source in <strong><span style="color: #87CEEB;">early December</span></strong>.</h3> -->


<p>
<a href="https://github.com/Yubo-Shankui" style="color: inherit;">Yubo Huang</a><sup>1,2</sup> Â·
<a href="#" style="color: inherit;">Hailong Guo</a><sup>2,3</sup> Â·
<a href="#" style="color: inherit;">Fangtai Wu</a><sup>2,4</sup> Â·
<a href="#" style="color: inherit;">Shifeng Zhang</a><sup>2</sup> Â·
<a href="#" style="color: inherit;">Shijie Huang</a><sup>2</sup> Â·
<a href="#" style="color: inherit;">Qijun Gan</a><sup>4</sup> Â·
<a href="#" style="color: inherit;">Lin Liu</a><sup>1</sup> Â·
<a href="#" style="color: inherit;">Sirui Zhao</a><sup>1,*</sup> Â·
<a href="http://staff.ustc.edu.cn/~cheneh/" style="color: inherit;">Enhong Chen</a><sup>1,*</sup> Â·
<a href="https://openreview.net/profile?id=%7EJiaming_Liu7" style="color: inherit;">Jiaming Liu</a><sup>2,â€¡</sup> Â·
<a href="https://sites.google.com/view/stevenhoi/" style="color: inherit;">Steven Hoi</a><sup>2</sup>
</p>

<p style="font-size: 0.9em;">
<sup>1</sup> University of Science and Technology of China &nbsp;&nbsp;
<sup>2</sup> Alibaba Group &nbsp;&nbsp;
<sup>3</sup> Beijing University of Posts and Telecommunications &nbsp;&nbsp;
<sup>4</sup> Zhejiang University
</p>

<p style="font-size: 0.9em;">
<sup>*</sup> Corresponding authors. &nbsp;&nbsp; <sup>â€¡</sup> Project leader.
</p>

<!-- Badges -->
<a href="https://arxiv.org/abs/2512.04677"><img src="https://img.shields.io/badge/arXiv-2512.04677-b31b1b.svg?style=for-the-badge" alt="arXiv"></a> <a href="https://huggingface.co/papers/2512.04677"><img src="https://img.shields.io/badge/ğŸ¤—%20Daily%20Paper-ff9d00?style=for-the-badge" alt="Daily Paper"></a> <a href="https://huggingface.co/Quark-Vision/Live-Avatar"><img src="https://img.shields.io/badge/Hugging%20Face-Model-ffbd45?style=for-the-badge&logo=huggingface&logoColor=white" alt="HuggingFace"></a> <a href="https://github.com/Alibaba-Quark/LiveAvatar"><img src="https://img.shields.io/badge/Github-Code-black?style=for-the-badge&logo=github" alt="Github"></a> <a href="https://liveavatar.github.io/"><img src="https://img.shields.io/badge/Project-Page-blue?style=for-the-badge&logo=googlechrome&logoColor=white" alt="Project Page"></a>

</div>

> **TL;DR:** **Live Avatar** is an algorithmâ€“system co-designed framework that enables real-time, streaming, infinite-length interactive avatar video generation. Powered by a **14B-parameter** diffusion model, it achieves **20 FPS** on **5Ã—H800** GPUs with **4-step** sampling and supports **Block-wise Autoregressive** processing for **10,000+** second streaming videos.

<div align="center">

[![Watch the video](assets/demo.png)](https://www.youtube.com/watch?v=srbsGlLNpAc)

<strong>ğŸ‘€ More Demos:</strong> <br>
ğŸ¤– Human-AI Conversation &nbsp;|&nbsp; â™¾ï¸ Infinite Video &nbsp;|&nbsp; ğŸ­ Diverse Characters &nbsp;|&nbsp; ğŸ¬ Animated Tech Explanation <br>
<a href="https://liveavatar.github.io/">
  <strong>ğŸ‘‰ Click Here to Visit Project Page! ğŸŒ</strong>
</a>
<br>

</div>

---
## âœ¨ Highlights

> - âš¡ **â€‹â€‹Real-time Streaming Interaction**â€‹â€‹ - Achieve **20** FPS real-time streaming with low latency
> - â™¾ï¸ â€‹â€‹**â€‹â€‹Infinite-length Autoregressive Generation**â€‹â€‹â€‹â€‹ - Support **10,000+** second continuous video generation
> - ğŸ¨ â€‹â€‹**â€‹â€‹Generalization Performances**â€‹â€‹â€‹â€‹ - Strong generalization across cartoon characters, singing, and diverse scenarios 


---
## ğŸ“° News
- **[2025.12.16]** ğŸ‰ LiveAvatar has reached 1,000+ stars on GitHub! Thank you to the community for the incredible support! â­
- **[2025.12.12]** ğŸš€ We released single-gpu inference [Code](infinite_inference_single_gpu.sh) â€” no need for 5Ã—H100 (house-priced server), a single 80GB VRAM GPU is enough to enjoy. 
- **[2025.12.08]** ğŸš€ We released real-time inference [Code](infinite_inference_multi_gpu.sh) and the model [Weight](https://huggingface.co/Quark-Vision/Live-Avatar).
- **[2025.12.08]** ğŸ‰ LiveAvatar won the Hugging Face [#1 Paper of the day](https://huggingface.co/papers/date/2025-12-05)!
- **[2025.12.04]** ğŸƒâ€â™‚ï¸ We committed to open-sourcing the code in **early December**.
- **[2025.12.04]** ğŸ”¥ We released [Paper](https://arxiv.org/abs/2512.04677) and [demo page](https://liveavatar.github.io/) Website.

---

## ğŸ“‘ Todo List

### ğŸŒŸ **Early December** (core code release)

- âœ… Release the paper
- âœ… Release the demo website
- âœ… Release checkpoints on Hugging Face
- âœ… Release Gradio Web UI
- âœ… Experimental real-time streaming inference on at least H800 GPUs
  - âœ… Distribution-matching distillation to 4 steps
  - âœ… Timestep-forcing pipeline parallelism

### âš™ï¸ **Later updates**

- âœ… Inference code supporting single GPU (offline generation)
- â¬œ Multi-character support
- â¬œ UI integration for easily streaming interaction
- â¬œ TTS integration
- â¬œ Training code 
- 