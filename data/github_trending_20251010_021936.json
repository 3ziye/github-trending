[
  {
    "basic_info": {
      "name": "RustGPT",
      "full_name": "tekaratzas/RustGPT",
      "owner": "tekaratzas",
      "description": "An transformer based LLM. Written completely in Rust",
      "url": "https://github.com/tekaratzas/RustGPT",
      "clone_url": "https://github.com/tekaratzas/RustGPT.git",
      "ssh_url": "git@github.com:tekaratzas/RustGPT.git",
      "homepage": null,
      "created_at": "2025-09-13T22:05:55Z",
      "updated_at": "2025-10-09T22:14:26Z",
      "pushed_at": "2025-10-05T22:18:19Z"
    },
    "stats": {
      "stars": 2828,
      "forks": 233,
      "watchers": 2828,
      "open_issues": 7,
      "size": 201
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 64634
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# 🦀 Rust LLM from Scratch\n\n[![Rust](https://github.com/tekaratzas/RustGPT/actions/workflows/rust.yml/badge.svg)](https://github.com/tekaratzas/RustGPT/actions/workflows/rust.yml)\n\nhttps://github.com/user-attachments/assets/ec4a4100-b03a-4b3c-a7d6-806ea54ed4ed\n\nA complete **Large Language Model implementation in pure Rust** with no external ML frameworks. Built from the ground up using only `ndarray` for matrix operations.\n\n## 🚀 What This Is\n\nThis project demonstrates how to build a transformer-based language model from scratch in Rust, including:\n- **Pre-training** on factual text completion\n- **Instruction tuning** for conversational AI\n- **Interactive chat mode** for testing\n- **Full backpropagation** with gradient clipping\n- **Modular architecture** with clean separation of concerns\n\n## ❌ What This Isn't\n\nThis is not a production grade LLM. It is so far away from the larger models.\n\nThis is just a toy project that demonstrates how these models work under the hood.\n\n## 🔍 Key Files to Explore\n\nStart with these two core files to understand the implementation:\n\n- **[`src/main.rs`](src/main.rs)** - Training pipeline, data preparation, and interactive mode\n- **[`src/llm.rs`](src/llm.rs)** - Core LLM implementation with forward/backward passes and training logic\n\n## 🏗️ Architecture\n\nThe model uses a **transformer-based architecture** with the following components:\n\n```\nInput Text → Tokenization → Embeddings → Transformer Blocks → Output Projection → Predictions\n```\n\n### Project Structure\n\n```\nsrc/\n├── main.rs              # 🎯 Training pipeline and interactive mode\n├── llm.rs               # 🧠 Core LLM implementation and training logic\n├── lib.rs               # 📚 Library exports and constants\n├── transformer.rs       # 🔄 Transformer block (attention + feed-forward)\n├── self_attention.rs    # 👀 Multi-head self-attention mechanism\n├── feed_forward.rs      # ⚡ Position-wise feed-forward networks\n├── embeddings.rs        # 📊 Token embedding layer\n├── output_projection.rs # 🎰 Final linear layer for vocabulary predictions\n├── vocab.rs            # 📝 Vocabulary management and tokenization\n├── layer_norm.rs       # 🧮 Layer normalization\n└── adam.rs             # 🏃 Adam optimizer implementation\n\ntests/\n├── llm_test.rs         # Tests for core LLM functionality\n├── transformer_test.rs # Tests for transformer blocks\n├── self_attention_test.rs # Tests for attention mechanisms\n├── feed_forward_test.rs # Tests for feed-forward layers\n├── embeddings_test.rs  # Tests for embedding layers\n├── vocab_test.rs       # Tests for vocabulary handling\n├── adam_test.rs        # Tests for optimizer\n└── output_projection_test.rs # Tests for output layer\n```\n\n## 🧪 What The Model Learns\n\nThe implementation includes two training phases:\n\n1. **Pre-training**: Learns basic world knowledge from factual statements\n   - \"The sun rises in the east and sets in the west\"\n   - \"Water flows downhill due to gravity\"\n   - \"Mountains are tall and rocky formations\"\n\n2. **Instruction Tuning**: Learns conversational patterns\n   - \"User: How do mountains form? Assistant: Mountains are formed through tectonic forces...\"\n   - Handles greetings, explanations, and follow-up questions\n\n## 🚀 Quick Start\n\n```bash\n# Clone and run\ngit clone https://github.com/tekaratzas/RustGPT.git\ncd RustGPT\ncargo run\n\n# The model will:\n# 1. Build vocabulary from training data\n# 2. Pre-train on factual statements (100 epochs)\n# 3. Instruction-tune on conversational data (100 epochs)\n# 4. Enter interactive mode for testing\n```\n\n## 🎮 Interactive Mode\n\nAfter training, test the model interactively:\n\n```\nEnter prompt: How do mountains form?\nModel output: Mountains are formed through tectonic forces or volcanism over long geological time periods\n\nEnter prompt: What causes rain?\nModel output: Rain is caused by water vapor in clouds condensing into droplets that become too heavy to remain airborne\n```\n\n## 🧮 Technical Implementation\n\n### Model Configuration\n- **Vocabulary Size**: Dynamic (built from training data)\n- **Embedding Dimension**: 128 (defined by `EMBEDDING_DIM` in `src/lib.rs`)\n- **Hidden Dimension**: 256 (defined by `HIDDEN_DIM` in `src/lib.rs`)\n- **Max Sequence Length**: 80 tokens (defined by `MAX_SEQ_LEN` in `src/lib.rs`)\n- **Architecture**: 3 Transformer blocks + embeddings + output projection\n\n### Training Details\n- **Optimizer**: Adam with gradient clipping\n- **Pre-training LR**: 0.0005 (100 epochs)\n- **Instruction Tuning LR**: 0.0001 (100 epochs)\n- **Loss Function**: Cross-entropy loss\n- **Gradient Clipping**: L2 norm capped at 5.0\n\n### Key Features\n- **Custom tokenization** with punctuation handling\n- **Greedy decoding** for text generation\n- **Gradient clipping** for training stability\n- **Modular layer system** with clean interfaces\n- **Comprehensive test coverage** for all components\n\n## 🔧 Development\n\n```bash\n# Run all tests\ncargo test\n\n# Test specific components\ncargo test --test llm_test\ncargo test --test transformer_test\ncargo test --test self_attention_test\n\n# Buil",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-10T02:19:37.359839"
  },
  {
    "basic_info": {
      "name": "pingoo",
      "full_name": "pingooio/pingoo",
      "owner": "pingooio",
      "description": "The fast and secure Load Balancer / API Gateway / Reverse Proxy with built-in service discovery, GeoIP, WAF, bot protection and much more - https://pingoo.io",
      "url": "https://github.com/pingooio/pingoo",
      "clone_url": "https://github.com/pingooio/pingoo.git",
      "ssh_url": "git@github.com:pingooio/pingoo.git",
      "homepage": "https://pingoo.io",
      "created_at": "2025-09-17T07:18:40Z",
      "updated_at": "2025-10-10T01:52:53Z",
      "pushed_at": "2025-10-06T08:45:13Z"
    },
    "stats": {
      "stars": 795,
      "forks": 26,
      "watchers": 795,
      "open_issues": 8,
      "size": 403
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 224470,
        "TypeScript": 7020,
        "Dockerfile": 6708,
        "Makefile": 2265,
        "Shell": 1620,
        "JavaScript": 1234,
        "HTML": 892,
        "CSS": 620,
        "Vim Script": 19
      },
      "license": "MIT License",
      "topics": [
        "akamai",
        "anti-bot",
        "apache2",
        "api",
        "api-gateway",
        "captcha",
        "cloudflare",
        "fastly",
        "firewall",
        "haproxy",
        "load-balancer",
        "nginx",
        "pingoo",
        "proxy",
        "quic",
        "reverse-proxy",
        "rust",
        "security",
        "service-discovery",
        "waf"
      ]
    },
    "content": {
      "readme": "<p align=\"center\">\n  <a href=\"https://pingoo.io\" target=\"_blank\" rel=\"noopener\"><img alt=\"Pingoo logo\" src=\"https://pingoo.io/icon-256.png\" height=\"128\" /></a>\n  <h1 align=\"center\">Pingoo</h1>\n  <h3 align=\"center\">The fast and secure Load Balancer / API Gateway / Reverse Proxy with built-in service discovery, GeoIP, WAF, bot protection and much more</h3>\n  <h3 align=\"center\">\n    <a href=\"https://pingoo.io\">Documentation</a> | <a href=\"https://kerkour.com/announcing-pingoo\">Read the launch post</a>\n  </h3>\n</p>\n\nOpen Source load balancers and reverse proxies are stuck in the past century with a very slow pace of development and most of the important features reserved for \"Enterprise Editions\" which lead developers to use third-party cloud services, exposing their users' traffic to legal, security and reliability risks.\n\nPingoo is a modern Load Balancer / API Gateway / Reverse Proxy that run on your own servers and already have (or will have soon) all the features you expect from managed services and even more. All of that with a huge boost in performance and security thanks to reduced latency and, of course, Rust ;)\n\n* Automatic and Post-Quantum HTTPS / TLS\n* Service Discovery (Docker, DNS...)\n* Web Application Firewall (WAF)\n* Easy compliance because the data never leaves your servers\n* Bot protection and management\n* TCP proxying\n* GeoIP (country, ASN)\n* Static sites\n* And much more\n\n\n## Quickstart\n\n```bash\n# You have a static site in the www folder\n$ ls www\nindex.html\n$ docker run --rm -ti --network host -v `pwd`/www:/var/wwww ghcr.io/pingooio/pingoo\n# Pingoo is now listenning on http://0.0.0.0\n```\n\n## Documentation\n\nSee https://pingoo.io\n\n\n## Updates\n\n[Click Here](https://kerkour.com/blog) to visit the blog and [subscribe](https://kerkour.com/subscribe) by RSS or email to get weekly / monthly updates. No spam ever, only technical deep dives.\n\n\n## Contributing\n\nPlease open an issue to discuss your idea before submitting a Pull Request.\n\n\n## Support\n\nDo you have custom needs? Do you want your features to be prioritized? Are you under attack and need help? Do you need support for deploying and self-hosting Pingoo?\n\nFeel free to reach our team of experts to see how we can help: https://pingoo.io/contact\n\n\n## Security\n\nWe are committed to make Pingoo the most secure Load Balancer / Reverse Proxy in the universe and beyond. If you've found a security issue in Pingoo, we appreciate your help in disclosing it to us in a responsible manner by contacting us: https://pingoo.io/contact\n\n\n## License\n\nMIT. See `LICENSE.txt`\n\nForever Open Source. No Open Core or \"Enterprise Edition\".\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-10T02:19:38.526112"
  },
  {
    "basic_info": {
      "name": "run",
      "full_name": "Esubaalew/run",
      "owner": "Esubaalew",
      "description": "Universal multi-language runner and smart REPL written in Rust.",
      "url": "https://github.com/Esubaalew/run",
      "clone_url": "https://github.com/Esubaalew/run.git",
      "ssh_url": "git@github.com:Esubaalew/run.git",
      "homepage": "https://run.esubalew.et",
      "created_at": "2025-09-30T08:03:00Z",
      "updated_at": "2025-10-10T01:47:52Z",
      "pushed_at": "2025-10-09T12:10:05Z"
    },
    "stats": {
      "stars": 649,
      "forks": 11,
      "watchers": 649,
      "open_issues": 1,
      "size": 169
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 505606,
        "Shell": 4946,
        "Smarty": 1134
      },
      "license": "Apache License 2.0",
      "topics": [
        "repl",
        "rust"
      ]
    },
    "content": {
      "readme": "<h1 align=\"center\">run</h1>\n\n<p align=\"center\">\n\t<strong>Polyglot command runner & smart REPL that lets you script, compile, and iterate in 25+ languages without touching another CLI.</strong>\n</p>\n\n<p align=\"center\">\n  <!-- Release -->\n  <a href=\"https://github.com/Esubaalew/run/releases/latest\">\n    <img src=\"https://img.shields.io/github/v/release/Esubaalew/run?style=flat-square&color=orange&logo=github\" alt=\"Latest release\" />\n  </a>\n\n  <!-- Release status -->\n  <img src=\"https://img.shields.io/badge/release-passing-brightgreen?style=flat-square\" alt=\"Release passing\" />\n\n  <!-- Docs -->\n  <a href=\"https://docs.rs/run-kit\">\n    <img src=\"https://img.shields.io/badge/docs-passing-brightgreen?style=flat-square&logo=rust\" alt=\"Docs passing\" />\n  </a>\n\n  <!-- Crates.io -->\n  <a href=\"https://crates.io/crates/run-kit\">\n    <img src=\"https://img.shields.io/crates/v/run-kit.svg?style=flat-square&logo=rust&color=red\" alt=\"crates.io\" />\n  </a>\n\n  <!-- Downloads -->\n  <a href=\"https://github.com/Esubaalew/run/releases\">\n    <img src=\"https://img.shields.io/github/downloads/Esubaalew/run/total?style=flat-square&color=blue\" alt=\"Downloads\" />\n  </a>\n\n  <!-- Stars -->\n  <a href=\"https://github.com/Esubaalew/run/stargazers\">\n    <img src=\"https://img.shields.io/github/stars/Esubaalew/run?style=flat-square&color=yellow\" alt=\"GitHub stars\" />\n  </a>\n\n  <!-- Platforms -->\n  <img src=\"https://img.shields.io/badge/platform-Linux%20%7C%20macOS%20%7C%20Windows-lightgrey?style=flat-square\" alt=\"Platform support\" />\n\n  <!-- License -->\n  <a href=\"LICENSE\">\n    <img src=\"https://img.shields.io/badge/license-Apache%202.0-blue?style=flat-square\" alt=\"License\" />\n  </a>\n</p>\n\n\n\n<p align=\"center\">\n\t<a href=\"https://run.esubalew.et/\">Website</a>\n\t•\n\t<a href=\"https://run.esubalew.et/docs/overview\">Docs Overview</a>\n</p>\n\n> Built in Rust for developers who live in multiple runtimes. `run` gives you a consistent CLI, persistent REPLs, and batteries-included examples for your favorite languages.\n\n---\n\n<details>\n<summary><strong>Table of contents</strong></summary>\n\n- [Website and Docs](#website-and-docs)\n- [Overview](#overview---universal-multi-language-runner)\n  - [What is run?](#what-is-run)\n  - [Who is this for?](#who-is-this-for)\n  - [Why was run created?](#why-was-run-created)\n  - [Why Rust?](#why-rust)\n- [Highlights](#-highlights)\n- [Quickstart](#-quickstart)\n- [Installation](#-installation)\n- [How it works](#-how-it-works)\n- [Supported languages](#-supported-languages)\n  - [Complete Language Aliases Reference](#complete-language-aliases-reference)\n- [Command Variations - Flexible Syntax](#command-variations---flexible-syntax)\n- [Command-Line Flags Reference](#command-line-flags-reference)\n- [⚠️ When to Use --lang (Important!)](#️-when-to-use---lang-important)\n- [Main Function Flexibility](#main-function-flexibility)\n- [Examples](#-examples)\n- [REPL](#-repl)\n  - [Interactive REPL - Line by Line or Paste All](#interactive-repl---line-by-line-or-paste-all)\n  - [Variable Persistence & Language Switching](#variable-persistence--language-switching)\n  - [REPL Commands](#repl-commands)\n- [Stdin Piping Examples](#stdin-piping-examples)\n- [Language-Specific Notes](#language-specific-notes)\n- [📄 License](#-license)\n\n</details>\n\n---\n\n# Website and Docs\n\nThe official website and full documentation are available here:\n\n- Website: https://run.esubalew.et/\n- Docs Overview: https://run.esubalew.et/docs/overview\n\nUse these links to explore features, language guides, and detailed examples.\n\n---\n\n# Overview - Universal Multi-Language Runner\n\nA powerful command-line tool for executing code in 25 programming languages\n\n## What is run?\n\nrun is a universal multi-language runner and smart REPL (Read-Eval-Print Loop) written in Rust. It provides a unified interface for executing code across 25 programming languages without the hassle of managing multiple compilers, interpreters, or build tools.\n\nWhether you're a beginner learning your first programming language or an experienced polyglot developer, run streamlines your workflow by providing consistent commands and behavior across all supported languages.\n\n## Who is this for?\n\n• Beginners: Learn programming without worrying about complex setup procedures. Just install run and start coding in any language.\n\n• Students: Quickly test code snippets and experiment with different programming paradigms across multiple languages.\n\n• Developers: Prototype ideas rapidly, test algorithms, and switch between languages seamlessly without context switching.\n\n• DevOps Engineers: Write and test automation scripts in various languages from a single tool.\n\n• Educators: Teach programming concepts across multiple languages with a consistent interface.\n\n## Why was run created?\n\nTraditional development workflows require installing and configuring separate tools for each programming language. This creates several problems:\n\n• Time-consuming setup: Installing compilers, interpreters, package managers, and configuring environment",
      "default_branch": "master"
    },
    "fetched_at": "2025-10-10T02:19:39.682550"
  },
  {
    "basic_info": {
      "name": "reddix",
      "full_name": "ck-zhang/reddix",
      "owner": "ck-zhang",
      "description": "Reddix - Reddit, refined for the terminal.",
      "url": "https://github.com/ck-zhang/reddix",
      "clone_url": "https://github.com/ck-zhang/reddix.git",
      "ssh_url": "git@github.com:ck-zhang/reddix.git",
      "homepage": "",
      "created_at": "2025-10-03T09:57:33Z",
      "updated_at": "2025-10-10T01:42:21Z",
      "pushed_at": "2025-10-10T01:42:24Z"
    },
    "stats": {
      "stars": 402,
      "forks": 2,
      "watchers": 402,
      "open_issues": 8,
      "size": 2194
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 458818
      },
      "license": "MIT License",
      "topics": [
        "reddit",
        "reddit-client"
      ]
    },
    "content": {
      "readme": "# Reddix\n\n[![Release](https://img.shields.io/github/v/release/ck-zhang/reddix?style=flat-square)](https://github.com/ck-zhang/reddix/releases/latest)\n[![License](https://img.shields.io/badge/license-MIT-blue.svg?style=flat-square)](LICENSE)\n\nReddix - Reddit, refined for the terminal.\n\n![Reddix UI](docs/assets/reddix-ui-preview.png)\n\n## Features\n\n- image preview based on kitty graphics protocol\n- multi-account support\n- keyboard first navigation\n- smart caching\n\n## Install\n\nDownload the latest [release](https://github.com/ck-zhang/reddix/releases/latest) from GitHub or run one of the installers\n\n```sh\ncurl --proto '=https' --tlsv1.2 -LsSf https://github.com/ck-zhang/reddix/releases/latest/download/reddix-installer.sh | sh\n```\n\n## Quickstart\n1. Create a Reddit “script” at https://www.reddit.com/prefs/apps and set the redirect URI to `http://127.0.0.1:65010/reddix/callback`.\n2. Launch `reddix`, press `m`, and follow the guided menu for setup.\n3. Prefer to configure things manually? Copy [`docs/examples/config.yaml`](docs/examples/config.yaml) into `~/.config/reddix/config.yaml` and fill in your credentials.\n\nCore shortcuts: `j/k` move, `h/l` change panes, `m` guided menu, `o` action menu, `r` refresh, `s` sync subs, `u/d` vote, `q` quit.\n\n## Support\n- Feature requests and contributions are welcome, this project is in its very early stage.\n- Track ongoing ideas in the [feature request log](docs/feature-requests.md).\n- Donation: https://ko-fi.com/ckzhang\n",
      "default_branch": "master"
    },
    "fetched_at": "2025-10-10T02:19:40.851387"
  },
  {
    "basic_info": {
      "name": "mdserve",
      "full_name": "jfernandez/mdserve",
      "owner": "jfernandez",
      "description": "Fast markdown preview server with live reload and theme support.",
      "url": "https://github.com/jfernandez/mdserve",
      "clone_url": "https://github.com/jfernandez/mdserve.git",
      "ssh_url": "git@github.com:jfernandez/mdserve.git",
      "homepage": "",
      "created_at": "2025-09-22T04:15:44Z",
      "updated_at": "2025-10-09T22:50:34Z",
      "pushed_at": "2025-10-04T14:45:10Z"
    },
    "stats": {
      "stars": 297,
      "forks": 18,
      "watchers": 297,
      "open_issues": 6,
      "size": 1392
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 29010,
        "HTML": 18579,
        "Shell": 7161,
        "Nix": 1005
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# mdserve\n\nFast markdown preview server with **live reload** and **theme support**.\n\nJust run `mdserve file.md` and start writing. One statically-compiled executable that runs anywhere - no installation, no dependencies.\n\n![Terminal output when starting mdserve](mdserve-terminal-output.png)\n\n## Features\n\n- ⚡ **Instant Live Reload** - Real-time updates via WebSocket when markdown file changes\n- 🎨 **Multiple Themes** - Built-in theme selector with 5 themes including Catppuccin variants\n- 📝 **GitHub Flavored Markdown** - Full GFM support including tables, strikethrough, code blocks, and task lists\n- 📊 **Mermaid Diagrams** - Automatic rendering of flowcharts, sequence diagrams, class diagrams, and more\n- 🚀 **Fast** - Built with Rust and Axum for excellent performance and low memory usage\n\n## Installation\n\n### macOS (Homebrew)\n\n```bash\nbrew install mdserve\n```\n\n### Linux\n\n```bash\ncurl -sSfL https://raw.githubusercontent.com/jfernandez/mdserve/main/install.sh | bash\n```\n\nThis will automatically detect your platform and install the latest binary to your system.\n\n### Alternative Methods\n\n#### Using Cargo\n\n```bash\ncargo install mdserve\n```\n\n#### Arch Linux (AUR)\n\n```bash\nyay -S mdserve\n```\n\n#### Nix Package Manager\n\n``` bash\nnix profile install github:jfernandez/mdserve\n```\n\n#### From Source\n\n```bash\ngit clone https://github.com/jfernandez/mdserve.git\ncd mdserve\ncargo build --release\ncp target/release/mdserve <folder in your PATH>\n```\n\n#### Manual Download\n\nDownload the appropriate binary for your platform from the [latest release](https://github.com/jfernandez/mdserve/releases/latest).\n\n## Usage\n\n### Basic Usage\n\n```bash\n# Serve a markdown file on default port (3000)\nmdserve README.md\n\n# Serve on custom port\nmdserve README.md --port 8080\nmdserve README.md -p 8080\n```\n\n\n## Endpoints\n\nOnce running, the server provides (default: [http://localhost:3000](http://localhost:3000)):\n\n- **[`/`](http://localhost:3000/)** - Rendered HTML with live reload via WebSocket\n- **[`/raw`](http://localhost:3000/raw)** - Raw markdown content (useful for debugging)\n- **[`/ws`](http://localhost:3000/ws)** - WebSocket endpoint for real-time updates\n\n## Theme System\n\n**Built-in Theme Selector**\n- Click the 🎨 button in the top-right corner to open theme selector\n- **5 Available Themes**:\n  - **Light**: Clean, bright theme optimized for readability\n  - **Dark**: GitHub-inspired dark theme with comfortable contrast\n  - **Catppuccin Latte**: Warm light theme with soothing pastels\n  - **Catppuccin Macchiato**: Cozy mid-tone theme with rich colors\n  - **Catppuccin Mocha**: Deep dark theme with vibrant accents\n- **Persistent Preference**: Your theme choice is automatically saved in browser localStorage\n\n*Click the theme button (🎨) to access the built-in theme selector*\n\n![Theme picker interface](mdserve-theme-picker.png)\n\n*mdserve running with the Catppuccin Macchiato theme - notice the warm, cozy colors and excellent readability*\n\n![mdserve with Catppuccin Macchiato theme](mdserve-catppuccin-macchiato.png)\n\n## Development\n\n### Prerequisites\n\n- Rust 1.85+ (2024 edition)\n\n### Building\n\n```bash\ncargo build --release\n```\n\n### Running Tests\n\n```bash\n# Run all tests\ncargo test\n\n# Run integration tests only\ncargo test --test integration_test\n```\n\n## License\n\nThis project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.\n\n## Acknowledgments\n\n- Built with [Axum](https://github.com/tokio-rs/axum) web framework\n- Markdown parsing by [markdown-rs](https://github.com/wooorm/markdown-rs)\n- [Catppuccin](https://catppuccin.com/) color themes\n- Inspired by various markdown preview tools\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-10T02:19:42.023578"
  },
  {
    "basic_info": {
      "name": "gpu-kill",
      "full_name": "kagehq/gpu-kill",
      "owner": "kagehq",
      "description": "Manage your GPUs across NVIDIA, AMD, Intel, and Apple Silicon systems.",
      "url": "https://github.com/kagehq/gpu-kill",
      "clone_url": "https://github.com/kagehq/gpu-kill.git",
      "ssh_url": "git@github.com:kagehq/gpu-kill.git",
      "homepage": "https://gpukill.com",
      "created_at": "2025-09-18T17:21:38Z",
      "updated_at": "2025-10-10T00:44:33Z",
      "pushed_at": "2025-10-05T02:22:30Z"
    },
    "stats": {
      "stars": 270,
      "forks": 7,
      "watchers": 270,
      "open_issues": 1,
      "size": 514
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 392220,
        "Shell": 21084,
        "PowerShell": 2451
      },
      "license": "Other",
      "topics": []
    },
    "content": {
      "readme": "# GPU Kill\n\nA CLI tool for managing GPUs across NVIDIA, AMD, Intel, and Apple Silicon systems. Monitor, control, and secure your GPU infrastructure with ease.\n\n## Community & Support\n\nJoin our Discord community for discussions, support, and updates:\n\n[![Discord](https://img.shields.io/badge/Discord-Join%20our%20community-7289DA?style=for-the-badge&logo=discord&logoColor=white)](https://discord.gg/KqdBcqRk5E)\n\n\n## Features\n\n- **Monitor GPUs**: Real-time usage, memory, temperature, and processes\n- **Kill Processes**: Gracefully terminate stuck GPU processes\n- **Security**: Detect crypto miners and suspicious activity\n- **Guard Mode**: Policy enforcement to prevent resource abuse\n- **Remote**: Manage GPUs across multiple servers\n- **Multi-Vendor**: Works with NVIDIA, AMD, Intel, and Apple Silicon\n- **AI Integration**: MCP server for AI assistant integration\n\n## Requirements\n\n### Build Performance\n\n**For faster development builds:**\n```bash\n# Fast release build (recommended for development)\ncargo build --profile release-fast\n\n# Standard release build (optimized for production)\ncargo build --release\n\n# Maximum optimization (slowest, best performance)\ncargo build --profile release-max\n```\n\n**Build times on typical hardware:**\n- Debug build: ~3 seconds\n- Release-fast: ~28 seconds  \n- Release: ~28 seconds (improved from 76 seconds)\n- Release-max: ~60+ seconds (maximum optimization)\n\n### System Dependencies\n\n**Linux (Ubuntu/Debian):**\n```bash\nsudo apt install build-essential libssl-dev pkg-config\n```\n\n**Linux (Fedora/RHEL/CentOS):**\n```bash\nsudo dnf install gcc gcc-c++ pkg-config openssl-devel\n# or for older systems:\n# sudo yum install gcc gcc-c++ pkg-config openssl-devel\n```\n\n**macOS:**\n```bash\n# Install Xcode command line tools\nxcode-select --install\n# OpenSSL is included with macOS\n```\n\n**Windows:**\n- Install Visual Studio Build Tools\n- OpenSSL is handled automatically by vcpkg\n\n### GPU Drivers\n\n- **NVIDIA**: NVIDIA drivers installed\n- **AMD**: ROCm drivers installed  \n- **Intel**: intel-gpu-tools package installed\n- **Apple Silicon**: macOS with Apple Silicon (M1/M2/M3/M4)\n\n### Build Requirements\n\n- **OS**: Linux, macOS, or Windows\n- **Rust**: 1.70+ (for building from source)\n\n## Quick Start\n\n### Install & Run\n```bash\n# Build from source (first build may take 2-3 minutes)\ngit clone https://github.com/kagehq/gpu-kill.git\ncd gpu-kill\ncargo build --release\n\n# Or install via Cargo\ncargo install gpukill\n\n# Or one-liner installers (recommended)\n# macOS/Linux\ncurl -fsSL https://raw.githubusercontent.com/kagehq/gpu-kill/refs/heads/main/scripts/install.sh | sh\n# Windows (PowerShell)\nirm https://raw.githubusercontent.com/kagehq/gpu-kill/refs/heads/main/scripts/install.ps1 | iex\n\n# List your GPUs\ngpukill --list\n\n# Watch GPU usage in real-time\ngpukill --list --watch\n```\n\n### Dead-simple cheatsheet\n```bash\n# Live watch (alias)\ngpukill watch            # = gpukill --list --watch\n\n# Kill job by PID (positional alias)\ngpukill 12345            # = gpukill --kill --pid 12345\n\n# Free a specific GPU index (kill all jobs on GPU 0)\ngpukill --kill --gpu 0   # add --batch to actually kill; preview without it\n\n# Force reset a GPU (shorthand)\ngpukill --reset 0        # = gpukill --reset --gpu 0\n\n# Safe mode: dry-run first (no changes)\ngpukill 12345 --safe     # alias: --dry-run\n```\n\n## Dashboard\n\n![GPU Kill Dashboard](dashboard/public/screenshot.png)\n\nCheck the [Kill Suite](https://kagehq.com) website.\n\n## MCP Server\n\nGPU Kill includes a MCP server that enables AI assistants to interact with GPU management functionality:\n\n- **Resources**: Read GPU status, processes, audit data, policies, and security scans\n- **Tools**: Kill processes, reset GPUs, scan for threats, create policies\n\n```bash\n# Start the MCP server\ncargo run --release -p gpukill-mcp\n\n# Server runs on http://localhost:3001/mcp\n```\n\n## Usage\n\nAsk your AI to use the tools.\n\n```text\nWhat GPUs do I have and what's their current usage?\n```\n\n```text\nKill the Python process that's stuck on GPU 0\n```\n\n```text\nKill all training processes that are using too much GPU memory\n```\n\n```text\nShow me GPU usage and kill any stuck processes\n```\n\n```text\nScan for crypto miners and suspicious activity\n```\n\n```text\nCreate a policy to limit user memory usage to 8GB\n```\n\n```text\nReset GPU 1 because it's not responding\n```\n\n```text\nWhat processes are currently using my GPUs?\n```\n\nSee [mcp/README.md](mcp/README.md) for detailed MCP server documentation.\n\n\n## Security & Policies\n\n### Detect Threats\n```bash\n# Scan for crypto miners and suspicious activity\ngpukill --audit --rogue\n\n# Configure detection rules\ngpukill --audit --rogue-config\n```\n\n### Policy Enforcement\n```bash\n# Enable Guard Mode\ngpukill --guard --guard-enable\n\n# Test policies safely\ngpukill --guard --guard-test-policies\n```\n\n*For detailed security and policy documentation, see [DETAILED.md](DETAILED.md).*\n\n## Remote Management\n\nManage GPUs across multiple servers via SSH:\n\n```bash\n# List GPUs on remote server\ngpukill --remote staging-serve",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-10T02:19:43.174844"
  },
  {
    "basic_info": {
      "name": "Wyrm",
      "full_name": "0xflux/Wyrm",
      "owner": "0xflux",
      "description": " The dragon in the dark. A red team post exploitation framework for testing security controls during red team assessments. ",
      "url": "https://github.com/0xflux/Wyrm",
      "clone_url": "https://github.com/0xflux/Wyrm.git",
      "ssh_url": "git@github.com:0xflux/Wyrm.git",
      "homepage": "",
      "created_at": "2025-09-25T16:41:37Z",
      "updated_at": "2025-10-10T01:00:05Z",
      "pushed_at": "2025-10-05T16:03:04Z"
    },
    "stats": {
      "stars": 211,
      "forks": 21,
      "watchers": 211,
      "open_issues": 1,
      "size": 3890
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 260642,
        "HTML": 15757,
        "CSS": 5881,
        "Shell": 3318,
        "PowerShell": 729,
        "PLpgSQL": 691,
        "Dockerfile": 646
      },
      "license": "MIT License",
      "topics": [
        "adversary-emulation",
        "adversary-simulation",
        "c2",
        "command-and-control",
        "pentest",
        "pentesting",
        "red-team",
        "red-teaming",
        "rust",
        "security-tools",
        "wyrm"
      ]
    },
    "content": {
      "readme": "# Wyrm - v0.3 Hatchling\n\n&#128679; Pre-release version &#128679;. If you want to support this project, please give it a star! I will be releasing updates and\ndevlogs on my [blog](https://fluxsec.red/) and [YouTube](https://www.youtube.com/@FluxSec) to document progress, so please give me a follow there.\n\nWyrm (pronounced 'worm', an old English word for 'serpent' or 'dragon') is a post exploitation, open source, Red Team security testing framework framework, written in Rust designed to be used by Red Teams, Purple Teams, \nPenetration Testers, and general infosec hobbyists. This project is fully built in Rust, with extra effort going into obfuscating artifacts which\ncould be present in memory. Project created and maintained by [flux](https://github.com/0xflux/), for **legal authorised security testing only**.\n\n![Wyrm Malware Post Exploitation Implant Red Team](resources/wyrm_landscape.png)\n\nWyrm currently supports only HTTP(S) agents using a custom encryption scheme for encrypting traffic below TLS, with a unique packet design so that\nthe packets cannot be realistically decrypted even under firewall level TLS inspection.\n\nThis project is a work in progress, currently released at v0.2 (Hatchling). Updates are planned through versions 1,0, 2.0, 3.0, and 4.0. You can view\nthe planned roadmap in this project (see [Milestones.md](https://github.com/0xflux/Wyrm/blob/master/Milestones.md)). In time, this is designed to be an open source competitor to **Cobalt Strike**, **Mythic**, **Sliver**, etc.\n\nFor any bugs, or feature requests, please use the Issues tab, and for anything else - please use GitHub Discussions. I am active on this project,\nso I will be attentive to anything raised.\n\n### Features\n\n- Implant uses a configurable profile to customise features and configurations\n- IOCs encrypted in the payload to assist in anti-analysis and anti-yara hardening\n- Implant transmits data encrypted below TLS, defeating perimeter inspection security tools out the box\n- Dynamic payload generation\n- Easy mechanism to stage files (such as built implants, PDF, zip, etc) on the C2 for download to support phishing campaigns and initial attack vectors\n- Supports native Windows API commands, more planned in future updates\n- Easy to use terminal client for the operator to task & inspect agents, and to manage staged resources\n- Implant uses the most common User-Agent for comms to help it blend in covertly with traffic by default, this is also configurable to suit your engagement\n- Easy, automated C2 infrastructure deployment with `install_server.sh`\n- Anti-sandbox techniques which are highly configurable by the operator through profiles\n- Backed by a database, fully timestamped to make reporting easier\n\nThis project is not currently accepting contributions, please **raise issues** or use **GitHub Discussions** and I will look into them, and help\nanswer any questions.\n\n**Before deploying the C2**, you should read the C2 readme file, found in the `/c2` directory. Proper docs are coming soon\nin time for v1.0 release, at https://wyrm-c2.com.\n\nA mental model for the C2 is as follows:\n\n![Wyrm C2](resources/c2_model.png)\n\nThe below image demonstrates the **Below TLS Encryption** feature and how it is implemented:\n\n![Wyrm Below TLS Encryption](resources/wyrm_post_diag.png)\n\n### Updates\n\n**WARNING:** Before pulling an update; please check the [release notes](https://github.com/0xflux/Wyrm/blob/master/RELEASE_NOTES.md) to see whether there are any breaking changes - for example if the\n**configurable C2 profile** changes in a breaking way from a previous profile you have, you will want to make sure you backup and migrate\nyour profile. I will be excluding `/c2/profiles/*` from git once the project is published in pre-release to prevent accidentally overwriting\nyour previous profile when running `git pull` to update your software.\n\nAs per the roadmap, this project will see significant development over the next 12 months. To pull updates, whether they are new features\nor bug fixes, you simply just do a git pull, re-build the c2 in release mode via:\n\n- `sudo systemctl stop wyrm`\n- `cd c2`, \n- `cargo build --release`\n- `sudo systemctl start wyrm`\n\n### Setup\n\nThe project contains an install shell script, and is designed to be run on `Debian` based Linux flavours.\nThe install script will install all required dependencies to the project, as well as making a new user, `wyrm_user`\nthat will run the C2 service.\n\nThe user account is created as `sudo useradd --system --no-create-home --shell /usr/sbin/nologin wyrm_user`.\n\n**Server Setup**\n\n1) Install your favourite reverse proxy (NGINX / Apache etc). The web app will default to serve on `0.0.0.0` at `:8080`. You can edit this in `/c2/.env` (at step 2), so configure your reverse proxy to use whatever you define in the `.env`.\n2) Clone the repo to your server & mark the install script executable.\n3) **SECURITY**: \n   1) In `c2/.env` edit:\n      1) `POSTGRES_PASSWORD`\n      2) `ADMIN_TOKEN` - **DO NOT USE THE ",
      "default_branch": "master"
    },
    "fetched_at": "2025-10-10T02:19:44.358558"
  },
  {
    "basic_info": {
      "name": "db-back-tool",
      "full_name": "iKeepLearn/db-back-tool",
      "owner": "iKeepLearn",
      "description": "postgresql、mysql数据库备份并上传到腾讯云或者阿里云或兼容S3协议的其他云存储，同时可列出、删除云上存储的备份文件。",
      "url": "https://github.com/iKeepLearn/db-back-tool",
      "clone_url": "https://github.com/iKeepLearn/db-back-tool.git",
      "ssh_url": "git@github.com:iKeepLearn/db-back-tool.git",
      "homepage": "",
      "created_at": "2025-09-22T08:49:42Z",
      "updated_at": "2025-10-09T11:42:06Z",
      "pushed_at": "2025-10-01T01:45:04Z"
    },
    "stats": {
      "stars": 175,
      "forks": 16,
      "watchers": 175,
      "open_issues": 0,
      "size": 289
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 44511
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# 使用说明\n\n一款基于 Rust 开发的数据库备份工具，支持单实例 PostgreSQL/MySQL 数据库的自动备份、加密、压缩，并可将备份文件上传至腾讯云 COS 或阿里云 OSS或兼容 S3 协议的其他云存储。\n\n开发动机是本人维护着很多单体服务分布在各个云服务器上，每个单体服务都使用各自的数据库实例，因为甲方预算原因没有配置数据库主从备份。\n但又有备份的需求，所以只好写个工具使用数据库自带的 dump 工具备份，再加密压缩上传到云存储。\n\n## 功能特性\n\n- 支持 PostgreSQL\\MySql 数据库自动备份\n- 备份文件自动加密、压缩\n- 一键上传备份到腾讯云 COS\\阿里云 OSS\\兼容S3协议的其他云存储\n- 支持备份文件的批量上传、批量删除、列表查看\n- 支持自定义配置文件\n\n## 前置条件\n\n请确保服务器已安装 `7z`。  \n安装命令（Debian/Ubuntu）：\n\n```bash\nsudo apt install p7zip-full\n```\n\n---\n\n## 快速开始\n\n1. 从 [release 页面](https://github.com/iKeepLearn/db-back-tool/releases) 下载可执行文件的 zip 包。\n2. 解压后，修改其中的 `config.yaml` 配置文件为正确的配置。\n\n---\n\n## 常用命令示例\n\n- **备份指定数据库**\n\n  ```bash\n  ./backupdbtool --config config.yaml backup <database_name>\n  ```\n\n- **上传所有待上传备份文件**\n\n  ```bash\n  ./backupdbtool --config config.yaml upload --all\n  ```\n\n- **上传单个备份文件**\n\n  ```bash\n  ./backupdbtool --config config.yaml upload --file /path/to/filename.ext\n  ```\n\n- **删除所有两天前的备份以减少云存储成本**\n\n  ```bash\n  ./backupdbtool --config config.yaml delete --all\n  ```\n\n- **删除单个云存储文件**\n\n  ```bash\n  ./backupdbtool --config config.yaml delete --key key\n  ```\n  > key 为云存储中的完整路径，比如想删除下方 list 中的 config.yaml 则 key 为 db/config.yaml。\n\n  > 完整示例: ./backupdbtool --config config.yaml delete --key db/config.yaml。\n\n- **列出所有备份文件**\n  ```bash\n  ./backupdbtool --config config.yaml list\n  ```\n  ![list](images/list.png)\n\n## 定时任务（Cron）推荐配置\n\n- **每日凌晨 2 点自动备份数据库**\n\n  ```bash\n  0 2 * * * /path/to/backupdbtool --config /path/to/config.yaml backup <database_name>\n  ```\n\n- **每日凌晨 2:30 上传所有待上传备份**\n\n  ```bash\n  30 2 * * * /path/to/backupdbtool --config /path/to/config.yaml upload --all\n  ```\n\n- **每周日凌晨 3 点删除所有两天前的备份以减少云存储成本**\n  ```bash\n  0 3 * * 0 /path/to/backupdbtool --config /path/to/config.yaml delete --all\n  ```\n\n> 请将 `/path/to/backupdbtool` 和 `/path/to/config.yaml` 替换为实际路径，`<database_name>` 替换为目标数据库名称。\n\n## 联系方式\n\n如有疑问，请联系开发者。\n\n![联系作者](images/ccwechat.jpg)\n",
      "default_branch": "master"
    },
    "fetched_at": "2025-10-10T02:19:45.505144"
  },
  {
    "basic_info": {
      "name": "blogr",
      "full_name": "bahdotsh/blogr",
      "owner": "bahdotsh",
      "description": "Write, edit, and publish your blog without ever leaving your terminal!",
      "url": "https://github.com/bahdotsh/blogr",
      "clone_url": "https://github.com/bahdotsh/blogr.git",
      "ssh_url": "git@github.com:bahdotsh/blogr.git",
      "homepage": "https://github.com/bahdotsh/blogr",
      "created_at": "2025-09-20T04:59:23Z",
      "updated_at": "2025-10-10T02:05:51Z",
      "pushed_at": "2025-10-07T06:11:01Z"
    },
    "stats": {
      "stars": 174,
      "forks": 13,
      "watchers": 174,
      "open_issues": 9,
      "size": 653
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 563037,
        "HTML": 169493,
        "CSS": 115263,
        "JavaScript": 17740,
        "Makefile": 2390,
        "Dockerfile": 1274
      },
      "license": "MIT License",
      "topics": [
        "blog",
        "blog-engine",
        "cli",
        "documentation-tool",
        "hacktoberfest",
        "newsletter",
        "ratatui",
        "rust",
        "ssg",
        "ssg-build",
        "static-site-generator",
        "tui"
      ]
    },
    "content": {
      "readme": "# Blogr\n\n[![Rust](https://img.shields.io/badge/rust-1.70%2B-orange.svg)](https://www.rust-lang.org)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![GitHub Pages](https://img.shields.io/badge/deploy-GitHub%20Pages-blue.svg)](https://pages.github.com/)\n\nA fast, lightweight static site generator built in Rust for creating and managing blogs. Write in Markdown, preview with a built-in terminal editor, and deploy to GitHub Pages with a single command.\n\n## Features\n\n**Two Site Types**\n- **Blog Mode**: Traditional blog with posts, archives, tags, and RSS feeds\n- **Personal Mode**: Portfolio/personal website without blog functionality\n- Single command initialization for either type\n- Theme-specific optimizations for each mode\n\n**Content Creation**\n- Write posts in Markdown with YAML frontmatter\n- Built-in terminal editor with live preview\n- Draft and published post management\n- Tag-based organization\n- Automatic slug generation\n\n**Site Generation**\n- Fast static site builds\n- Multiple themes: 7 built-in themes for blogs and personal sites\n  - Blog: Minimal Retro, Obsidian, Terminal Candy\n  - Personal: Dark Minimal, Musashi, Slate Portfolio, Typewriter (NEW)\n- Full-text search with MiniSearch integration\n- Syntax highlighting for code blocks\n- RSS/Atom feeds (blog mode)\n- SEO-friendly output\n\n**Development**\n- Live reload development server\n- Interactive configuration editor\n- Project validation and cleanup tools\n- Comprehensive CLI commands\n\n**Deployment**\n- One-command GitHub Pages deployment\n- Custom domain support with CNAME generation\n- Automatic git branch management\n- Deployment status checking\n\n**Newsletter System** (optional)\n- Email subscription collection via IMAP\n- Interactive subscriber approval interface\n- Newsletter creation from blog posts or custom content\n- SMTP integration for reliable email delivery\n- Import/export from popular services (Mailchimp, ConvertKit, etc.)\n- REST API for external integrations\n- Extensible plugin system\n\n## Installation\n\n**Requirements**\n- Rust 1.70+\n- Git (for deployment)\n- GitHub account (for GitHub Pages deployment)\n\n**Install from source:**\n```bash\ngit clone https://github.com/bahdotsh/blogr.git\ncd blogr\ncargo install --path blogr-cli\n```\n\n**Install from crates.io:**\n```bash\ncargo install blogr-cli\n```\n\n## Quick Start\n\n**1. Create a new blog or personal website**\n```bash\n# For a traditional blog\nblogr init my-blog\ncd my-blog\n\n# For a personal website (no blog posts)\nblogr init --personal my-portfolio\ncd my-portfolio\n```\n\n**2. Set up GitHub token** (for deployment)\n```bash\nexport GITHUB_TOKEN=your_github_token\n```\nGet a token at: https://github.com/settings/tokens (needs `repo` and `workflow` scopes)\n\n**3. Create your first post**\n```bash\nblogr new \"Hello World\"\n```\n\n**4. Choose a theme (optional)**\n```bash\n# Use default Minimal Retro theme, or switch to Obsidian\nblogr theme set obsidian              # For Obsidian community themes\ncurl -o static/obsidian.css https://raw.githubusercontent.com/kepano/obsidian-minimal/HEAD/obsidian.css\n```\n\n**5. Preview your blog**\n```bash\nblogr serve\n# Opens http://localhost:3000\n```\n\n**6. Deploy to GitHub Pages**\n```bash\nblogr deploy\n```\n\n## Commands\n\n**Project Management**\n```bash\nblogr init [NAME]           # Create new blog\nblogr init --personal [NAME] # Create personal website (no blog)\n  --github-username USER    # Set GitHub username\n  --github-repo REPO        # Set repository name\n  --no-github               # Skip GitHub setup\n\nblogr project info          # Show project details\nblogr project check         # Validate project\nblogr project clean         # Clean build files\n```\n\n**Content Management**\n```bash\nblogr new \"Post Title\"      # Create new post\n  --draft                   # Save as draft\n  --tags \"rust,web\"         # Add tags\n\nblogr list                  # List all posts\n  --drafts                  # Show only drafts\n  --tag rust                # Filter by tag\n\nblogr edit my-post-slug     # Edit existing post\nblogr delete my-post-slug   # Delete post\n```\n\n**Development**\n```bash\nblogr serve                 # Start dev server\n  --port 8080               # Custom port\n  --open                    # Open browser\n\nblogr build                 # Build static site\n  --drafts                  # Include drafts\n```\n\n**Deployment**\n```bash\nblogr deploy                # Deploy to GitHub Pages\n  --message \"Update\"        # Custom commit message\n```\n\n**Configuration**\n```bash\nblogr config edit          # Interactive config editor\nblogr config get blog.title # Get config value\nblogr config set blog.title \"My Blog\" # Set config value\n\n# Domain setup\nblogr config domain set example.com     # Set custom domain\nblogr config domain list                # List domains\n```\n\n**Newsletter** (optional)\n```bash\n# Subscriber management\nblogr newsletter fetch-subscribers      # Fetch from email inbox\nblogr newsletter approve                 # Launch approval UI\nblogr newsletter list    ",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-10T02:19:46.654627"
  },
  {
    "basic_info": {
      "name": "tsink",
      "full_name": "h2337/tsink",
      "owner": "h2337",
      "description": "Embedded time-series database for Rust",
      "url": "https://github.com/h2337/tsink",
      "clone_url": "https://github.com/h2337/tsink.git",
      "ssh_url": "git@github.com:h2337/tsink.git",
      "homepage": "",
      "created_at": "2025-09-12T21:29:24Z",
      "updated_at": "2025-10-09T00:12:47Z",
      "pushed_at": "2025-09-21T01:11:14Z"
    },
    "stats": {
      "stars": 158,
      "forks": 7,
      "watchers": 158,
      "open_issues": 2,
      "size": 245
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 186920
      },
      "license": "MIT License",
      "topics": [
        "database",
        "embedded-database",
        "rust",
        "time-series",
        "timeseries",
        "timeseries-database",
        "tsdb"
      ]
    },
    "content": {
      "readme": "# tsink\n\n<div align=\"center\">\n\n<p align=\"right\">\n  <img src=\"https://raw.githubusercontent.com/h2337/tsink/refs/heads/master/logo.svg\" width=\"250\" height=\"250\">\n</p>\n\n**A high-performance embedded time-series database for Rust**\n\n</div>\n\n## Overview\n\ntsink is a lightweight, high-performance time-series database engine written in Rust. It provides efficient storage and retrieval of time-series data with automatic compression, time-based partitioning, and thread-safe operations.\n\n### Key Features\n\n- **🚀 High Performance**: Gorilla compression achieves ~1.37 bytes per data point\n- **🔒 Thread-Safe**: Lock-free reads and concurrent writes with configurable worker pools\n- **💾 Flexible Storage**: Choose between in-memory or persistent disk storage\n- **📊 Time Partitioning**: Automatic data organization by configurable time ranges\n- **🏷️ Label Support**: Multi-dimensional metrics with key-value labels\n- **📝 WAL Support**: Write-ahead logging for durability and crash recovery\n- **🗑️ Auto-Retention**: Configurable automatic data expiration\n- **🐳 Container-Aware**: cgroup support for optimal resource usage in containers\n- **⚡ Zero-Copy Reads**: Memory-mapped files for efficient disk operations\n\n## Installation\n\nAdd tsink to your `Cargo.toml`:\n\n```toml\n[dependencies]\ntsink = \"0.3.1\"\n```\n\n## Quick Start\n\n### Basic Usage\n\n```rust\nuse tsink::{DataPoint, Row, StorageBuilder, Storage, TimestampPrecision};\n\nfn main() -> Result<(), Box<dyn std::error::Error>> {\n    // Create storage with default settings\n    let storage = StorageBuilder::new()\n        .with_timestamp_precision(TimestampPrecision::Seconds)\n        .build()?;\n\n    // Insert data points\n    let rows = vec![\n        Row::new(\"cpu_usage\", DataPoint::new(1600000000, 45.5)),\n        Row::new(\"cpu_usage\", DataPoint::new(1600000060, 47.2)),\n        Row::new(\"cpu_usage\", DataPoint::new(1600000120, 46.8)),\n    ];\n    storage.insert_rows(&rows)?;\n\n    // Note: Using timestamp 0 will automatically use the current timestamp\n    // let row = Row::new(\"cpu_usage\", DataPoint::new(0, 50.0));  // timestamp = current time\n\n    // Query data points\n    let points = storage.select(\"cpu_usage\", &[], 1600000000, 1600000121)?;\n    for point in points {\n        println!(\"Timestamp: {}, Value: {}\", point.timestamp, point.value);\n    }\n\n    storage.close()?;\n    Ok(())\n}\n```\n\n### Persistent Storage\n\n```rust\nuse tsink::{StorageBuilder, Storage};\nuse std::time::Duration;\n\nlet storage = StorageBuilder::new()\n    .with_data_path(\"./tsink-data\")              // Enable disk persistence\n    .with_partition_duration(Duration::from_secs(3600))  // 1-hour partitions\n    .with_retention(Duration::from_secs(7 * 24 * 3600))  // 7-day retention\n    .with_wal_buffer_size(8192)                  // 8KB WAL buffer\n    .build()?;\n```\n\n### Multi-Dimensional Metrics with Labels\n\n```rust\nuse tsink::{DataPoint, Label, Row};\n\n// Create metrics with labels for detailed categorization\nlet rows = vec![\n    Row::with_labels(\n        \"http_requests\",\n        vec![\n            Label::new(\"method\", \"GET\"),\n            Label::new(\"status\", \"200\"),\n            Label::new(\"endpoint\", \"/api/users\"),\n        ],\n        DataPoint::new(1600000000, 150.0),\n    ),\n    Row::with_labels(\n        \"http_requests\",\n        vec![\n            Label::new(\"method\", \"POST\"),\n            Label::new(\"status\", \"201\"),\n            Label::new(\"endpoint\", \"/api/users\"),\n        ],\n        DataPoint::new(1600000000, 25.0),\n    ),\n];\n\nstorage.insert_rows(&rows)?;\n\n// Query specific label combinations\nlet points = storage.select(\n    \"http_requests\",\n    &[\n        Label::new(\"method\", \"GET\"),\n        Label::new(\"status\", \"200\"),\n    ],\n    1600000000,\n    1600000100,\n)?;\n\n// Query all label combinations for a metric\nlet all_results = storage.select_all(\"http_requests\", 1600000000, 1600000100)?;\nfor (labels, points) in all_results {\n    println!(\"Labels: {:?}, Points: {}\", labels, points.len());\n}\n```\n\n## Architecture\n\ntsink uses a linear-order partition model that divides time-series data into time-bounded chunks:\n\n```\n┌─────────────────────────────────────────┐\n│             tsink Storage               │\n├─────────────────────────────────────────┤\n│                                         │\n│  ┌───────────────┐  Active Partition    │\n│  │ Memory Part.  │◄─ (Writable)         │\n│  └───────────────┘                      │\n│                                         │\n│  ┌───────────────┐  Buffer Partition    │\n│  │ Memory Part.  │◄─ (Out-of-order)     │\n│  └───────────────┘                      │\n│                                         │\n│  ┌───────────────┐                      │\n│  │ Disk Part. 1  │◄─ Read-only          │\n│  └───────────────┘   (Memory-mapped)    │\n│                                         │\n│  ┌───────────────┐                      │\n│  │ Disk Part. 2  │◄─ Read-only          │\n│  └───────────────┘                      │\n│         ...                             │\n└─────────────────────────────────────────┘\n```\n\n### Partition ",
      "default_branch": "master"
    },
    "fetched_at": "2025-10-10T02:19:47.821779"
  },
  {
    "basic_info": {
      "name": "crispy-palm-tree",
      "full_name": "bingcicle/crispy-palm-tree",
      "owner": "bingcicle",
      "description": "dirhash",
      "url": "https://github.com/bingcicle/crispy-palm-tree",
      "clone_url": "https://github.com/bingcicle/crispy-palm-tree.git",
      "ssh_url": "git@github.com:bingcicle/crispy-palm-tree.git",
      "homepage": null,
      "created_at": "2025-09-29T15:13:51Z",
      "updated_at": "2025-10-08T01:04:18Z",
      "pushed_at": "2025-09-29T15:15:30Z"
    },
    "stats": {
      "stars": 150,
      "forks": 0,
      "watchers": 150,
      "open_issues": 0,
      "size": 6
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 2599
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# dirhash\nCompute SHA-256 for files in a directory and list duplicates.\n\n## Build\n```bash\ncargo build --release\n./target/release/dirhash ./data --exts jpg,png --dupes > dupes.csv\n```\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-10T02:19:49.027987"
  },
  {
    "basic_info": {
      "name": "kotofetch",
      "full_name": "hxpe-dev/kotofetch",
      "owner": "hxpe-dev",
      "description": "kotofetch is a small, configurable CLI that displays Japanese quotes in the terminal.",
      "url": "https://github.com/hxpe-dev/kotofetch",
      "clone_url": "https://github.com/hxpe-dev/kotofetch.git",
      "ssh_url": "git@github.com:hxpe-dev/kotofetch.git",
      "homepage": "",
      "created_at": "2025-09-10T15:26:52Z",
      "updated_at": "2025-10-08T12:35:22Z",
      "pushed_at": "2025-10-06T09:59:26Z"
    },
    "stats": {
      "stars": 133,
      "forks": 8,
      "watchers": 133,
      "open_issues": 3,
      "size": 3060
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 26217,
        "Nix": 706
      },
      "license": "MIT License",
      "topics": [
        "archlinux",
        "cli",
        "command-line",
        "fetch",
        "hyprland",
        "i3",
        "i3wm",
        "japanese",
        "linux",
        "quotes",
        "sway",
        "swaywm",
        "terminal",
        "unixporn"
      ]
    },
    "content": {
      "readme": "# kotofetch\n\nkotofetch is a small, configurable CLI tool that displays Japanese quotes in the terminal. It comes with built-in quotes and allows users to customize display options such as padding, width, translation display, and text styles.\n\n![image](./images/demo-01.png)\n\n## Installation\n\n### Arch Linux / AUR\nYou can install the stable release from the AUR:\n\n```bash\nyay -S kotofetch\n```\n\n> When prompted, choose All to clean-build the package from the downloaded PKGBUILD.\n\nOr by cloning the AUR from [here](https://aur.archlinux.org/packages/kotofetch):\n```bash\ngit clone https://aur.archlinux.org/kotofetch.git\ncd kotofetch\nmakepkg -si\n```\n\n### Nix / NixOS\nIf you use Nix, you can install `kotofetch` using those commands:\n```bash\ngit clone https://github.com/hxpe-dev/kotofetch.git\ncd kotofetch\nnix-build\n```\n\n### Prebuilt Binaries\nYou can download prebuilt binaries for **Linux**, **Windows** and **macOS** from the [Releases page](https://github.com/hxpe-dev/kotofetch/releases).\n\n| System / Distribution | File Extension | Description |\n|:----------------------|:---------------|:------------|\n| **Generic Linux** | `.tar.gz`      | The most universal build. Extract and run the binary. |\n| **Debian / Ubuntu** | `.deb`         | Install using `dpkg`. |\n| **Fedora / CentOS / openSUSE** | `.rpm`  | For all RPM-based systems. |\n| **Windows** | `.exe` or `.zip` | The standalone **`.exe`** is ready to run. The **`.zip`** contains the executable. |\n| **macOS** | `.tar.gz`      | Extract and run the binary. |\n\n### From Source\nRequires **Rust** and **Cargo**:\n\n```bash\ngit clone https://github.com/hxpe-dev/kotofetch.git\ncd kotofetch\ncargo install --path .\n```\n\nAfter installation, you can run `kotofetch` from anywhere in your terminal.\n\n## Configuration\n\n### Config File\n\nUser configuration lives in:  \n```bash\n~/.config/kotofetch/config.toml                       # On Linux\n~/Library/Application Support/kotofetch/config.toml   # On macOS\n%APPDATA%\\kotofetch\\config.toml                       # On Windows\n```\n\nHere you can customize:\n- `horizontal_padding` / `vertical_padding` - spacing around quotes\n- `width` - max width for text wrapping (`0` for automatic width)\n- `show_translation` - translation mode (`\"none\"`, `\"english\"`, `\"romaji\"`)\n- `quote_color` - named ANSI colors (`\"red\"`, `\"yellow\"`, `\"dim\"`, etc.) or hex (`\"#ffcc00\"`)\n- `translation_color` - named ANSI colors (`\"red\"`, `\"yellow\"`, `\"dim\"`, etc.) or hex (`\"#ffcc00\"`)\n- `border_color` - named ANSI colors (`\"red\"`, `\"yellow\"`, `\"dim\"`, etc.) or hex (`\"#ffcc00\"`)\n- `font_size` - small, medium, or large (adds spacing between characters)\n- `bold` - bold Japanese text (true/false)\n- `border` - show a box border (true/false)\n- `rounded_border` - show rounded border (need `border` to be enabled) (true/false)\n- `source` - show the quote source (true/false)\n- `modes` - list of quote files to use (any `.toml` file in `~/.config/kotofetch/quotes/` or built-in)\n- `seed` - RNG seed for random quotes (`0` for random seed)\n- `centered` - center text (true/false)\n- `dynamic` - dynamic re-centering of the text (true/false)\n\nExample `config.toml`:\n```toml\n[display]\nhorizontal_padding = 3\nvertical_padding = 1\nwidth = 50\nshow_translation = \"romaji\"\nquote_color = \"#a3be8c\"\ntranslation_color = \"dim\"\nborder_color = \"#be8ca3\"\nfont_size = \"medium\"\nbold = true\nborder = true\nrounded_border = true\nsource = true\nmodes = [\"proverb\", \"anime\"]\nseed = 0\ncentered = true\ndynamic = false\n```\n\n### Custom quotes\nBuilt-in quotes are embedded in the binary. To add your own quotes, create:\n```bash\n~/.config/kotofetch/quotes/                       # On Linux\n~/Library/Application Support/kotofetch/quotes/   # On macOS\n%APPDATA%\\kotofetch\\quotes\\                       # On Windows\n```\n- Place any `.toml` file there.\n- The filenames can be arbitrary, the program automatically reads all `.toml` files in this folder.\n- Each `.toml` must follow this structure:\n\n```toml\n[[quote]]\njapanese = \"逃げちゃダメだ\"\ntranslation = \"You mustn't run away.\"\nromaji = \"Nigeccha dame da\"\nsource = \"Neon Genesis Evangelion\"\n\n[[quote]]\njapanese = \"人は心で生きるんだ\"\ntranslation = \"People live by their hearts.\"\nromaji = \"Hito wa kokoro de ikiru nda\"\nsource = \"Your Name\"\n```\n- These custom quotes automatically merge with the built-in ones.\n\nYou can see the built-in quotes in the [quotes folder](quotes/).\n\n## Usage\n```bash\nkotofetch                               # display a quote following the config\nkotofetch --horizontal-padding 3        # override specific config parameter temporarily\nkotofetch --modes anime,mycustomquotes  # display quotes from specific files\n```\n\n## Contributing\nContributions are welcome! Here's how you can help:\n1. **Fork** the repository.\n2. **Clone** your fork locally:\n```bash\ngit clone https://github.com/YOUR_USERNAME/kotofetch.git\ncd kotofetch\n```\n3. **Create a branch** for your changes:\n```bash\ngit checkout -b feature/my-feature\n```\n\n4. **Make changes** and **commit**:\n```bash\ngit add .\ngit commit -m \"Add my feature\"\n```\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-10T02:19:50.175931"
  },
  {
    "basic_info": {
      "name": "DriftDB",
      "full_name": "DavidLiedle/DriftDB",
      "owner": "DavidLiedle",
      "description": "DriftDB - An experimental append-only database with built-in time travel. Query any point in history, guaranteed data integrity, and immutable audit trails. Written in Rust.",
      "url": "https://github.com/DavidLiedle/DriftDB",
      "clone_url": "https://github.com/DavidLiedle/DriftDB.git",
      "ssh_url": "git@github.com:DavidLiedle/DriftDB.git",
      "homepage": null,
      "created_at": "2025-09-14T16:27:28Z",
      "updated_at": "2025-10-08T12:37:30Z",
      "pushed_at": "2025-09-25T00:18:28Z"
    },
    "stats": {
      "stars": 129,
      "forks": 5,
      "watchers": 129,
      "open_issues": 2,
      "size": 2576
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 2453325,
        "Python": 338364,
        "Shell": 4308,
        "PLpgSQL": 2708,
        "Makefile": 2693,
        "Dockerfile": 1122
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# DriftDB\n\n**Experimental PostgreSQL-Compatible Time-Travel Database (v0.7.3-alpha)** - An ambitious temporal database project with advanced architectural designs for enterprise features. Query your data at any point in history using standard SQL.\n\n⚠️ **ALPHA SOFTWARE - NOT FOR PRODUCTION USE**: This version contains experimental implementations of enterprise features. The codebase now compiles cleanly with minimal warnings (reduced from 335 to 17). Many advanced features remain as architectural designs requiring implementation.\n\n## 🚀 Quick Start\n\n```bash\n# Start the PostgreSQL-compatible server\n./target/release/driftdb-server --data-path ./data\n\n# Connect with any PostgreSQL client\npsql -h localhost -p 5433 -d driftdb\n\n# Use standard SQL with time-travel\nCREATE TABLE events (id INT PRIMARY KEY, data VARCHAR);\nINSERT INTO events (id, data) VALUES (1, 'original');\nUPDATE events SET data = 'modified' WHERE id = 1;\n\n-- Query historical state!\nSELECT * FROM events AS OF @seq:1;  -- Shows 'original'\nSELECT * FROM events;                -- Shows 'modified'\n```\n\n## ✅ Working Features\n\n### Full SQL Support\n- **All 5 standard JOIN types**: INNER, LEFT, RIGHT, FULL OUTER, CROSS (including self-joins)\n- **Subqueries**: IN/NOT IN, EXISTS/NOT EXISTS (including correlated!), scalar subqueries\n- **Common Table Expressions (CTEs)**: WITH clause including RECURSIVE CTEs\n- **Transactions**: BEGIN, COMMIT, ROLLBACK with ACID guarantees\n- **Views**: CREATE/DROP VIEW with persistence across restarts\n- **DDL operations**: CREATE TABLE, ALTER TABLE ADD COLUMN, CREATE INDEX, TRUNCATE\n- **Aggregation functions**: COUNT(*), COUNT(DISTINCT), SUM, AVG, MIN, MAX\n- **GROUP BY and HAVING**: Full support for grouping with aggregate filtering\n- **CASE WHEN expressions**: Conditional logic in queries\n- **Set operations**: UNION, INTERSECT, EXCEPT\n- **Multi-row INSERT**: INSERT INTO ... VALUES (row1), (row2), ...\n- **Foreign key constraints**: Referential integrity enforcement\n- **Time-travel queries**: `AS OF` for querying historical states\n\n### Core Database Engine\n- **Event sourcing**: Every change is an immutable event with full history\n- **Time-travel queries**: Query any historical state by sequence number\n- **ACID compliance**: Full transaction support with isolation levels\n- **CRC32 verification**: Data integrity on every frame\n- **Append-only storage**: Never lose data, perfect audit trail\n- **JSON documents**: Flexible schema with structured data\n\n### Tested & Verified\n- ✅ Python psycopg2 driver\n- ✅ Node.js pg driver\n- ✅ JDBC PostgreSQL driver\n- ✅ SQLAlchemy ORM\n- ✅ Any PostgreSQL client\n\n## 🎯 Perfect For\n\n- **Debugging Production Issues**: \"What was the state when the bug occurred?\"\n- **Compliance & Auditing**: Complete audit trail built-in, no extra work\n- **Data Recovery**: Accidentally deleted data? It's still there!\n- **Analytics**: Track how metrics changed over time\n- **Testing**: Reset to any point, perfect for test scenarios\n- **Development**: Branch your database like Git\n\n## ✨ Core Features\n\n### SQL:2011 Temporal Queries (Native Support)\n- **`FOR SYSTEM_TIME AS OF`**: Query data at any point in time\n- **`FOR SYSTEM_TIME BETWEEN`**: Get all versions in a time range\n- **`FOR SYSTEM_TIME FROM...TO`**: Exclusive range queries\n- **`FOR SYSTEM_TIME ALL`**: Complete history of changes\n- **System-versioned tables**: Automatic history tracking\n\n### Data Model & Storage\n- **Append-only storage**: Immutable events preserve complete history\n- **Time travel queries**: Standard SQL:2011 temporal syntax\n- **ACID transactions**: Full transaction support with isolation levels\n- **Secondary indexes**: B-tree indexes for fast lookups\n- **Snapshots & compaction**: Optimized performance with compression\n\n### Planned Enterprise Features (Not Yet Functional)\nThe following features have been architecturally designed but are not yet operational:\n- **Authentication & Authorization**: Planned RBAC with user management (code incomplete)\n- **Encryption at Rest**: Designed AES-256-GCM encryption (not functional)\n- **Distributed Consensus**: Raft protocol structure (requires debugging)\n- **Advanced Transactions**: MVCC design for isolation levels (partial implementation)\n- **Enterprise Backup**: Backup system architecture (compilation errors)\n- **Security Monitoring**: Monitoring framework (not integrated)\n\n### Working Infrastructure\n- **Connection pooling**: Thread-safe connection pool with RAII guards\n- **Health checks**: Basic metrics endpoint\n- **Rate limiting**: Token bucket algorithm for connection limits\n\n### Query Features (Partially Working)\n- **B-tree indexes**: Secondary indexes for fast lookups (functional)\n- **Basic query planner**: Simple execution plans (working)\n- **Prepared statements**: Statement caching (functional)\n\n### Planned Query Optimization (Design Phase)\n- **Advanced Query Optimizer**: Cost-based optimization design (not implemented)\n- **Join Strategies**: Theoretical star schema optimization (code incomplete)\n- **Subquery O",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-10T02:19:51.390241"
  },
  {
    "basic_info": {
      "name": "servo-gtk",
      "full_name": "nacho/servo-gtk",
      "owner": "nacho",
      "description": "GTK integration for Servo",
      "url": "https://github.com/nacho/servo-gtk",
      "clone_url": "https://github.com/nacho/servo-gtk.git",
      "ssh_url": "git@github.com:nacho/servo-gtk.git",
      "homepage": null,
      "created_at": "2025-09-26T13:52:40Z",
      "updated_at": "2025-10-09T23:56:19Z",
      "pushed_at": "2025-10-09T17:11:54Z"
    },
    "stats": {
      "stars": 109,
      "forks": 2,
      "watchers": 109,
      "open_issues": 5,
      "size": 1579
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 35822,
        "JavaScript": 1965,
        "HTML": 135
      },
      "license": "Other",
      "topics": []
    },
    "content": {
      "readme": "# Servo GTK\n\nA GTK4 library that embeds the Servo web engine.\n\n## Features\n\n- GTK4-based web browser widget\n- Servo web engine integration\n- OpenGL-accelerated rendering\n- Async event handling\n\n## Building\n\n```bash\ncargo build\n```\n\n## Running the Example\n\n```bash\ncargo run --example browser\n```\n\n## Using as a Library\n\nAdd to your `Cargo.toml`:\n\n```toml\n[dependencies]\nservo-gtk = { path = \"path/to/servo-gtk\" }\n```\n\nThen use in your code:\n\n```rust\nuse servo_gtk::WebView;\n\nlet webview = WebView::new();\nwebview.load_url(\"https://example.com\");\n```\n\n## Dependencies\n\n- GTK4\n- OpenGL\n- Servo web engine\n- Rust toolchain\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-10T02:19:52.547107"
  },
  {
    "basic_info": {
      "name": "free-ferris-pack",
      "full_name": "MariaLetta/free-ferris-pack",
      "owner": "MariaLetta",
      "description": "🦀 Pack of 50+ Ferris pictures and elements will help you to build your own design for anything related to Rust Programming Language: presentations, README files, posts in blogs or social media, courses, videos and many, many more. ",
      "url": "https://github.com/MariaLetta/free-ferris-pack",
      "clone_url": "https://github.com/MariaLetta/free-ferris-pack.git",
      "ssh_url": "git@github.com:MariaLetta/free-ferris-pack.git",
      "homepage": "",
      "created_at": "2025-10-04T20:22:05Z",
      "updated_at": "2025-10-09T10:25:36Z",
      "pushed_at": "2025-10-05T14:55:22Z"
    },
    "stats": {
      "stars": 103,
      "forks": 4,
      "watchers": 103,
      "open_issues": 0,
      "size": 226654
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 44238598
      },
      "license": "Creative Commons Zero v1.0 Universal",
      "topics": []
    },
    "content": {
      "readme": "# Free Ferris Pack\n![alt](/preview/main.png)\n🦀 Meet the New Emotional Ferris! 🦀\n\n- 50+ unique Ferris illustrations - emotions, poses, and situations\n- 10+ funny elements for your own creating\n- Consistent art style - all illustrations work together\n- Professional quality - suitable for presentations and documents\n- Multiple formats - SVG, PNG in large sizes\n- Absolutely free - no attribution required\n- Ready to use - download and go\n\nCreated with ❤️ for the Rust community\n\n## Why This Pack Exists\nSome time ago I created Free Gophers Pack, which became quite popular in the community. Then I learned about Ferris and thought - why not?\n\n![alt](/preview/preview2.png)\n\n## Contents\n0. [Examples](/examples/)\n1. [Elements](/elements/) \n2. [Illustrations](/illustrations/) \n\n![alt](/preview/preview3.png)\n\n![alt](/preview/preview4.png)\n\n![alt](/preview/preview5.png)\n\n## Perfect For\n- Rust developers building projects and tools\n- Educators teaching Rust programming\n- Speakers with talks about Rust\n- Technical writers creating Rust content\n- Companies using Rust in their stack\n- Community organizers running Rust events\n\nSee different use cases in [examples](/examples/).\n\n![alt](/examples/presentation4.png)\n\n![alt](/examples/presentation9.png)\n\n## License\nThis package is licensed as CC0 (public domain) so you can use the images in any way with no restrictions.\n\n## My other projects\nIf you liked this project, you may also want to see \n- [Free Gophers Pack](https://github.com/MariaLetta/free-gophers-pack)\n- [Mega Doodles Pack](https://github.com/MariaLetta/mega-doodles-pack)\n\n## About me\nMy name is Maria Letta, I am a professional illustrator and product designer, some of my works can be found here:    \n🦄 instagram https://instagram.com/maria_letta_art     \n🎨 creativemarket https://creativemarket.com/Maria_Letta\n\nDrop me an email, if you have any questions or suggestions:\n✉ designbyletta@gmail.com\n\n![alt](/examples/presentation10.png)",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-10T02:19:53.709983"
  },
  {
    "basic_info": {
      "name": "ghostscan",
      "full_name": "h2337/ghostscan",
      "owner": "h2337",
      "description": "A modern, Rust-powered Linux scanner that unmasks hidden rootkits, stealthy eBPF tricks, and ghost processes in one fast sweep (45+ scanners)",
      "url": "https://github.com/h2337/ghostscan",
      "clone_url": "https://github.com/h2337/ghostscan.git",
      "ssh_url": "git@github.com:h2337/ghostscan.git",
      "homepage": "",
      "created_at": "2025-09-28T05:45:03Z",
      "updated_at": "2025-10-09T17:45:47Z",
      "pushed_at": "2025-09-29T10:51:35Z"
    },
    "stats": {
      "stars": 95,
      "forks": 2,
      "watchers": 95,
      "open_issues": 0,
      "size": 82
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 189766,
        "C": 3549
      },
      "license": "MIT License",
      "topics": [
        "antivirus",
        "linux-security",
        "malware-detection",
        "rootkit-detection",
        "scanner",
        "security",
        "security-scanner",
        "security-tools"
      ]
    },
    "content": {
      "readme": "# ghostscan\n\nFast one-shot sweep for Linux incident response. Drop the binary on a host, run it once, and collect actionable leads from the kernel, procfs, bpffs, systemd, cron, sockets, and more.\n\n## Quick start\n\n1. Install a current Rust toolchain.\n2. Build with `cargo build --release`.\n3. Copy `target/release/ghostscan` to the target host.\n4. Run as root (or with equivalent capabilities): `sudo ./ghostscan`.\n5. Optional helpers (`bpftool`, `nft`, `ss`, `journalctl`, `auditctl`) expand coverage; when missing, the output explains what was skipped.\n\n## Reading results\n\n- Each scanner prints a bracketed name followed by either findings, `OK`, or an error string.\n- The process always exits with code `0`; treat the log itself as the verdict.\n- Findings are heuristics designed for triage; validate before acting.\n\n## Available scanners\n\n- **Hidden LKM**: compares procfs/sysfs clusters against `kallsyms` to surface hidden modules.\n- **Kernel taint**: highlights taint flags that lack a visible explanation.\n- **Ftrace redirection**: spots risky `ftrace` hooks on critical kernel paths.\n- **Unknown kprobes**: looks for kprobes attached to sensitive symbols that ghostscan cannot explain.\n- **Syscall table integrity**: verifies syscall table pointers for tampering.\n- **Netfilter hook drift**: finds orphaned or invalid netfilter hook jumps.\n- **Module linkage tamper**: checks module list pointers for manipulation.\n- **Ownerless BPF objects**: reports BPF maps/programs without a backing task.\n- **BPF kprobe attachments**: flags kprobes pointed at high-value kernel routines.\n- **BPF LSM**: notes when BPF LSM programs are active.\n- **Detached XDP/TC programs**: detects XDP or TC programs that no longer have an interface.\n- **Sockmap/Sockhash verdicts**: surfaces sockmap/sockhash programs lacking owners.\n- **Sensitive kfunc usage**: tracks invocations of dangerous `kfunc` targets.\n- **Non-bpffs pins**: finds BPF pins created outside bpffs mounts.\n- **Netlink vs proc**: compares netlink inventories with `/proc/net` to expose hidden sockets.\n- **Task list mismatch**: contrasts BPF snapshots with `/proc` task lists to expose hidden PIDs.\n- **Hidden PIDs**: uses BPF-only views to reveal task IDs invisible to `/proc`.\n- **Kernel thread masquerade**: detects kernel threads spoofing user process metadata.\n- **Suspicious ptrace edges**: reports unusual ptrace parent/child relationships.\n- **Deleted or memfd binaries**: lists processes executing from deleted files or memfd mounts.\n- **Hidden listeners**: identifies listeners seen via netlink vs `/proc` vs BPF.\n- **Ownerless sockets**: reports sockets without an owning task.\n- **Netfilter cloaking**: spots tampering patterns that hide netfilter rules.\n- **Local port backdoors**: highlights sockets bound to deleted or temporary paths.\n- **`ld.so.preload` tamper**: inspects `ld.so.preload` for unexpected entries.\n- **Cron ghosts**: checks cron/anacron/at directories for orphaned or cloaked jobs.\n- **Systemd ghosts**: finds unit files pointing to deleted or temporary executables.\n- **SSH footholds**: surfaces dangerous `authorized_keys` options and forced commands.\n- **OverlayFS whiteouts**: reports suspicious opaque or whiteout entries in OverlayFS.\n- **Hidden bind mounts**: lists bind or immutable mounts likely used for concealment.\n- **PAM/NSS modules**: flags PAM or NSS modules loaded from non-system paths.\n- **Live `LD_PRELOAD`**: notes processes still using deleted or writable preload libraries.\n- **Library search hijack**: checks SUID/privileged binaries for unsafe search paths.\n- **`LD_AUDIT` daemons**: finds daemons configured with `LD_AUDIT` despite lacking TTYs.\n- **Large RX regions**: surfaces non-JIT daemons with large anonymous RX memory.\n- **Kernel text RO**: verifies that kernel text sections remain read-only.\n- **`/etc/scripts.d` provenance**: warns on executable scripts from tmp or non-root owners.\n- **Sudoers**: examines sudoers entries for insecure privilege escalation paths.\n- **Kernel cmdline**: alerts on boot parameters that disable audit, lockdown, or IMA.\n- **Sensitive host mounts**: identifies sensitive host paths exposed inside containers.\n- **Host PID namespace**: reports containers sharing the host PID namespace.\n- **Overlay lowerdir**: catches OverlayFS lowerdirs that escape the storage root.\n- **Audit disabled**: detects when auditd is off or dropping records.\n- **Journal gaps**: looks for missing spans in the current boot's journal.\n- **Kernel message suppression**: notices unusual suppression of kernel logs.\n\n## Development pointers\n\n- Format and lint locally with `cargo fmt && cargo check`.\n- New scanners live in `src/scanners/` and expose `pub fn run() -> ScanOutcome` before being registered in `SCANNERS` inside `src/main.rs`.\n\n## Operational notes\n\n- Most modules require elevated privileges to read privileged interfaces, and they report missing access instead of silently failing.\n\n## License\n\nMIT\n",
      "default_branch": "master"
    },
    "fetched_at": "2025-10-10T02:19:54.870790"
  },
  {
    "basic_info": {
      "name": "chroma",
      "full_name": "yuri-xyz/chroma",
      "owner": "yuri-xyz",
      "description": "🌈 Shader-based audio visualizer for the terminal",
      "url": "https://github.com/yuri-xyz/chroma",
      "clone_url": "https://github.com/yuri-xyz/chroma.git",
      "ssh_url": "git@github.com:yuri-xyz/chroma.git",
      "homepage": "",
      "created_at": "2025-10-04T22:39:52Z",
      "updated_at": "2025-10-09T09:11:42Z",
      "pushed_at": "2025-10-09T08:53:08Z"
    },
    "stats": {
      "stars": 90,
      "forks": 3,
      "watchers": 90,
      "open_issues": 3,
      "size": 255
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 182946,
        "WGSL": 35774,
        "Nix": 2943,
        "Shell": 1703
      },
      "license": "GNU General Public License v3.0",
      "topics": [
        "audio",
        "audio-visualizer",
        "hyprland",
        "linux",
        "rust",
        "shaders",
        "shell",
        "tui"
      ]
    },
    "content": {
      "readme": "<div align=\"center\">\n  <img width=\"300\" alt=\"Chroma's logo in ASCII rainbow\" src=\"https://github.com/user-attachments/assets/871f6c7b-8b7c-486d-8cae-41ec13ed2d02\" />\n\n🌈 A Rust-based, ASCII art shader audio visualizer for your terminal!\n\n  <img src=\"https://github.com/user-attachments/assets/b71074f2-3e77-4fb9-a8ef-30288a3690c4\" width=\"550\" />\n\n</div>\n\n## ⭐ Features\n\n- 🎨 **GPU-accelerated shaders** using wgpu (compute shaders)\n- 🖼️ **ASCII art rendering** with ANSI color support\n- ⚙️ **Highly configurable parameters** via config file\n- 💾 **Save/Load configurations** with automatic deduping via hashing\n- 🔄 **Live config reloading** for real-time parameter adjustment\n- 🎵 **Audio visualization** driven by system audio input\n- 📊 **FFT-based audio analysis** for reactive visual effects\n\n## ✨ Demos & screenshots\n\n🔊 Make sure you turn on sound on the videos!\n\n<img width=\"2474\" height=\"1248\" alt=\"chroma\" src=\"https://github.com/user-attachments/assets/b6caaef4-f861-4a96-b06d-d087a3ad15fa\" />\n\n<img width=\"1958\" height=\"1103\" alt=\"chroma-config\" src=\"https://github.com/user-attachments/assets/96dae99e-2e93-470a-b44f-40c0a09f098a\" />\n\n[chroma.webm](https://github.com/user-attachments/assets/9e821a20-8394-445c-9542-91e294225e63)\n\n[chroma-demo-long.webm](https://github.com/user-attachments/assets/3ae02009-b9a5-4003-93b3-8120db869447)\n\n## 🔗 Install\n\n### Arch Linux\n\n```bash\n# With an AUR helper: yay\nyay -S chroma-visualizer-git\n\n# With an AUR helper: paru\nparu -S chroma-visualizer-git\n\n# Or manually:\ngit clone https://aur.archlinux.org/chroma-visualizer-git.git\ncd chroma-visualizer-git\nmakepkg -si\n\n# If you're lazy:\ngit clone https://aur.archlinux.org/chroma-visualizer-git.git \\\n  && cd chroma-visualizer-git \\\n  && makepkg -si\n```\n\n### Other distros\n\n...More packaging coming soon!...\n\nMeanwhile you can build from source below:\n\n### From source (manual)\n\n```bash\n# Clone the git repo and enter it:\ngit clone https://github.com/yuri-xyz/chroma.git\ncd chroma\n\n# Make sure you have the `alsa-lib` & `pipewire` packages installed,\n# the exact package names may vary depending on your distro.\n\n# Pick one:\ncargo build --release                    # visuals only\ncargo build --release --features audio   # with audio reactivity (recommended)\n\n# Install the built bin so that you can run it with `chroma`:\nsudo install -Dm755 target/release/chroma /usr/local/bin/chroma\n```\n\n## ℹ️ Usage\n\n```bash\n# Run with default settings\nchroma\n\n# Load a saved configuration\nchroma --config config_a3f8c2d9e1b5.toml\n\n# Or using the short form\nchroma -c config_a3f8c2d9e1b5.toml\n\n# View help for all arguments and settings\nchroma --help\n```\n\n## 🕹️ Controls\n\n- `Q` or `Esc` - Quit application\n- `R` - **Randomize parameters** ⭐ (Discover new effects!)\n- `S` - **Save configuration** 💾 (Creates `config_<hash>.toml` in current directory)\n- `P`/`O` - **Cycle palettes** 🎨 (16 different character sets!)\n- `↑`/`↓` - Adjust frequency\n- `→`/`←` - Adjust speed\n- `+`/`-` - Adjust amplitude\n- `[`/`]` - Adjust scale\n\nSee [CONTROLS.md](./notes/CONTROLS.md) and [PALETTES.md](./notes/PALETTES.md) for more details.\n\n## 🎨 Configuration & Ricing\n\nChroma is designed to be highly configurable and CLI-friendly, so it feels natural alongside your other terminal tools. There are multiple ways to configure the effects and visuals:\n\n**Config files**: Load preset configurations from TOML files. You can find [example preset configs in the `examples` directory](./examples):\n\n```\nchroma -c examples/0.toml\n```\n\n**Live reloading**: Edit your config file while chroma is running and see changes applied instantly! This makes it easy to tweak parameters and visualize your adjustments in real time.\n\n**CLI parameters**: Most parameters can be set via command-line arguments. Run `chroma --help` to see all available options.\n\n> [!TIP]\n> You can combine config files with CLI parameters—CLI args take precedence. This is perfect when you have a favorite base config but want to tweak specific values on the fly or in a script.\n\n> [!TIP]\n> Use `--random` or `-r` to randomize any parameters that haven't been explicitly set by your config file or CLI args. Great for adding variety to each run!\n\nIf you're feeling brave, you can even create your own custom shader patterns and load them like this: `chroma --custom-shader my_shader.wgsl`. Take a look at [`examples/custom_shader.wgsl`](./examples/custom_shader.wgsl) as a beginner template.\n\n## 📦 Dependencies\n\n- Runtime\n  - vulkan-icd-loader\n  - A Vulkan driver: one of `vulkan-intel`, `vulkan-radeon`, or `nvidia-utils`\n  - Terminal with ANSI color support\n- Optional (audio feature)\n  - pipewire (recommended) or alsa-lib\n- Build\n  - rust, cargo, git\n\n## 🏗️ Contributing\n\nAll contributions welcome! If you have some cool ideas, found some bugs, or would like to improve the project anyhow, feel free to create an issue and then a corresponding PR :)\n\nHere's some tips to making good contributions:\n\n- ✅ Create a corresponding issue with a reasonable explanation.\n- ✅ Keep PRs",
      "default_branch": "develop"
    },
    "fetched_at": "2025-10-10T02:19:56.029374"
  },
  {
    "basic_info": {
      "name": "net-mux",
      "full_name": "Poseidon-fan/net-mux",
      "owner": "Poseidon-fan",
      "description": "network connection multiplexing async lib in rust, built on tokio",
      "url": "https://github.com/Poseidon-fan/net-mux",
      "clone_url": "https://github.com/Poseidon-fan/net-mux.git",
      "ssh_url": "git@github.com:Poseidon-fan/net-mux.git",
      "homepage": "",
      "created_at": "2025-09-25T09:12:59Z",
      "updated_at": "2025-10-10T00:50:02Z",
      "pushed_at": "2025-10-07T14:23:22Z"
    },
    "stats": {
      "stars": 88,
      "forks": 0,
      "watchers": 88,
      "open_issues": 0,
      "size": 64
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 30837,
        "Dockerfile": 189,
        "Shell": 108
      },
      "license": "MIT License",
      "topics": [
        "async",
        "kcp",
        "multiplexing",
        "network-programming",
        "rust",
        "tcp",
        "tokio"
      ]
    },
    "content": {
      "readme": "<h1 align=\"center\">net-mux</h1>\n\n<div align=\"center\">\n\n[![GitHub][github-badge]][github-url]\n[![Crates.io][crates-badge]][crates-url]\n[![MIT licensed][mit-badge]][mit-url]\n[![Build Status][actions-badge]][actions-url]\n\n</div>\n\n[crates-badge]: https://img.shields.io/crates/v/net-mux.svg\n[crates-url]: https://crates.io/crates/net-mux\n[mit-badge]: https://img.shields.io/badge/license-MIT-blue.svg\n[mit-url]: https://github.com/Poseidon-fan/net-mux/blob/master/LICENSE\n[actions-badge]: https://github.com/Poseidon-fan/net-mux/actions/workflows/rust.yaml/badge.svg\n[actions-url]: https://github.com/Poseidon-fan/net-mux/actions?branch=master\n[github-badge]: https://img.shields.io/badge/github-repo-black?logo=github\n[github-url]: https://github.com/Poseidon-fan/net-mux\n\nnet-mux is an asynchronous connection multiplexing library built on tokio. It multiplexes ordered, connection-oriented transports such as TCP, KCP, and TLS-over-TCP into multiple logical concurrent, ordered, bidirectional streams.\n\n![system architecture](https://github.com/Poseidon-fan/net-mux/raw/master/docs/images/architecture.svg)\n\n## Getting Started\n\n**Examples**\n\n```sh\n$ cargo run --example tcp_server\n$ cargo run --example tcp_client\n```\n\nThis launches a TCP listener on the local loopback address, waiting for client connections. Each connection is wrapped as a mux session. The server and client interact over this single connection through multiple streams. The server receives messages from the client and writes them back unchanged, while the client reads strings from the standard input, sends them to the server, and prints the received messages.\n\n**Links**\n\n- Usage [examples][examples]\n- Released API [Docs][documentation]\n\n[examples]: https://github.com/Poseidon-fan/net-mux/tree/master/examples\n[documentation]: https://docs.rs/crate/net-mux/\n\n## Contribution\n\nThe project is currently under active development, all feedback welcome!\n",
      "default_branch": "master"
    },
    "fetched_at": "2025-10-10T02:19:57.214043"
  },
  {
    "basic_info": {
      "name": "walrus",
      "full_name": "nubskr/walrus",
      "owner": "nubskr",
      "description": "A high performance Write Ahead Log in Rust",
      "url": "https://github.com/nubskr/walrus",
      "clone_url": "https://github.com/nubskr/walrus.git",
      "ssh_url": "git@github.com:nubskr/walrus.git",
      "homepage": "https://nubskr.com/2025/10/06/walrus.html",
      "created_at": "2025-09-17T02:25:21Z",
      "updated_at": "2025-10-10T02:03:00Z",
      "pushed_at": "2025-10-06T11:31:24Z"
    },
    "stats": {
      "stars": 86,
      "forks": 4,
      "watchers": 86,
      "open_issues": 0,
      "size": 13185
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 188836,
        "Python": 13219,
        "Makefile": 2745
      },
      "license": "MIT License",
      "topics": [
        "database",
        "rust"
      ]
    },
    "content": {
      "readme": "<div align=\"center\">\n  <img src=\"./figures/walrus1.png\"\n       alt=\"walrus\"\n       width=\"30%\">\n    <div>Walrus: A high performance Write Ahead Log (WAL) in Rust</div>\n\n[![Crates.io](https://img.shields.io/crates/v/walrus-rust.svg)](https://crates.io/crates/walrus-rust)\n[![Documentation](https://docs.rs/walrus-rust/badge.svg)](https://docs.rs/walrus-rust)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)\n\n\n</div>\n\n## Features\n\n- **High Performance**: Optimized for concurrent writes and reads\n- **Topic-based Organization**: Separate read/write streams per topic\n- **Configurable Consistency**: Choose between strict and relaxed consistency models\n- **Memory-mapped I/O**: Efficient file operations using memory mapping\n- **Persistent Read Offsets**: Read positions survive process restarts\n- **Coordination-free Deletion**: Atomic file cleanup without blocking operations\n- **Comprehensive Benchmarking**: Built-in performance testing suite\n\n## Benchmarks\n\nRun quick benchmarks with:\n\n```bash\npip install pandas matplotlib # we need these to show graphs\nmake bench-and-show-reads\n```\n\n## Quick Start\n\nAdd Walrus to your `Cargo.toml`:\n\n```toml\n[dependencies]\nwalrus-rust = \"0.1.0\"\n```\n\n### Basic Usage\n\n```rust\nuse walrus_rust::{Walrus, ReadConsistency};\n\n// Create a new WAL instance with default settings\nlet wal = Walrus::new()?;\n\n// Write data to a topic\nlet data = b\"Hello, Walrus!\";\nwal.append_for_topic(\"my-topic\", data)?;\n\n// Read data from the topic\nif let Some(entry) = wal.read_next(\"my-topic\")? {\n    println!(\"Read: {:?}\", String::from_utf8_lossy(&entry.data));\n}\n```\n\n### Advanced Configuration\n\n```rust\nuse walrus_rust::{Walrus, ReadConsistency, FsyncSchedule};\n\n// Configure with custom consistency and fsync behavior\nlet wal = Walrus::with_consistency_and_schedule(\n    ReadConsistency::AtLeastOnce { persist_every: 1000 },\n    FsyncSchedule::Milliseconds(500)\n)?;\n\n// Write and read operations work the same way\nwal.append_for_topic(\"events\", b\"event data\")?;\n```\n\n## Configuration Options\n\n### Read Consistency Modes\n\nWalrus supports two consistency models:\n\n#### `ReadConsistency::StrictlyAtOnce`\n- **Behavior**: Read offsets are persisted after every read operation\n- **Guarantees**: No message will be read more than once, even after crashes\n- **Performance**: Higher I/O overhead due to frequent persistence\n- **Use Case**: Critical systems where duplicate processing must be avoided\n\n```rust\nlet wal = Walrus::with_consistency(ReadConsistency::StrictlyAtOnce)?;\n```\n\n#### `ReadConsistency::AtLeastOnce { persist_every: u32 }`\n- **Behavior**: Read offsets are persisted every N read operations\n- **Guarantees**: Messages may be re-read after crashes (at-least-once delivery)\n- **Performance**: Better throughput with configurable persistence frequency\n- **Use Case**: High-throughput systems that can handle duplicate processing\n\n```rust\nlet wal = Walrus::with_consistency(\n    ReadConsistency::AtLeastOnce { persist_every: 5000 }\n)?;\n```\n\n### Fsync Scheduling\n\nControl when data is flushed to disk:\n\n#### `FsyncSchedule::Milliseconds(u64)`\n- **Behavior**: Background thread flushes data every N milliseconds\n- **Default**: 1000ms (1 second)\n- **Range**: Minimum 1ms, recommended 100-5000ms\n\n```rust\nlet wal = Walrus::with_consistency_and_schedule(\n    ReadConsistency::AtLeastOnce { persist_every: 1000 },\n    FsyncSchedule::Milliseconds(2000)  // Flush every 2 seconds\n)?;\n```\n\n### Environment Variables\n\n- **`WALRUS_QUIET`**: Set to any value to suppress debug output during operations\n\n```bash\nexport WALRUS_QUIET=1  # Suppress debug messages\n```\n\n## File Structure and Storage\n\nWalrus organizes data in the following structure:\n\n```\nwal_files/\n├── wal_1234567890.log          # Log files (10MB blocks, 100 blocks per file)\n├── wal_1234567891.log\n├── read_offset_idx_index.db    # Persistent read offset index\n└── read_offset_idx_index.db.tmp # Temporary file for atomic updates\n```\n\n### Storage Configuration\n\n- **Block Size**: 10MB per block (configurable via `DEFAULT_BLOCK_SIZE`)\n- **Blocks Per File**: 100 blocks per file (1GB total per file)\n- **Max File Size**: 1GB per log file\n- **Index Persistence**: Read offsets stored in separate index files\n\n## API Reference\n\n### Core Methods\n\n#### `Walrus::new() -> std::io::Result<Self>`\nCreates a new WAL instance with default settings (`StrictlyAtOnce` consistency).\n\n#### `Walrus::with_consistency(mode: ReadConsistency) -> std::io::Result<Self>`\nCreates a WAL with custom consistency mode and default fsync schedule (1000ms).\n\n#### `Walrus::with_consistency_and_schedule(mode: ReadConsistency, schedule: FsyncSchedule) -> std::io::Result<Self>`\nCreates a WAL with full configuration control.\n\n#### `append_for_topic(&self, topic: &str, data: &[u8]) -> std::io::Result<()>`\nAppends data to the specified topic. Topics are created automatically on first write.\n\n#### `read_next(&self, topic: &str) -> std::io::Result<Option<Entry>>`\nReads the next entry from the topic. Returns `None` if",
      "default_branch": "master"
    },
    "fetched_at": "2025-10-10T02:19:58.373961"
  },
  {
    "basic_info": {
      "name": "pingora_web",
      "full_name": "pingora-web/pingora_web",
      "owner": "pingora-web",
      "description": null,
      "url": "https://github.com/pingora-web/pingora_web",
      "clone_url": "https://github.com/pingora-web/pingora_web.git",
      "ssh_url": "git@github.com:pingora-web/pingora_web.git",
      "homepage": null,
      "created_at": "2025-09-13T18:03:17Z",
      "updated_at": "2025-10-06T11:42:29Z",
      "pushed_at": "2025-09-14T12:25:51Z"
    },
    "stats": {
      "stars": 86,
      "forks": 9,
      "watchers": 86,
      "open_issues": 0,
      "size": 140
    },
    "tech_info": {
      "language": "Rust",
      "languages": {
        "Rust": 82881
      },
      "license": "Apache License 2.0",
      "topics": []
    },
    "content": {
      "readme": "# 🚀 pingora_web\n\n[![CI](https://github.com/pingora-web/pingora_web/actions/workflows/ci.yml/badge.svg)](https://github.com/pingora-web/pingora_web/actions/workflows/ci.yml)\n[![Crates.io](https://img.shields.io/crates/v/pingora_web.svg)](https://crates.io/crates/pingora_web)\n[![Documentation](https://docs.rs/pingora_web/badge.svg)](https://docs.rs/pingora_web)\n[![License](https://img.shields.io/badge/license-MIT%2FApache--2.0-blue.svg)](LICENSE)\n[![Downloads](https://img.shields.io/crates/d/pingora_web.svg)](https://crates.io/crates/pingora_web)\n[![Stars](https://img.shields.io/github/stars/pingora-web/pingora_web.svg)](https://github.com/pingora-web/pingora_web)\n\n**🔥 Fast setup | Built on Pingora | Beginner friendly** 🦀\n\n[English](README.md) | [中文](README_zh.md)\n\nA web framework built on Cloudflare's Pingora proxy infrastructure, designed to be fast, reliable, and easy to use.\n\n## ✨ Features\n\n### Core Features\n- 🛣️ **Path routing** with parameters (`/users/{id}`)\n- 🧅 **Middleware system** with onion model (like Express.js)\n- 🏷️ **Request ID tracking** (automatic `x-request-id` header)\n- 📝 **Structured logging** with tracing integration\n- 📦 **JSON support** with automatic serialization\n- 📁 **Static file serving** with MIME type detection\n- 🌊 **Streaming responses** for large data transfers\n\n### Built on Pingora\n- ⚡ **High performance** - leverages Cloudflare's production-tested proxy\n- 🗜️ **HTTP compression** - built-in gzip support\n- 🛡️ **Request limits** - timeout, body size, and header constraints\n- 🚨 **Panic recovery** - automatic error handling\n- 🔗 **HTTP/1.1 & HTTP/2** support via Pingora\n\n## 🚀 Quick Start\n\n### 1. Create a new project\n```bash\ncargo new my_api && cd my_api\n```\n\n### 2. Add dependencies to `Cargo.toml`\n\n**Minimal setup (Hello World):**\n```toml\n[dependencies]\npingora_web = \"0.1\"\n```\n\n**Full setup (with JSON, logging, etc.):**\n```toml\n[dependencies]\npingora_web = \"0.1\"\nserde = { version = \"1.0\", features = [\"derive\"] }\nserde_json = \"1.0\"\ntracing-subscriber = { version = \"0.3\", features = [\"env-filter\"] }\n```\n\n### 3. Hello World (5 lines - like Express/Gin)\n\n```rust\nuse pingora_web::{App, StatusCode, PingoraWebHttpResponse, WebError, PingoraHttpRequest};\n\nfn main() {\n    let mut app = App::default();\n    app.get_fn(\"/\", |_req: PingoraHttpRequest| -> Result<PingoraWebHttpResponse, WebError> {\n        Ok(PingoraWebHttpResponse::text(StatusCode::OK, \"Hello World!\"))\n    });\n    app.listen(\"0.0.0.0:8080\").unwrap();\n}\n```\n\n### 4. With Parameters (beginner-friendly)\n\n```rust\nuse pingora_web::{App, StatusCode, PingoraWebHttpResponse, WebError, PingoraHttpRequest};\n\nfn main() {\n    let mut app = App::default();\n    app.get_fn(\"/\", |_req: PingoraHttpRequest| -> Result<PingoraWebHttpResponse, WebError> {\n        Ok(PingoraWebHttpResponse::text(StatusCode::OK, \"Hello World!\"))\n    });\n    app.get_fn(\"/hi/{name}\", |req: PingoraHttpRequest| -> Result<PingoraWebHttpResponse, WebError> {\n        let name = req.param(\"name\").unwrap_or(\"world\");\n        Ok(PingoraWebHttpResponse::text(StatusCode::OK, format!(\"Hello {}\", name)))\n    });\n    app.listen(\"0.0.0.0:8080\").unwrap();\n}\n```\n\n### 5. Full-featured example\n\n```rust\nuse async_trait::async_trait;\nuse pingora_web::{App, Handler, StatusCode, TracingMiddleware, ResponseCompressionBuilder, WebError, PingoraHttpRequest, PingoraWebHttpResponse};\nuse std::sync::Arc;\n\nstruct Hello;\n#[async_trait]\nimpl Handler for Hello {\n    async fn handle(&self, req: PingoraHttpRequest) -> Result<PingoraWebHttpResponse, WebError> {\n        let name = req.param(\"name\").unwrap_or(\"world\");\n        Ok(PingoraWebHttpResponse::text(StatusCode::OK, format!(\"Hello {}\", name)))\n    }\n}\n\nfn main() {\n    tracing_subscriber::fmt()\n        .with_env_filter(\"info\")\n        .init();\n\n    let mut app = App::default();\n    app.get(\"/hi/{name}\", Arc::new(Hello));\n    app.use_middleware(TracingMiddleware::new());\n    app.add_http_module(ResponseCompressionBuilder::enable(6));\n\n    app.listen(\"0.0.0.0:8080\").unwrap();\n}\n```\n\n### 6. Run the server\n```bash\ncargo run\n```\n\nVisit `http://localhost:8080/` or `http://localhost:8080/hi/world` to see it working!\n\n### Advanced usage (for complex setups)\n\nIf you need more control over the server configuration:\n\n```rust\nuse async_trait::async_trait;\nuse pingora_web::{App, Handler, StatusCode, WebError, PingoraHttpRequest, PingoraWebHttpResponse};\nuse pingora::server::Server;\nuse std::sync::Arc;\n\nstruct Hello;\n#[async_trait]\nimpl Handler for Hello {\n    async fn handle(&self, req: PingoraHttpRequest) -> Result<PingoraWebHttpResponse, WebError> {\n        let name = req.param(\"name\").unwrap_or(\"world\");\n        Ok(PingoraWebHttpResponse::text(StatusCode::OK, format!(\"Hello {}\", name)))\n    }\n}\n\nfn main() {\n    let mut app = App::default();\n    app.get(\"/hi/{name}\", Arc::new(Hello));\n    let app = app;\n\n    // Advanced: Convert to service for more control\n    let mut service = app.to_service(\"my-web-app\");\n    service.add_tcp(\"0.0.0.0:8080\");\n    service.add_tcp",
      "default_branch": "main"
    },
    "fetched_at": "2025-10-10T02:19:59.529605"
  }
]