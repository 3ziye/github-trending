[
  {
    "basic_info": {
      "name": "nanochat",
      "full_name": "karpathy/nanochat",
      "owner": "karpathy",
      "description": "The best ChatGPT that $100 can buy.",
      "url": "https://github.com/karpathy/nanochat",
      "clone_url": "https://github.com/karpathy/nanochat.git",
      "ssh_url": "git@github.com:karpathy/nanochat.git",
      "homepage": "",
      "created_at": "2025-10-13T13:46:35Z",
      "updated_at": "2025-11-08T02:20:09Z",
      "pushed_at": "2025-11-05T21:08:37Z"
    },
    "stats": {
      "stars": 36044,
      "forks": 4184,
      "watchers": 36044,
      "open_issues": 45,
      "size": 167
    },
    "tech_info": {
      "language": "Python",
      "languages": {
        "Python": 327694,
        "HTML": 20192,
        "Rust": 16627,
        "Shell": 13520
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# nanochat\n\n![nanochat logo](dev/nanochat.png)\n\n> The best ChatGPT that $100 can buy.\n\nThis repo is a full-stack implementation of an LLM like ChatGPT in a single, clean, minimal, hackable, dependency-lite codebase. nanochat is designed to run on a single 8XH100 node via scripts like [speedrun.sh](speedrun.sh), that run the entire pipeline start to end. This includes tokenization, pretraining, finetuning, evaluation, inference, and web serving over a simple UI so that you can talk to your own LLM just like ChatGPT. nanochat will become the capstone project of the course LLM101n being developed by Eureka Labs.\n\n## Talk to it\n\nTo get a sense of the endpoint of this repo, you can currently find [nanochat d32](https://github.com/karpathy/nanochat/discussions/8) hosted on [nanochat.karpathy.ai](https://nanochat.karpathy.ai/). \"d32\" means that this model has 32 layers in the Transformer neural network. This model has 1.9 billion parameters, it was trained on 38 billion tokens by simply running the single script [run1000.sh](run1000.sh), and the total cost of training was ~$800 (about 33 hours training time on 8XH100 GPU node). While today this is enough to outperform GPT-2 of 2019, it falls dramatically short of modern Large Language Models like GPT-5. When talking to these micro models, you'll see that they make a lot of mistakes, they are a little bit naive and silly and they hallucinate a ton, a bit like children. It's kind of amusing. But what makes nanochat unique is that it is fully yours - fully configurable, tweakable, hackable, and trained by you from start to end. To train and talk to your own, we turn to...\n\n## Quick start\n\nThe fastest way to feel the magic is to run the speedrun script [speedrun.sh](speedrun.sh), which trains and inferences the $100 tier of nanochat. On an 8XH100 node at $24/hr, this gives a total run time of about 4 hours. Boot up a new 8XH100 GPU box from your favorite provider (e.g. I use and like [Lambda](https://lambda.ai/service/gpu-cloud)), and kick off the training script:\n\n```bash\nbash speedrun.sh\n```\n\nAlternatively, since the script runs for 4 hours, I like to launch it like this inside a new screen session `speedrun` (and also log output to `speedrun.log`):\n\n```bash\nscreen -L -Logfile speedrun.log -S speedrun bash speedrun.sh\n```\n\nSee the [screen cheatsheet](https://gist.github.com/jctosta/af918e1618682638aa82) if you are less familiar. You can watch it go inside the screen session, or detach with `Ctrl-a d` and `tail speedrun.log` to view progress. Now wait 4 hours. Once it's done, you can talk to your LLM via the ChatGPT-like web UI. Make sure again that your local uv virtual environment is active (run `source .venv/bin/activate`), and serve it:\n\n```bash\npython -m scripts.chat_web\n```\n\nAnd then visit the URL shown. Make sure to access it correctly, e.g. on Lambda use the public IP of the node you're on, followed by the port, so for example [http://209.20.xxx.xxx:8000/](http://209.20.xxx.xxx:8000/), etc. Then talk to your LLM as you'd normally talk to ChatGPT! Get it to write stories or poems. Ask it to tell you who you are to see a hallucination. Ask it why the sky is blue. Or why it's green. The speedrun is a 4e19 FLOPs capability model so it's a bit like talking to a kindergartener :).\n\n---\n\n<img width=\"2672\" height=\"1520\" alt=\"image\" src=\"https://github.com/user-attachments/assets/ed39ddf8-2370-437a-bedc-0f39781e76b5\" />\n\n---\n\nYou can also `cat report.md` file which appeared in the project directory and contains the \"report card\" of the run, i.e. a bunch of evaluations and metrics. At the very end, you'll see a summary table, for example:\n\n---\n\n- Characters: 333,989\n- Lines: 8,304\n- Files: 44\n- Tokens (approx): 83,497\n- Dependencies (uv.lock lines): 2,004\n\n| Metric          | BASE     | MID      | SFT      | RL       |\n|-----------------|----------|----------|----------|----------|\n| CORE            | 0.2219   | -        | -        | -        |\n| ARC-Challenge   | -        | 0.2875   | 0.2807   | -        |\n| ARC-Easy        | -        | 0.3561   | 0.3876   | -        |\n| GSM8K           | -        | 0.0250   | 0.0455   | 0.0758   |\n| HumanEval       | -        | 0.0671   | 0.0854   | -        |\n| MMLU            | -        | 0.3111   | 0.3151   | -        |\n| ChatCORE        | -        | 0.0730   | 0.0884   | -        |\n\nTotal wall clock time: 3h51m\n\n---\n\n(Your table might be missing the RL number by default). For a lot more information around the speedrun script and what to look for and expect, please refer to the walkthrough that I posted in Discussions of the repo: [\"Introducing nanochat: The best ChatGPT that $100 can buy\"](https://github.com/karpathy/nanochat/discussions/1).\n\n## Bigger models\n\nUnsurprisingly, $100 is not enough to train a highly performant ChatGPT clone. In fact, LLMs are famous for their multi-million dollar capex. For our purposes, I think there are two more scales of interest. First is the ~$300 tier d26 model (i.e. depth=26) that trains in ~1",
      "default_branch": "master"
    },
    "fetched_at": "2025-11-08T02:20:36.734621"
  },
  {
    "basic_info": {
      "name": "DeepSeek-OCR",
      "full_name": "deepseek-ai/DeepSeek-OCR",
      "owner": "deepseek-ai",
      "description": "Contexts Optical Compression",
      "url": "https://github.com/deepseek-ai/DeepSeek-OCR",
      "clone_url": "https://github.com/deepseek-ai/DeepSeek-OCR.git",
      "ssh_url": "git@github.com:deepseek-ai/DeepSeek-OCR.git",
      "homepage": null,
      "created_at": "2025-10-17T06:14:27Z",
      "updated_at": "2025-11-08T02:11:26Z",
      "pushed_at": "2025-10-25T02:43:18Z"
    },
    "stats": {
      "stars": 19828,
      "forks": 1417,
      "watchers": 19828,
      "open_issues": 209,
      "size": 7948
    },
    "tech_info": {
      "language": "Python",
      "languages": {
        "Python": 113538
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "<!-- markdownlint-disable first-line-h1 -->\n<!-- markdownlint-disable html -->\n<!-- markdownlint-disable no-duplicate-header -->\n\n\n<div align=\"center\">\n  <img src=\"assets/logo.svg\" width=\"60%\" alt=\"DeepSeek AI\" />\n</div>\n\n\n<hr>\n<div align=\"center\">\n  <a href=\"https://www.deepseek.com/\" target=\"_blank\">\n    <img alt=\"Homepage\" src=\"assets/badge.svg\" />\n  </a>\n  <a href=\"https://huggingface.co/deepseek-ai/DeepSeek-OCR\" target=\"_blank\">\n    <img alt=\"Hugging Face\" src=\"https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-DeepSeek%20AI-ffc107?color=ffc107&logoColor=white\" />\n  </a>\n\n</div>\n\n<div align=\"center\">\n\n  <a href=\"https://discord.gg/Tc7c45Zzu5\" target=\"_blank\">\n    <img alt=\"Discord\" src=\"https://img.shields.io/badge/Discord-DeepSeek%20AI-7289da?logo=discord&logoColor=white&color=7289da\" />\n  </a>\n  <a href=\"https://twitter.com/deepseek_ai\" target=\"_blank\">\n    <img alt=\"Twitter Follow\" src=\"https://img.shields.io/badge/Twitter-deepseek_ai-white?logo=x&logoColor=white\" />\n  </a>\n\n</div>\n\n\n\n<p align=\"center\">\n  <a href=\"https://huggingface.co/deepseek-ai/DeepSeek-OCR\"><b>üì• Model Download</b></a> |\n  <a href=\"https://github.com/deepseek-ai/DeepSeek-OCR/blob/main/DeepSeek_OCR_paper.pdf\"><b>üìÑ Paper Link</b></a> |\n  <a href=\"https://arxiv.org/abs/2510.18234\"><b>üìÑ Arxiv Paper Link</b></a> |\n</p>\n\n<h2>\n<p align=\"center\">\n  <a href=\"\">DeepSeek-OCR: Contexts Optical Compression</a>\n</p>\n</h2>\n\n<p align=\"center\">\n<img src=\"assets/fig1.png\" style=\"width: 1000px\" align=center>\n</p>\n<p align=\"center\">\n<a href=\"\">Explore the boundaries of visual-text compression.</a>       \n</p>\n\n## Release\n- [2025/10/23]üöÄüöÄüöÄ DeepSeek-OCR is now officially supported in upstream [vLLM](https://docs.vllm.ai/projects/recipes/en/latest/DeepSeek/DeepSeek-OCR.html#installing-vllm). Thanks to the [vLLM](https://github.com/vllm-project/vllm) team for their help.\n- [2025/10/20]üöÄüöÄüöÄ We release DeepSeek-OCR, a model to investigate the role of vision encoders from an LLM-centric viewpoint.\n\n## Contents\n- [Install](#install)\n- [vLLM Inference](#vllm-inference)\n- [Transformers Inference](#transformers-inference)\n  \n\n\n\n\n## Install\n>Our environment is cuda11.8+torch2.6.0.\n1. Clone this repository and navigate to the DeepSeek-OCR folder\n```bash\ngit clone https://github.com/deepseek-ai/DeepSeek-OCR.git\n```\n2. Conda\n```Shell\nconda create -n deepseek-ocr python=3.12.9 -y\nconda activate deepseek-ocr\n```\n3. Packages\n\n- download the vllm-0.8.5 [whl](https://github.com/vllm-project/vllm/releases/tag/v0.8.5) \n```Shell\npip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 --index-url https://download.pytorch.org/whl/cu118\npip install vllm-0.8.5+cu118-cp38-abi3-manylinux1_x86_64.whl\npip install -r requirements.txt\npip install flash-attn==2.7.3 --no-build-isolation\n```\n**Note:** if you want vLLM and transformers codes to run in the same environment, you don't need to worry about this installation error like: vllm 0.8.5+cu118 requires transformers>=4.51.1\n\n## vLLM-Inference\n- VLLM:\n>**Note:** change the INPUT_PATH/OUTPUT_PATH and other settings in the DeepSeek-OCR-master/DeepSeek-OCR-vllm/config.py\n```Shell\ncd DeepSeek-OCR-master/DeepSeek-OCR-vllm\n```\n1. image: streaming output\n```Shell\npython run_dpsk_ocr_image.py\n```\n2. pdf: concurrency ~2500tokens/s(an A100-40G)\n```Shell\npython run_dpsk_ocr_pdf.py\n```\n3. batch eval for benchmarks\n```Shell\npython run_dpsk_ocr_eval_batch.py\n```\n\n**[2025/10/23] The version of upstream [vLLM](https://docs.vllm.ai/projects/recipes/en/latest/DeepSeek/DeepSeek-OCR.html#installing-vllm):**\n\n```shell\nuv venv\nsource .venv/bin/activate\n# Until v0.11.1 release, you need to install vLLM from nightly build\nuv pip install -U vllm --pre --extra-index-url https://wheels.vllm.ai/nightly\n```\n\n```python\nfrom vllm import LLM, SamplingParams\nfrom vllm.model_executor.models.deepseek_ocr import NGramPerReqLogitsProcessor\nfrom PIL import Image\n\n# Create model instance\nllm = LLM(\n    model=\"deepseek-ai/DeepSeek-OCR\",\n    enable_prefix_caching=False,\n    mm_processor_cache_gb=0,\n    logits_processors=[NGramPerReqLogitsProcessor]\n)\n\n# Prepare batched input with your image file\nimage_1 = Image.open(\"path/to/your/image_1.png\").convert(\"RGB\")\nimage_2 = Image.open(\"path/to/your/image_2.png\").convert(\"RGB\")\nprompt = \"<image>\\nFree OCR.\"\n\nmodel_input = [\n    {\n        \"prompt\": prompt,\n        \"multi_modal_data\": {\"image\": image_1}\n    },\n    {\n        \"prompt\": prompt,\n        \"multi_modal_data\": {\"image\": image_2}\n    }\n]\n\nsampling_param = SamplingParams(\n            temperature=0.0,\n            max_tokens=8192,\n            # ngram logit processor args\n            extra_args=dict(\n                ngram_size=30,\n                window_size=90,\n                whitelist_token_ids={128821, 128822},  # whitelist: <td>, </td>\n            ),\n            skip_special_tokens=False,\n        )\n# Generate output\nmodel_outputs = llm.generate(model_input, sampling_param)\n\n# Print output\nfor output in model_outputs:\n    print(output.outputs[0].text)\n```\n## ",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-08T02:20:37.861575"
  },
  {
    "basic_info": {
      "name": "toon",
      "full_name": "toon-format/toon",
      "owner": "toon-format",
      "description": "üéí Token-Oriented Object Notation (TOON) ‚Äì A compact, deterministic JSON format for LLM prompts. Spec, benchmarks, TypeScript SDK.",
      "url": "https://github.com/toon-format/toon",
      "clone_url": "https://github.com/toon-format/toon.git",
      "ssh_url": "git@github.com:toon-format/toon.git",
      "homepage": "https://toonformat.dev",
      "created_at": "2025-10-22T18:17:32Z",
      "updated_at": "2025-11-08T01:59:15Z",
      "pushed_at": "2025-11-07T20:31:18Z"
    },
    "stats": {
      "stars": 11639,
      "forks": 418,
      "watchers": 11639,
      "open_issues": 5,
      "size": 1198
    },
    "tech_info": {
      "language": "TypeScript",
      "languages": {
        "TypeScript": 230060,
        "JavaScript": 229
      },
      "license": "MIT License",
      "topics": [
        "data-format",
        "llm",
        "serialization",
        "tokenization"
      ]
    },
    "content": {
      "readme": "![TOON logo with step‚Äëby‚Äëstep guide](./.github/og.png)\n\n# Token-Oriented Object Notation (TOON)\n\n[![CI](https://github.com/toon-format/toon/actions/workflows/ci.yml/badge.svg)](https://github.com/toon-format/toon/actions)\n[![npm version](https://img.shields.io/npm/v/@toon-format/toon.svg)](https://www.npmjs.com/package/@toon-format/toon)\n[![SPEC v1.4](https://img.shields.io/badge/spec-v1.4-lightgray)](https://github.com/toon-format/spec)\n[![npm downloads (total)](https://img.shields.io/npm/dt/@toon-format/toon.svg)](https://www.npmjs.com/package/@toon-format/toon)\n[![License: MIT](https://img.shields.io/badge/license-MIT-blue.svg)](./LICENSE)\n\n**Token-Oriented Object Notation** is a compact, human-readable serialization format designed for passing structured data to Large Language Models with significantly reduced token usage. It's intended for *LLM input* as a lossless, drop-in representation of JSON data.\n\nTOON's sweet spot is **uniform arrays of objects** ‚Äì multiple fields per row, same structure across items. It borrows YAML's indentation-based structure for nested objects and CSV's tabular format for uniform data rows, then optimizes both for token efficiency in LLM contexts. For deeply nested or non-uniform data, JSON may be more efficient.\n\nTOON achieves CSV-like compactness while adding explicit structure that helps LLMs parse and validate data reliably.\n\n> [!TIP]\n> Think of TOON as a translation layer: use JSON programmatically, convert to TOON for LLM input.\n\n## Table of Contents\n\n- [Why TOON?](#why-toon)\n- [Key Features](#key-features)\n- [Benchmarks](#benchmarks)\n- [üìã Full Specification](https://github.com/toon-format/spec/blob/main/SPEC.md)\n- [Installation & Quick Start](#installation--quick-start)\n- [CLI](#cli)\n- [Format Overview](#format-overview)\n- [API](#api)\n- [Using TOON in LLM Prompts](#using-toon-in-llm-prompts)\n- [Notes and Limitations](#notes-and-limitations)\n- [Syntax Cheatsheet](#syntax-cheatsheet)\n- [Other Implementations](#other-implementations)\n\n## Why TOON?\n\nAI is becoming cheaper and more accessible, but larger context windows allow for larger data inputs as well. **LLM tokens still cost money** ‚Äì and standard JSON is verbose and token-expensive:\n\n```json\n{\n  \"users\": [\n    { \"id\": 1, \"name\": \"Alice\", \"role\": \"admin\" },\n    { \"id\": 2, \"name\": \"Bob\", \"role\": \"user\" }\n  ]\n}\n```\n\nTOON conveys the same information with **fewer tokens**:\n\n```\nusers[2]{id,name,role}:\n  1,Alice,admin\n  2,Bob,user\n```\n\n<details>\n<summary><strong>Why create a new format?</strong></summary>\n\nFor small payloads, JSON/CSV/YAML work fine. TOON's value emerges at scale: when you're making hundreds of LLM calls with uniform tabular data, eliminating repeated keys compounds savings significantly. If token costs matter to your use case, TOON reduces them. If not, stick with what works.\n\n</details>\n\n<details>\n<summary><strong>When NOT to use TOON</strong></summary>\n\nTOON excels with uniform arrays of objects, but there are cases where other formats are better:\n\n- **Deeply nested or non-uniform structures** (tabular eligibility ‚âà 0%): JSON-compact often uses fewer tokens. Example: complex configuration objects with many nested levels.\n- **Semi-uniform arrays** (~40‚Äì60% tabular eligibility): Token savings diminish. Prefer JSON if your pipelines already rely on it.\n- **Flat CSV use-cases**: CSV is smaller than TOON for pure tabular data. TOON adds minimal overhead (~5-10%) to provide structure (length markers, field headers, delimiter scoping) that improves LLM reliability.\n\nSee [benchmarks](#benchmarks) for concrete comparisons across different data structures.\n\n</details>\n\n## Key Features\n\n- üí∏ **Token-efficient:** typically 30-60% fewer tokens on large uniform arrays vs formatted JSON[^1]\n- ü§ø **LLM-friendly guardrails:** explicit lengths and fields enable validation\n- üç± **Minimal syntax:** removes redundant punctuation (braces, brackets, most quotes)\n- üìê **Indentation-based structure:** like YAML, uses whitespace instead of braces\n- üß∫ **Tabular arrays:** declare keys once, stream data as rows\n\n[^1]: For flat tabular data, CSV is more compact. TOON adds minimal overhead to provide explicit structure and validation that improves LLM reliability.\n\n## Benchmarks\n\n> [!TIP]\n> Try the interactive [Format Tokenization Playground](https://www.curiouslychase.com/playground/format-tokenization-exploration) to compare token usage across CSV, JSON, YAML, and TOON with your own data.\n\nBenchmarks are organized into two tracks to ensure fair comparisons:\n\n- **Mixed-Structure Track**: Datasets with nested or semi-uniform structures (TOON vs JSON, YAML, XML). CSV excluded as it cannot properly represent these structures.\n- **Flat-Only Track**: Datasets with flat tabular structures where CSV is applicable (CSV vs TOON vs JSON, YAML, XML).\n\n### Token Efficiency\n\nToken counts are measured using the GPT-5 `o200k_base` tokenizer via [`gpt-tokenizer`](https://github.com/niieani/gpt-tokenizer). Savings are calculated against formatted JSO",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-08T02:20:38.986135"
  },
  {
    "basic_info": {
      "name": "AI-Trader",
      "full_name": "HKUDS/AI-Trader",
      "owner": "HKUDS",
      "description": "\"AI-Trader: Can AI Beat the Market?\" Live Trading Bench: https://hkuds.github.io/AI-Trader/",
      "url": "https://github.com/HKUDS/AI-Trader",
      "clone_url": "https://github.com/HKUDS/AI-Trader.git",
      "ssh_url": "git@github.com:HKUDS/AI-Trader.git",
      "homepage": "",
      "created_at": "2025-10-23T12:45:00Z",
      "updated_at": "2025-11-08T01:55:52Z",
      "pushed_at": "2025-11-07T08:56:08Z"
    },
    "stats": {
      "stars": 9085,
      "forks": 1320,
      "watchers": 9085,
      "open_issues": 38,
      "size": 12171
    },
    "tech_info": {
      "language": "Python",
      "languages": {
        "Python": 244505,
        "Shell": 3328
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "<div align=\"center\">\n\n# üöÄ AI-Trader: Can AI Beat the Market?\n\n[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://python.org)\n[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)\n[![GitHub stars](https://img.shields.io/github/stars/HKUDS/AI-Trader?style=social)](https://github.com/HKUDS/AI-Trader)\n[![Feishu](https://img.shields.io/badge/üí¨Feishu-Group-blue?style=flat)](./Communication.md) \n[![WeChat](https://img.shields.io/badge/WeChat-Group-green?style=flat&logo=wechat)](./Communication.md)\n\n**AI agents battle for supremacy in NASDAQ 100 and SSE 50 markets. Zero human input. Pure competition.**\n\n## üèÜ Current Championship Leaderboard üèÜ \n[*Click Here: AI Live Trading*](https://ai4trade.ai)\n\n</div>\n\n---\n## üéâ Weekly Update\n\nWe're excited to announce the following major updates completed this week:\n\n### üìà Market Expansion\n- ‚úÖ **A-Share Market Support** - Extended our trading capabilities to include Chinese A-share markets, expanding our global market coverage.\n\n### ‚è∞ Enhanced Trading Capabilities\n- ‚úÖ **Hourly Trading Support** - We've upgraded from daily to hourly trading intervals, enabling more precise and responsive market participation with granular timing control.\n\n### üé® User Experience Improvements\n- ‚úÖ **Live Trading Dashboard** - Introduced real-time visualization of all agent trading activities, providing comprehensive oversight of market operations.\n\n- ‚úÖ **Agent Reasoning Display** - Implemented complete transparency into AI decision-making processes, featuring detailed reasoning chains that show how each trading decision is formed.\n\n- ‚úÖ **Interactive Leaderboard** - Launched a dynamic performance ranking system with live updates, allowing users to track and compare agent performance in real-time.\n\n---\n\n## **How to use this dataset**\n\nIt's simple! \n\nYou just need to submit a PR that includes at least: `./agent/{your_strategy}.py` (you can inherit from Basemodel to create your strategy!), `./configs/{yourconfig}`, and instructions on how to run your strategy. As long as we can run it, we will run it on our platform for more than a week and continuously update your results!\n\n---\n\n<div align=\"center\">\n\n[üöÄ Quick Start](#-quick-start) ‚Ä¢ [üìà Performance Analysis](#-performance-analysis) ‚Ä¢ [üõ†Ô∏è Configuration Guide](#-configuration-guide) ‚Ä¢ [‰∏≠ÊñáÊñáÊ°£](README_CN.md)\n\n</div>\n\n\n## üåü Project Introduction\n\n> **AI-Trader enables five distinct AI models, each employing unique investment strategies, to compete autonomously in the same market and determine which can generate the highest profits in NASDAQ 100 or SSE 50 trading!**\n\n### üéØ Core Features\n\n- ü§ñ **Fully Autonomous Decision-Making**: AI agents perform 100% independent analysis, decision-making, and execution without human intervention\n- üõ†Ô∏è **Pure Tool-Driven Architecture**: Built on MCP toolchain, enabling AI to complete all trading operations through standardized tool calls\n- üèÜ **Multi-Model Competition Arena**: Deploy multiple AI models (GPT, Claude, Qwen, etc.) for competitive trading\n- üìä **Real-Time Performance Analytics**: Comprehensive trading records, position monitoring, and profit/loss analysis\n- üîç **Intelligent Market Intelligence**: Integrated Jina search for real-time market news and financial reports\n- ‚ö° **MCP Toolchain Integration**: Modular tool ecosystem based on Model Context Protocol\n- üîå **Extensible Strategy Framework**: Support for third-party strategies and custom AI agent integration\n- ‚è∞ **Historical Replay Capability**: Time-period replay functionality with automatic future information filtering\n\n---\n\n### üéÆ Trading Environment\nEach AI model starts with $10,000 or 100,000¬• to trade NASDAQ 100 stocks or SSE 50 stocks in a controlled environment with real market data and historical replay capabilities.\n\n- üí∞ **Initial Capital**: $10,000 USD or 100,000¬• CNY starting balance\n- üìà **Trading Universe**: NASDAQ 100 component stocks (top 100 technology stocks) or SSE 50 component stocks\n- ‚è∞ **Trading Schedule**: Weekday market hours with historical simulation support\n- üìä **Data Integration**: Alpha Vantage API combined with Jina AI market intelligence\n- üîÑ **Time Management**: Historical period replay with automated future information filtering\n\n---\n\n### üß† Agentic Trading Capabilities\nAI agents operate with complete autonomy, conducting market research, making trading decisions, and continuously evolving their strategies without human intervention.\n\n- üì∞ **Autonomous Market Research**: Intelligent retrieval and filtering of market news, analyst reports, and financial data\n- üí° **Independent Decision Engine**: Multi-dimensional analysis driving fully autonomous buy/sell execution\n- üìù **Comprehensive Trade Logging**: Automated documentation of trading rationale, execution details, and portfolio changes\n- üîÑ **Adaptive Strategy Evolution**: Self-optimizing algorithms that adjust based on market performance feedback\n\n---\n\n### üèÅ Competition Rules\nAll AI models compete under identical conditions with the same capital, data ac",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-08T02:20:40.125548"
  },
  {
    "basic_info": {
      "name": "nofx",
      "full_name": "NoFxAiOS/nofx",
      "owner": "NoFxAiOS",
      "description": "NOFX: Defining the Next-Generation AI Trading Operating System. A multi-exchange Al trading platform(Binance/Hyperliquid/Aster) with multi-Ai competition(deepseek/qwen/claude)self-evolution, and real-time dashboard",
      "url": "https://github.com/NoFxAiOS/nofx",
      "clone_url": "https://github.com/NoFxAiOS/nofx.git",
      "ssh_url": "git@github.com:NoFxAiOS/nofx.git",
      "homepage": "https://nofxai.com",
      "created_at": "2025-10-28T07:17:53Z",
      "updated_at": "2025-11-08T02:03:14Z",
      "pushed_at": "2025-11-08T00:41:29Z"
    },
    "stats": {
      "stars": 7018,
      "forks": 1714,
      "watchers": 7018,
      "open_issues": 257,
      "size": 42163
    },
    "tech_info": {
      "language": "TypeScript",
      "languages": {
        "TypeScript": 548646,
        "Go": 490683,
        "Shell": 84320,
        "CSS": 9821,
        "JavaScript": 4014,
        "HTML": 1062
      },
      "license": "GNU Affero General Public License v3.0",
      "topics": [
        "agentic-ai",
        "agentictrading",
        "ai",
        "ai-trading",
        "aitradingos",
        "nof1ai",
        "trading"
      ]
    },
    "content": {
      "readme": "# ü§ñ NOFX - Agentic Trading OS\n\n[![Go Version](https://img.shields.io/badge/Go-1.21+-00ADD8?style=flat&logo=go)](https://golang.org/)\n[![React](https://img.shields.io/badge/React-18+-61DAFB?style=flat&logo=react)](https://reactjs.org/)\n[![TypeScript](https://img.shields.io/badge/TypeScript-5.0+-3178C6?style=flat&logo=typescript)](https://www.typescriptlang.org/)\n[![License](https://img.shields.io/badge/License-AGPL--3.0-blue.svg)](LICENSE)\n[![Backed by Amber.ac](https://img.shields.io/badge/Backed%20by-Amber.ac-orange.svg)](https://amber.ac)\n\n**Languages:** [English](README.md) | [‰∏≠Êñá](docs/i18n/zh-CN/README.md) | [–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞](docs/i18n/uk/README.md) | [–†—É—Å—Å–∫–∏–π](docs/i18n/ru/README.md) | [Êó•Êú¨Ë™û](docs/i18n/ja/README.md)\n\n**Official Twitter:** [@nofx_ai](https://x.com/nofx_ai)\n\n**üìö Documentation:** [Docs Home](docs/README.md) | [Getting Started](docs/getting-started/README.md) | [Changelog](CHANGELOG.md) | [Contributing](CONTRIBUTING.md) | [Security](SECURITY.md)\n\n---\n\n## üìë Table of Contents\n\n- [üöÄ Universal AI Trading Operating System](#-universal-ai-trading-operating-system)\n- [üë• Developer Community](#-developer-community)\n- [üÜï What's New](#-whats-new-latest-update)\n- [üì∏ Screenshots](#-screenshots)\n- [‚ú® Current Implementation](#-current-implementation---crypto-markets)\n- [üîÆ Roadmap](#-roadmap---universal-market-expansion)\n- [üèóÔ∏è Technical Architecture](#Ô∏è-technical-architecture)\n- [üí∞ Register Binance Account](#-register-binance-account-save-on-fees)\n- [üöÄ Quick Start](#-quick-start)\n- [üìñ AI Decision Flow](#-ai-decision-flow)\n- [üß† AI Self-Learning](#-ai-self-learning-example)\n- [üìä Web Interface Features](#-web-interface-features)\n- [üéõÔ∏è API Endpoints](#Ô∏è-api-endpoints)\n- [üîê Admin Mode (Single-User)](#-admin-mode-single-user) \n- [‚ö†Ô∏è Important Risk Warnings](#Ô∏è-important-risk-warnings)\n- [üõ†Ô∏è Common Issues](#Ô∏è-common-issues)\n- [üìà Performance Tips](#-performance-optimization-tips)\n- [üîÑ Changelog](#-changelog)\n- [üìÑ License](#-license)\n- [ü§ù Contributing](#-contributing)\n\n---\n\n## üöÄ Universal AI Trading Operating System\n\n**NOFX** is a **universal Agentic Trading OS** built on a unified architecture. We've successfully closed the loop in crypto markets: **\"Multi-Agent Decision ‚Üí Unified Risk Control ‚Üí Low-Latency Execution ‚Üí Live/Paper Account Backtesting\"**, and are now expanding this same technology stack to **stocks, futures, options, forex, and all financial markets**.\n\n### üéØ Core Features\n\n- **Universal Data & Backtesting Layer**: Cross-market, cross-timeframe, cross-exchange unified representation and factor library, accumulating transferable \"strategy memory\"\n- **Multi-Agent Self-Play & Self-Evolution**: Strategies automatically compete and select the best, continuously iterating based on account-level PnL and risk constraints\n- **Integrated Execution & Risk Control**: Low-latency routing, slippage/risk control sandbox, account-level limits, one-click market switching\n\n### üè¢ Backed by [Amber.ac](https://amber.ac)\n\n### üë• Core Team\n\n- **Tinkle** - [@Web3Tinkle](https://x.com/Web3Tinkle)\n- **Zack** - [@0x_ZackH](https://x.com/0x_ZackH)\n\n### üíº Seed Funding Round Open\n\nWe are currently raising our **seed round**. \n\n**For investment inquiries**, please DM **Tinkle** or **Zack** via Twitter.\n\n**For partnerships and collaborations**, please DM our official Twitter [@nofx_ai](https://x.com/nofx_ai).\n\n---\n\n> ‚ö†Ô∏è **Risk Warning**: This system is experimental. AI auto-trading carries significant risks. Strongly recommended for learning/research purposes or testing with small amounts only!\n\n## üë• Developer Community\n\nJoin our Telegram developer community to discuss, share ideas, and get support:\n\n**üí¨ [NOFX Developer Community](https://t.me/nofx_dev_community)**\n\n---\n\n## üÜï What's New (Latest Update)\n\n### üöÄ Multi-Exchange Support!\n\nNOFX now supports **three major exchanges**: Binance, Hyperliquid, and Aster DEX!\n\n#### **Hyperliquid Exchange**\n\nA high-performance decentralized perpetual futures exchange!\n\n**Key Features:**\n- ‚úÖ Full trading support (long/short, leverage, stop-loss/take-profit)\n- ‚úÖ Automatic precision handling (order size & price)\n- ‚úÖ Unified trader interface (seamless exchange switching)\n- ‚úÖ Support for both mainnet and testnet\n- ‚úÖ No API keys needed - just your Ethereum private key\n\n**New Workflow:**\n1. **Configure AI Models**: Add your DeepSeek/Qwen API keys through the web interface\n2. **Configure Exchanges**: Set up Binance/Hyperliquid API credentials\n3. **Create Traders**: Combine any AI model with any exchange to create custom traders\n4. **Monitor & Control**: Start/stop traders and monitor performance in real-time\n\n**Why This Update?**\n- üéØ **User-Friendly**: No more editing JSON files or server restarts\n- üîß **Flexible**: Mix and match different AI models with different exchanges\n- üìä **Scalable**: Create unlimited trader combinations\n- üîí **Secure**: Database storage with proper data management\n\nSee [Quick Start](#-quick-start) for the new setup process!\n\n#### **Aster DEX Exchange** (NEW! v2.0.2)\n\nA Binance-compati",
      "default_branch": "dev"
    },
    "fetched_at": "2025-11-08T02:20:41.246628"
  },
  {
    "basic_info": {
      "name": "superpowers",
      "full_name": "obra/superpowers",
      "owner": "obra",
      "description": "Claude Code superpowers: core skills library",
      "url": "https://github.com/obra/superpowers",
      "clone_url": "https://github.com/obra/superpowers.git",
      "ssh_url": "git@github.com:obra/superpowers.git",
      "homepage": null,
      "created_at": "2025-10-09T19:45:18Z",
      "updated_at": "2025-11-08T01:16:40Z",
      "pushed_at": "2025-11-06T20:44:59Z"
    },
    "stats": {
      "stars": 6291,
      "forks": 464,
      "watchers": 6291,
      "open_issues": 24,
      "size": 254
    },
    "tech_info": {
      "language": "JavaScript",
      "languages": {
        "JavaScript": 13429,
        "Shell": 6289,
        "TypeScript": 5054
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# Superpowers\n\nA comprehensive skills library of proven techniques, patterns, and workflows for AI coding assistants.\n\n## What You Get\n\n- **Testing Skills** - TDD, async testing, anti-patterns\n- **Debugging Skills** - Systematic debugging, root cause tracing, verification\n- **Collaboration Skills** - Brainstorming, planning, code review, parallel agents\n- **Development Skills** - Git worktrees, finishing branches, subagent workflows\n- **Meta Skills** - Creating, testing, and sharing skills\n\nPlus:\n- **Slash Commands** - `/superpowers:brainstorm`, `/superpowers:write-plan`, `/superpowers:execute-plan`\n- **Automatic Integration** - Skills activate automatically when relevant\n- **Consistent Workflows** - Systematic approaches to common engineering tasks\n\n## Learn More\n\nRead the introduction: [Superpowers for Claude Code](https://blog.fsck.com/2025/10/09/superpowers/)\n\n## Installation\n\n### Claude Code (via Plugin Marketplace)\n\nIn Claude Code, register the marketplace first:\n\n```bash\n/plugin marketplace add obra/superpowers-marketplace\n```\n\nThen install the plugin from this marketplace:\n\n```bash\n/plugin install superpowers@superpowers-marketplace\n```\n\n### Verify Installation\n\nCheck that commands appear:\n\n```bash\n/help\n```\n\n```\n# Should see:\n# /superpowers:brainstorm - Interactive design refinement\n# /superpowers:write-plan - Create implementation plan\n# /superpowers:execute-plan - Execute plan in batches\n```\n\n### Codex (Experimental)\n\n**Note:** Codex support is experimental and may require refinement based on user feedback.\n\nTell Codex to fetch https://raw.githubusercontent.com/obra/superpowers/refs/heads/main/.codex/INSTALL.md and follow the instructions.\n\n## Quick Start\n\n### Using Slash Commands\n\n**Brainstorm a design:**\n```\n/superpowers:brainstorm\n```\n\n**Create an implementation plan:**\n```\n/superpowers:write-plan\n```\n\n**Execute the plan:**\n```\n/superpowers:execute-plan\n```\n\n### Automatic Skill Activation\n\nSkills activate automatically when relevant. For example:\n- `test-driven-development` activates when implementing features\n- `systematic-debugging` activates when debugging issues\n- `verification-before-completion` activates before claiming work is done\n\n## What's Inside\n\n### Skills Library\n\n**Testing** (`skills/testing/`)\n- **test-driven-development** - RED-GREEN-REFACTOR cycle\n- **condition-based-waiting** - Async test patterns\n- **testing-anti-patterns** - Common pitfalls to avoid\n\n**Debugging** (`skills/debugging/`)\n- **systematic-debugging** - 4-phase root cause process\n- **root-cause-tracing** - Find the real problem\n- **verification-before-completion** - Ensure it's actually fixed\n- **defense-in-depth** - Multiple validation layers\n\n**Collaboration** (`skills/collaboration/`)\n- **brainstorming** - Socratic design refinement\n- **writing-plans** - Detailed implementation plans\n- **executing-plans** - Batch execution with checkpoints\n- **dispatching-parallel-agents** - Concurrent subagent workflows\n- **requesting-code-review** - Pre-review checklist\n- **receiving-code-review** - Responding to feedback\n- **using-git-worktrees** - Parallel development branches\n- **finishing-a-development-branch** - Merge/PR decision workflow\n- **subagent-driven-development** - Fast iteration with quality gates\n\n**Meta** (`skills/meta/`)\n- **writing-skills** - Create new skills following best practices\n- **sharing-skills** - Contribute skills back via branch and PR\n- **testing-skills-with-subagents** - Validate skill quality\n- **using-superpowers** - Introduction to the skills system\n\n### Commands\n\nAll commands are thin wrappers that activate the corresponding skill:\n\n- **brainstorm.md** - Activates the `brainstorming` skill\n- **write-plan.md** - Activates the `writing-plans` skill\n- **execute-plan.md** - Activates the `executing-plans` skill\n\n## How It Works\n\n1. **SessionStart Hook** - Loads the `using-superpowers` skill at session start\n2. **Skills System** - Uses Claude Code's first-party skills system\n3. **Automatic Discovery** - Claude finds and uses relevant skills for your task\n4. **Mandatory Workflows** - When a skill exists for your task, using it becomes required\n\n## Philosophy\n\n- **Test-Driven Development** - Write tests first, always\n- **Systematic over ad-hoc** - Process over guessing\n- **Complexity reduction** - Simplicity as primary goal\n- **Evidence over claims** - Verify before declaring success\n- **Domain over implementation** - Work at problem level, not solution level\n\n## Contributing\n\nSkills live directly in this repository. To contribute:\n\n1. Fork the repository\n2. Create a branch for your skill\n3. Follow the `writing-skills` skill for creating new skills\n4. Use the `testing-skills-with-subagents` skill to validate quality\n5. Submit a PR\n\nSee `skills/meta/writing-skills/SKILL.md` for the complete guide.\n\n## Updating\n\nSkills update automatically when you update the plugin:\n\n```bash\n/plugin update superpowers\n```\n\n## License\n\nMIT License - see LICENSE file for details\n\n## Support\n\n- **Issues**: https://g",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-08T02:20:42.375126"
  },
  {
    "basic_info": {
      "name": "claude-code-infrastructure-showcase",
      "full_name": "diet103/claude-code-infrastructure-showcase",
      "owner": "diet103",
      "description": "Examples of my Claude Code infrastructure with skill auto-activation, hooks, and agents",
      "url": "https://github.com/diet103/claude-code-infrastructure-showcase",
      "clone_url": "https://github.com/diet103/claude-code-infrastructure-showcase.git",
      "ssh_url": "git@github.com:diet103/claude-code-infrastructure-showcase.git",
      "homepage": null,
      "created_at": "2025-10-30T03:12:16Z",
      "updated_at": "2025-11-08T02:07:06Z",
      "pushed_at": "2025-10-31T01:41:31Z"
    },
    "stats": {
      "stars": 4108,
      "forks": 578,
      "watchers": 4108,
      "open_issues": 9,
      "size": 214
    },
    "tech_info": {
      "language": "Shell",
      "languages": {
        "Shell": 19297,
        "JavaScript": 12798
      },
      "license": "MIT License",
      "topics": []
    },
    "content": {
      "readme": "# Claude Code Infrastructure Showcase\n\n**A curated reference library of production-tested Claude Code infrastructure.**\n\nBorn from 6 months of real-world use managing a complex TypeScript microservices project, this showcase provides the patterns and systems that solved the \"skills don't activate automatically\" problem and scaled Claude Code for enterprise development.\n\n> **This is NOT a working application** - it's a reference library. Copy what you need into your own projects.\n\n---\n\n## What's Inside\n\n**Production-tested infrastructure for:**\n- ‚úÖ **Auto-activating skills** via hooks\n- ‚úÖ **Modular skill pattern** (500-line rule with progressive disclosure)\n- ‚úÖ **Specialized agents** for complex tasks\n- ‚úÖ **Dev docs system** that survives context resets\n- ‚úÖ **Comprehensive examples** using generic blog domain\n\n**Time investment to build:** 6 months of iteration\n**Time to integrate into your project:** 15-30 minutes\n\n---\n\n## Quick Start - Pick Your Path\n\n### ü§ñ Using Claude Code to Integrate?\n\n**Claude:** Read [`CLAUDE_INTEGRATION_GUIDE.md`](CLAUDE_INTEGRATION_GUIDE.md) for step-by-step integration instructions tailored for AI-assisted setup.\n\n### üéØ I want skill auto-activation\n\n**The breakthrough feature:** Skills that actually activate when you need them.\n\n**What you need:**\n1. The skill-activation hooks (2 files)\n2. A skill or two relevant to your work\n3. 15 minutes\n\n**üëâ [Setup Guide: .claude/hooks/README.md](.claude/hooks/README.md)**\n\n### üìö I want to add ONE skill\n\nBrowse the [skills catalog](.claude/skills/) and copy what you need.\n\n**Available:**\n- **backend-dev-guidelines** - Node.js/Express/TypeScript patterns\n- **frontend-dev-guidelines** - React/TypeScript/MUI v7 patterns\n- **skill-developer** - Meta-skill for creating skills\n- **route-tester** - Test authenticated API routes\n- **error-tracking** - Sentry integration patterns\n\n**üëâ [Skills Guide: .claude/skills/README.md](.claude/skills/README.md)**\n\n### ü§ñ I want specialized agents\n\n10 production-tested agents for complex tasks:\n- Code architecture review\n- Refactoring assistance\n- Documentation generation\n- Error debugging\n- And more...\n\n**üëâ [Agents Guide: .claude/agents/README.md](.claude/agents/README.md)**\n\n---\n\n## What Makes This Different?\n\n### The Auto-Activation Breakthrough\n\n**Problem:** Claude Code skills just sit there. You have to remember to use them.\n\n**Solution:** UserPromptSubmit hook that:\n- Analyzes your prompts\n- Checks file context\n- Automatically suggests relevant skills\n- Works via `skill-rules.json` configuration\n\n**Result:** Skills activate when you need them, not when you remember them.\n\n### Production-Tested Patterns\n\nThese aren't theoretical examples - they're extracted from:\n- ‚úÖ 6 microservices in production\n- ‚úÖ 50,000+ lines of TypeScript\n- ‚úÖ React frontend with complex data grids\n- ‚úÖ Sophisticated workflow engine\n- ‚úÖ 6 months of daily Claude Code use\n\nThe patterns work because they solved real problems.\n\n### Modular Skills (500-Line Rule)\n\nLarge skills hit context limits. The solution:\n\n```\nskill-name/\n  SKILL.md                  # <500 lines, high-level guide\n  resources/\n    topic-1.md              # <500 lines each\n    topic-2.md\n    topic-3.md\n```\n\n**Progressive disclosure:** Claude loads main skill first, loads resources only when needed.\n\n---\n\n## Repository Structure\n\n```\n.claude/\n‚îú‚îÄ‚îÄ skills/                 # 5 production skills\n‚îÇ   ‚îú‚îÄ‚îÄ backend-dev-guidelines/  (12 resource files)\n‚îÇ   ‚îú‚îÄ‚îÄ frontend-dev-guidelines/ (11 resource files)\n‚îÇ   ‚îú‚îÄ‚îÄ skill-developer/         (7 resource files)\n‚îÇ   ‚îú‚îÄ‚îÄ route-tester/\n‚îÇ   ‚îú‚îÄ‚îÄ error-tracking/\n‚îÇ   ‚îî‚îÄ‚îÄ skill-rules.json    # Skill activation configuration\n‚îú‚îÄ‚îÄ hooks/                  # 6 hooks for automation\n‚îÇ   ‚îú‚îÄ‚îÄ skill-activation-prompt.*  (ESSENTIAL)\n‚îÇ   ‚îú‚îÄ‚îÄ post-tool-use-tracker.sh   (ESSENTIAL)\n‚îÇ   ‚îú‚îÄ‚îÄ tsc-check.sh        (optional, needs customization)\n‚îÇ   ‚îî‚îÄ‚îÄ trigger-build-resolver.sh  (optional)\n‚îú‚îÄ‚îÄ agents/                 # 10 specialized agents\n‚îÇ   ‚îú‚îÄ‚îÄ code-architecture-reviewer.md\n‚îÇ   ‚îú‚îÄ‚îÄ refactor-planner.md\n‚îÇ   ‚îú‚îÄ‚îÄ frontend-error-fixer.md\n‚îÇ   ‚îî‚îÄ‚îÄ ... 7 more\n‚îî‚îÄ‚îÄ commands/               # 3 slash commands\n    ‚îú‚îÄ‚îÄ dev-docs.md\n    ‚îî‚îÄ‚îÄ ...\n\ndev/\n‚îî‚îÄ‚îÄ active/                 # Dev docs pattern examples\n    ‚îî‚îÄ‚îÄ public-infrastructure-repo/\n```\n\n---\n\n## Component Catalog\n\n### üé® Skills (5)\n\n| Skill | Lines | Purpose | Best For |\n|-------|-------|---------|----------|\n| [**skill-developer**](.claude/skills/skill-developer/) | 426 | Creating and managing skills | Meta-development |\n| [**backend-dev-guidelines**](.claude/skills/backend-dev-guidelines/) | 304 | Express/Prisma/Sentry patterns | Backend APIs |\n| [**frontend-dev-guidelines**](.claude/skills/frontend-dev-guidelines/) | 398 | React/MUI v7/TypeScript | React frontends |\n| [**route-tester**](.claude/skills/route-tester/) | 389 | Testing authenticated routes | API testing |\n| [**error-tracking**](.claude/skills/error-tracking/) | ~250 | Sentry integration | Error monitoring |\n\n**All skills follow the modular pattern** - main",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-08T02:20:43.532734"
  },
  {
    "basic_info": {
      "name": "Skill_Seekers",
      "full_name": "yusufkaraaslan/Skill_Seekers",
      "owner": "yusufkaraaslan",
      "description": "Convert documentation websites, GitHub repositories, and PDFs into Claude AI skills with automatic conflict detection",
      "url": "https://github.com/yusufkaraaslan/Skill_Seekers",
      "clone_url": "https://github.com/yusufkaraaslan/Skill_Seekers.git",
      "ssh_url": "git@github.com:yusufkaraaslan/Skill_Seekers.git",
      "homepage": "",
      "created_at": "2025-10-17T14:43:48Z",
      "updated_at": "2025-11-08T02:10:13Z",
      "pushed_at": "2025-11-06T22:25:41Z"
    },
    "stats": {
      "stars": 3562,
      "forks": 356,
      "watchers": 3562,
      "open_issues": 118,
      "size": 696
    },
    "tech_info": {
      "language": "Python",
      "languages": {
        "Python": 682739,
        "Shell": 8958
      },
      "license": "MIT License",
      "topics": [
        "ai-tools",
        "ast-parser",
        "automation",
        "claude-ai",
        "claude-skills",
        "code-analysis",
        "conflict-detection",
        "documentation",
        "documentation-generator",
        "github",
        "github-scraper",
        "mcp",
        "mcp-server",
        "multi-source",
        "ocr",
        "pdf",
        "python",
        "web-scraping"
      ]
    },
    "content": {
      "readme": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/yusufkaraaslan-skill-seekers-badge.png)](https://mseep.ai/app/yusufkaraaslan-skill-seekers)\n\n# Skill Seeker\n\n[![Version](https://img.shields.io/badge/version-2.0.0-blue.svg)](https://github.com/yusufkaraaslan/Skill_Seekers/releases/tag/v2.0.0)\n[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)\n[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)\n[![MCP Integration](https://img.shields.io/badge/MCP-Integrated-blue.svg)](https://modelcontextprotocol.io)\n[![Tested](https://img.shields.io/badge/Tests-299%20Passing-brightgreen.svg)](tests/)\n[![Project Board](https://img.shields.io/badge/Project-Board-purple.svg)](https://github.com/users/yusufkaraaslan/projects/2)\n\n**Automatically convert documentation websites, GitHub repositories, and PDFs into Claude AI skills in minutes.**\n\n> üìã **[View Development Roadmap & Tasks](https://github.com/users/yusufkaraaslan/projects/2)** - 134 tasks across 10 categories, pick any to contribute!\n\n## What is Skill Seeker?\n\nSkill Seeker is an automated tool that transforms documentation websites, GitHub repositories, and PDF files into production-ready [Claude AI skills](https://www.anthropic.com/news/skills). Instead of manually reading and summarizing documentation, Skill Seeker:\n\n1. **Scrapes** multiple sources (docs, GitHub repos, PDFs) automatically\n2. **Analyzes** code repositories with deep AST parsing\n3. **Detects** conflicts between documentation and code implementation\n4. **Organizes** content into categorized reference files\n5. **Enhances** with AI to extract best examples and key concepts\n6. **Packages** everything into an uploadable `.zip` file for Claude\n\n**Result:** Get comprehensive Claude skills for any framework, API, or tool in 20-40 minutes instead of hours of manual work.\n\n## Why Use This?\n\n- üéØ **For Developers**: Create skills from documentation + GitHub repos with conflict detection\n- üéÆ **For Game Devs**: Generate skills for game engines (Godot docs + GitHub, Unity, etc.)\n- üîß **For Teams**: Combine internal docs + code repositories into single source of truth\n- üìö **For Learners**: Build comprehensive skills from docs, code examples, and PDFs\n- üîç **For Open Source**: Analyze repos to find documentation gaps and outdated examples\n\n## Key Features\n\n### üåê Documentation Scraping\n- ‚úÖ **llms.txt Support** - Automatically detects and uses LLM-ready documentation files (10x faster)\n- ‚úÖ **Universal Scraper** - Works with ANY documentation website\n- ‚úÖ **Smart Categorization** - Automatically organizes content by topic\n- ‚úÖ **Code Language Detection** - Recognizes Python, JavaScript, C++, GDScript, etc.\n- ‚úÖ **8 Ready-to-Use Presets** - Godot, React, Vue, Django, FastAPI, and more\n\n### üìÑ PDF Support (**v1.2.0**)\n- ‚úÖ **Basic PDF Extraction** - Extract text, code, and images from PDF files\n- ‚úÖ **OCR for Scanned PDFs** - Extract text from scanned documents\n- ‚úÖ **Password-Protected PDFs** - Handle encrypted PDFs\n- ‚úÖ **Table Extraction** - Extract complex tables from PDFs\n- ‚úÖ **Parallel Processing** - 3x faster for large PDFs\n- ‚úÖ **Intelligent Caching** - 50% faster on re-runs\n\n### üêô GitHub Repository Scraping (**v2.0.0**)\n- ‚úÖ **Deep Code Analysis** - AST parsing for Python, JavaScript, TypeScript, Java, C++, Go\n- ‚úÖ **API Extraction** - Functions, classes, methods with parameters and types\n- ‚úÖ **Repository Metadata** - README, file tree, language breakdown, stars/forks\n- ‚úÖ **GitHub Issues & PRs** - Fetch open/closed issues with labels and milestones\n- ‚úÖ **CHANGELOG & Releases** - Automatically extract version history\n- ‚úÖ **Conflict Detection** - Compare documented APIs vs actual code implementation\n- ‚úÖ **MCP Integration** - Natural language: \"Scrape GitHub repo facebook/react\"\n\n### üîÑ Unified Multi-Source Scraping (**NEW - v2.0.0**)\n- ‚úÖ **Combine Multiple Sources** - Mix documentation + GitHub + PDF in one skill\n- ‚úÖ **Conflict Detection** - Automatically finds discrepancies between docs and code\n- ‚úÖ **Intelligent Merging** - Rule-based or AI-powered conflict resolution\n- ‚úÖ **Transparent Reporting** - Side-by-side comparison with ‚ö†Ô∏è warnings\n- ‚úÖ **Documentation Gap Analysis** - Identifies outdated docs and undocumented features\n- ‚úÖ **Single Source of Truth** - One skill showing both intent (docs) and reality (code)\n- ‚úÖ **Backward Compatible** - Legacy single-source configs still work\n\n### ü§ñ AI & Enhancement\n- ‚úÖ **AI-Powered Enhancement** - Transforms basic templates into comprehensive guides\n- ‚úÖ **No API Costs** - FREE local enhancement using Claude Code Max\n- ‚úÖ **MCP Server for Claude Code** - Use directly from Claude Code with natural language\n\n### ‚ö° Performance & Scale\n- ‚úÖ **Async Mode** - 2-3x faster scraping with async/await (use `--async` flag)\n- ‚úÖ **Large Documentation Support** - Handle 10K-40K+ page docs with intelligent splitting\n- ‚úÖ **Router/Hub Skills** - Intelligent routing to specialized sub-skills\n-",
      "default_branch": "development"
    },
    "fetched_at": "2025-11-08T02:20:44.661653"
  },
  {
    "basic_info": {
      "name": "bentopdf",
      "full_name": "alam00000/bentopdf",
      "owner": "alam00000",
      "description": "A Privacy First PDF Toolkit",
      "url": "https://github.com/alam00000/bentopdf",
      "clone_url": "https://github.com/alam00000/bentopdf.git",
      "ssh_url": "git@github.com:alam00000/bentopdf.git",
      "homepage": "https://bentopdf.com/",
      "created_at": "2025-10-12T13:30:08Z",
      "updated_at": "2025-11-08T02:08:16Z",
      "pushed_at": "2025-11-07T21:31:55Z"
    },
    "stats": {
      "stars": 3388,
      "forks": 223,
      "watchers": 3388,
      "open_issues": 45,
      "size": 996
    },
    "tech_info": {
      "language": "TypeScript",
      "languages": {
        "TypeScript": 612621,
        "HTML": 129494,
        "CSS": 12067,
        "JavaScript": 4438,
        "Dockerfile": 1227
      },
      "license": "GNU Affero General Public License v3.0",
      "topics": [
        "bentopdf",
        "hacktoberfest",
        "hacktoberfest-accepted",
        "javascript",
        "jpgtopdf",
        "pdf",
        "pdf-converter",
        "pdf-document",
        "pdf-document-processor",
        "pdf-generation",
        "pdf-viewer",
        "pdffiller",
        "privacy",
        "toolkit",
        "typescript"
      ]
    },
    "content": {
      "readme": "# BentoPDF\n\n**BentoPDF** is a powerful, privacy-first, client-side PDF toolkit that allows you to manipulate, edit, merge, and process PDF files directly in your browser. No server-side processing is required, ensuring your files remain secure and private.\n\n![Docker Pulls](https://img.shields.io/docker/pulls/bentopdf/bentopdf) [![Ko-fi](https://img.shields.io/badge/Buy%20me%20a%20Coffee-yellow?logo=kofi&style=flat-square)](https://ko-fi.com/alio0) ![GitHub Stars](https://img.shields.io/github/stars/alam00000/bentopdf?style=social)\n[![Sponsor me on GitHub](https://img.shields.io/badge/Sponsor-%E2%9D%A4-ff69b4)](https://github.com/sponsors/alam00000)\n\n## ‚≠ê Stargazers over time\n\n[![Star History Chart](https://api.star-history.com/svg?repos=alam00000/bentopdf&type=Date)](https://star-history.com/#alam00000/bentopdf&Date)\n\n---\n\n## ‚ú® Why BentoPDF?\n\n- **Privacy First**: All processing happens in your browser. Your files are never uploaded to a server, guaranteeing 100% privacy.\n- **No Limits**: Manipulate as many files as you want, as often you want. There are no restrictions or upload limits.\n- **High Performance**: Built with modern web technologies, BentoPDF is fast and efficient, handling even large PDF files with ease.\n- **Completely Free**: BentoPDF is a free and open-source tool for everyone.\n\n---\n\n## üõ†Ô∏è Features / Tools Supported\n\nBentoPDF offers a comprehensive suite of tools to handle all your PDF needs.\n\n### Organize & Manage PDFs\n\n| Tool Name                 | Description                                                                |\n| :------------------------ | :------------------------------------------------------------------------- |\n| **Merge PDFs**            | Combine multiple PDF files into one.                                       |\n| **Split PDFs**            | Extract specific pages or divide a document into smaller files.            |\n| **Organize Pages**        | Reorder, duplicate, or delete pages with a simple drag-and-drop interface. |\n| **Extract Pages**         | Save a specific range of pages as a new PDF.                               |\n| **Delete Pages**          | Remove unwanted pages from your document.                                  |\n| **Rotate PDF**            | Rotate individual or all pages in a document.                              |\n| **N-Up PDF**              | Combine multiple pages onto a single page.                                 |\n| **View PDF**              | A powerful, integrated PDF viewer.                                         |\n| **Alternate & Mix pages** | Merge pages by alternating pages from each PDF.                            |\n| **Posterize PDF**         | Split a PDF into multiple smaller pages for print.                         |\n\n### Edit & Modify PDFs\n\n| Tool Name              | Description                                                 |\n| :--------------------- | :---------------------------------------------------------- |\n| **PDF Editor**         | A comprehensive editor to modify your PDFs.                 |\n| **Add Page Numbers**   | Easily add page numbers with customizable formatting.       |\n| **Add Watermark**      | Add text or image watermarks to protect your documents.     |\n| **Header & Footer**    | Add customizable headers and footers.                       |\n| **Crop PDF**           | Crop specific pages or the entire document.                 |\n| **Invert Colors**      | Invert the colors of your PDF pages for better readability. |\n| **Change Background**  | Modify the background color of your PDF.                    |\n| **Change Text Color**  | Change the color of text content within the PDF.            |\n| **Fill Forms**         | Fill out PDF forms directly in your browser.                |\n| **Flatten PDF**        | Flatten form fields and annotations into static content.    |\n| **Remove Annotations** | Remove comments, highlights, and other annotations.         |\n| **Remove Blank Pages** | Auto detect and remove blank pages in a PDF.                |\n\n### Convert to PDF\n\n| Tool Name           | Description                                                     |\n| :------------------ | :-------------------------------------------------------------- |\n| **Image to PDF**    | Convert JPG, PNG, WebP, SVG, BMP, HEIC, and TIFF images to PDF. |\n| **Markdown to PDF** | Convert `.md` files into professional PDF documents.            |\n| **Text to PDF**     | Convert plain text files into a PDF.                            |\n\n### Convert from PDF\n\n| Tool Name            | Description                                                                    |\n| :------------------- | :----------------------------------------------------------------------------- |\n| **PDF to Image**     | Convert PDF pages to JPG, PNG, WebP, BMP, or TIFF formats.                     |\n| **PDF to Greyscale** | Convert a color PDF into a black-and-white version.                            |\n| **OCR PDF**          | Make scanned PDFs searchable and copyable ",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-08T02:20:45.810801"
  },
  {
    "basic_info": {
      "name": "agentic-design-patterns-cn",
      "full_name": "ginobefun/agentic-design-patterns-cn",
      "owner": "ginobefun",
      "description": "„ÄäAgentic Design Patterns„Äã‰∏≠ÊñáÁøªËØëÁâà",
      "url": "https://github.com/ginobefun/agentic-design-patterns-cn",
      "clone_url": "https://github.com/ginobefun/agentic-design-patterns-cn.git",
      "ssh_url": "git@github.com:ginobefun/agentic-design-patterns-cn.git",
      "homepage": null,
      "created_at": "2025-10-09T04:36:28Z",
      "updated_at": "2025-11-08T01:53:07Z",
      "pushed_at": "2025-11-05T09:07:45Z"
    },
    "stats": {
      "stars": 3069,
      "forks": 326,
      "watchers": 3069,
      "open_issues": 3,
      "size": 8380
    },
    "tech_info": {
      "language": "Python",
      "languages": {
        "Python": 114397
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/ginobefun-agentic-design-patterns-cn-badge.png)](https://mseep.ai/app/ginobefun-agentic-design-patterns-cn)\n\n# Agentic Design Patterns | <mark>Êô∫ËÉΩ‰ΩìËÆæËÆ°Ê®°Âºè</mark>\n\n## A Hands-On Guide to Building Intelligent Systems | <mark>ÊûÑÂª∫Êô∫ËÉΩÁ≥ªÁªüÁöÑÂÆûË∑µÊåáÂçó</mark>\n\n[![License: CC BY-NC 4.0](https://img.shields.io/badge/License-CC%20BY--NC%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc/4.0/)\n[![GitHub stars](https://img.shields.io/github/stars/ginobefun/agentic-design-patterns-cn)](https://github.com/ginobefun/agentic-design-patterns-cn/stargazers)\n[![GitHub forks](https://img.shields.io/github/forks/ginobefun/agentic-design-patterns-cn)](https://github.com/ginobefun/agentic-design-patterns-cn/network)\n\n**Âéü‰π¶‰ΩúËÄÖ (Author)**: [Antonio Gulli](https://www.linkedin.com/in/searchguy/)\n\n**Âéü‰π¶ÈìæÊé• (Original Book)**: [Amazon](https://www.amazon.com/Agentic-Design-Patterns-Hands-Intelligent/dp/3032014018/)\n\n**ÂéüÂßãÊñáÊ°£ÈìæÊé• (Original Book Link)**: [Google Docs](https://docs.google.com/document/d/1rsaK53T3Lg5KoGwvf8ukOUvbELRtH-V0LnOIFDxBryE/preview?tab=t.0#heading=h.pxcur8v2qagu)\n\n---\n\n## üìñ È°πÁõÆÁÆÄ‰ªã | Project Description\n\nÊú¨È°πÁõÆÊòØÂØπ Antonio Gulli ÊâÄËëó„ÄäAgentic Design Patterns: A Hands-On Guide to Building Intelligent Systems„ÄãÁöÑ**‰∏≠Ëã±ÊñáÂØπÁÖßÁøªËØë**„ÄÇËØ•‰π¶ÊòØ‰∏ÄÈÉ®ÂÖ®Èù¢ÁöÑÊäÄÊúØÊåáÂçóÔºåÊ∂µÁõñ‰∫ÜÁé∞‰ª£‰∫∫Â∑•Êô∫ËÉΩÁ≥ªÁªü‰∏≠Êô∫ËÉΩ‰Ωì (Agent) ËÆæËÆ°ÁöÑÊ†∏ÂøÉÊ¶ÇÂøµÂíåÂÆûË∑µÊñπÊ≥ï„ÄÇ\n\nThis project is a **bilingual Chinese-English translation** of \"Agentic Design Patterns: A Hands-On Guide to Building Intelligent Systems\" by Antonio Gulli. The book is a comprehensive technical guide covering core concepts and practical approaches to agent design in modern AI systems.\n\n---\n\n## üéØ È°πÁõÆÁâπËâ≤ | Key Features\n\n- üìö **‰∏≠Ëã±ÊñáÂØπÁÖß** - ÂÆåÊï¥ÁöÑÂèåËØ≠ÂØπÁÖßÁøªËØë\n- üé® **È´ò‰∫ÆÊòæÁ§∫** - ‰∏≠ÊñáÂÜÖÂÆπ‰ΩøÁî®ÈªÑËâ≤È´ò‰∫ÆÔºåÊòì‰∫éÂå∫ÂàÜ\n- üìù **Ê†ºÂºèËßÑËåÉ** - ‰∏•Ê†ºÈÅµÂæ™ Markdown Ê†áÂáÜÂíåÁøªËØëËßÑËåÉ\n- üîó **‰ª£Á†ÅÈìæÊé•** - ‰øùÁïôÊâÄÊúâÂéü‰π¶‰ª£Á†ÅÁ§∫‰æãÈìæÊé•\n- ‚ö° **ÊåÅÁª≠Êõ¥Êñ∞** - ÈÄêÁ´†ÁøªËØëÔºåÊåÅÁª≠Êõ¥Êñ∞ËøõÂ∫¶\n\n---\n\n## üìã ÁøªËØëËøõÂ∫¶ | Translation Progress\n\n**<mark>ÊÄªÈ°µÊï∞Ôºö424 È°µ</mark>** | **Total: 424 Pages**\n\n### ÂâçÁΩÆÂÜÖÂÆπ | Front Matter\n\n| Á´†ËäÇ | Ê¶ÇËø∞ | Ë¥üË¥£‰∫∫ | AI ÁøªËØë | ‰∫∫Â∑•ËØÑÂÆ° | ‰∫§ÂèâËØÑÂÆ° |\n|------|------|--------|---------|----------|----------|\n| [ÁåÆËæû](01-Dedication.md) | ‰ΩúËÄÖÁöÑÁåÆËæû‰∏éËá¥Êï¨ | @ginobefun | ‚úÖ | ‚úÖ | ‚è≥ |\n| [Ëá¥Ë∞¢](02-Acknowledgment.md) | Ëá¥Ë∞¢‰∏éÊÑüË∞¢ÂêçÂçï | @ginobefun | ‚úÖ | ‚úÖ | ‚è≥ |\n| [Â∫èË®Ä](03-Foreword.md) | Êú¨‰π¶ÁöÑÂ∫èË®Ä‰∏éËÉåÊôØ‰ªãÁªç | @ginobefun | ‚úÖ | ‚úÖ | ‚è≥ |\n| [ÊÄùÊÉ≥È¢ÜË¢ñÁöÑÊ¥ûËßÅ](04-Thought-Leader.md) | ÊùÉÂäõ‰∏éË¥£‰ªªÁöÑÊ∑±Â∫¶ÊÄùËÄÉ | @ginobefun | ‚úÖ | ‚úÖ | ‚è≥ |\n| [‰ªãÁªç](05-Introduction.md) | ÂÖ®‰π¶ÂºïË®Ä‰∏éÊ†∏ÂøÉÊ¶ÇÂøµ | @ginobefun | ‚úÖ | ‚úÖ | ‚è≥ |\n| [‰ªÄ‰πàÊòØ\"Êô∫ËÉΩ‰Ωì\"Ôºü](06-What-Makes-Agent.md) | ÂÆö‰πâ AI Á≥ªÁªüÁöÑ\"Êô∫ËÉΩ‰Ωì\"ÁâπÂæÅ | @ginobefun | ‚úÖ | ‚úÖ | ‚è≥ |\n\n### Á¨¨‰∏ÄÈÉ®ÂàÜÔºöÊ†∏ÂøÉËÆæËÆ°Ê®°Âºè | Part One: Core Patterns (103 È°µ)\n\n| Á´†ËäÇ | ËÆæËÆ°Ê®°ÂºèÊ¶ÇËø∞ | Ë¥üË¥£‰∫∫ | AI ÁøªËØë | ‰∫∫Â∑•ËØÑÂÆ° | ‰∫§ÂèâËØÑÂÆ° |\n|------|-------------|--------|---------|----------|----------|\n| [Á¨¨ 1 Á´†ÔºöÊèêÁ§∫Èìæ](07-Chapter-01-Prompt-Chaining.md) | ÂàÜËÄåÊ≤ª‰πãÁöÑ‰ªªÂä°ÂàÜËß£Ê®°ÂºèÔºåÂ∞ÜÂ§çÊùÇ‰ªªÂä°ÂàÜËß£‰∏∫Â§ÑÁêÜÊµÅÊ∞¥Á∫ø | @ginobefun | ‚úÖ | ‚úÖ | ‚è≥ |\n| [Á¨¨ 2 Á´†ÔºöË∑ØÁî±](08-Chapter-02-Routing.md) | Êô∫ËÉΩÂÜ≥Á≠ñ‰∏éÂä®ÊÄÅÂàÜÂèëÔºåÊ†πÊçÆÊÉÖÂ¢ÉÈÄâÊã©ÊúÄ‰Ω≥Ë°åÂä®Ë∑ØÂæÑ | @ginobefun | ‚úÖ | ‚úÖ | ‚è≥ |\n| [Á¨¨ 3 Á´†ÔºöÂπ∂Ë°åÂåñ](09-Chapter-03-Parallelization.md) | Âπ∂ÂèëÊâßË°å‰∏éÊÄßËÉΩÊèêÂçáÔºåÂêåÊó∂ÊâßË°åÂ§ö‰∏™Áã¨Á´ã‰ªªÂä° | @ginobefun | ‚úÖ | ‚úÖ | ‚è≥ |\n| [Á¨¨ 4 Á´†ÔºöÂèçÊÄù](10-Chapter-04-Reflection.md) | Ëá™ÊàëËØÑ‰º∞ÂíåËø≠‰ª£ÊîπËøõÔºåÈÄöËøáÂèçÈ¶àÂæ™ÁéØ‰ºòÂåñËæìÂá∫Ë¥®Èáè | @ginobefun | ‚úÖ | ‚úÖ | ‚è≥ |\n| [Á¨¨ 5 Á´†ÔºöÂ∑•ÂÖ∑‰ΩøÁî®](11-Chapter-05-Tool-Use.md) | Â§ñÈÉ®Â∑•ÂÖ∑‰∏é API ÈõÜÊàêÔºåÊâ©Â±ïÊô∫ËÉΩ‰ΩìËÉΩÂäõËæπÁïå | @ginobefun | ‚úÖ | ‚úÖ | ‚è≥ |\n| [Á¨¨ 6 Á´†ÔºöËßÑÂàí](12-Chapter-06-Planning.md) | Â§öÊ≠•È™§ËÆ°ÂàíÂà∂ÂÆö‰∏éÊâßË°åÔºåÂÆûÁé∞Â§çÊùÇÁõÆÊ†áÂàÜËß£ | @ginobefun | ‚úÖ | ‚úÖ | ‚è≥ |\n| [Á¨¨ 7 Á´†ÔºöÂ§öÊô∫ËÉΩ‰ΩìÂçè‰Ωú](13-Chapter-07-Multi-Agent-Collaboration.md) | ÂçèÂêåÂ∑•‰ΩúÊû∂ÊûÑÔºåÂ§ö‰∏™Êô∫ËÉΩ‰ΩìÈÖçÂêàÂÆåÊàê‰ªªÂä° | @ginobefun | ‚úÖ  | ‚úÖ | ‚è≥ |\n\n### Á¨¨‰∫åÈÉ®ÂàÜÔºöÈ´òÁ∫ßËÆæËÆ°Ê®°Âºè | Part Two: Advanced Patterns (61 È°µ)\n\n| Á´†ËäÇ | ËÆæËÆ°Ê®°ÂºèÊ¶ÇËø∞ | Ë¥üË¥£‰∫∫ | AI ÁøªËØë | ‰∫∫Â∑•ËØÑÂÆ° | ‰∫§ÂèâËØÑÂÆ° |\n|------|-------------|--------|---------|----------|----------|\n| [Á¨¨ 8 Á´†ÔºöËÆ∞ÂøÜÁÆ°ÁêÜ](14-Chapter-08-Memory-Management.md) | Áü≠ÊúüÂíåÈïøÊúüËÆ∞ÂøÜÁÆ°ÁêÜÔºåÁª¥ÊåÅ‰∏ä‰∏ãÊñáËøûÁª≠ÊÄß | @ÈÉëÊ∂õ | ‚úÖ | ‚úÖ | ‚ùå |\n| [Á¨¨ 9 Á´†ÔºöÂ≠¶‰π†‰∏éÈÄÇÂ∫î](15-Chapter-09-Learning-and-Adaptation.md) | ‰ªéÁªèÈ™å‰∏≠Â≠¶‰π†ÔºåÊåÅÁª≠‰ºòÂåñÊô∫ËÉΩ‰ΩìË°å‰∏∫ | @ÈôàËØó‰∏≠ | ‚è≥ | ‚ùå | ‚ùå |\n| [Á¨¨ 10 Á´†ÔºöÊ®°Âûã‰∏ä‰∏ãÊñáÂçèËÆÆ](16-Chapter-10-Model-Context-Protocol.md) | Ê†áÂáÜÂåñ‰∫§‰∫íÂçèËÆÆÔºåËßÑËåÉÊô∫ËÉΩ‰ΩìÈÄö‰ø°ÊñπÂºè | @ÈÉëÊ∂õ | ‚è≥ | ‚ùå | ‚ùå |\n| [Á¨¨ 11 Á´†ÔºöÁõÆÊ†áËÆæÂÆö‰∏éÁõëÊéß](17-Chapter-11-Goal-Setting-and-Monitoring.md) | Âä®ÊÄÅÁõÆÊ†áÁÆ°ÁêÜÔºåÂÆûÊó∂ËøΩË∏™‰ªªÂä°ËøõÂ±ï | [@ÊùéÊµ™Ê∫™](https://github.com/seabornlee) | ‚úÖ | ‚úÖ | ‚è≥ |\n\n### Á¨¨‰∏âÈÉ®ÂàÜÔºöÈõÜÊàêËÆæËÆ°Ê®°Âºè | Part Three: Integration Patterns (34 È°µ)\n\n| Á´†ËäÇ | ËÆæËÆ°Ê®°ÂºèÊ¶ÇËø∞ | Ë¥üË¥£‰∫∫ | AI ÁøªËØë | ‰∫∫Â∑•ËØÑÂÆ° | ‰∫§ÂèâËØÑÂÆ° |\n|------|-------------|--------|---------|----------|----------|\n| [Á¨¨ 12 Á´†ÔºöÂºÇÂ∏∏Â§ÑÁêÜ‰∏éÊÅ¢Â§ç](18-Chapter-12-Exception-Handling-and-Recovery.md) | ‰ºòÈõÖÈîôËØØÂ§ÑÁêÜÔºåÁ°Æ‰øùÁ≥ªÁªüÁ®≥ÂÆöÊÄß | @EE | ‚ùå | ‚ùå | ‚ùå |\n| [Á¨¨ 13 Á´†Ôºö‰∫∫Êú∫Âçè‰Ωú](19-Chapter-13-Human-in-the-Loop.md) | ‰∫∫Êú∫Âçè‰ΩúÂÜ≥Á≠ñÔºåËûçÂêà‰∫∫Á±ªÊô∫ÊÖß‰∏é AI ËÉΩÂäõ | @ÊõæÊ±â | ‚úÖ | ‚úÖ | ‚è≥ |\n| [Á¨¨ 14 Á´†ÔºöÁü•ËØÜÊ£ÄÁ¥¢ (RAG)](20-Chapter-14-Knowledge-Retrieval.md) | Ê£ÄÁ¥¢Â¢ûÂº∫ÁîüÊàêÊäÄÊúØÔºåÁªìÂêàÂ§ñÈÉ®Áü•ËØÜÂ∫ì | @EE | ‚úÖ | ‚úÖ | ‚è≥ |\n\n### Á¨¨ÂõõÈÉ®ÂàÜÔºöÁîü‰∫ßËÆæËÆ°Ê®°Âºè | Part Four: Production Patterns (114 È°µ)\n\n| Á´†ËäÇ | ËÆæËÆ°Ê®°ÂºèÊ¶ÇËø∞ | Ë¥üË¥£‰∫∫ | AI ÁøªËØë | ‰∫∫Â∑•ËØÑÂÆ° | ‰∫§ÂèâËØÑÂÆ° |\n|------|-------------|--------|---------|----------|----------|\n| [Á¨¨ 15 Á´†ÔºöÊô∫ËÉΩ‰ΩìÈó¥ÈÄö‰ø° (A2A)](21-Chapter-15-Inter-Agent-Communication.md) | Êô∫ËÉΩ‰ΩìÈÄö‰ø°ÂçèËÆÆÔºåÂÆûÁé∞Êô∫ËÉΩ‰ΩìÈó¥È´òÊïà‰∫§‰∫í | @ÊúµÊúµËÇ• | ‚úÖ | ‚úÖ | ‚ùå |\n| [Á¨¨ 16 Á´†ÔºöËµÑÊ∫êÊÑüÁü•‰ºòÂåñ](22-Chapter-16-Resource-Aware-Optimization.md) | ËµÑÊ∫ê‰ºòÂåñÁÆ°ÁêÜÔºåÂπ≥Ë°°ÊÄßËÉΩ‰∏éÊàêÊú¨ | @IsaacZhaoo | ‚úÖ | ‚úÖ | ‚è≥ |\n| [Á¨¨ 17 Á´†ÔºöÊé®ÁêÜÊäÄÊúØ](23-Chapter-17-Reasoning-Techniques.md) | Â¢ûÂº∫Êé®ÁêÜËÉΩÂäõÔºåÊèêÂçáÂÜ≥Á≠ñË¥®Èáè | @Diqing | ‚ùå | ‚ùå | ‚ùå |\n| [Á¨¨ 18 Á´†ÔºöÊä§Ê†è/ÂÆâÂÖ®Ê®°Âºè](24-Chapter-18-Guardrails-Safety-Patterns.md) | ÂÆâÂÖ®‰øùÈöúÊú∫Âà∂ÔºåÈò≤Ê≠¢‰∏çÂΩìË°å‰∏∫ | @IsaacZhaoo | ‚è≥ | ‚ùå | ‚ùå |\n| [Á¨¨ 19 Á´†ÔºöËØÑ‰º∞‰∏éÁõëÊéß](25-Chapter-19-Evaluation-and-Monitoring.md) | ÊÄßËÉΩËØÑ‰º∞‰ΩìÁ≥ªÔºåÈáèÂåñÊô∫ËÉΩ‰ΩìË°®Áé∞ | @ÊúµÊúµËÇ• | ‚ùå | ‚ùå ",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-08T02:20:46.923761"
  },
  {
    "basic_info": {
      "name": "dexter",
      "full_name": "virattt/dexter",
      "owner": "virattt",
      "description": "An autonomous agent for deep financial research",
      "url": "https://github.com/virattt/dexter",
      "clone_url": "https://github.com/virattt/dexter.git",
      "ssh_url": "git@github.com:virattt/dexter.git",
      "homepage": null,
      "created_at": "2025-10-14T21:02:00Z",
      "updated_at": "2025-11-07T20:07:16Z",
      "pushed_at": "2025-11-05T23:32:24Z"
    },
    "stats": {
      "stars": 2726,
      "forks": 347,
      "watchers": 2726,
      "open_issues": 8,
      "size": 105
    },
    "tech_info": {
      "language": "Python",
      "languages": {
        "Python": 67362,
        "JavaScript": 228
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# Dexter ü§ñ\n\nDexter is an autonomous financial research agent that thinks, plans, and learns as it works. It performs analysis using task planning, self-reflection, and real-time market data. Think Claude Code, but built specifically for financial research.\n\n\n<img width=\"979\" height=\"651\" alt=\"Screenshot 2025-10-14 at 6 12 35‚ÄØPM\" src=\"https://github.com/user-attachments/assets/5a2859d4-53cf-4638-998a-15cef3c98038\" />\n\n## Overview\n\nDexter takes complex financial questions and turns them into clear, step-by-step research plans. It runs those tasks using live market data, checks its own work, and refines the results until it has a confident, data-backed answer.  \n\n**Key Capabilities:**\n- **Intelligent Task Planning**: Automatically decomposes complex queries into structured research steps\n- **Autonomous Execution**: Selects and executes the right tools to gather financial data\n- **Self-Validation**: Checks its own work and iterates until tasks are complete\n- **Real-Time Financial Data**: Access to income statements, balance sheets, and cash flow statements\n- **Safety Features**: Built-in loop detection and step limits to prevent runaway execution\n\n[![Twitter Follow](https://img.shields.io/twitter/follow/virattt?style=social)](https://twitter.com/virattt)\n\n### Prerequisites\n\n- Python 3.10 or higher\n- [uv](https://github.com/astral-sh/uv) package manager\n- OpenAI API key (get [here](https://platform.openai.com/api-keys))\n- Financial Datasets API key (get [here](https://financialdatasets.ai))\n\n### Installation\n\n1. Clone the repository:\n```bash\ngit clone https://github.com/virattt/dexter.git\ncd dexter\n```\n\n2. Install dependencies with uv:\n```bash\nuv sync\n```\n\n3. Set up your environment variables:\n```bash\n# Copy the example environment file\ncp env.example .env\n\n# Edit .env and add your API keys\n# OPENAI_API_KEY=your-openai-api-key\n# FINANCIAL_DATASETS_API_KEY=your-financial-datasets-api-key\n```\n\n### Usage\n\nRun Dexter in interactive mode:\n```bash\nuv run dexter-agent\n```\n\n### Example Queries\n\nTry asking Dexter questions like:\n- \"What was Apple's revenue growth over the last 4 quarters?\"\n- \"Compare Microsoft and Google's operating margins for 2023\"\n- \"Analyze Tesla's cash flow trends over the past year\"\n- \"What is Amazon's debt-to-equity ratio based on recent financials?\"\n\nDexter will automatically:\n1. Break down your question into research tasks\n2. Fetch the necessary financial data\n3. Perform calculations and analysis\n4. Provide a comprehensive, data-rich answer\n\n## Architecture\n\nDexter uses a multi-agent architecture with specialized components:\n\n- **Planning Agent**: Analyzes queries and creates structured task lists\n- **Action Agent**: Selects appropriate tools and executes research steps\n- **Validation Agent**: Verifies task completion and data sufficiency\n- **Answer Agent**: Synthesizes findings into comprehensive responses\n\n## Project Structure\n\n```\ndexter/\n‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îú‚îÄ‚îÄ dexter/\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agent.py      # Main agent orchestration logic\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model.py      # LLM interface\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tools.py      # Financial data tools\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prompts.py    # System prompts for each component\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ schemas.py    # Pydantic models\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ utils/        # Utility functions\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cli.py        # CLI entry point\n‚îú‚îÄ‚îÄ pyproject.toml\n‚îî‚îÄ‚îÄ uv.lock\n```\n\n## Configuration\n\nDexter supports configuration via the `Agent` class initialization:\n\n```python\nfrom dexter.agent import Agent\n\nagent = Agent(\n    max_steps=20,              # Global safety limit\n    max_steps_per_task=5       # Per-task iteration limit\n)\n```\n\n## How to Contribute\n\n1. Fork the repository\n2. Create a feature branch\n3. Commit your changes\n4. Push to the branch\n5. Create a Pull Request\n\n**Important**: Please keep your pull requests small and focused.  This will make it easier to review and merge.\n\n\n## License\n\nThis project is licensed under the MIT License.\n\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-08T02:20:48.052472"
  },
  {
    "basic_info": {
      "name": "nof0",
      "full_name": "wquguru/nof0",
      "owner": "wquguru",
      "description": "NOF0 - ÂºÄÊ∫êÁöÑ AI ‰∫§ÊòìÁ´ûÊäÄÂú∫",
      "url": "https://github.com/wquguru/nof0",
      "clone_url": "https://github.com/wquguru/nof0.git",
      "ssh_url": "git@github.com:wquguru/nof0.git",
      "homepage": "https://nof0.wqu.guru",
      "created_at": "2025-10-22T16:30:45Z",
      "updated_at": "2025-11-08T02:03:17Z",
      "pushed_at": "2025-11-06T14:41:46Z"
    },
    "stats": {
      "stars": 2642,
      "forks": 412,
      "watchers": 2642,
      "open_issues": 14,
      "size": 6126
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 711679,
        "TypeScript": 240568,
        "Python": 17418,
        "CSS": 7723,
        "JavaScript": 6050,
        "Makefile": 5532,
        "PLpgSQL": 3276,
        "Shell": 2688,
        "Dockerfile": 739
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# NOF0 - ÂºÄÊ∫êÁöÑ AI ‰∫§ÊòìÁ´ûÊäÄÂú∫\n\n<div align=\"center\">\n\n[![Next.js](https://img.shields.io/badge/Next.js-000000?style=flat&logo=nextdotjs&logoColor=white)](https://nextjs.org/)\n[![React](https://img.shields.io/badge/React-20232A?style=flat&logo=react&logoColor=61DAFB)](https://reactjs.org/)\n[![Go](https://img.shields.io/badge/Go-00ADD8?style=flat&logo=go&logoColor=white)](https://go.dev/)\n[![Go-Zero](https://img.shields.io/badge/Go--Zero-000000?style=flat&logo=go&logoColor=white)](https://go-zero.dev/)\n[![ZenMux](https://img.shields.io/badge/ZenMux-LLM-000000)](https://zenmux.ai?utm_source=nof0)\n\n\n</div>\n\n<div align=\"center\">\n\n[![Hyperliquid](https://img.shields.io/badge/Hyperliquid-DEX-000000)](https://hyperliquid.xyz/)\n\n</div>\n\n<div align=\"center\">\n\n[![Documentation](https://img.shields.io/badge/Documentation-GitBook-3884FF?style=flat&logo=gitbook&logoColor=white)](https://wquguru.gitbook.io/nof0)\n[![Join Telegram Group](https://img.shields.io/badge/Telegram-nof0__ai-26A5E4?style=flat&logo=telegram&logoColor=white)](https://t.me/nof0_ai)\n[![Follow @wquguru](https://img.shields.io/badge/Follow-@wquguru-1DA1F2?style=flat&logo=x&logoColor=white)](https://twitter.com/intent/follow?screen_name=wquguru)\n\n</div>\n\n<div align=\"center\">\n\n![ÂâçÁ´ØËøõÂ∫¶](https://img.shields.io/badge/ÂâçÁ´ØËøõÂ∫¶-100%25-success?style=flat-square)\n![ÂêéÁ´ØËøõÂ∫¶](https://img.shields.io/badge/ÂêéÁ´ØËøõÂ∫¶-70%25-yellow?style=flat-square)\n![AI‰∫§ÊòìÂºïÊìéËøõÂ∫¶](https://img.shields.io/badge/AI‰∫§ÊòìÂºïÊìéËøõÂ∫¶-80%25-yellowgreen?style=flat-square)\n\n</div>\n\n\n> **ÂºÄÁÆ±Âç≥Áî®ÁöÑ LLM/Agentic Trading È°πÁõÆ**\n>\n> ÂÆåÊï¥Â§çÂàª [NOF1.ai](https://nof1.ai) Alpha ArenaÔºåËÆ© AI + Crypto Ëµ∞ÂêëÂ§ß‰ºóËßÜÈáé\n\n**Áî®ÁúüÂÆûÊï∞ÊçÆÂíåÊ∏ÖÊô∞ÂèØËßÜÂåñÔºåÂõûÁ≠î\"Âì™‰∏™Ê®°ÂûãÊõ¥‰ºöËµö\"ÁöÑÊú¥Á¥†ÈóÆÈ¢ò**\n\n## È°πÁõÆÁÆÄ‰ªã\n\nNOF0 ÊòØ‰∏Ä‰∏™ËÆ©Â§ö‰∏™ AI Ê®°ÂûãÂú®ÁúüÂÆûÂä†ÂØÜË¥ßÂ∏ÅÂ∏ÇÂú∫‰∏≠ËøõË°å‰∫§ÊòìÁ´ûËµõÁöÑÂπ≥Âè∞„ÄÇ\n\n**Ê†∏ÂøÉÁâπÊÄß**:\n\n- ÊØè‰∏™ AI LLM / Agent ‰ªé $10,000 ÂêØÂä®ËµÑÈáëÂºÄÂßã\n- ÂÆûÊó∂Â±ïÁ§∫ÊØè‰∏™Ê®°ÂûãÁöÑÁõà‰∫èË°®Áé∞\n- ÂÆåÊï¥ÂºÄÊ∫êÂ§çÂàª nof1.ai ÁöÑÂäüËÉΩ\n- ËÆ©‰ªª‰Ωï‰∫∫ÈÉΩËÉΩÈÉ®ÁΩ≤Ëá™Â∑±ÁöÑ AI ‰∫§ÊòìÁ´ûÊäÄÂú∫\n\n## Ê†∏ÂøÉÁêÜÂøµ\n\nNOF0 ‰∏çÊòØ‰º†ÁªüÁöÑÂõûÊµãÂ∑•ÂÖ∑ÔºåËÄåÊòØ‰∏Ä‰∏™ **‰ª• Prompt ‰∏∫‰∏≠ÂøÉÁöÑ‰∫§ÊòìÁ´ûÊäÄÂú∫**Ôºö\n\n- **ÂÆûÁõòÁ´ûÊäÄÔºå‰∏çÊòØÂõûÊµãÂ∑•ÂÖ∑** - Áî®ÁúüÂÆûÁõà‰∫èÈ™åËØÅÁ≠ñÁï•ÔºåÊåÅÁª≠ÂØπÊäóËøáÂ∫¶ÊãüÂêà\n- **Á´ûÊäÄÂú∫ (Arena)Ôºå‰∏çÊòØÂçï‰∏ÄÊ®°Âûã** - ‰∏ÄÈîÆÈÉ®ÁΩ≤Âü∫Á°ÄËÆæÊñΩÔºå‰∏ìÊ≥® Prompt Á≠ñÁï•Êú¨Ë∫´\n- **‰ª• Prompt ‰∏∫‰∏≠ÂøÉ** - ËÆ©Á≠ñÁï•ÂêåÂè∞Á´ûÊäÄÔºåÁî®Êï∞ÊçÆÂõûÁ≠îÔºöÂì™‰∏™Ê®°ÂûãÊõ¥‰ºöËµöÔºü\n\n### Ê†∏ÂøÉÂ∑•‰ΩúÊµÅ\n\n```\n[ÊÄùËÄÉÁ≠ñÁï•] ‚Üí [Êí∞ÂÜôPrompt] ‚Üí [ÂÆûÁõò‰∫§Êòì] ‚Üí [PNLÊéíË°å] ‚Üí [Ëø≠‰ª£Prompt]\n     ‚Üë                                                      ‚Üì\n     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n‰ªé $10,000 ÂêØÂä®ËµÑÈáëÂºÄÂßãÔºåÂÆûÊó∂ÁúãÊùøÂ±ïÁ§∫ÊâÄÊúâ Prompt-LLM Agent ÁöÑÁúüÂÆûË°®Áé∞„ÄÇ\n\n**[Êü•ÁúãÂÆåÊï¥ËÆæËÆ°ÂéüÂàô](go/docs/principles.md)** - ‰∫ÜËß£ÊØè‰∏™ÁêÜÂøµËÉåÂêéÁöÑÊÄùËÄÉ\n\n### ÂºÄÂèëËøõÂ∫¶\n\n1. ÂâçÁ´ØÔºö100% ÂèØÁã¨Á´ãËøêË°åÔºå‰∏ç‰æùËµñÂêéÁ´Ø\n2. ÂêéÁ´ØÔºö70% Ê†∏ÂøÉÂäüËÉΩÂºÄÂèë‰∏≠\n3. ÊâßË°åÂºïÊìéÔºàÂü∫‰∫éAIÂ∑•‰ΩúÊµÅÔºâ80% Á®≥ÂÆöÊÄßÊèêÂçá‰∏≠\n\n## È°πÁõÆÁªìÊûÑ\n\n```\nnof0/\n‚îú‚îÄ‚îÄ web/          # [ÂâçÁ´Ø] Next.js + React + Recharts\n‚îú‚îÄ‚îÄ go/           # [ÂêéÁ´Ø] Go-Zero + REST API\n‚îÇ   ‚îî‚îÄ‚îÄ pkg/      # Ê†∏ÂøÉ‰∏öÂä°ÂåÖ\n‚îÇ       ‚îú‚îÄ‚îÄ executor/   # AI Êï∞ÊçÆÊµÅ‰∏éÂ∑•‰ΩúÊµÅÂºïÊìé\n‚îÇ       ‚îú‚îÄ‚îÄ llm/        # LLM Êèê‰æõÂïÜÂ∞ÅË£Ö\n‚îÇ       ‚îú‚îÄ‚îÄ manager/    # Á≠ñÁï•ÁÆ°ÁêÜÂô®\n‚îÇ       ‚îú‚îÄ‚îÄ exchange/   # ‰∫§ÊòìÊâÄÊé•Âè£\n‚îÇ       ‚îú‚îÄ‚îÄ market/     # Â∏ÇÂú∫Êï∞ÊçÆ\n‚îÇ       ‚îî‚îÄ‚îÄ prompt/     # Prompt Ê®°Êùø\n‚îî‚îÄ‚îÄ mcp/          # [MCPÊï∞ÊçÆ] MCPÊµèËßàÂô®Êà™Âõæ„ÄÅJSONÈùôÊÄÅÊï∞ÊçÆÁ≠â\n```\n\n## Âø´ÈÄüÂºÄÂßã\n\n### 1. ÂàùÂßãÂåñÈ°πÁõÆ\n\nÂÖãÈöÜÈ°πÁõÆÂêéÔºåÈÖçÁΩÆ Git Ëá™Âä®ÈÄíÂΩíÂ§ÑÁêÜÂ≠êÊ®°ÂùóÔºö\n\n```bash\ngit clone <repo>\ncd nof0\ngit config submodule.recurse true\n```\n\n> Ê≠§Âêé `git pull` ‰ºöËá™Âä®Êõ¥Êñ∞Â≠êÊ®°ÂùóÔºàÂåÖÊã¨ `go/etc/prompts/base`ÔºâÔºåÊó†ÈúÄÊâãÂä®ÊâßË°å `git submodule update`\n\n### 2. ÂêØÂä®ÂâçÁ´Ø\n\n```bash\ncd web\nnpm install\nnpm run dev\n```\n\nËÆøÈóÆ `http://localhost:3000`\n\n**ÂâçÁ´ØÊ†∏ÂøÉÁâπÊÄß**:\n\n- Ë¥¶Êà∑ÊÄªËµÑ‰∫ßÊõ≤Á∫ø\n- ÊåÅ‰ªìÊÉÖÂÜµ\n- Êàê‰∫§Á∫™ÂΩï\n- Ê®°ÂûãÂØπËØùÔºàModel ChatÔºâ\n- ÊéíË°åÊ¶ú\n- Ê®°ÂûãËØ¶ÊÉÖ\n\n### 3. ÂêØÂä®ÂêéÁ´Ø\n\n> Â∞öÊú™ÂºÄÂèëÂÆåÊØïÔºåÊ¨¢ËøéÂä†ÂÖ•tgÁæ§Ëé∑ÂèñÂºÄÂèëËøõÂ∫¶ÈÄöÁü•Ôºöhttps://t.me/nof0_ai\n\n## ÊäÄÊúØÊ†à\n\n### ÂâçÁ´Ø (web/)\n\n| Á±ªÂà´   | ÊäÄÊúØÈÄâÂûã                               | ËØ¥Êòé              |\n|------|------------------------------------|-----------------|\n| Ê°ÜÊû∂   | Next.js 15 + React 19 + TypeScript | ÂÖ®Ê†àÊ°ÜÊû∂ + Á±ªÂûãÂÆâÂÖ®     |\n| ÂõæË°®   | Recharts                           | Ëá™ÂÆö‰πâÂõæ‰æã‰∏éÊú´Á´ØÊ†áËÆ∞      |\n| Áä∂ÊÄÅÁÆ°ÁêÜ | Zustand                            | ËΩªÈáèÁ∫ßÁä∂ÊÄÅÁÆ°ÁêÜ         |\n| Ê†∑ÂºèÁ≥ªÁªü | CSS Variables                      | ÈÅøÂÖç SSR/CSR Ê∞¥ÂêàÂ∑ÆÂºÇ |\n\n**ÊäÄÊúØ‰∫ÆÁÇπ**:\n\n- Âú® `src/lib/model/meta.ts` Áªü‰∏ÄÈÖçÁΩÆÂìÅÁâåËâ≤‰∏éÁôΩËâ≤Áâà Logo\n- `globals.css` ‰ΩøÁî® CSS ÂèòÈáèÈ©±Âä®‰∏ªÈ¢òÔºà`--panel-bg`„ÄÅ`--muted-text`„ÄÅ`--axis-tick` Á≠âÔºâ\n- ÂºÄÂèëËßÑËåÉÔºöÂèÇËÄÉ `web/docs/theme.md`ÔºåÈÅøÂÖç `isDark` ÂàÜÊîØÂà§Êñ≠\n\n### ÂêéÁ´Ø (go/)\n\n| Á±ªÂà´   | ÊäÄÊúØÈÄâÂûã    | ËØ¥Êòé          |\n|------|---------|-------------|\n| Ê°ÜÊû∂   | Go-Zero | ÂæÆÊúçÂä°Ê°ÜÊû∂       |\n\n> ËØ¶ÁªÜÊñáÊ°£ËßÅ [go/README.md](go/README.md)\n\n## Êï∞ÊçÆÂø´ÁÖßÂ∑•ÂÖ∑\n\n‰∏ÄÈîÆ‰∏ãËΩΩ nof1.ai ÁöÑ‰∏äÊ∏∏Êé•Âè£ÂéüÂßãÊï∞ÊçÆÔºåÁ¶ªÁ∫ø‰øùÂ≠òÔºö\n\n```bash\ncd web\nnpm run snapshot:nof1\n```\n\n**ËæìÂá∫ËØ¥Êòé**:\n\n- **ÁîüÊàêÁõÆÂΩï**: `snapshots/nof1/<ISOÊó∂Èó¥Êà≥>/*.json` ‰∏é `index.json`\n- **ÂåÖÂê´Êï∞ÊçÆ**:\n    - crypto-pricesÔºàÂä†ÂØÜË¥ßÂ∏Å‰ª∑Ê†ºÔºâ\n    - positionsÔºàÊåÅ‰ªìÊÉÖÂÜµÔºâ\n    - tradesÔºàÊàê‰∫§Á∫™ÂΩïÔºâ\n    - account-totalsÔºàË¥¶Êà∑ÊÄªÂÄºÔºâ\n    - since-inception-valuesÔºàÁ¥ØËÆ°Êî∂ÁõäÔºâ\n    - leaderboardÔºàÊéíË°åÊ¶úÔºâ\n    - analyticsÔºàÂàÜÊûêÊï∞ÊçÆÔºâ\n    - conversationsÔºàÊ®°ÂûãÂØπËØùÔºâ\n- **ÁâàÊú¨ÊéßÂà∂**: ÈªòËÆ§‰∏çÊèê‰∫§Âà∞‰ªìÂ∫ìÔºàËßÅ `.gitignore`Ôºâ\n\n## Áõ∏ÂÖ≥ËµÑÊ∫ê\n\n- [ÂÆåÊï¥ÊñáÊ°£](https://wquguru.gitbook.io/nof0) - GitBook Âú®Á∫øÊñáÊ°£\n- [NOF1 ÂÆòÊñπÁΩëÁ´ô](https://nof1.ai/) - ÂéüÁâà Alpha Arena\n- [ÂêéÁ´ØÂÆåÊï¥ÊñáÊ°£](go/README.md) - Go ÊúçÂä°ËØ¶ÁªÜËØ¥Êòé\n- [Go-Zero Ê°ÜÊû∂](https://go-zero.dev/) - ÂæÆÊúçÂä°Ê°ÜÊû∂ÊñáÊ°£\n\n## ËÆ∏ÂèØËØÅ\n\nMIT License\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-08T02:20:49.167847"
  },
  {
    "basic_info": {
      "name": "surf",
      "full_name": "deta/surf",
      "owner": "deta",
      "description": "Personal AI Notebooks. Organize files & webpages and generate notes from them. Open source, local & open data, open model choice (incl. local).",
      "url": "https://github.com/deta/surf",
      "clone_url": "https://github.com/deta/surf.git",
      "ssh_url": "git@github.com:deta/surf.git",
      "homepage": "https://deta.surf",
      "created_at": "2025-10-20T15:09:57Z",
      "updated_at": "2025-11-08T00:30:35Z",
      "pushed_at": "2025-11-07T18:48:46Z"
    },
    "stats": {
      "stars": 2569,
      "forks": 168,
      "watchers": 2569,
      "open_issues": 18,
      "size": 274646
    },
    "tech_info": {
      "language": "TypeScript",
      "languages": {
        "TypeScript": 1877432,
        "Svelte": 1614432,
        "Rust": 675921,
        "JavaScript": 39662,
        "SCSS": 39395,
        "CSS": 18112,
        "HTML": 4089,
        "NSIS": 3077,
        "Handlebars": 972,
        "Shell": 369
      },
      "license": "Apache License 2.0",
      "topics": [
        "claude",
        "deepseek",
        "gemma",
        "knowledge-base",
        "knowledge-management",
        "llm",
        "local",
        "local-llm",
        "ollama",
        "openai",
        "productivity",
        "rust",
        "svelte",
        "typescript"
      ]
    },
    "content": {
      "readme": "<div align=\"center\">\n  \n![splash](./docs/assets/repo-header.png)\n\n[**Website**](https://deta.surf) - [**Discord**](https://deta.surf/discord)\n\n</div>\n\n<br>\n\n# Deta Surf: Your AI Notebook\n\nDeta Surf is an AI notebook that brings all your files and the web directly into your stream of thought.\n\nIt‚Äôs meant for simultaneous research and thinking that minimizes the grunt work: manually searching, opening windows & tabs, scrolling, copying and pasting into a document editor.\n\nSurf is primarily built in Svelte, TypeScript and Rust, runs on MacOS, Windows & Linux, stores data locally in open formats, and is open source.\n\n![split](./docs/assets/split-note.webp)\n\n## Motivation\n\nMost applications are focused on a single task, or a single media type: notes, websites, or PDFs. Real thinking requires juggling media across sources to make connections and synthesize ideas. We want to help people think better, across all their media.\n\nSurf is built to be personal and open, in service of the user. This means local first data, open data formats, open source, and openness with respect to AI models. [Read more](https://deta.surf/motivation).\n\n## Installation\n\nCheckout the [GitHub releases](https://github.com/deta/surf/releases) for the latest stable version of Surf for MacOS, Windows and Linux.\n\nYou can also download Surf with some managed & additional features (e.g.¬†AI) from the [Deta website](https://deta.surf). That version is subject to different terms.\n\nFor building from source and local development, see [CONTRIBUTING.md](CONTRIBUTING.md).\n\n## TL;DR - Things to try\n\n- _YouTube Notes_: visit a YouTube video and ask a question\n- _PDF Notes_: open a PDF and ask a question\n- _Create an applet_: use the \"app generation\" tool and ask for an app\n- _Notes that search the web_: use the \"web search\" tool and ask a question with \"search\" in it\n\n## Features\n\n### Multi-Media Library & Notebooks\n\n![notebooks](./docs/assets/readme/notebook-grid.png)\n\nStore almost any media in a private library on your computer, in an open and transparent format.\n\n- Support for local files, sites & links from the web (YouTube, Tweets & more), or create media directly in Surf.\n- Organize this library into Notebooks.\n- Open and use much of your library offline.\n- Use your library to power Surf‚Äôs AI features.\n\nSurf's library is built on a local storage engine called SFFS (Surf Flat File System), which stores data in open and transparent formats.\n\n[Details on the library](/docs/LIBRARY.md).\n\n### Smart Notes\n\n![smart-notes](./docs/assets/readme/smart-notes.png)\n\nExplore and think across your digital stuff without opening up a bunch of windows, clicking, scrolling and copying & pasting into your document (or chatbot).\n\n- `@-mention` and auto-generate from any tab, website or any resource in your [library](./docs/LIBRARY.md).\n- Trigger [web searches](./docs/SMART_NOTES.md#web-search) to do research, and bring the results back in your notes.\n- Integrated [citations](./docs/SMART_NOTES.md#citations) deeplinked to original sources, whether a section on a webpage, a timestamp in a video, or a page in a PDF.\n- Generate interactive applications without writing code using [Surflets](./docs/Surflets.md).\n- Paste in images, tables or data from other applications and have Surf understand and incorporate them.\n- Use rich formating, code blocks, to-do lists and more in your notes.\n\n[Read more](/docs/SMART_NOTES.md).\n\n### Tabs, Split View & Sidebar\n\n![split](./docs/assets/another-split.webp)\n\nSurf is built around tabs, split view and a sidebar for easy navigation.\n\n- Open local notes, files or web pages in tabs.\n- Split view allows you to view and interact with multiple resources side by side.\n- The sidebar provides quick access to your Notebooks & notes.\n\n### Surflets (App Generation)\n\n![surflets](./docs/assets/readme/surflets.png)\n\nSurf can code interactive applets to help you visualize, understand or explore concepts or data that are aided with code.\n\n[Read more](./docs/SURFLETS.md).\n\n### AI\n\n![models.png](./docs/assets/readme/models.png)\n\n[Surf‚Äôs notes](./docs/SMART_NOTES.md) and [Surflets](./docs/SURFLETS.md) are powered by large language models of your choice.\n\n- Bring your own key for popular models\n- Add a cloud model\n- Use Local Language Models\n\n[Read more](./docs/AI_MODELS.md).\n\n### Shortcuts\n\nFind the most common shortcuts [here](./docs/SHORTCUTS.md).\n\n## Security\n\n_To report a security concern, please see_ https://github.com/deta/surf/security/policy\n\n## Contributing\n\nSee [CONTRIBUTING.md](CONTRIBUTING.md) for details on contributing to the project and an overview of the codebase.\n\n## Code of Conduct\n\nSee [CODE_OF_CONDUCT.md](CODE_OF_CONDUCT.md) for details on our code of conduct.\n\n## License\n\nThe source code for this project is licensed under the Apache 2.0 license, with the following exceptions:\n\n1. Our patch for the @ghostery/adblocker-electron package is licensed under the Mozilla Public License 2.0 (MPL-2.0), consistent with the upstream project's licensing.",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-08T02:20:50.298698"
  },
  {
    "basic_info": {
      "name": "beads",
      "full_name": "steveyegge/beads",
      "owner": "steveyegge",
      "description": "Beads - A memory upgrade for your coding agent",
      "url": "https://github.com/steveyegge/beads",
      "clone_url": "https://github.com/steveyegge/beads.git",
      "ssh_url": "git@github.com:steveyegge/beads.git",
      "homepage": "",
      "created_at": "2025-10-12T03:09:46Z",
      "updated_at": "2025-11-08T01:36:01Z",
      "pushed_at": "2025-11-08T00:54:24Z"
    },
    "stats": {
      "stars": 2532,
      "forks": 155,
      "watchers": 2532,
      "open_issues": 17,
      "size": 66166
    },
    "tech_info": {
      "language": "Go",
      "languages": {
        "Go": 2393439,
        "Python": 216199,
        "Shell": 38308,
        "JavaScript": 24030,
        "PowerShell": 9844,
        "Nix": 1412
      },
      "license": "MIT License",
      "topics": [
        "agents",
        "claude-code",
        "coding"
      ]
    },
    "content": {
      "readme": "# bd - Beads Issue Tracker üîó\n\n[![Go Version](https://img.shields.io/github/go-mod/go-version/steveyegge/beads)](https://go.dev/)\n[![Release](https://img.shields.io/github/v/release/steveyegge/beads)](https://github.com/steveyegge/beads/releases)\n[![npm version](https://img.shields.io/npm/v/@beads/bd)](https://www.npmjs.com/package/@beads/bd)\n[![CI](https://img.shields.io/github/actions/workflow/status/steveyegge/beads/ci.yml?branch=main&label=tests)](https://github.com/steveyegge/beads/actions/workflows/ci.yml)\n[![Go Report Card](https://goreportcard.com/badge/github.com/steveyegge/beads)](https://goreportcard.com/report/github.com/steveyegge/beads)\n[![License](https://img.shields.io/github/license/steveyegge/beads)](LICENSE)\n[![PyPI](https://img.shields.io/pypi/v/beads-mcp)](https://pypi.org/project/beads-mcp/)\n\n**Give your coding agent a memory upgrade**\n\n> ## üéâ **v0.20.1: Multi-Worker Support Unlocked!** üéâ\n>\n> **Hash-based IDs eliminate merge conflicts and collision issues!**\n>\n> Previous versions used sequential IDs (bd-1, bd-2, bd-3...) which caused frequent collisions when multiple agents or branches created issues concurrently. Version 0.20.1 switches to **hash-based IDs** (bd-a1b2, bd-f14c, bd-3e7a...) that are collision-resistant and merge-friendly.\n>\n> **What's new:** ‚úÖ Multi-clone, multi-branch, multi-agent workflows now work reliably  \n> **What changed:** Issue IDs are now short hashes instead of sequential numbers  \n> **Migration:** Run `bd migrate` to upgrade existing databases (optional - old DBs still work)\n>\n> Hash IDs use progressive length scaling (4/5/6 characters) with birthday paradox math to keep collisions extremely rare while maintaining human readability. See \"Hash-Based Issue IDs\" section below for details.\n\n> **‚ö†Ô∏è Alpha Status**: This project is in active development. The core features work well, but expect API changes before 1.0. Use for development/internal projects first.\n\nBeads is a lightweight memory system for coding agents, using a graph-based issue tracker. Four kinds of dependencies work to chain your issues together like beads, making them easy for agents to follow for long distances, and reliably perform complex task streams in the right order.\n\nDrop Beads into any project where you're using a coding agent, and you'll enjoy an instant upgrade in organization, focus, and your agent's ability to handle long-horizon tasks over multiple compaction sessions. Your agents will use issue tracking with proper epics, rather than creating a swamp of rotten half-implemented markdown plans.\n\nInstant start:\n\n```bash\ncurl -fsSL https://raw.githubusercontent.com/steveyegge/beads/main/scripts/install.sh | bash\n```\n\nThen tell your coding agent to start using the `bd` tool instead of markdown for all new work, somewhere in your `AGENTS.md` or `CLAUDE.md`. That's all there is to it!\n\nYou don't use Beads directly as a human. Your coding agent will file and manage issues on your behalf. They'll file things they notice automatically, and you can ask them at any time to add or update issues for you.\n\nBeads gives agents unprecedented long-term planning capability, solving their amnesia when dealing with complex nested plans. They can trivially query the ready work, orient themselves, and land on their feet as soon as they boot up.\n\nAgents using Beads will no longer silently pass over problems they notice due to lack of context space -- instead, they will automatically file issues for newly-discovered work as they go. No more lost work, ever.\n\nBeads issues are backed by git, but through a clever design it manages to act like a managed, centrally hosted SQL database shared by all of the agents working on a project (repo), even across machines.\n\nBeads even improves work auditability. The issue tracker has a sophisticated audit trail, which agents can use to reconstruct complex operations that may have spanned multiple sessions.\n\nAgents report that they enjoy working with Beads, and they will use it spontaneously for both recording new work and reasoning about your project in novel ways. Whether you are a human or an AI, Beads lets you have more fun and less stress with agentic coding.\n\n![AI Agent using Beads](https://raw.githubusercontent.com/steveyegge/beads/main/.github/images/agent-using-beads.jpg)\n\n## Features\n\n- ‚ú® **Zero setup** - `bd init` creates project-local database (and your agent will do it)\n- üîó **Dependency tracking** - Four dependency types (blocks, related, parent-child, discovered-from)\n- üìã **Ready work detection** - Automatically finds issues with no open blockers\n- ü§ñ **Agent-friendly** - `--json` flags for programmatic integration\n- üì¶ **Git-versioned** - JSONL records stored in git, synced across machines\n- üåç **Distributed by design** - Agents on multiple machines share one logical database via git\n- üîê **Protected branch support** - Works with GitHub/GitLab protected branches via separate sync branch\n- üèóÔ∏è **Extensible** - Add your own tables to the SQLite database\n- üîç **Multi-pr",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-08T02:20:51.436720"
  },
  {
    "basic_info": {
      "name": "kimi-cli",
      "full_name": "MoonshotAI/kimi-cli",
      "owner": "MoonshotAI",
      "description": "Kimi CLI is your next CLI agent.",
      "url": "https://github.com/MoonshotAI/kimi-cli",
      "clone_url": "https://github.com/MoonshotAI/kimi-cli.git",
      "ssh_url": "git@github.com:MoonshotAI/kimi-cli.git",
      "homepage": null,
      "created_at": "2025-10-15T12:58:03Z",
      "updated_at": "2025-11-08T02:11:49Z",
      "pushed_at": "2025-11-07T12:58:25Z"
    },
    "stats": {
      "stars": 2490,
      "forks": 205,
      "watchers": 2490,
      "open_issues": 54,
      "size": 1488
    },
    "tech_info": {
      "language": "Python",
      "languages": {
        "Python": 518223,
        "Makefile": 2775
      },
      "license": "Apache License 2.0",
      "topics": []
    },
    "content": {
      "readme": "# Kimi CLI\n\n[![Commit Activity](https://img.shields.io/github/commit-activity/w/MoonshotAI/kimi-cli)](https://github.com/MoonshotAI/kimi-cli/graphs/commit-activity)\n[![Checks](https://img.shields.io/github/check-runs/MoonshotAI/kimi-cli/main)](https://github.com/MoonshotAI/kimi-cli/actions)\n[![Version](https://img.shields.io/pypi/v/kimi-cli)](https://pypi.org/project/kimi-cli/)\n[![Downloads](https://img.shields.io/pypi/dw/kimi-cli)](https://pypistats.org/packages/kimi-cli)\n[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/MoonshotAI/kimi-cli)\n\n[‰∏≠Êñá](https://www.kimi.com/coding/docs/kimi-cli.html)\n\nKimi CLI is a new CLI agent that can help you with your software development tasks and terminal operations.\n\n> [!IMPORTANT]\n> Kimi CLI is currently in technical preview.\n\n## Key features\n\n- Shell-like UI and raw shell command execution\n- Zsh integration\n- [Agent Client Protocol] support\n- MCP support\n- And more to come...\n\n[Agent Client Protocol]: https://github.com/agentclientprotocol/agent-client-protocol\n\n## Installation\n\n> [!IMPORTANT]\n> Kimi CLI currently only supports macOS and Linux. Windows support is coming soon.\n\nKimi CLI is published as a Python package on PyPI. We highly recommend installing it with [uv](https://docs.astral.sh/uv/). If you have not installed uv yet, please follow the instructions [here](https://docs.astral.sh/uv/getting-started/installation/) to install it first.\n\nOnce uv is installed, you can install Kimi CLI with:\n\n```sh\nuv tool install --python 3.13 kimi-cli\n```\n\nRun `kimi --help` to check if Kimi CLI is installed successfully.\n\n> [!IMPORTANT]\n> Due to the security checks on macOS, the first time you run `kimi` command may take 10 seconds or more depending on your system environment.\n\n## Upgrading\n\nUpgrade Kimi CLI to the latest version with:\n\n```sh\nuv tool upgrade kimi-cli --no-cache\n```\n\n## Usage\n\nRun `kimi` command in the directory you want to work on, then send `/setup` to setup Kimi CLI:\n\n![](./docs/images/setup.png)\n\nAfter setup, Kimi CLI will be ready to use. You can send `/help` to get more information.\n\n## Features\n\n### Shell mode\n\nKimi CLI is not only a coding agent, but also a shell. You can switch the mode by pressing `Ctrl-X`. In shell mode, you can directly run shell commands without leaving Kimi CLI.\n\n> [!NOTE]\n> Built-in shell commands like `cd` are not supported yet.\n\n### Zsh integration\n\nYou can use Kimi CLI together with Zsh, to empower your shell experience with AI agent capabilities.\n\nInstall the [zsh-kimi-cli](https://github.com/MoonshotAI/zsh-kimi-cli) plugin via:\n\n```sh\ngit clone https://github.com/MoonshotAI/zsh-kimi-cli.git \\\n  ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/kimi-cli\n```\n\n> [!NOTE]\n> If you are using a plugin manager other than Oh My Zsh, you may need to refer to the plugin's README for installation instructions.\n\nThen add `kimi-cli` to your Zsh plugin list in `~/.zshrc`:\n\n```sh\nplugins=(... kimi-cli)\n```\n\nAfter restarting Zsh, you can switch to agent mode by pressing `Ctrl-X`.\n\n### ACP support\n\nKimi CLI supports [Agent Client Protocol] out of the box. You can use it together with any ACP-compatible editor or IDE.\n\nFor example, to use Kimi CLI with [Zed](https://zed.dev/), add the following configuration to your `~/.config/zed/settings.json`:\n\n```json\n{\n  \"agent_servers\": {\n    \"Kimi CLI\": {\n      \"command\": \"kimi\",\n      \"args\": [\"--acp\"],\n      \"env\": {}\n    }\n  }\n}\n```\n\nThen you can create Kimi CLI threads in Zed's agent panel.\n\n### Using MCP tools\n\nKimi CLI supports the well-established MCP config convention. For example:\n\n```json\n{\n  \"mcpServers\": {\n    \"context7\": {\n      \"url\": \"https://mcp.context7.com/mcp\",\n      \"headers\": {\n        \"CONTEXT7_API_KEY\": \"YOUR_API_KEY\"\n      }\n    },\n    \"chrome-devtools\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"chrome-devtools-mcp@latest\"]\n    }\n  }\n}\n```\n\nRun `kimi` with `--mcp-config-file` option to connect to the specified MCP servers:\n\n```sh\nkimi --mcp-config-file /path/to/mcp.json\n```\n\n## Development\n\nTo develop Kimi CLI, run:\n\n```sh\ngit clone https://github.com/MoonshotAI/kimi-cli.git\ncd kimi-cli\n\nmake prepare  # prepare the development environment\n```\n\nThen you can start working on Kimi CLI.\n\nRefer to the following commands after you make changes:\n\n```sh\nuv run kimi  # run Kimi CLI\n\nmake format  # format code\nmake check  # run linting and type checking\nmake test  # run tests\nmake help  # show all make targets\n```\n\n## Contributing\n\nWe welcome contributions to Kimi CLI! Please refer to [CONTRIBUTING.md](./CONTRIBUTING.md) for more information.\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-08T02:20:52.553065"
  },
  {
    "basic_info": {
      "name": "react-native-godot",
      "full_name": "borndotcom/react-native-godot",
      "owner": "borndotcom",
      "description": "React Native Godot - Embed Godot Engine in React Native apps",
      "url": "https://github.com/borndotcom/react-native-godot",
      "clone_url": "https://github.com/borndotcom/react-native-godot.git",
      "ssh_url": "git@github.com:borndotcom/react-native-godot.git",
      "homepage": "",
      "created_at": "2025-11-01T10:54:51Z",
      "updated_at": "2025-11-08T01:41:38Z",
      "pushed_at": "2025-11-07T13:56:23Z"
    },
    "stats": {
      "stars": 2231,
      "forks": 91,
      "watchers": 2231,
      "open_issues": 3,
      "size": 43456
    },
    "tech_info": {
      "language": "C++",
      "languages": {
        "C++": 96704,
        "Objective-C++": 44758,
        "TypeScript": 31195,
        "Java": 29411,
        "JavaScript": 13042,
        "C": 6699,
        "Ruby": 4547,
        "Objective-C": 4216,
        "Python": 4120,
        "Shell": 3800,
        "GDScript": 3456,
        "Kotlin": 2881,
        "CMake": 2267,
        "Swift": 1232
      },
      "license": "MIT License",
      "topics": [
        "android",
        "godot",
        "godot-engine",
        "ios",
        "react-native"
      ]
    },
    "content": {
      "readme": "![Cover-21](https://github.com/user-attachments/assets/770e4972-84f7-433e-87db-6391601256ba)\nBorn React Native Godot\n-----------------------\n\nReact Native Godot allows embedding the Godot Engine into React Native applications.\n\nBorn React Native Godot was created by [Born](https://born.com) and developed by [Migeran](https://migeran.com), in close collaboration between the two teams.\n\n# Main Features\n\n* Supports Android and iOS, built on [LibGodot](https://github.com/migeran/libgodot).\n* Stable implementation serving millions of users in [Born](https://born.com)'s applications.\n* Supports starting, stopping and restarting the Godot Engine. [(docs)](#initialize-the-godot-instance)\n* When restarting, the engine can be reconfigured, so a different Godot app may be loaded each time. [(docs)](#stop-the-godot-instance)\n* It is also possible to pause and resume the running Godot instance. [(docs)](#pause-the-godot-instance)\n* Godot is running on a separate thread, so it does not affect the main thread of the application nor the React Native JavaScript thread. [(docs)](#threading-and-javascript-in-react-native)\n* The Godot main window and any subwindows created by the Godot app may be embedded into the React Native application either on the same screen, or on separate screens (see [example app](example/)).\n* The whole Godot API is accessible from TypeScript / JavaScript. It is possible to instantiate objects, call methods, get and set properties, attach JS functions to signals, provide JS functions as callables to Godot methods ... etc. [(docs)](#godot-api-usage)\n\n<p align=\"center\">\n  <video src=\"https://github.com/user-attachments/assets/33266f05-d733-4c1d-ab49-edaaf426e3e1\" width=\"600\" controls></video>\n</p>\n\n# Getting Started with the Example App\n\nThe [example app](example/) shows the main features of React Native Godot in action.\n\n## Install Prerequisites\n\nDuring development we use [ASDF](https://asdf-vm.com/) to manage most external dependencies required for React Native development, like Node, Java, Gradle or Ruby. If you also use ASDF, just run:\n\n```sh\nasdf install\n```\n    \nThis will make sure that all the dependencies are the same like in our environment. Otherwise you may also install React Native prerequisites using any other method.\n\n## Export the Godot app\n\nRun the following scripts for either platform you plan to test (or both):\n\n```sh\ncd example\n./export_godot_GodotTest.sh android\n./export_godot_GodotTest.sh ios\n./export_godot_GodotTest2.sh android\n./export_godot_GodotTest2.sh ios\n```\n\nThe script is configured to look for Godot in the standard system wide installation folder on macOS. If your Godot is installed elsewhere, or you are on Linux, just point the `GODOT_EDITOR`\nenvironment variable to your Godot editor prior to running the above scripts:\n\n```sh\nexport GODOT_EDITOR=/path/to/godot_editor\n```\n\n## Configure and download LibGodot\n\n```sh\ncd example\nyarn\nyarn download-prebuilt\n```\n\nThese commands will resolve all the React Native and other dependencies from npm. The second one will download the prebuilt LibGodot release from GitHub.\n\n## Run on the iOS Simulator\n\n```sh\ncd example/ios\nbundle install\nbundle exec pod install\ncd ..\nyarn ios\n```\n\n## Run on the Android Emulator\n\n```sh\ncd example\nyarn android\n```\n\n## Use your native IDEs\n\nYou may use Xcode and Android Studio the same way as with any other project. Just open:\n\n* ``ios/GodotTest.xcworkspace`` from Xcode\n* ``android`` from Android Studio\n\n> [!note]\n> If you are using ASDF to manage your Java and Node dependencies, you should start Android Studio from under the `react-native-godot` (or `example`) folder, so it can find these tools. For example on macOS:\n\n```sh\ncd example\nopen -a \"Android Studio\"\n```\n\n## Convenience script for dependency management\n\nThere is an `update_deps.sh` script included in the example app's folder. It will execute all the setup commands for both iOS and Android in one step, so you may start your work immediately.\n\n```sh\ncd example\n./update_deps.sh\nyarn ios # or yarn android\n```\n\n# Your first React Native Godot App\n\nBorn React Native Godot is distributed on npm.\n\nJust follow these steps to add it to your React Native application:\n\n## Update `package.json`\n\n```sh\nyarn add @borndotcom/react-native-godot\n```\n\n## Download the prebuilt LibGodot packages\n\nThe LibGodot packages used by React Native Godot are not distributed on npm. Instead, they are downloaded separately by issuing the following command:\n\n```sh\nyarn download-prebuilt\n```\n\nThis way React Native Godot can be updated independently from LibGodot, and also local, customized builds of LibGodot are supported.\n\n## Import React Native Godot in your App code\n\n```typescript\nimport { RTNGodot, RTNGodotView, runOnGodotThread } from \"@borndotcom/react-native-godot\";\n```\n\n## Add the Godot View to your view, e.g.\n\n```tsx\nconst App = () => {\n  return (\n    <View>\n      <RTNGodotView style={...}/>\n    </View>\n  );\n};\n```\n\nIf no `windowName` property is specified, that view is fo",
      "default_branch": "master"
    },
    "fetched_at": "2025-11-08T02:20:53.670554"
  },
  {
    "basic_info": {
      "name": "awesome-claude-skills",
      "full_name": "BehiSecc/awesome-claude-skills",
      "owner": "BehiSecc",
      "description": "A curated list of Claude Skills.",
      "url": "https://github.com/BehiSecc/awesome-claude-skills",
      "clone_url": "https://github.com/BehiSecc/awesome-claude-skills.git",
      "ssh_url": "git@github.com:BehiSecc/awesome-claude-skills.git",
      "homepage": null,
      "created_at": "2025-10-17T15:05:35Z",
      "updated_at": "2025-11-08T01:45:21Z",
      "pushed_at": "2025-11-07T05:39:43Z"
    },
    "stats": {
      "stars": 2015,
      "forks": 140,
      "watchers": 2015,
      "open_issues": 1,
      "size": 34
    },
    "tech_info": {
      "language": null,
      "languages": {},
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# Awesome Claude Skills\n\n## üìö Table of Contents  \n- [Document Skills](#-document-skills)  \n- [Development & Code Tools](#-development--code-tools)  \n- [Data & Analysis](#-data--analysis)  \n- [Scientific & Research Tools](#-scientific--research-tools)  \n- [Writing & Research](#-writing--research)  \n- [Learning & Knowledge](#-learning--knowledge)  \n- [Media & Content](#-media--content)  \n- [Collaboration & Project Management](#-collaboration--project-management)  \n- [Security & Web Testing](#-security--web-testing)  \n- [Utility & Automation](#-utility--automation)\n\n\n\n## üìÑ Document Skills  \n- [docx](https://github.com/anthropics/skills/tree/main/document-skills/docx) - Create, edit, analyze Word docs with tracked changes, comments, formatting.  \n- [pdf](https://github.com/anthropics/skills/tree/main/document-skills/pdf) - Extract text, tables, metadata, merge & annotate PDFs.  \n- [pptx](https://github.com/anthropics/skills/tree/main/document-skills/pptx) - Read, generate, and adjust slides, layouts, templates.  \n- [xlsx](https://github.com/anthropics/skills/tree/main/document-skills/xlsx) - Spreadsheet manipulation: formulas, charts, data transformations.  \n\n\n\n## üõ† Development & Code Tools\n- [artifacts-builder](https://github.com/anthropics/skills/tree/main/artifacts-builder) - Suite of tools for creating elaborate, multi-component claude.ai HTML artifacts using modern frontend web technologies (React, Tailwind CSS, shadcn/ui).\n- [test-driven-development](https://github.com/obra/superpowers/tree/main/skills/test-driven-development) - Use when implementing any feature or bugfix, before writing implementation code\n- [using-git-worktrees](https://github.com/obra/superpowers/blob/main/skills/using-git-worktrees/) - Creates isolated git worktrees with smart directory selection and safety verification.\n- [finishing-a-development-branch](https://github.com/obra/superpowers/tree/main/skills/finishing-a-development-branch) - Guides completion of development work by presenting clear options and handling chosen workflow.\n- [pypict-claude-skill](https://github.com/omkamal/pypict-claude-skill) - Design comprehensive test cases using PICT (Pairwise Independent Combinatorial Testing) for requirements or code, generating optimized test suites with pairwise coverage.\n- [aws-skills](https://github.com/zxkane/aws-skills) - AWS development with CDK best practices, cost optimization MCP servers, and serverless/event-driven architecture patterns.\n- [move-code-quality-skill](https://github.com/1NickPappas/move-code-quality-skill) - Analyzes Move language packages against the official Move Book Code Quality Checklist for Move 2024 Edition compliance and best practices.\n\n\n\n## üìä Data & Analysis  \n- [root-cause-tracing](https://github.com/obra/superpowers/tree/main/skills/root-cause-tracing) - Use when errors occur deep in execution and you need to trace back to find the original trigger \n- [csv-data-summarizer-claude-skill](https://github.com/coffeefuelbump/csv-data-summarizer-claude-skill) - Automatically analyzes CSVs: columns, distributions, missing data, correlations.\n\n\n\n## üî¨ Scientific & Research Tools\n- [scientific-databases](https://github.com/K-Dense-AI/claude-scientific-skills/tree/main/scientific-databases) - Access to 26 scientific databases including PubMed, PubChem, UniProt, ChEMBL, and AlphaFold DB.\n- [scientific-integrations](https://github.com/K-Dense-AI/claude-scientific-skills/tree/main/scientific-integrations) - Platform integrations for lab automation and workflow management (Benchling, DNAnexus, Opentrons, and more).\n- [scientific-packages](https://github.com/K-Dense-AI/claude-scientific-skills/tree/main/scientific-packages) - 58 specialized Python packages for bioinformatics, cheminformatics, machine learning, and data analysis.\n- [scientific-thinking](https://github.com/K-Dense-AI/claude-scientific-skills/tree/main/scientific-thinking) - Analysis tools and document processing for scientific writing, visualization, and methodology.\n\n\n\n## ‚úçÔ∏è Writing & Research  \n- [article-extractor](https://github.com/michalparkola/tapestry-skills-for-claude-code/tree/main/article-extractor) - Extract full article text and metadata from web pages.\n- [content-research-writer](https://github.com/ComposioHQ/awesome-claude-skills/tree/master/content-research-writer) - Assists in writing high-quality content by conducting research, adding citations, improving hooks, iterating on outlines, and providing real-time feedback on each section\n-  [internal-comms](https://github.com/anthropics/skills/tree/main/internal-comms) - Create internal communications\t(status reports, leadership updates, etc)\n- [brainstorming](https://github.com/obra/superpowers/tree/main/skills/brainstorming) - Transform rough ideas into fully-formed designs through structured questioning and alternative exploration.\n- [family-history-research](https://github.com/emaynard/claude-family-history-research-skill) - Provides assistance with planning family history and genea",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-08T02:20:54.787199"
  },
  {
    "basic_info": {
      "name": "open-agent-builder",
      "full_name": "firecrawl/open-agent-builder",
      "owner": "firecrawl",
      "description": "üî• Visual workflow builder for AI agents powered by Firecrawl - drag-and-drop web scraping pipelines with real-time execution",
      "url": "https://github.com/firecrawl/open-agent-builder",
      "clone_url": "https://github.com/firecrawl/open-agent-builder.git",
      "ssh_url": "git@github.com:firecrawl/open-agent-builder.git",
      "homepage": null,
      "created_at": "2025-10-16T15:34:46Z",
      "updated_at": "2025-11-07T23:14:39Z",
      "pushed_at": "2025-10-20T15:15:47Z"
    },
    "stats": {
      "stars": 1823,
      "forks": 317,
      "watchers": 1823,
      "open_issues": 9,
      "size": 1104
    },
    "tech_info": {
      "language": "TypeScript",
      "languages": {
        "TypeScript": 1583973,
        "CSS": 48176,
        "JavaScript": 4757
      },
      "license": null,
      "topics": []
    },
    "content": {
      "readme": "# Open Agent Builder\n\n<p align=\"center\">\n  <img src=\"https://media4.giphy.com/media/v1.Y2lkPTc5MGI3NjExcGNoY25xY2ptZTZtcDN6czBmdXJ2dnpkdWVjcXlqNXNhdjgyZXpkaiZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/tWtopK29eXAbvaDpi5/giphy.gif\" alt=\"Demo\" width=\"100%\" />\n</p>\n\n<div align=\"center\">\n\n**Build, test, and deploy AI agent workflows with a visual no-code interface**\n\n[![MIT License](https://img.shields.io/badge/License-MIT-green.svg)](https://choosealicense.com/licenses/mit/)\n[![Firecrawl](https://img.shields.io/badge/Powered%20by-Firecrawl-orange)](https://firecrawl.dev)\n\n[Documentation](#documentation) ‚Ä¢ [Examples](#example-workflows)\n\n</div>\n\n---\n\n## What is Open Agent Builder?\n\nOpen Agent Builder is a visual workflow builder for creating AI agent pipelines powered by [Firecrawl](https://firecrawl.dev). Design complex agent workflows with a drag-and-drop interface, then execute them with real-time streaming updates.\n\n**Perfect for:**\n- Web scraping and data extraction workflows\n- Multi-step AI agent pipelines\n- Automated research and content generation\n- Data transformation and analysis\n- Web automation with human-in-the-loop approvals\n\n> **Note:** This project is actively under development. Some features are still in progress and we welcome contributions and PRs!\n\n---\n\n## Key Features\n\n### Visual Workflow Builder\n- **Drag-and-drop interface** for building agent workflows\n- **Real-time execution** with streaming updates\n- **8 core node types**: Start, Agent, MCP Tools, Transform, If/Else, While Loop, User Approval, End\n- **Template library** with pre-built workflows\n- **MCP protocol support** for extensible tool integration\n\n### Powered by Firecrawl\n- **Native Firecrawl integration** for web scraping and searching\n\n### Enterprise Features\n- **LangGraph execution engine** for reliable state management\n- **Clerk authentication** for secure multi-user access\n- **Convex database** for persistent storage\n- **API endpoints** for programmatic execution\n- **Human-in-the-loop** approvals for sensitive operations\n\n---\n\n## Tech Stack\n\n| Technology | Purpose |\n|-----------|---------|\n| **[Firecrawl](https://firecrawl.dev)** | Web scraping API for converting websites into LLM-ready data |\n| **[Next.js 16 (canary)](https://nextjs.org/)** | React framework with App Router for frontend and API routes |\n| **[TypeScript](https://www.typescriptlang.org/)** | Type-safe development across the stack |\n| **[LangGraph](https://github.com/langchain-ai/langgraph)** | Workflow orchestration engine with state management, conditional routing, and human-in-the-loop support |\n| **[Convex](https://convex.dev)** | Real-time database with automatic reactivity for workflows, executions, and user data |\n| **[Clerk](https://clerk.com)** | Authentication and user management with JWT integration |\n| **[Tailwind CSS](https://tailwindcss.com/)** | Utility-first CSS framework for responsive UI |\n| **[React Flow](https://reactflow.dev/)** | Visual workflow builder canvas with drag-and-drop nodes |\n| **[Anthropic](https://www.anthropic.com/)** | Claude AI integration with native MCP support (Claude Haiku 4.5 & Sonnet 4.5) |\n| **[OpenAI](https://platform.openai.com/)** | gpt-5 integration (MCP support coming soon) |\n| **[Groq](https://groq.com/)** | Fast inference for open models (MCP support coming soon) |\n| **[E2B](https://e2b.dev)** | Sandboxed code execution for secure transform nodes |\n| **[Vercel](https://vercel.com)** | Deployment platform with edge functions |\n\n---\n\n## Prerequisites\n\nBefore you begin, you'll need:\n\n1. **Node.js 18+** installed on your machine\n2. **Firecrawl API key** (Required for web scraping) - [Get one here](https://firecrawl.dev)\n3. **Convex account** - [Sign up free](https://convex.dev)\n4. **Clerk account** - [Sign up free](https://clerk.com)\n\n> **Note:** LLM API keys can be added directly in the UI via Settings ‚Üí API Keys after setup. For MCP tool support, Anthropic Claude (Haiku 4.5 or Sonnet 4.5) is currently recommended as the default option.\n\n---\n\n## Installation & Setup\n\n### 1. Clone the Repository\n\n```bash\ngit clone https://github.com/firecrawl/open-agent-builder.git\ncd open-agent-builder\nnpm install\n```\n\n### 2. Set Up Convex (Database)\n\nConvex handles all workflow and execution data persistence.\n\n```bash\n# Install Convex CLI globally\nnpm install -g convex\n\n# Initialize Convex project\nnpx convex dev\n```\n\nThis will:\n- Open your browser to create/link a Convex project\n- Generate a `NEXT_PUBLIC_CONVEX_URL` in your `.env.local`\n- Start the Convex development server\n\nKeep the Convex dev server running in a separate terminal.\n\n### 3. Set Up Clerk (Authentication)\n\nClerk provides secure user authentication and management.\n\n1. Go to [clerk.com](https://clerk.com) and create a new application\n2. In your Clerk dashboard:\n   - Go to **API Keys**\n   - Copy your keys\n3. Go to **JWT Templates** ‚Üí **Convex**:\n   - Click \"Apply\"\n   - Copy the issuer URL\n\nAdd to your `.env.local`:\n\n```bash\n# Clerk Authentication\nNEXT_PUBLIC_CLERK_PUBLI",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-08T02:20:55.940319"
  },
  {
    "basic_info": {
      "name": "OpenMemory",
      "full_name": "CaviraOSS/OpenMemory",
      "owner": "CaviraOSS",
      "description": "Add long-term memory to any AI in minutes. Self-hosted, open, and framework-free.",
      "url": "https://github.com/CaviraOSS/OpenMemory",
      "clone_url": "https://github.com/CaviraOSS/OpenMemory.git",
      "ssh_url": "git@github.com:CaviraOSS/OpenMemory.git",
      "homepage": "https://openmemory.cavira.app",
      "created_at": "2025-10-19T16:12:49Z",
      "updated_at": "2025-11-08T01:52:17Z",
      "pushed_at": "2025-11-07T14:43:59Z"
    },
    "stats": {
      "stars": 1728,
      "forks": 172,
      "watchers": 1728,
      "open_issues": 0,
      "size": 908
    },
    "tech_info": {
      "language": "TypeScript",
      "languages": {
        "TypeScript": 444311,
        "JavaScript": 78265,
        "Python": 31947,
        "Makefile": 5382,
        "Dockerfile": 2118,
        "CSS": 1533
      },
      "license": "MIT License",
      "topics": [
        "ai",
        "ai-agents",
        "ai-infrastructure",
        "ai-memory",
        "artificial-intelligence",
        "cognitive-architecture",
        "embeddings",
        "gemini",
        "llm",
        "long-term-memory",
        "memory",
        "memory-engine",
        "memory-retrieval",
        "ollama",
        "openai",
        "openmemory",
        "rag",
        "supermemory",
        "vector-database"
      ]
    },
    "content": {
      "readme": "<img width=\"1577\" height=\"781\" alt=\"image\" src=\"https://github.com/user-attachments/assets/3baada32-1111-4c2c-bf13-558f2034e511\" />\n\n# OpenMemory\n\nLong-term memory for AI systems. Open source, self-hosted, and explainable.\n\n‚ö†Ô∏è **Upgrading from v1.1?** Multi-user tenant support requires database migration. See [MIGRATION.md](./MIGRATION.md) for upgrade instructions.\n\n[VS Code Extension](https://marketplace.visualstudio.com/items?itemName=Nullure.openmemory-vscode) ‚Ä¢ [Report Bug](https://github.com/caviraOSS/openmemory/issues) ‚Ä¢ [Request Feature](https://github.com/caviraOSS/openmemor/issues) ‚Ä¢ [Discord server](https://discord.gg/P7HaRayqTh)\n\n---\n\n## 1. Overview\n\nOpenMemory gives AI systems persistent memory. It stores what matters, recalls it when needed, and explains why it matters.\n\nUnlike traditional vector databases, OpenMemory uses a cognitive architecture. It organizes memories by type (semantic, episodic, procedural, emotional, reflective), tracks importance over time, and builds associations between related memories.\n\n### Key Features\n\n- **Multi-sector memory** - Different memory types for different content\n- **Automatic decay** - Memories fade naturally unless reinforced\n- **Graph associations** - Memories link to related memories\n- **Pattern recognition** - Finds and consolidates similar memories\n- **User isolation** - Each user gets separate memory space\n- **Local or cloud** - Run with your own embeddings or use OpenAI/Gemini\n- **Framework agnostic** - Works with any LLM or agent system\n\n### VS Code Extension\n\nThe OpenMemory extension tracks your coding activity and gives AI assistants access to your project history.\n\n**[Get it on VS Code Marketplace](https://marketplace.visualstudio.com/items?itemName=Nullure.openmemory-vscode)**\n\nWorks with GitHub Copilot, Cursor, Claude Desktop, Windsurf, and any MCP-compatible AI.\n\nFeatures:\n\n- Tracks file edits, saves, and opens\n- Compresses context to reduce token usage by 30-70%\n- Query responses under 80ms\n- Supports Direct HTTP and MCP protocol modes\n- Zero configuration required\n\n### Architecture\n\nOpenMemory uses Hierarchical Memory Decomposition (HMD):\n\n- One canonical node per memory (no duplication)\n- Multiple embeddings per memory (one per sector)\n- Single-waypoint linking between memories\n- Composite similarity scoring across sectors\n\nThis approach improves recall accuracy while reducing costs.\n\n---\n\n## 2. Competitor Comparison\n\n| **Feature / Metric**                     | **OpenMemory (Our Tests ‚Äì Nov 2025)**                       | **Zep (Their Benchmarks)**         | **Supermemory (Their Docs)**    | **Mem0 (Their Tests)**        | **OpenAI Memory**          | **LangChain Memory**        | **Vector DBs (Chroma / Weaviate / Pinecone)** |\n| ---------------------------------------- | ----------------------------------------------------------- | ---------------------------------- | ------------------------------- | ----------------------------- | -------------------------- | --------------------------- | --------------------------------------------- |\n| **Open-source License**                  | ‚úÖ MIT (verified)                                           | ‚úÖ Apache 2.0                      | ‚úÖ Source available (GPL-like)  | ‚úÖ Apache 2.0                 | ‚ùå Closed                  | ‚úÖ Apache 2.0               | ‚úÖ Varies (OSS + Cloud)                       |\n| **Self-hosted / Local**                  | ‚úÖ Full (Local / Docker / MCP) tested ‚úì                     | ‚úÖ Local + Cloud SDK               | ‚ö†Ô∏è Mostly managed cloud tier    | ‚úÖ Self-hosted ‚úì              | ‚ùå No                      | ‚úÖ Yes (in your stack)      | ‚úÖ Chroma / Weaviate ‚ùå Pinecone (cloud)      |\n| **Per-user namespacing (`user_id`)**     | ‚úÖ Built-in (`user_id` linking added)                       | ‚úÖ Sessions / Users API            | ‚ö†Ô∏è Multi-tenant via API key     | ‚úÖ Explicit `user_id` field ‚úì | ‚ùå Internal only           | ‚úÖ Namespaces via LangGraph | ‚úÖ Collection-per-user schema                 |\n| **Architecture**                         | HSG v3 (Hierarchical Semantic Graph + Decay + Coactivation) | Flat embeddings + Postgres + FAISS | Graph + Embeddings              | Flat vector store             | Proprietary cache          | Context memory utils        | Vector index (ANN)                            |\n| **Avg Response Time (100k nodes)**       | **115 ms avg (measured)**                                   | 310 ms (docs)                      | 200‚Äì340 ms (on-prem/cloud)      | ~250 ms                       | 300 ms (observed)          | 200 ms (avg)                | 160 ms (avg)                                  |\n| **Throughput (QPS)**                     | **338 QPS avg (8 workers, P95 103 ms)** ‚úì                   | ~180 QPS (reported)                | ~220 QPS (on-prem)              | ~150 QPS                      | ~180 QPS                   | ~140 QPS                    | ~250 QPS typical                              |\n| **Recall @5 (Accuracy)**                 | **95 % re",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-08T02:20:57.109129"
  },
  {
    "basic_info": {
      "name": "awesome-claude-skills",
      "full_name": "travisvn/awesome-claude-skills",
      "owner": "travisvn",
      "description": "A curated list of awesome Claude Skills, resources, and tools for customizing Claude AI workflows ‚Äî particularly Claude Code",
      "url": "https://github.com/travisvn/awesome-claude-skills",
      "clone_url": "https://github.com/travisvn/awesome-claude-skills.git",
      "ssh_url": "git@github.com:travisvn/awesome-claude-skills.git",
      "homepage": "",
      "created_at": "2025-10-16T20:42:39Z",
      "updated_at": "2025-11-08T01:54:09Z",
      "pushed_at": "2025-10-29T00:38:27Z"
    },
    "stats": {
      "stars": 1719,
      "forks": 102,
      "watchers": 1719,
      "open_issues": 2,
      "size": 143
    },
    "tech_info": {
      "language": null,
      "languages": {},
      "license": null,
      "topics": [
        "agentic-coding",
        "anthropic",
        "awesome",
        "awesome-list",
        "awesome-lists",
        "claude",
        "claude-ai",
        "claude-code",
        "claude-desktop",
        "claude-skills",
        "claudeskills"
      ]
    },
    "content": {
      "readme": "<p align=\"center\">\n  <a href=\"https://github.com/travisvn/awesome-claude-skills\">\n    <img alt=\"Awesome Claude Skills\" src=\"https://pc0o4oduww.ufs.sh/f/crfz5GypRfo0lI4924gMSJKLY6297aVP0zZpilXBvqTbDyrs\"/>\n  </a>\n</p>\n\n# Awesome Claude Skills\n\n[![Awesome](https://awesome.re/badge.svg)](https://awesome.re)\n[![Last Updated](https://img.shields.io/badge/updated-Oct%202025-green.svg)]()\n[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](CONTRIBUTING.md)\n[![License](https://img.shields.io/badge/license-CC0--1.0-blue.svg)](LICENSE)\n\n> A curated list of awesome Claude Skills, resources, and tools for customizing Claude AI workflows\n\n**Claude Skills** teach Claude how to **perform tasks in a repeatable way**\n\nThey are specialized folders containing instructions, scripts, and resources.\n\n## üöÄ Quick Start\n\n### Claude Code\n\n```bash\n/plugin marketplace add anthropics/skills\n```\n\n### Claude Desktop\n\n[Enable Skills here](https://claude.ai/settings/capabilities)\n\n## üõ†Ô∏è Installation & Setup\n\n### Claude.ai Web Interface\n\n1. Go to [Settings > Capabilities](https://claude.ai/settings/capabilities)\n2. Enable Skills toggle\n3. Browse available skills or upload custom skills\n4. **For Team/Enterprise**: Admin must enable Skills organization-wide first\n\n### Claude Code CLI\n\n```bash\n# Install skills from marketplace\n/plugin marketplace add anthropics/skills\n\n# Or install from local directory\n/plugin add /path/to/skill-directory\n```\n\n### Claude API\n\nSkills are accessible via the `/v1/skills` API endpoint. See the [Skills API documentation](https://docs.claude.com/en/api/skills) for detailed integration examples.\n\n```python\nimport anthropic\n\nclient = anthropic.Client(api_key=\"your-api-key\")\n# See API docs for full implementation details\n```\n\n## üéØ Official Skills\n\n### Document Skills\n\nSkills for working with complex file formats:\n\n- **[docx](https://github.com/anthropics/skills/tree/main/document-skills/docx)** - Create, edit, and analyze Word documents with support for tracked changes, comments, formatting preservation, and text extraction\n- **[pdf](https://github.com/anthropics/skills/tree/main/document-skills/pdf)** - Comprehensive PDF manipulation toolkit for extracting text and tables, creating new PDFs, merging/splitting documents, and handling forms\n- **[pptx](https://github.com/anthropics/skills/tree/main/document-skills/pptx)** - Create, edit, and analyze PowerPoint presentations with support for layouts, templates, charts, and automated slide generation\n- **[xlsx](https://github.com/anthropics/skills/tree/main/document-skills/xlsx)** - Create, edit, and analyze Excel spreadsheets with support for formulas, formatting, data analysis, and visualization\n\n### Design & Creative\n\n- **[algorithmic-art](https://github.com/anthropics/skills/tree/main/algorithmic-art)** - Create generative art using p5.js with seeded randomness, flow fields, and particle systems\n- **[canvas-design](https://github.com/anthropics/skills/tree/main/canvas-design)** - Design beautiful visual art in .png and .pdf formats using design philosophies\n- **[slack-gif-creator](https://github.com/anthropics/skills/tree/main/slack-gif-creator)** - Create animated GIFs optimized for Slack's size constraints\n\n### Development\n\n- **[artifacts-builder](https://github.com/anthropics/skills/tree/main/artifacts-builder)** - Build complex claude.ai HTML artifacts using React, Tailwind CSS, and shadcn/ui components\n- **[mcp-builder](https://github.com/anthropics/skills/tree/main/mcp-builder)** - Guide for creating high-quality MCP servers to integrate external APIs and services\n- **[webapp-testing](https://github.com/anthropics/skills/tree/main/webapp-testing)** - Test local web applications using Playwright for UI verification and debugging\n\n### Communication\n\n- **[brand-guidelines](https://github.com/anthropics/skills/tree/main/brand-guidelines)** - Apply Anthropic's official brand colors and typography to artifacts\n- **[internal-comms](https://github.com/anthropics/skills/tree/main/internal-comms)** - Write internal communications like status reports, newsletters, and FAQs\n\n### Skill Creation\n\n- **[skill-creator](https://github.com/anthropics/skills/tree/main/skill-creator)** - Interactive skill creation tool that guides you through building new skills with Q&A\n\n## üåü Community Skills\n\n> [!Warning]\n> Skills can execute arbitrary code in Claude's environment.\n> \n> See [Security & Best Practices](#-security--best-practices) for more information\n\n### Collections & Libraries\n\n- **[obra/superpowers](https://github.com/obra/superpowers)** - Core skills library for Claude Code with 20+ battle-tested skills including TDD, debugging, and collaboration patterns\n  - Features `/brainstorm`, `/write-plan`, `/execute-plan` commands and skills-search tool\n  - [superpowers-skills](https://github.com/obra/superpowers-skills) - Community-editable skills repository\n  - [Blog: Superpowers](https://blog.fsck.com/2025/10/09/superpowers/) - Author's overview by Jesse Vincent\n",
      "default_branch": "main"
    },
    "fetched_at": "2025-11-08T02:20:58.247888"
  }
]